setup: context limit of 128k tokens
model: gpt-4o
temp: 0.5
approach: give llm all the methods in the class and ask it to sort.
Llm seems to pick order all the methods without deleting any.