{"id":"e4ab2c4e-49a6-47f7-aa72-67582bc32c59","methodCount":12,"hostFunctionTelemetryData":{"hostFunctionSize":130,"lineStart":472,"lineEnd":601,"bodyLineStart":472,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java","sourceCode":"public record ShardSnapshotStatus(\n        @Nullable String nodeId,\n        ShardState state,\n        @Nullable ShardGeneration generation,\n        @Nullable String reason,\n        @Nullable // only present in state SUCCESS; may be null even in SUCCESS if this state came over the wire from an older node\n        ShardSnapshotResult shardSnapshotResult\n    ) implements Writeable {\n\n        /**\n         * Shard snapshot status for shards that are waiting for another operation to finish before they can be assigned to a node.\n         */\n        public static final ShardSnapshotStatus UNASSIGNED_QUEUED \u003d new SnapshotsInProgress.ShardSnapshotStatus(\n            null,\n            ShardState.QUEUED,\n            null\n        );\n\n        /**\n         * Shard snapshot status for shards that could not be snapshotted because their index was deleted from before the shard snapshot\n         * started.\n         */\n        public static final ShardSnapshotStatus MISSING \u003d new SnapshotsInProgress.ShardSnapshotStatus(\n            null,\n            ShardState.MISSING,\n            null,\n            \"missing index\"\n        );\n\n        public ShardSnapshotStatus(String nodeId, ShardGeneration generation) {\n            this(nodeId, ShardState.INIT, generation);\n        }\n\n        public ShardSnapshotStatus(@Nullable String nodeId, ShardState state, @Nullable ShardGeneration generation) {\n            this(nodeId, assertNotSuccess(state), generation, null);\n        }\n\n        @SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public ShardSnapshotStatus(@Nullable String nodeId, ShardState state, @Nullable ShardGeneration generation, String reason) {\n            this(nodeId, assertNotSuccess(state), generation, reason, null);\n        }\n\n        private static ShardState assertNotSuccess(ShardState shardState) {\n            assert shardState !\u003d ShardState.SUCCESS : \"use ShardSnapshotStatus#success\";\n            return shardState;\n        }\n\n        @SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static ShardSnapshotStatus success(String nodeId, ShardSnapshotResult shardSnapshotResult) {\n            return new ShardSnapshotStatus(nodeId, ShardState.SUCCESS, shardSnapshotResult.getGeneration(), null, shardSnapshotResult);\n        }\n\n        public ShardSnapshotStatus(\n            @Nullable String nodeId,\n            ShardState state,\n            @Nullable ShardGeneration generation,\n            String reason,\n            @Nullable ShardSnapshotResult shardSnapshotResult\n        ) {\n            this.nodeId \u003d nodeId;\n            this.state \u003d state;\n            this.reason \u003d reason;\n            this.generation \u003d generation;\n            this.shardSnapshotResult \u003d shardSnapshotResult;\n            assert assertConsistent();\n        }\n\n        private boolean assertConsistent() {\n            // If the state is failed we have to have a reason for this failure\n            assert state.failed() \u003d\u003d false || reason !\u003d null;\n            assert (state !\u003d ShardState.INIT \u0026\u0026 state !\u003d ShardState.WAITING) || nodeId !\u003d null : \"Null node id for state [\" + state + \"]\";\n            assert state !\u003d ShardState.QUEUED || (nodeId \u003d\u003d null \u0026\u0026 generation \u003d\u003d null \u0026\u0026 reason \u003d\u003d null)\n                : \"Found unexpected non-null values for queued state shard nodeId[\" + nodeId + \"][\" + generation + \"][\" + reason + \"]\";\n            assert state \u003d\u003d ShardState.SUCCESS || shardSnapshotResult \u003d\u003d null;\n            assert shardSnapshotResult \u003d\u003d null || shardSnapshotResult.getGeneration().equals(generation)\n                : \"generation [\" + generation + \"] does not match result generation [\" + shardSnapshotResult.getGeneration() + \"]\";\n            return true;\n        }\n\n        @SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static ShardSnapshotStatus readFrom(StreamInput in) throws IOException {\n            final String nodeId \u003d DiscoveryNode.deduplicateNodeIdentifier(in.readOptionalString());\n            final ShardState state \u003d ShardState.fromValue(in.readByte());\n            final ShardGeneration generation \u003d in.readOptionalWriteable(ShardGeneration::new);\n            final String reason \u003d in.readOptionalString();\n            final ShardSnapshotResult shardSnapshotResult \u003d in.readOptionalWriteable(ShardSnapshotResult::new);\n            if (state \u003d\u003d ShardState.QUEUED) {\n                return UNASSIGNED_QUEUED;\n            }\n            return new ShardSnapshotStatus(nodeId, state, generation, reason, shardSnapshotResult);\n        }\n\n        @SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public ShardSnapshotStatus withUpdatedGeneration(ShardGeneration newGeneration) {\n            assert state \u003d\u003d ShardState.SUCCESS : \"can\u0027t move generation in state \" + state;\n            return new ShardSnapshotStatus(\n                nodeId,\n                state,\n                newGeneration,\n                reason,\n                shardSnapshotResult \u003d\u003d null\n                    ? null\n                    : new ShardSnapshotResult(newGeneration, shardSnapshotResult.getSize(), shardSnapshotResult.getSegmentCount())\n            );\n        }\n\n        @Nullable\n        public ShardSnapshotResult shardSnapshotResult() {\n            assert state \u003d\u003d ShardState.SUCCESS : \"result is unavailable in state \" + state;\n            return shardSnapshotResult;\n        }\n\n        /**\n         * Checks if this shard snapshot is actively executing.\n         * A shard is defined as actively executing if it either is in a state that may write to the repository\n         * ({@link ShardState#INIT} or {@link ShardState#ABORTED}) or about to write to it in state {@link ShardState#WAITING}.\n         */\n        public boolean isActive() {\n            return state \u003d\u003d ShardState.INIT || state \u003d\u003d ShardState.ABORTED || state \u003d\u003d ShardState.WAITING;\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeOptionalString(nodeId);\n            out.writeByte(state.value);\n            out.writeOptionalWriteable(generation);\n            out.writeOptionalString(reason);\n            out.writeOptionalWriteable(shardSnapshotResult);\n        }\n    }","methodCount":12},"candidatesTelemetryData":{"numberOfSuggestions":7,"candidates":[{"lineStart":518,"lineEnd":521,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method success to class SnapshotsInProgress","description":"move method success to PsiClass:SnapshotsInProgress\nRationale: The success() method creates a ShardSnapshotStatus, which is closely related to the state of snapshots in progress. Moving it to SnapshotsInProgress aligns with the Single Responsibility Principle, as it centralizes snapshot-related status handling. This enhances cohesion, making the class more focused on managing snapshot states. However, care should be taken to ensure that the method\u0027s dependencies on ShardSnapshotResult are appropriately addressed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":518,"lineEnd":521,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method success to class DesiredNodes","description":"move method success to PsiClass:DesiredNodes\nRationale: The method constructs a ShardSnapshotStatus based on nodeId and shardSnapshotResult, which are relevant to the desired nodes\u0027 state in a cluster. Relocating it here would enhance the encapsulation of the logic related to node statuses, adhering to the Open-Closed Principle, as it allows for future extensions related to node status management. A potential drawback is ensuring that DesiredNodes has the necessary context for the shardSnapshotResult.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":518,"lineEnd":521,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method success to class DesiredBalanceShardsAllocator","description":"move method success to PsiClass:DesiredBalanceShardsAllocator\nRationale: The success() method\u0027s purpose is to create a status related to shard snapshots, which is integral to shard allocation decisions. By moving it to DesiredBalanceShardsAllocator, it can better reflect the state of shards during allocation processes, improving the system\u0027s responsiveness to the state of snapshots. This move supports the Interface Segregation Principle by keeping allocation logic separate from unrelated functionalities. However, it may introduce coupling with allocation logic that could complicate future changes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":513,"lineEnd":516,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method assertNotSuccess to class SnapshotsInProgress","description":"move method assertNotSuccess to PsiClass:SnapshotsInProgress\nRationale: The assertNotSuccess() method checks if a ShardState is not successful, which is relevant when dealing with snapshots and their states. Moving this method to SnapshotsInProgress aligns with the Single Responsibility Principle, as it centralizes shard state validation related to snapshots. This enhances cohesion and keeps snapshot management logic in one place. However, it may introduce a dependency on SnapshotsInProgress for other classes that need this validation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":513,"lineEnd":516,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method assertNotSuccess to class DesiredNodesMetadata","description":"move method assertNotSuccess to PsiClass:DesiredNodesMetadata\nRationale: This method is about asserting the state of shards, which is closely related to the desired state of nodes in a cluster. Moving it to DesiredNodesMetadata would enhance the coherence of state management within the cluster. This adheres to the Open/Closed Principle, allowing for future extensions related to shard state handling without modifying existing classes. A potential drawback is that it may increase the size of DesiredNodesMetadata, making it less focused.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":513,"lineEnd":516,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method assertNotSuccess to class DesiredBalanceShardsAllocator","description":"move method assertNotSuccess to PsiClass:DesiredBalanceShardsAllocator\nRationale: The assertNotSuccess() method is concerned with shard states, which directly impact shard allocation decisions. Relocating it here would improve the design by ensuring that shard state validation is part of the allocation logic, thus adhering to the Single Responsibility Principle. This move could also facilitate better shard state management during allocation processes. However, it may tightly couple state validation with allocation logic, which should be evaluated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":538,"lineEnd":548,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertConsistent to class ShardState","description":"Move method assertConsistent to org.elasticsearch.cluster.SnapshotsInProgress.ShardState\nRationale: The assertConsistent() method is primarily concerned with validating the state of a shard, which directly relates to the ShardState class that defines the various states a shard can be in. Moving this method to ShardState aligns with the Single Responsibility Principle, as it encapsulates the logic for state validation within the context of the state itself. This enhances cohesion, as the method operates closely with the attributes and behaviors of ShardState. Additionally, it supports the Open/Closed Principle by allowing future extensions or modifications to state validation without affecting other parts of the code. However, one consideration is that the method may need access to additional context or data from its original class, which could complicate its implementation in ShardState if those dependencies are not properly managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"assertNotSuccess","method_signature":"private static assertNotSuccess(ShardState shardState)","target_class":"","rationale":""},{"method_name":"success","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static success(String nodeId, ShardSnapshotResult shardSnapshotResult)","target_class":"","rationale":""},{"method_name":"assertConsistent","method_signature":"private assertConsistent()","target_class":"","rationale":""},{"method_name":"readFrom","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"withUpdatedGeneration","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public withUpdatedGeneration(ShardGeneration newGeneration)","target_class":"","rationale":""},{"method_name":"shardSnapshotResult","method_signature":"@Nullable\n        public shardSnapshotResult()","target_class":"","rationale":""},{"method_name":"isActive","method_signature":"public isActive()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"success","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static success(String nodeId, ShardSnapshotResult shardSnapshotResult)","target_class":"","rationale":""},{"method_name":"assertNotSuccess","method_signature":"private static assertNotSuccess(ShardState shardState)","target_class":"","rationale":""},{"method_name":"assertConsistent","method_signature":"private assertConsistent()","target_class":"","rationale":""},{"method_name":"isActive","method_signature":"public isActive()","target_class":"","rationale":""},{"method_name":"readFrom","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"shardSnapshotResult","method_signature":"@Nullable\n        public shardSnapshotResult()","target_class":"","rationale":""},{"method_name":"withUpdatedGeneration","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public withUpdatedGeneration(ShardGeneration newGeneration)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static success(String nodeId, ShardSnapshotResult shardSnapshotResult)":{"first":{"method_name":"success","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static success(String nodeId, ShardSnapshotResult shardSnapshotResult)","target_class":"","rationale":""},"second":0.250960414218527},"private static assertNotSuccess(ShardState shardState)":{"first":{"method_name":"assertNotSuccess","method_signature":"private static assertNotSuccess(ShardState shardState)","target_class":"","rationale":""},"second":0.31098520678556146},"private assertConsistent()":{"first":{"method_name":"assertConsistent","method_signature":"private assertConsistent()","target_class":"","rationale":""},"second":0.3165543137865778},"public isActive()":{"first":{"method_name":"isActive","method_signature":"public isActive()","target_class":"","rationale":""},"second":0.41426465200429247},"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static readFrom(StreamInput in)":{"first":{"method_name":"readFrom","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public static readFrom(StreamInput in)","target_class":"","rationale":""},"second":0.4526349987495188},"@Nullable\n        public shardSnapshotResult()":{"first":{"method_name":"shardSnapshotResult","method_signature":"@Nullable\n        public shardSnapshotResult()","target_class":"","rationale":""},"second":0.4973565280219581},"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public withUpdatedGeneration(ShardGeneration newGeneration)":{"first":{"method_name":"withUpdatedGeneration","method_signature":"@SuppressForbidden(reason \u003d \"using a private constructor within the same file\")\n        public withUpdatedGeneration(ShardGeneration newGeneration)","target_class":"","rationale":""},"second":0.5221325306189205}},"llmMethodPriority":{"priority_method_names":["success","assertNotSuccess","assertConsistent","isActive","readFrom","shardSnapshotResult","withUpdatedGeneration"],"llm_response_time":1757},"targetClassMap":{"success":{"target_classes":[{"class_name":"SnapshotsInProgress","similarity_score":0.4412939899664327},{"class_name":"DiffableUtils","similarity_score":0.392945711191961},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.22704744811853877},{"class_name":"DiscoveryNodeUtils","similarity_score":0.4527361806019313},{"class_name":"ClusterChangedEventUtils","similarity_score":0.32710225430843876},{"class_name":"ClusterInfoServiceUtils","similarity_score":0.39360132250266544},{"class_name":"ClusterStateTaskExecutorUtils","similarity_score":0.3359436210504341},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.21528258616218468},{"class_name":"StringSetValueSerializer","similarity_score":0.34010851192571795},{"class_name":"MapperTestUtils","similarity_score":0.328390372402101},{"class_name":"MappingMetadata","similarity_score":0.4261746889704928},{"class_name":"DesiredBalance","similarity_score":0.3640008289559568},{"class_name":"DesiredBalanceComputer","similarity_score":0.3235487241988761},{"class_name":"DesiredBalanceComputerTests","similarity_score":0.3555115690243658},{"class_name":"DesiredBalanceInput","similarity_score":0.24856710151240585},{"class_name":"DesiredBalanceReconcilerTests","similarity_score":0.28454281130025566},{"class_name":"MasterHistory","similarity_score":0.31363369029605015},{"class_name":"MasterHistoryServiceTests","similarity_score":0.2898010400398388},{"class_name":"MasterHistoryTests","similarity_score":0.24830563483032247},{"class_name":"DesiredBalanceShardsAllocator","similarity_score":0.4189760148934986},{"class_name":"DesiredBalanceShardsAllocatorTests","similarity_score":0.36835093042106254},{"class_name":"MasterService","similarity_score":0.42780991378425837},{"class_name":"DesiredBalanceStats","similarity_score":0.2934213817746552},{"class_name":"JwkValidateUtil","similarity_score":0.291552265428287},{"class_name":"DesiredBalanceStatsTests","similarity_score":0.18460947892456775},{"class_name":"DesiredBalanceTests","similarity_score":0.13144933752826846},{"class_name":"JwkValidateUtilTests","similarity_score":0.3311548464750965},{"class_name":"DesiredNode","similarity_score":0.4268730602639386},{"class_name":"DesiredNodes","similarity_score":0.3990724842854515},{"class_name":"DesiredNodeSerializationTests","similarity_score":0.23292936426918648}],"target_classes_sorted_by_llm":["SnapshotsInProgress","DesiredNodes","DesiredBalanceShardsAllocator","MasterService","DiscoveryNodeUtils","ClusterInfoServiceUtils","MappingMetadata","DiffableUtils","DesiredBalanceShardsAllocatorTests","DesiredNode"],"llm_response_time":11339,"similarity_computation_time":70,"similarity_metric":"voyage"},"assertNotSuccess":{"target_classes":[{"class_name":"SnapshotsInProgress","similarity_score":0.3707390516701634},{"class_name":"DiffableUtils","similarity_score":0.33532756321523816},{"class_name":"DiscoveryNodeUtils","similarity_score":0.35519020893817344},{"class_name":"ClusterChangedEventUtils","similarity_score":0.2721655269759087},{"class_name":"ClusterInfoServiceUtils","similarity_score":0.3153666111941774},{"class_name":"ClusterStateTaskExecutorUtils","similarity_score":0.4037539837874613},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.15749237164799298},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.18760298703543868},{"class_name":"StringSetValueSerializer","similarity_score":0.28613169175965075},{"class_name":"AuditUtil","similarity_score":0.3890543579737243},{"class_name":"RestResponseUtils","similarity_score":0.35613814953099693},{"class_name":"FunctionTestUtils","similarity_score":0.36300570155752687},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.18133089162051858},{"class_name":"AuthorizationUtils","similarity_score":0.1438272119751987},{"class_name":"DesiredBalance","similarity_score":0.2939282139782306},{"class_name":"DesiredBalanceComputer","similarity_score":0.2881571073427102},{"class_name":"DesiredBalanceComputerTests","similarity_score":0.17949314700867058},{"class_name":"DesiredBalanceInput","similarity_score":0.08962214298964417},{"class_name":"DesiredBalanceReconcilerTests","similarity_score":0.13846387747731354},{"class_name":"DesiredBalanceShardsAllocator","similarity_score":0.3537848265757988},{"class_name":"DesiredBalanceShardsAllocatorTests","similarity_score":0.20622101496002845},{"class_name":"DesiredBalanceStats","similarity_score":0.31164295982657786},{"class_name":"DesiredBalanceStatsTests","similarity_score":0.2990461914228369},{"class_name":"DesiredBalanceTests","similarity_score":0.07626738588707158},{"class_name":"RestTestUtil","similarity_score":0.21689882684940226},{"class_name":"DesiredNode","similarity_score":0.3879961543070807},{"class_name":"DesiredNodes","similarity_score":0.2986678532381669},{"class_name":"DesiredNodeSerializationTests","similarity_score":0.17729929513602055},{"class_name":"DesiredNodesMetadata","similarity_score":0.36357504732808926},{"class_name":"DesiredNodesMetadataSerializationTests","similarity_score":0.35969874265395435}],"target_classes_sorted_by_llm":["SnapshotsInProgress","DesiredNodesMetadata","DesiredBalanceShardsAllocator","ClusterStateTaskExecutorUtils","DiscoveryNodeUtils","AuditUtil","RestResponseUtils","FunctionTestUtils","DesiredNode","DesiredNodesMetadataSerializationTests"],"llm_response_time":10305,"similarity_computation_time":35,"similarity_metric":"voyage"},"assertConsistent":{"target_classes":[{"class_name":"ShardState","similarity_score":0.1671811274443979}],"target_classes_sorted_by_llm":["ShardState"],"llm_response_time":2129,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"c891738f-ae1d-439a-8917-11db2dc611f8","methodCount":15,"hostFunctionTelemetryData":{"hostFunctionSize":189,"lineStart":22,"lineEnd":210,"bodyLineStart":22,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/test/yaml-rest-runner/src/main/java/org/elasticsearch/test/rest/yaml/section/SkipSection.java","sourceCode":"/**\n * Represents a skip section that tells whether a specific test section or suite needs to be skipped\n * based on:\n * - the elasticsearch version the tests are running against\n * - a specific test feature required that might not be implemented yet by the runner\n * - an operating system (full name, including specific Linux distributions) that might show a certain behavior\n */\npublic class SkipSection {\n    /**\n     * Parse a {@link SkipSection} if the next field is {@code skip}, otherwise returns {@link SkipSection#EMPTY}.\n     */\n    public static SkipSection parseIfNext(XContentParser parser) throws IOException {\n        ParserUtils.advanceToFieldName(parser);\n\n        if (\"skip\".equals(parser.currentName())) {\n            SkipSection section \u003d parse(parser);\n            parser.nextToken();\n            return section;\n        }\n\n        return EMPTY;\n    }\n\n    public static SkipSection parse(XContentParser parser) throws IOException {\n        if (parser.nextToken() !\u003d XContentParser.Token.START_OBJECT) {\n            throw new IllegalArgumentException(\n                \"Expected [\"\n                    + XContentParser.Token.START_OBJECT\n                    + \", found [\"\n                    + parser.currentToken()\n                    + \"], the skip section is not properly indented\"\n            );\n        }\n        String currentFieldName \u003d null;\n        XContentParser.Token token;\n        String version \u003d null;\n        String reason \u003d null;\n        List\u003cString\u003e features \u003d new ArrayList\u003c\u003e();\n        List\u003cString\u003e operatingSystems \u003d new ArrayList\u003c\u003e();\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            if (token \u003d\u003d XContentParser.Token.FIELD_NAME) {\n                currentFieldName \u003d parser.currentName();\n            } else if (token.isValue()) {\n                if (\"version\".equals(currentFieldName)) {\n                    version \u003d parser.text();\n                } else if (\"reason\".equals(currentFieldName)) {\n                    reason \u003d parser.text();\n                } else if (\"features\".equals(currentFieldName)) {\n                    features.add(parser.text());\n                } else if (\"os\".equals(currentFieldName)) {\n                    operatingSystems.add(parser.text());\n                } else {\n                    throw new ParsingException(\n                        parser.getTokenLocation(),\n                        \"field \" + currentFieldName + \" not supported within skip section\"\n                    );\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n                if (\"features\".equals(currentFieldName)) {\n                    while (parser.nextToken() !\u003d XContentParser.Token.END_ARRAY) {\n                        features.add(parser.text());\n                    }\n                } else if (\"os\".equals(currentFieldName)) {\n                    while (parser.nextToken() !\u003d XContentParser.Token.END_ARRAY) {\n                        operatingSystems.add(parser.text());\n                    }\n                }\n            }\n        }\n\n        parser.nextToken();\n\n        if ((Strings.hasLength(version) \u003d\u003d false) \u0026\u0026 features.isEmpty() \u0026\u0026 operatingSystems.isEmpty()) {\n            throw new ParsingException(parser.getTokenLocation(), \"version, features or os is mandatory within skip section\");\n        }\n        if (Strings.hasLength(version) \u0026\u0026 Strings.hasLength(reason) \u003d\u003d false) {\n            throw new ParsingException(parser.getTokenLocation(), \"reason is mandatory within skip version section\");\n        }\n        if (operatingSystems.isEmpty() \u003d\u003d false \u0026\u0026 Strings.hasLength(reason) \u003d\u003d false) {\n            throw new ParsingException(parser.getTokenLocation(), \"reason is mandatory within skip version section\");\n        }\n        // make feature \"skip_os\" mandatory if os is given, this is a temporary solution until language client tests know about os\n        if (operatingSystems.isEmpty() \u003d\u003d false \u0026\u0026 features.contains(\"skip_os\") \u003d\u003d false) {\n            throw new ParsingException(parser.getTokenLocation(), \"if os is specified, feature skip_os must be set\");\n        }\n        return new SkipSection(version, features, operatingSystems, reason);\n    }\n\n    public static final SkipSection EMPTY \u003d new SkipSection();\n\n    private final List\u003cVersionRange\u003e versionRanges;\n    private final List\u003cString\u003e features;\n    private final List\u003cString\u003e operatingSystems;\n    private final String reason;\n\n    private SkipSection() {\n        this.versionRanges \u003d new ArrayList\u003c\u003e();\n        this.features \u003d new ArrayList\u003c\u003e();\n        this.operatingSystems \u003d new ArrayList\u003c\u003e();\n        this.reason \u003d null;\n    }\n\n    public SkipSection(String versionRange, List\u003cString\u003e features, List\u003cString\u003e operatingSystems, String reason) {\n        assert features !\u003d null;\n        this.versionRanges \u003d parseVersionRanges(versionRange);\n        assert versionRanges.isEmpty() \u003d\u003d false;\n        this.features \u003d features;\n        this.operatingSystems \u003d operatingSystems;\n        this.reason \u003d reason;\n    }\n\n    public Version getLowerVersion() {\n        return versionRanges.get(0).lower();\n    }\n\n    public Version getUpperVersion() {\n        return versionRanges.get(versionRanges.size() - 1).upper();\n    }\n\n    public List\u003cString\u003e getFeatures() {\n        return features;\n    }\n\n    public List\u003cString\u003e getOperatingSystems() {\n        return operatingSystems;\n    }\n\n    public String getReason() {\n        return reason;\n    }\n\n    public boolean skip(Version currentVersion) {\n        if (isEmpty()) {\n            return false;\n        }\n        boolean skip \u003d versionRanges.stream().anyMatch(range -\u003e range.contains(currentVersion));\n        return skip || Features.areAllSupported(features) \u003d\u003d false;\n    }\n\n    public boolean skip(String os) {\n        return this.operatingSystems.contains(os);\n    }\n\n    public boolean isVersionCheck() {\n        return features.isEmpty() \u0026\u0026 operatingSystems.isEmpty();\n    }\n\n    public boolean isEmpty() {\n        return EMPTY.equals(this);\n    }\n\n    static List\u003cVersionRange\u003e parseVersionRanges(String rawRanges) {\n        if (rawRanges \u003d\u003d null) {\n            return Collections.singletonList(new VersionRange(null, null));\n        }\n        String[] ranges \u003d rawRanges.split(\",\");\n        List\u003cVersionRange\u003e versionRanges \u003d new ArrayList\u003c\u003e();\n        for (String rawRange : ranges) {\n            if (rawRange.trim().equals(\"all\")) {\n                return Collections.singletonList(new VersionRange(VersionUtils.getFirstVersion(), Version.CURRENT));\n            }\n            String[] skipVersions \u003d rawRange.split(\"-\", -1);\n            if (skipVersions.length \u003e 2) {\n                throw new IllegalArgumentException(\"version range malformed: \" + rawRanges);\n            }\n\n            String lower \u003d skipVersions[0].trim();\n            String upper \u003d skipVersions[1].trim();\n            VersionRange versionRange \u003d new VersionRange(\n                lower.isEmpty() ? VersionUtils.getFirstVersion() : Version.fromString(lower),\n                upper.isEmpty() ? Version.CURRENT : Version.fromString(upper)\n            );\n            versionRanges.add(versionRange);\n        }\n        return versionRanges;\n    }\n\n    public String getSkipMessage(String description) {\n        StringBuilder messageBuilder \u003d new StringBuilder();\n        messageBuilder.append(\"[\").append(description).append(\"] skipped,\");\n        if (reason !\u003d null) {\n            messageBuilder.append(\" reason: [\").append(getReason()).append(\"]\");\n        }\n        if (features.isEmpty() \u003d\u003d false) {\n            messageBuilder.append(\" unsupported features \").append(getFeatures());\n        }\n        return messageBuilder.toString();\n    }\n}","methodCount":15},"candidatesTelemetryData":{"numberOfSuggestions":0,"candidates":[]},"processingTime":{"llmResponseTime":-1,"pluginProcessingTime":-1,"totalTime":3765},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"parseIfNext","method_signature":"public static parseIfNext(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parse","method_signature":"public static parse(XContentParser parser)","target_class":"","rationale":""},{"method_name":"skip","method_signature":"public skip(Version currentVersion)","target_class":"","rationale":""},{"method_name":"skip","method_signature":"public skip(String os)","target_class":"","rationale":""},{"method_name":"isVersionCheck","method_signature":"public isVersionCheck()","target_class":"","rationale":""},{"method_name":"isEmpty","method_signature":"public isEmpty()","target_class":"","rationale":""},{"method_name":"parseVersionRanges","method_signature":"static parseVersionRanges(String rawRanges)","target_class":"","rationale":""},{"method_name":"getSkipMessage","method_signature":"public getSkipMessage(String description)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"isVersionCheck","method_signature":"public isVersionCheck()","target_class":"","rationale":""},{"method_name":"isEmpty","method_signature":"public isEmpty()","target_class":"","rationale":""},{"method_name":"skip","method_signature":"public skip(String os)","target_class":"","rationale":""},{"method_name":"skip","method_signature":"public skip(Version currentVersion)","target_class":"","rationale":""},{"method_name":"parseIfNext","method_signature":"public static parseIfNext(XContentParser parser)","target_class":"","rationale":""},{"method_name":"getSkipMessage","method_signature":"public getSkipMessage(String description)","target_class":"","rationale":""},{"method_name":"parse","method_signature":"public static parse(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseVersionRanges","method_signature":"static parseVersionRanges(String rawRanges)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public isVersionCheck()":{"first":{"method_name":"isVersionCheck","method_signature":"public isVersionCheck()","target_class":"","rationale":""},"second":0.5103929499818124},"public isEmpty()":{"first":{"method_name":"isEmpty","method_signature":"public isEmpty()","target_class":"","rationale":""},"second":0.5884426754004826},"public skip(String os)":{"first":{"method_name":"skip","method_signature":"public skip(String os)","target_class":"","rationale":""},"second":0.5884851116804498},"public skip(Version currentVersion)":{"first":{"method_name":"skip","method_signature":"public skip(Version currentVersion)","target_class":"","rationale":""},"second":0.5991082163497536},"public static parseIfNext(XContentParser parser)":{"first":{"method_name":"parseIfNext","method_signature":"public static parseIfNext(XContentParser parser)","target_class":"","rationale":""},"second":0.645340070850652},"public getSkipMessage(String description)":{"first":{"method_name":"getSkipMessage","method_signature":"public getSkipMessage(String description)","target_class":"","rationale":""},"second":0.6617183058554275},"public static parse(XContentParser parser)":{"first":{"method_name":"parse","method_signature":"public static parse(XContentParser parser)","target_class":"","rationale":""},"second":0.6745374534082366},"static parseVersionRanges(String rawRanges)":{"first":{"method_name":"parseVersionRanges","method_signature":"static parseVersionRanges(String rawRanges)","target_class":"","rationale":""},"second":0.6754025630227215}},"llmMethodPriority":{"priority_method_names":["isVersionCheck","isEmpty","skip","skip","parseIfNext","getSkipMessage","parse","parseVersionRanges"],"llm_response_time":1372},"targetClassMap":{"isVersionCheck":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":468,"similarity_computation_time":0,"similarity_metric":"voyage"},"isEmpty":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":409,"similarity_computation_time":0,"similarity_metric":"voyage"},"skip":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":628,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"034ff9d8-9f92-4d71-8218-ea93434403d2","methodCount":14,"hostFunctionTelemetryData":{"hostFunctionSize":176,"lineStart":31,"lineEnd":206,"bodyLineStart":31,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/admin/indices/settings/get/GetSettingsResponse.java","sourceCode":"public class GetSettingsResponse extends ActionResponse implements ChunkedToXContentObject {\n\n    private final Map\u003cString, Settings\u003e indexToSettings;\n    private final Map\u003cString, Settings\u003e indexToDefaultSettings;\n\n    public GetSettingsResponse(Map\u003cString, Settings\u003e indexToSettings, Map\u003cString, Settings\u003e indexToDefaultSettings) {\n        this.indexToSettings \u003d indexToSettings;\n        this.indexToDefaultSettings \u003d indexToDefaultSettings;\n    }\n\n    public GetSettingsResponse(StreamInput in) throws IOException {\n        super(in);\n        indexToSettings \u003d in.readImmutableMap(Settings::readSettingsFromStream);\n        indexToDefaultSettings \u003d in.readImmutableMap(Settings::readSettingsFromStream);\n    }\n\n    /**\n     * Returns a map of index name to {@link Settings} object.  The returned {@link Settings}\n     * objects contain only those settings explicitly set on a given index.\n     */\n    public Map\u003cString, Settings\u003e getIndexToSettings() {\n        return indexToSettings;\n    }\n\n    /**\n     * Returns a map of index name to {@link Settings} object.  The returned {@link Settings}\n     * objects contain only the default settings\n     */\n    public Map\u003cString, Settings\u003e getIndexToDefaultSettings() {\n        return indexToDefaultSettings;\n    }\n\n    /**\n     * Returns the string value for the specified index and setting.  If the includeDefaults\n     * flag was not set or set to false on the GetSettingsRequest, this method will only\n     * return a value where the setting was explicitly set on the index.  If the includeDefaults\n     * flag was set to true on the GetSettingsRequest, this method will fall back to return the default\n     * value if the setting was not explicitly set.\n     */\n    public String getSetting(String index, String setting) {\n        Settings settings \u003d indexToSettings.get(index);\n        if (setting !\u003d null) {\n            if (settings !\u003d null \u0026\u0026 settings.hasValue(setting)) {\n                return settings.get(setting);\n            } else {\n                Settings defaultSettings \u003d indexToDefaultSettings.get(index);\n                if (defaultSettings !\u003d null) {\n                    return defaultSettings.get(setting);\n                } else {\n                    return null;\n                }\n            }\n        } else {\n            return null;\n        }\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeMap(indexToSettings, StreamOutput::writeWriteable);\n        out.writeMap(indexToDefaultSettings, StreamOutput::writeWriteable);\n    }\n\n    private static void parseSettingsField(\n        XContentParser parser,\n        String currentIndexName,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    ) throws IOException {\n\n        if (parser.currentToken() \u003d\u003d XContentParser.Token.START_OBJECT) {\n            switch (parser.currentName()) {\n                case \"settings\" -\u003e indexToSettings.put(currentIndexName, Settings.fromXContent(parser));\n                case \"defaults\" -\u003e indexToDefaultSettings.put(currentIndexName, Settings.fromXContent(parser));\n                default -\u003e parser.skipChildren();\n            }\n        } else if (parser.currentToken() \u003d\u003d XContentParser.Token.START_ARRAY) {\n            parser.skipChildren();\n        }\n        parser.nextToken();\n    }\n\n    private static void parseIndexEntry(\n        XContentParser parser,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    ) throws IOException {\n        String indexName \u003d parser.currentName();\n        parser.nextToken();\n        while (parser.isClosed() \u003d\u003d false \u0026\u0026 parser.currentToken() !\u003d XContentParser.Token.END_OBJECT) {\n            parseSettingsField(parser, indexName, indexToSettings, indexToDefaultSettings);\n        }\n    }\n\n    public static GetSettingsResponse fromXContent(XContentParser parser) throws IOException {\n        HashMap\u003cString, Settings\u003e indexToSettings \u003d new HashMap\u003c\u003e();\n        HashMap\u003cString, Settings\u003e indexToDefaultSettings \u003d new HashMap\u003c\u003e();\n\n        if (parser.currentToken() \u003d\u003d null) {\n            parser.nextToken();\n        }\n        XContentParserUtils.ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.currentToken(), parser);\n        parser.nextToken();\n\n        while (parser.isClosed() \u003d\u003d false) {\n            if (parser.currentToken() \u003d\u003d XContentParser.Token.START_OBJECT) {\n                // we must assume this is an index entry\n                parseIndexEntry(parser, indexToSettings, indexToDefaultSettings);\n            } else if (parser.currentToken() \u003d\u003d XContentParser.Token.START_ARRAY) {\n                parser.skipChildren();\n            } else {\n                parser.nextToken();\n            }\n        }\n\n        return new GetSettingsResponse(Map.copyOf(indexToSettings), Map.copyOf(indexToDefaultSettings));\n    }\n\n    @Override\n    public String toString() {\n        try {\n            ByteArrayOutputStream baos \u003d new ByteArrayOutputStream();\n            XContentBuilder builder \u003d new XContentBuilder(JsonXContent.jsonXContent, baos);\n            var iterator \u003d toXContentChunked(false);\n            while (iterator.hasNext()) {\n                iterator.next().toXContent(builder, ToXContent.EMPTY_PARAMS);\n            }\n            return Strings.toString(builder);\n        } catch (IOException e) {\n            throw new IllegalStateException(e); // should not be possible here\n        }\n    }\n\n    @Override\n    public Iterator\u003c? extends ToXContent\u003e toXContentChunked(ToXContent.Params params) {\n        final boolean omitEmptySettings \u003d indexToDefaultSettings.isEmpty();\n        return toXContentChunked(omitEmptySettings);\n    }\n\n    private Iterator\u003cToXContent\u003e toXContentChunked(boolean omitEmptySettings) {\n        final boolean indexToDefaultSettingsEmpty \u003d indexToDefaultSettings.isEmpty();\n        return Iterators.concat(\n            Iterators.single((builder, params) -\u003e builder.startObject()),\n            getIndexToSettings().entrySet()\n                .stream()\n                .filter(entry -\u003e omitEmptySettings \u003d\u003d false || entry.getValue().isEmpty() \u003d\u003d false)\n                .map(entry -\u003e (ToXContent) (builder, params) -\u003e {\n                    builder.startObject(entry.getKey());\n                    builder.startObject(\"settings\");\n                    entry.getValue().toXContent(builder, params);\n                    builder.endObject();\n                    if (indexToDefaultSettingsEmpty \u003d\u003d false) {\n                        builder.startObject(\"defaults\");\n                        indexToDefaultSettings.get(entry.getKey()).toXContent(builder, params);\n                        builder.endObject();\n                    }\n                    return builder.endObject();\n                })\n                .iterator(),\n            Iterators.single((builder, params) -\u003e builder.endObject())\n        );\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this \u003d\u003d o) return true;\n        if (o \u003d\u003d null || getClass() !\u003d o.getClass()) return false;\n        GetSettingsResponse that \u003d (GetSettingsResponse) o;\n        return Objects.equals(indexToSettings, that.indexToSettings) \u0026\u0026 Objects.equals(indexToDefaultSettings, that.indexToDefaultSettings);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(indexToSettings, indexToDefaultSettings);\n    }\n}","methodCount":14},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":112,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseIndexEntry to class TransportGetFieldMappingsAction","description":"move method parseIndexEntry to PsiClass:TransportGetFieldMappingsAction\nRationale: The parseIndexEntry() method is responsible for parsing index settings, which is directly related to field mappings. Moving this method to TransportGetFieldMappingsAction aligns with its purpose of handling field mappings and improves cohesion. This adheres to the Single Responsibility Principle by ensuring that the class is solely focused on field mappings. However, care must be taken to ensure that dependencies on the parser and settings maps are appropriately managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":112,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseIndexEntry to class TransportGetFieldMappingsIndexAction","description":"move method parseIndexEntry to PsiClass:TransportGetFieldMappingsIndexAction\nRationale: Similar to the previous class, TransportGetFieldMappingsIndexAction deals with field mappings and index resolution. Relocating parseIndexEntry() here would enhance the class\u0027s responsibility towards managing index settings directly. This move would also improve the class\u0027s cohesion, aligning with the Interface Segregation Principle. The drawback might be an increased complexity if the class becomes overloaded with parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":112,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseIndexEntry to class GetFieldMappingsResponse","description":"move method parseIndexEntry to PsiClass:GetFieldMappingsResponse\nRationale: The parseIndexEntry() method\u0027s functionality is closely tied to the creation and management of field mappings. By moving it to GetFieldMappingsResponse, we can encapsulate the parsing logic within the response handling, thus improving cohesion. This follows the Open/Closed Principle, allowing the class to be extended for new parsing behaviors. However, it may lead to a bloated response class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":93,"lineEnd":110,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseSettingsField to class TransportGetSettingsAction","description":"move method parseSettingsField to PsiClass:TransportGetSettingsAction\nRationale: The parseSettingsField() method deals with parsing settings, which is closely related to settings management. TransportGetSettingsAction is responsible for handling requests related to settings, making it a suitable target. This move adheres to the Single Responsibility Principle by consolidating settings-related logic in one class. Additionally, it enhances cohesion and reusability. However, care must be taken to ensure that any dependencies on the current class are managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":93,"lineEnd":110,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseSettingsField to class RolloverConfiguration","description":"move method parseSettingsField to PsiClass:RolloverConfiguration\nRationale: RolloverConfiguration deals with various settings and their evaluation, making it a fitting candidate for parseSettingsField(). This relocation would enhance the class\u0027s functionality by encapsulating parsing logic related to rollover settings. It aligns with the Open/Closed Principle, allowing for easy extension of rollover-related features. However, the increased complexity in RolloverConfiguration should be monitored.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":93,"lineEnd":110,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseSettingsField to class TransportGetAliasesAction","description":"move method parseSettingsField to PsiClass:TransportGetAliasesAction\nRationale: TransportGetAliasesAction is involved in alias management, which often includes settings. Moving parseSettingsField() here would centralize the settings parsing logic related to aliases. This adheres to the Interface Segregation Principle by ensuring that classes only have methods relevant to their specific operations. However, it may introduce a dependency on alias operations that could complicate the class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"getSetting","method_signature":"public getSetting(String index, String setting)","target_class":"","rationale":""},{"method_name":"parseSettingsField","method_signature":"private static parseSettingsField(\n        XContentParser parser,\n        String currentIndexName,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},{"method_name":"parseIndexEntry","method_signature":"private static parseIndexEntry(\n        XContentParser parser,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"toXContentChunked","method_signature":"private toXContentChunked(boolean omitEmptySettings)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toXContentChunked","method_signature":"private toXContentChunked(boolean omitEmptySettings)","target_class":"","rationale":""},{"method_name":"parseIndexEntry","method_signature":"private static parseIndexEntry(\n        XContentParser parser,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},{"method_name":"parseSettingsField","method_signature":"private static parseSettingsField(\n        XContentParser parser,\n        String currentIndexName,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"getSetting","method_signature":"public getSetting(String index, String setting)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private toXContentChunked(boolean omitEmptySettings)":{"first":{"method_name":"toXContentChunked","method_signature":"private toXContentChunked(boolean omitEmptySettings)","target_class":"","rationale":""},"second":0.401627439360495},"private static parseIndexEntry(\n        XContentParser parser,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )":{"first":{"method_name":"parseIndexEntry","method_signature":"private static parseIndexEntry(\n        XContentParser parser,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},"second":0.5417976872060591},"private static parseSettingsField(\n        XContentParser parser,\n        String currentIndexName,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )":{"first":{"method_name":"parseSettingsField","method_signature":"private static parseSettingsField(\n        XContentParser parser,\n        String currentIndexName,\n        Map\u003cString, Settings\u003e indexToSettings,\n        Map\u003cString, Settings\u003e indexToDefaultSettings\n    )","target_class":"","rationale":""},"second":0.5829903477288151},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.6631690639940828},"public getSetting(String index, String setting)":{"first":{"method_name":"getSetting","method_signature":"public getSetting(String index, String setting)","target_class":"","rationale":""},"second":0.6841983086012536}},"llmMethodPriority":{"priority_method_names":["toXContentChunked","parseIndexEntry","parseSettingsField","fromXContent","getSetting"],"llm_response_time":1848},"targetClassMap":{"toXContentChunked":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":613,"similarity_computation_time":0,"similarity_metric":"voyage"},"parseIndexEntry":{"target_classes":[{"class_name":"TransportGetSettingsAction","similarity_score":0.44258721316605426},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.35995968677249585},{"class_name":"GetAliasesResponseTests","similarity_score":0.4019064520158706},{"class_name":"GetFieldMappingsResponse","similarity_score":0.4464819737190701},{"class_name":"GetMappingsResponseTests","similarity_score":0.39995520752499536},{"class_name":"TransportGetAliasesAction","similarity_score":0.4389202162525972},{"class_name":"TransportGetFieldMappingsAction","similarity_score":0.41989503935860095},{"class_name":"TransportGetFieldMappingsIndexAction","similarity_score":0.4274545488170033},{"class_name":"TransportGetMappingsAction","similarity_score":0.32901945220503853},{"class_name":"UpdateSettingsRequest","similarity_score":0.36113838658425756},{"class_name":"UpdateSettingsRequestSerializationTests","similarity_score":0.3636541475397188},{"class_name":"UpdateSettingsRequestTests","similarity_score":0.40460980670073377},{"class_name":"ActionTestUtils","similarity_score":0.29713304003133156},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.20913407192853076},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.3151441326144942},{"class_name":"ClusterStateCreationUtils","similarity_score":0.2676997586344318},{"class_name":"SynonymsTestUtils","similarity_score":0.34455513097827417},{"class_name":"RolloverConditions","similarity_score":0.2908644070361475},{"class_name":"RolloverConditionsTests","similarity_score":0.22043121491043424},{"class_name":"RolloverConfiguration","similarity_score":0.37268578002351044},{"class_name":"RolloverConfigurationTests","similarity_score":0.3485669165993671},{"class_name":"RolloverInfo","similarity_score":0.4061416941602526},{"class_name":"RolloverResponseTests","similarity_score":0.30458446350285906},{"class_name":"OpenIndexResponse","similarity_score":0.37894918455123994},{"class_name":"Failure","similarity_score":0.4142364326791354},{"class_name":"GetShardSnapshotRequest","similarity_score":0.3998002266534377},{"class_name":"GetSnapshotsResponse","similarity_score":0.4385240816137595},{"class_name":"FieldLookup","similarity_score":0.40768783528900393},{"class_name":"After","similarity_score":0.3822886438993236}],"target_classes_sorted_by_llm":["TransportGetFieldMappingsAction","TransportGetFieldMappingsIndexAction","GetFieldMappingsResponse","TransportGetSettingsAction","FieldLookup","UpdateSettingsRequestTests","RolloverInfo","Failure","GetSnapshotsResponse","TransportGetAliasesAction"],"llm_response_time":7842,"similarity_computation_time":32,"similarity_metric":"voyage"},"parseSettingsField":{"target_classes":[{"class_name":"TransportGetSettingsAction","similarity_score":0.5066536266608378},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.4544523449638123},{"class_name":"GetAliasesResponseTests","similarity_score":0.5353568127239144},{"class_name":"GetFieldMappingsResponse","similarity_score":0.5660167983570922},{"class_name":"GetMappingsResponseTests","similarity_score":0.4792406546891111},{"class_name":"TransportGetAliasesAction","similarity_score":0.5142081886864334},{"class_name":"TransportGetFieldMappingsAction","similarity_score":0.47160138701114224},{"class_name":"TransportGetFieldMappingsIndexAction","similarity_score":0.5205196649978602},{"class_name":"TransportGetMappingsAction","similarity_score":0.36252219952892073},{"class_name":"UpdateSettingsRequest","similarity_score":0.40799699676993556},{"class_name":"UpdateSettingsRequestSerializationTests","similarity_score":0.45751133202117383},{"class_name":"UpdateSettingsRequestTests","similarity_score":0.518465302150475},{"class_name":"ActionTestUtils","similarity_score":0.37692803327431257},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.24372336781613027},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.37617017870799807},{"class_name":"SynonymsTestUtils","similarity_score":0.4581859835278747},{"class_name":"ClusterStateCreationUtils","similarity_score":0.27553253000593797},{"class_name":"MaxAgeCondition","similarity_score":0.4071572423879991},{"class_name":"MaxDocsCondition","similarity_score":0.45089532032828156},{"class_name":"MaxPrimaryShardDocsCondition","similarity_score":0.4572620044323146},{"class_name":"MaxPrimaryShardSizeCondition","similarity_score":0.4274597761619137},{"class_name":"MaxSizeCondition","similarity_score":0.4349334153235572},{"class_name":"SnapshotPredicates","similarity_score":0.4759918207822515},{"class_name":"ListDanglingIndicesResponse","similarity_score":0.4728368759054205},{"class_name":"RolloverConditions","similarity_score":0.39149786996220615},{"class_name":"RolloverConditionsTests","similarity_score":0.2686825177799894},{"class_name":"RolloverConfiguration","similarity_score":0.5187109675620774},{"class_name":"RolloverConfigurationTests","similarity_score":0.4296470709989442},{"class_name":"RolloverInfo","similarity_score":0.45548852051884675}],"target_classes_sorted_by_llm":["TransportGetSettingsAction","RolloverConfiguration","TransportGetAliasesAction","GetFieldMappingsResponse","UpdateSettingsRequestTests","GetMappingsResponseTests","ListDanglingIndicesResponse","SnapshotPredicates","TransportGetFieldMappingsIndexAction","GetAliasesResponseTests"],"llm_response_time":9785,"similarity_computation_time":11,"similarity_metric":"voyage"}}}
{"id":"b15a03aa-f031-4c54-b101-623beefe55a5","methodCount":13,"hostFunctionTelemetryData":{"hostFunctionSize":155,"lineStart":29,"lineEnd":183,"bodyLineStart":29,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/bulk/BulkResponse.java","sourceCode":"/**\n * A response of a bulk execution. Holding a response for each item responding (in order) of the\n * bulk requests. Each item holds the index/type/id is operated on, and if it failed or not (with the\n * failure message).\n */\npublic class BulkResponse extends ActionResponse implements Iterable\u003cBulkItemResponse\u003e, ChunkedToXContentObject {\n\n    private static final String ITEMS \u003d \"items\";\n    private static final String ERRORS \u003d \"errors\";\n    private static final String TOOK \u003d \"took\";\n    private static final String INGEST_TOOK \u003d \"ingest_took\";\n\n    public static final long NO_INGEST_TOOK \u003d -1L;\n\n    private final BulkItemResponse[] responses;\n    private final long tookInMillis;\n    private final long ingestTookInMillis;\n\n    public BulkResponse(StreamInput in) throws IOException {\n        super(in);\n        responses \u003d in.readArray(BulkItemResponse::new, BulkItemResponse[]::new);\n        tookInMillis \u003d in.readVLong();\n        ingestTookInMillis \u003d in.readZLong();\n    }\n\n    public BulkResponse(BulkItemResponse[] responses, long tookInMillis) {\n        this(responses, tookInMillis, NO_INGEST_TOOK);\n    }\n\n    public BulkResponse(BulkItemResponse[] responses, long tookInMillis, long ingestTookInMillis) {\n        this.responses \u003d responses;\n        this.tookInMillis \u003d tookInMillis;\n        this.ingestTookInMillis \u003d ingestTookInMillis;\n    }\n\n    /**\n     * How long the bulk execution took. Excluding ingest preprocessing.\n     */\n    public TimeValue getTook() {\n        return new TimeValue(tookInMillis);\n    }\n\n    /**\n     * If ingest is enabled returns the bulk ingest preprocessing time, otherwise 0 is returned.\n     */\n    public TimeValue getIngestTook() {\n        return new TimeValue(ingestTookInMillis);\n    }\n\n    /**\n     * If ingest is enabled returns the bulk ingest preprocessing time. in milliseconds, otherwise -1 is returned.\n     */\n    public long getIngestTookInMillis() {\n        return ingestTookInMillis;\n    }\n\n    /**\n     * Has anything failed with the execution.\n     */\n    public boolean hasFailures() {\n        for (BulkItemResponse response : responses) {\n            if (response.isFailed()) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    public String buildFailureMessage() {\n        StringBuilder sb \u003d new StringBuilder();\n        sb.append(\"failure in bulk execution:\");\n        for (int i \u003d 0; i \u003c responses.length; i++) {\n            BulkItemResponse response \u003d responses[i];\n            if (response.isFailed()) {\n                sb.append(\"\\n[\")\n                    .append(i)\n                    .append(\"]: index [\")\n                    .append(response.getIndex())\n                    .append(\"], id [\")\n                    .append(response.getId())\n                    .append(\"], message [\")\n                    .append(response.getFailureMessage())\n                    .append(\"]\");\n            }\n        }\n        return sb.toString();\n    }\n\n    /**\n     * The items representing each action performed in the bulk operation (in the same order!).\n     */\n    public BulkItemResponse[] getItems() {\n        return responses;\n    }\n\n    @Override\n    public Iterator\u003cBulkItemResponse\u003e iterator() {\n        return Iterators.forArray(responses);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeArray(responses);\n        out.writeVLong(tookInMillis);\n        out.writeZLong(ingestTookInMillis);\n    }\n\n    public static BulkResponse fromXContent(XContentParser parser) throws IOException {\n        XContentParser.Token token \u003d parser.nextToken();\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser);\n\n        long took \u003d -1L;\n        long ingestTook \u003d NO_INGEST_TOOK;\n        List\u003cBulkItemResponse\u003e items \u003d new ArrayList\u003c\u003e();\n\n        String currentFieldName \u003d parser.currentName();\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            if (token \u003d\u003d XContentParser.Token.FIELD_NAME) {\n                currentFieldName \u003d parser.currentName();\n            } else if (token.isValue()) {\n                if (TOOK.equals(currentFieldName)) {\n                    took \u003d parser.longValue();\n                } else if (INGEST_TOOK.equals(currentFieldName)) {\n                    ingestTook \u003d parser.longValue();\n                } else if (ERRORS.equals(currentFieldName) \u003d\u003d false) {\n                    throwUnknownField(currentFieldName, parser);\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n                if (ITEMS.equals(currentFieldName)) {\n                    while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                        items.add(BulkItemResponse.fromXContent(parser, items.size()));\n                    }\n                } else {\n                    throwUnknownField(currentFieldName, parser);\n                }\n            } else {\n                throwUnknownToken(token, parser);\n            }\n        }\n        return new BulkResponse(items.toArray(new BulkItemResponse[items.size()]), took, ingestTook);\n    }\n\n    @Override\n    public Iterator\u003c? extends ToXContent\u003e toXContentChunked(ToXContent.Params params) {\n        return Iterators.concat(Iterators.single((builder, p) -\u003e {\n            builder.startObject();\n            builder.field(ERRORS, hasFailures());\n            builder.field(TOOK, tookInMillis);\n            if (ingestTookInMillis !\u003d BulkResponse.NO_INGEST_TOOK) {\n                builder.field(INGEST_TOOK, ingestTookInMillis);\n            }\n            return builder.startArray(ITEMS);\n        }), Iterators.forArray(responses), Iterators.\u003cToXContent\u003esingle((builder, p) -\u003e builder.endArray().endObject()));\n    }\n}","methodCount":13},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":135,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class BulkItemResponse","description":"move method fromXContent to PsiClass:BulkItemResponse\nRationale: The fromXContent() method is responsible for parsing bulk response data, which directly relates to the creation of BulkItemResponse instances. Moving it to BulkItemResponse aligns with the Single Responsibility Principle, as it consolidates parsing logic within the class that represents the parsed objects. This enhances cohesion and encapsulation. However, this may lead to tighter coupling between the parser and BulkItemResponse.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":135,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class BulkRequestParser","description":"move method fromXContent to PsiClass:BulkRequestParser\nRationale: The fromXContent() method performs parsing operations that are closely related to the responsibilities of BulkRequestParser. By relocating this method here, we can centralize parsing logic, improving maintainability. This move adheres to the Open/Closed Principle by allowing future parsing variations without modifying existing classes. A potential drawback is that it may increase the size of BulkRequestParser, making it less focused.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":135,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class TransportBulkAction","description":"move method fromXContent to PsiClass:TransportBulkAction\nRationale: TransportBulkAction orchestrates bulk operations and handles responses. Moving fromXContent() here would allow it to directly manage the parsing of bulk responses, aligning with the Dependency Inversion Principle by abstracting the parsing logic within the transport layer. This could improve clarity in how responses are handled, but it may lead to a bloated TransportBulkAction class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"hasFailures","method_signature":"public hasFailures()","target_class":"","rationale":""},{"method_name":"buildFailureMessage","method_signature":"public buildFailureMessage()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"buildFailureMessage","method_signature":"public buildFailureMessage()","target_class":"","rationale":""},{"method_name":"hasFailures","method_signature":"public hasFailures()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public buildFailureMessage()":{"first":{"method_name":"buildFailureMessage","method_signature":"public buildFailureMessage()","target_class":"","rationale":""},"second":0.528701427513816},"public hasFailures()":{"first":{"method_name":"hasFailures","method_signature":"public hasFailures()","target_class":"","rationale":""},"second":0.6059854697522836},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.6070334919015006}},"llmMethodPriority":{"priority_method_names":["buildFailureMessage","hasFailures","fromXContent"],"llm_response_time":998},"targetClassMap":{"buildFailureMessage":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":397,"similarity_computation_time":0,"similarity_metric":"voyage"},"hasFailures":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":614,"similarity_computation_time":0,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"ClusterStateCreationUtils","similarity_score":0.5234073725646973},{"class_name":"ActionTestUtils","similarity_score":0.3987207573237429},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.5268307427304723},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.2478986938092433},{"class_name":"SynonymsTestUtils","similarity_score":0.5259541891182323},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.6084729738441479},{"class_name":"CustomScriptPlugin","similarity_score":0.3936960194351372},{"class_name":"BulkItemResponse","similarity_score":0.7423637305857526},{"class_name":"BulkItemResponseTests","similarity_score":0.7138935046666933},{"class_name":"BulkPrimaryExecutionContext","similarity_score":0.476264635680984},{"class_name":"BulkProcessor","similarity_score":0.5753366837393907},{"class_name":"BulkProcessor2","similarity_score":0.3911234281587984},{"class_name":"BulkProcessor2IT","similarity_score":0.6207410994783266},{"class_name":"BulkProcessor2RetryIT","similarity_score":0.7536596348308867},{"class_name":"BulkProcessorIT","similarity_score":0.6063434719854639},{"class_name":"BulkProcessorRetryIT","similarity_score":0.6575252935572621},{"class_name":"BulkRequest","similarity_score":0.5254787718706884},{"class_name":"BulkRequestParser","similarity_score":0.7462570683883919},{"class_name":"BulkResponseTests","similarity_score":0.6713699424509176},{"class_name":"BulkWithUpdatesIT","similarity_score":0.6305975968648526},{"class_name":"TransportBulkAction","similarity_score":0.7307080797838235},{"class_name":"TransportBulkActionTookTests","similarity_score":0.68144489751941},{"class_name":"TransportShardBulkAction","similarity_score":0.7096685796412956},{"class_name":"WriteAckDelay","similarity_score":0.6417670912661133},{"class_name":"AuditUtil","similarity_score":0.6278294467897685},{"class_name":"RestResponseUtils","similarity_score":0.7282034497070538},{"class_name":"FunctionTestUtils","similarity_score":0.6311209009756082},{"class_name":"FutureUtils","similarity_score":0.47848094749507664},{"class_name":"JwkValidateUtil","similarity_score":0.5845741236719384}],"target_classes_sorted_by_llm":["BulkItemResponse","BulkRequestParser","TransportBulkAction","BulkResponseTests","TransportShardBulkAction","RestResponseUtils","BulkProcessorRetryIT","TransportBulkActionTookTests","BulkItemResponseTests","BulkProcessor2RetryIT"],"llm_response_time":9781,"similarity_computation_time":43,"similarity_metric":"voyage"}}}
{"id":"f1147438-6406-4e22-9b75-c69beb45aad7","methodCount":16,"hostFunctionTelemetryData":{"hostFunctionSize":199,"lineStart":34,"lineEnd":232,"bodyLineStart":34,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/get/MultiGetResponse.java","sourceCode":"public class MultiGetResponse extends ActionResponse implements Iterable\u003cMultiGetItemResponse\u003e, ToXContentObject {\n    private static final DeprecationLogger deprecationLogger \u003d DeprecationLogger.getLogger(MultiGetResponse.class);\n\n    private static final ParseField INDEX \u003d new ParseField(\"_index\");\n    private static final ParseField TYPE \u003d new ParseField(\"_type\");\n    private static final ParseField ID \u003d new ParseField(\"_id\");\n    private static final ParseField ERROR \u003d new ParseField(\"error\");\n    private static final ParseField DOCS \u003d new ParseField(\"docs\");\n\n    /**\n     * Represents a failure.\n     */\n    public static class Failure implements Writeable, ToXContentObject {\n\n        private final String index;\n        private final String id;\n        private final Exception exception;\n\n        public Failure(String index, String id, Exception exception) {\n            this.index \u003d index;\n            this.id \u003d id;\n            this.exception \u003d exception;\n        }\n\n        Failure(StreamInput in) throws IOException {\n            index \u003d in.readString();\n            if (in.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n                in.readOptionalString();\n            }\n            id \u003d in.readString();\n            exception \u003d in.readException();\n        }\n\n        /**\n         * The index name of the action.\n         */\n        public String getIndex() {\n            return this.index;\n        }\n\n        /**\n         * The id of the action.\n         */\n        public String getId() {\n            return id;\n        }\n\n        /**\n         * The failure message.\n         */\n        public String getMessage() {\n            return exception !\u003d null ? exception.getMessage() : null;\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeString(index);\n            if (out.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n                out.writeOptionalString(MapperService.SINGLE_MAPPING_NAME);\n            }\n            out.writeString(id);\n            out.writeException(exception);\n        }\n\n        @Override\n        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n            builder.startObject();\n            builder.field(INDEX.getPreferredName(), index);\n            if (builder.getRestApiVersion() \u003d\u003d RestApiVersion.V_7) {\n                builder.field(MapperService.TYPE_FIELD_NAME, MapperService.SINGLE_MAPPING_NAME);\n            }\n            builder.field(ID.getPreferredName(), id);\n            ElasticsearchException.generateFailureXContent(builder, params, exception, true);\n            builder.endObject();\n            return builder;\n        }\n\n        public Exception getFailure() {\n            return exception;\n        }\n    }\n\n    private final MultiGetItemResponse[] responses;\n\n    public MultiGetResponse(MultiGetItemResponse[] responses) {\n        this.responses \u003d responses;\n    }\n\n    MultiGetResponse(StreamInput in) throws IOException {\n        super(in);\n        responses \u003d in.readArray(MultiGetItemResponse::new, MultiGetItemResponse[]::new);\n    }\n\n    public MultiGetItemResponse[] getResponses() {\n        return this.responses;\n    }\n\n    @Override\n    public Iterator\u003cMultiGetItemResponse\u003e iterator() {\n        return Iterators.forArray(responses);\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject();\n        builder.startArray(DOCS.getPreferredName());\n        for (MultiGetItemResponse response : responses) {\n            if (response.isFailed()) {\n                Failure failure \u003d response.getFailure();\n                failure.toXContent(builder, params);\n            } else {\n                GetResponse getResponse \u003d response.getResponse();\n                getResponse.toXContent(builder, params);\n            }\n        }\n        builder.endArray();\n        builder.endObject();\n        return builder;\n    }\n\n    public static MultiGetResponse fromXContent(XContentParser parser) throws IOException {\n        String currentFieldName \u003d null;\n        List\u003cMultiGetItemResponse\u003e items \u003d new ArrayList\u003c\u003e();\n        for (Token token \u003d parser.nextToken(); token !\u003d Token.END_OBJECT; token \u003d parser.nextToken()) {\n            switch (token) {\n                case FIELD_NAME:\n                    currentFieldName \u003d parser.currentName();\n                    break;\n                case START_ARRAY:\n                    if (DOCS.getPreferredName().equals(currentFieldName)) {\n                        for (token \u003d parser.nextToken(); token !\u003d Token.END_ARRAY; token \u003d parser.nextToken()) {\n                            if (token \u003d\u003d Token.START_OBJECT) {\n                                items.add(parseItem(parser));\n                            }\n                        }\n                    }\n                    break;\n                default:\n                    // If unknown tokens are encounter then these should be ignored, because\n                    // this is parsing logic on the client side.\n                    break;\n            }\n        }\n        return new MultiGetResponse(items.toArray(new MultiGetItemResponse[0]));\n    }\n\n    private static MultiGetItemResponse parseItem(XContentParser parser) throws IOException {\n        String currentFieldName \u003d null;\n        String index \u003d null;\n        String id \u003d null;\n        ElasticsearchException exception \u003d null;\n        GetResult getResult \u003d null;\n        for (Token token \u003d parser.nextToken(); token !\u003d Token.END_OBJECT; token \u003d parser.nextToken()) {\n            switch (token) {\n                case FIELD_NAME:\n                    currentFieldName \u003d parser.currentName();\n                    if (INDEX.match(currentFieldName, parser.getDeprecationHandler()) \u003d\u003d false\n                        \u0026\u0026 ID.match(currentFieldName, parser.getDeprecationHandler()) \u003d\u003d false\n                        \u0026\u0026 ERROR.match(currentFieldName, parser.getDeprecationHandler()) \u003d\u003d false) {\n                        getResult \u003d GetResult.fromXContentEmbedded(parser, index, id);\n                    }\n                    break;\n                case VALUE_STRING:\n                    if (INDEX.match(currentFieldName, parser.getDeprecationHandler())) {\n                        index \u003d parser.text();\n                    } else if (TYPE.match(currentFieldName, parser.getDeprecationHandler())) {\n                        deprecationLogger.compatibleCritical(\"mget_with_types\", RestMultiGetAction.TYPES_DEPRECATION_MESSAGE);\n                    } else if (ID.match(currentFieldName, parser.getDeprecationHandler())) {\n                        id \u003d parser.text();\n                    }\n                    break;\n                case START_OBJECT:\n                    if (ERROR.match(currentFieldName, parser.getDeprecationHandler())) {\n                        exception \u003d ElasticsearchException.fromXContent(parser);\n                    }\n                    break;\n                default:\n                    // If unknown tokens are encounter then these should be ignored, because\n                    // this is parsing logic on the client side.\n                    break;\n            }\n            if (getResult !\u003d null) {\n                break;\n            }\n        }\n\n        if (exception !\u003d null) {\n            return new MultiGetItemResponse(null, new Failure(index, id, exception));\n        } else {\n            GetResponse getResponse \u003d new GetResponse(getResult);\n            return new MultiGetItemResponse(getResponse, null);\n        }\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeArray(responses);\n    }\n}","methodCount":16},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":153,"lineEnd":177,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class MultiGetRequest","description":"move method fromXContent to PsiClass:MultiGetRequest\nRationale: The fromXContent() method is responsible for parsing a MultiGet response from an XContentParser, which is closely tied to the structure of MultiGet requests. Moving it to MultiGetRequest enhances cohesion since this class deals with the creation and management of MultiGet operations. This aligns with the Single Responsibility Principle and reduces the coupling between unrelated classes. However, care must be taken to ensure that the method does not create circular dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":153,"lineEnd":177,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class TransportMultiGetAction","description":"move method fromXContent to PsiClass:TransportMultiGetAction\nRationale: As this class is responsible for executing MultiGet actions, it would be logical to relocate the fromXContent() method here, as it deals with parsing the response of such actions. This move adheres to the Open/Closed Principle, allowing for easier extension of functionality related to MultiGet actions without modifying existing code. However, this class may become overloaded with responsibilities if additional parsing logic is added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":153,"lineEnd":177,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class MultiGetResponseTests","description":"move method fromXContent to PsiClass:MultiGetResponseTests\nRationale: Since the method is directly related to testing the response parsing, moving it here can help consolidate test-related parsing logic. This would improve the structure of test cases and maintain a clear focus on testing responses. It adheres to the Single Responsibility Principle, but could lead to confusion about the separation between production and testing code.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":179,"lineEnd":225,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseItem to class MultiGetRequest","description":"move method parseItem to PsiClass:MultiGetRequest\nRationale: The parseItem() method is responsible for parsing items related to multi-get requests. Moving it to MultiGetRequest adheres to the Single Responsibility Principle, as it centralizes parsing logic specific to multi-get operations. This enhances cohesion within MultiGetRequest, making it easier to maintain and understand. However, care must be taken to ensure that the method\u0027s static context is appropriately handled.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":179,"lineEnd":225,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseItem to class TransportMultiGetAction","description":"move method parseItem to PsiClass:TransportMultiGetAction\nRationale: TransportMultiGetAction is closely related to the execution of multi-get actions and handling responses. Relocating parseItem() here aligns with the Open/Closed Principle, as it allows for extension of multi-get behavior without modifying existing classes. This move would streamline the request handling process, but it may introduce dependencies on transport-level classes that need careful management.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":179,"lineEnd":225,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseItem to class GetResponseTests","description":"move method parseItem to PsiClass:GetResponseTests\nRationale: The method\u0027s functionality is closely tied to the creation and parsing of GetResponse objects. Moving parseItem() to GetResponseTests would allow for more focused testing of response parsing logic. This adheres to the Single Responsibility Principle by consolidating related parsing functionality. However, this may lead to overloading the test class with too much responsibility.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseItem","method_signature":"private static parseItem(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseItem","method_signature":"private static parseItem(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.7230210236376228},"private static parseItem(XContentParser parser)":{"first":{"method_name":"parseItem","method_signature":"private static parseItem(XContentParser parser)","target_class":"","rationale":""},"second":0.7447454982173393}},"llmMethodPriority":{"priority_method_names":["fromXContent","parseItem"],"llm_response_time":1013},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.4731362045122996},{"class_name":"ActionTestUtils","similarity_score":0.33541019662496846},{"class_name":"ClusterStateCreationUtils","similarity_score":0.5093284028961202},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.5043913124018792},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.22772163458297692},{"class_name":"SynonymsTestUtils","similarity_score":0.438296584636358},{"class_name":"TransportMultiGetAction","similarity_score":0.6545622662530873},{"class_name":"TransportMultiGetActionTests","similarity_score":0.460761691738269},{"class_name":"MultiGetRequest","similarity_score":0.7311008391023314},{"class_name":"MultiGetResponseTests","similarity_score":0.6382009467483524},{"class_name":"MultiGetShardRequestTests","similarity_score":0.643185986265059},{"class_name":"TransportGetAction","similarity_score":0.6246515650487716},{"class_name":"GetResponseTests","similarity_score":0.5857063918049128},{"class_name":"AuditUtil","similarity_score":0.5554561393966264},{"class_name":"JwkValidateUtil","similarity_score":0.5073682114273176},{"class_name":"JwkValidateUtilTests","similarity_score":0.5703782689244626},{"class_name":"RestResponseUtils","similarity_score":0.5994336950130358},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.5215942925882203},{"class_name":"AuthorizationUtils","similarity_score":0.3714565735543926},{"class_name":"JwtUtil","similarity_score":0.5991214909663727},{"class_name":"CredentialsRedaction","similarity_score":0.6754290336978739},{"class_name":"CheckedFunctionUtils","similarity_score":0.14974882445184812},{"class_name":"CryptUtils","similarity_score":0.5658733969907058},{"class_name":"RestTestUtil","similarity_score":0.3668367577587118},{"class_name":"CsvTestUtils","similarity_score":0.6279660642083134},{"class_name":"RestUtils","similarity_score":0.5373222202057336},{"class_name":"RestUtilsTests","similarity_score":0.3616729141767294},{"class_name":"NumericUtilsTests","similarity_score":0.1815448420885944},{"class_name":"KeyStoreUtil","similarity_score":0.4921135904225577}],"target_classes_sorted_by_llm":["MultiGetRequest","TransportMultiGetAction","MultiGetResponseTests","MultiGetShardRequestTests","RestResponseUtils","TransportGetAction","CsvTestUtils","GetResponseTests","CredentialsRedaction","JwtUtil"],"llm_response_time":8633,"similarity_computation_time":21,"similarity_metric":"voyage"},"parseItem":{"target_classes":[{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.4648375956063789},{"class_name":"ClusterStateCreationUtils","similarity_score":0.5496120716587293},{"class_name":"ActionTestUtils","similarity_score":0.3297134172277495},{"class_name":"SynonymsTestUtils","similarity_score":0.4663375479619745},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.23728673545737142},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.5369398661023063},{"class_name":"GetResponseTests","similarity_score":0.6399702466562462},{"class_name":"MultiGetRequest","similarity_score":0.8059074741327594},{"class_name":"MultiGetResponseTests","similarity_score":0.6812020253853439},{"class_name":"MultiGetShardRequestTests","similarity_score":0.6929374532671778},{"class_name":"TransportGetAction","similarity_score":0.7004913367179546},{"class_name":"TransportMultiGetAction","similarity_score":0.7101686427904004},{"class_name":"TransportMultiGetActionTests","similarity_score":0.5043137814056795},{"class_name":"AuditUtil","similarity_score":0.6061298647120763},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.21286987396657917},{"class_name":"FunctionTestUtils","similarity_score":0.5699601663321272},{"class_name":"FutureUtils","similarity_score":0.42996842956408327},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.5784946006355002},{"class_name":"AuthorizationUtils","similarity_score":0.375063023173581},{"class_name":"JwkValidateUtil","similarity_score":0.5645221153857668},{"class_name":"JwkValidateUtilTests","similarity_score":0.5997801138139564},{"class_name":"GceMockUtils","similarity_score":0.6158115059929745},{"class_name":"CredentialsRedaction","similarity_score":0.7328647845016465},{"class_name":"JwtUtil","similarity_score":0.6320520394892587},{"class_name":"CryptUtils","similarity_score":0.6007452099981062},{"class_name":"GeneratorUtils","similarity_score":0.5999409987798082},{"class_name":"CsvTestUtils","similarity_score":0.6609410026223814},{"class_name":"CheckedFunctionUtils","similarity_score":0.12694681711789368},{"class_name":"AwsEc2Utils","similarity_score":0.5905086748300188}],"target_classes_sorted_by_llm":["MultiGetRequest","TransportMultiGetAction","GetResponseTests","MultiGetResponseTests","TransportGetAction","MultiGetShardRequestTests","CsvTestUtils","JwtUtil","CredentialsRedaction","GceMockUtils"],"llm_response_time":11900,"similarity_computation_time":9,"similarity_metric":"voyage"}}}
{"id":"4fc099ab-3784-4743-8d3f-2ffead879cef","methodCount":23,"hostFunctionTelemetryData":{"hostFunctionSize":237,"lineStart":39,"lineEnd":275,"bodyLineStart":39,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/index/reindex/BulkByScrollResponse.java","sourceCode":"/**\n * Response used for actions that index many documents using a scroll request.\n */\npublic class BulkByScrollResponse extends ActionResponse implements ToXContentFragment {\n    private TimeValue took;\n    private BulkByScrollTask.Status status;\n    private List\u003cFailure\u003e bulkFailures;\n    private List\u003cScrollableHitSource.SearchFailure\u003e searchFailures;\n    private boolean timedOut;\n\n    private static final String TOOK_FIELD \u003d \"took\";\n    private static final String TIMED_OUT_FIELD \u003d \"timed_out\";\n    private static final String FAILURES_FIELD \u003d \"failures\";\n\n    @SuppressWarnings(\"unchecked\")\n    private static final ObjectParser\u003cBulkByScrollResponseBuilder, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\n        \"bulk_by_scroll_response\",\n        true,\n        BulkByScrollResponseBuilder::new\n    );\n    static {\n        PARSER.declareLong(BulkByScrollResponseBuilder::setTook, new ParseField(TOOK_FIELD));\n        PARSER.declareBoolean(BulkByScrollResponseBuilder::setTimedOut, new ParseField(TIMED_OUT_FIELD));\n        PARSER.declareObjectArray(BulkByScrollResponseBuilder::setFailures, (p, c) -\u003e parseFailure(p), new ParseField(FAILURES_FIELD));\n        // since the result of BulkByScrollResponse.Status are mixed we also parse that in this\n        Status.declareFields(PARSER);\n    }\n\n    public BulkByScrollResponse(StreamInput in) throws IOException {\n        super(in);\n        took \u003d in.readTimeValue();\n        status \u003d new BulkByScrollTask.Status(in);\n        bulkFailures \u003d in.readCollectionAsList(Failure::new);\n        searchFailures \u003d in.readCollectionAsList(ScrollableHitSource.SearchFailure::new);\n        timedOut \u003d in.readBoolean();\n    }\n\n    public BulkByScrollResponse(\n        TimeValue took,\n        BulkByScrollTask.Status status,\n        List\u003cFailure\u003e bulkFailures,\n        List\u003cScrollableHitSource.SearchFailure\u003e searchFailures,\n        boolean timedOut\n    ) {\n        this.took \u003d took;\n        this.status \u003d requireNonNull(status, \"Null status not supported\");\n        this.bulkFailures \u003d bulkFailures;\n        this.searchFailures \u003d searchFailures;\n        this.timedOut \u003d timedOut;\n    }\n\n    public BulkByScrollResponse(Iterable\u003cBulkByScrollResponse\u003e toMerge, @Nullable String reasonCancelled) {\n        long mergedTook \u003d 0;\n        List\u003cBulkByScrollTask.StatusOrException\u003e statuses \u003d new ArrayList\u003c\u003e();\n        bulkFailures \u003d new ArrayList\u003c\u003e();\n        searchFailures \u003d new ArrayList\u003c\u003e();\n        for (BulkByScrollResponse response : toMerge) {\n            mergedTook \u003d max(mergedTook, response.getTook().nanos());\n            statuses.add(new BulkByScrollTask.StatusOrException(response.status));\n            bulkFailures.addAll(response.getBulkFailures());\n            searchFailures.addAll(response.getSearchFailures());\n            timedOut |\u003d response.isTimedOut();\n        }\n        took \u003d timeValueNanos(mergedTook);\n        status \u003d new BulkByScrollTask.Status(statuses, reasonCancelled);\n    }\n\n    public TimeValue getTook() {\n        return took;\n    }\n\n    public BulkByScrollTask.Status getStatus() {\n        return status;\n    }\n\n    public long getCreated() {\n        return status.getCreated();\n    }\n\n    public long getTotal() {\n        return status.getTotal();\n    }\n\n    public long getDeleted() {\n        return status.getDeleted();\n    }\n\n    public long getUpdated() {\n        return status.getUpdated();\n    }\n\n    public int getBatches() {\n        return status.getBatches();\n    }\n\n    public long getVersionConflicts() {\n        return status.getVersionConflicts();\n    }\n\n    public long getNoops() {\n        return status.getNoops();\n    }\n\n    /**\n     * The reason that the request was canceled or null if it hasn\u0027t been.\n     */\n    public String getReasonCancelled() {\n        return status.getReasonCancelled();\n    }\n\n    /**\n     * The number of times that the request had retry bulk actions.\n     */\n    public long getBulkRetries() {\n        return status.getBulkRetries();\n    }\n\n    /**\n     * The number of times that the request had retry search actions.\n     */\n    public long getSearchRetries() {\n        return status.getSearchRetries();\n    }\n\n    /**\n     * All of the bulk failures. Version conflicts are only included if the request sets abortOnVersionConflict to true (the default).\n     */\n    public List\u003cFailure\u003e getBulkFailures() {\n        return bulkFailures;\n    }\n\n    /**\n     * All search failures.\n     */\n    public List\u003cScrollableHitSource.SearchFailure\u003e getSearchFailures() {\n        return searchFailures;\n    }\n\n    /**\n     * Did any of the sub-requests that were part of this request timeout?\n     */\n    public boolean isTimedOut() {\n        return timedOut;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeTimeValue(took);\n        status.writeTo(out);\n        out.writeCollection(bulkFailures);\n        out.writeCollection(searchFailures);\n        out.writeBoolean(timedOut);\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.field(TOOK_FIELD, took.millis());\n        builder.field(TIMED_OUT_FIELD, timedOut);\n        status.innerXContent(builder, params);\n        builder.startArray(\"failures\");\n        for (Failure failure : bulkFailures) {\n            builder.startObject();\n            failure.toXContent(builder, params);\n            builder.endObject();\n        }\n        for (ScrollableHitSource.SearchFailure failure : searchFailures) {\n            failure.toXContent(builder, params);\n        }\n        builder.endArray();\n        return builder;\n    }\n\n    public static BulkByScrollResponse fromXContent(XContentParser parser) {\n        return PARSER.apply(parser, null).buildResponse();\n    }\n\n    private static Object parseFailure(XContentParser parser) throws IOException {\n        ensureExpectedToken(Token.START_OBJECT, parser.currentToken(), parser);\n        Token token;\n        String index \u003d null;\n        String id \u003d null;\n        Integer status \u003d null;\n        Integer shardId \u003d null;\n        String nodeId \u003d null;\n        ElasticsearchException bulkExc \u003d null;\n        ElasticsearchException searchExc \u003d null;\n        while ((token \u003d parser.nextToken()) !\u003d Token.END_OBJECT) {\n            ensureExpectedToken(Token.FIELD_NAME, token, parser);\n            String name \u003d parser.currentName();\n            token \u003d parser.nextToken();\n            if (token \u003d\u003d Token.START_ARRAY) {\n                parser.skipChildren();\n            } else if (token \u003d\u003d Token.START_OBJECT) {\n                switch (name) {\n                    case SearchFailure.REASON_FIELD -\u003e searchExc \u003d ElasticsearchException.fromXContent(parser);\n                    case Failure.CAUSE_FIELD -\u003e bulkExc \u003d ElasticsearchException.fromXContent(parser);\n                    default -\u003e parser.skipChildren();\n                }\n            } else if (token \u003d\u003d Token.VALUE_STRING) {\n                switch (name) {\n                    // This field is the same as SearchFailure.index\n                    case Failure.INDEX_FIELD -\u003e index \u003d parser.text();\n                    case Failure.ID_FIELD -\u003e id \u003d parser.text();\n                    case SearchFailure.NODE_FIELD -\u003e nodeId \u003d parser.text();\n                }\n            } else if (token \u003d\u003d Token.VALUE_NUMBER) {\n                switch (name) {\n                    case Failure.STATUS_FIELD -\u003e status \u003d parser.intValue();\n                    case SearchFailure.SHARD_FIELD -\u003e shardId \u003d parser.intValue();\n                }\n            }\n        }\n        if (bulkExc !\u003d null) {\n            return new Failure(index, id, bulkExc, RestStatus.fromCode(status));\n        } else if (searchExc !\u003d null) {\n            if (status \u003d\u003d null) {\n                return new SearchFailure(searchExc, index, shardId, nodeId);\n            } else {\n                return new SearchFailure(searchExc, index, shardId, nodeId, RestStatus.fromCode(status));\n            }\n        } else {\n            throw new ElasticsearchParseException(\"failed to parse failures array. At least one of {reason,cause} must be present\");\n        }\n    }\n\n    @Override\n    public String toString() {\n        StringBuilder builder \u003d new StringBuilder();\n        builder.append(getClass().getSimpleName()).append(\"[\");\n        builder.append(\"took\u003d\").append(took).append(\u0027,\u0027);\n        builder.append(\"timed_out\u003d\").append(timedOut).append(\u0027,\u0027);\n        status.innerToString(builder);\n        builder.append(\",bulk_failures\u003d\").append(getBulkFailures().subList(0, min(3, getBulkFailures().size())));\n        builder.append(\",search_failures\u003d\").append(getSearchFailures().subList(0, min(3, getSearchFailures().size())));\n        return builder.append(\u0027]\u0027).toString();\n    }\n}","methodCount":23},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":210,"lineEnd":212,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class ReindexRequest","description":"move method fromXContent to PsiClass:ReindexRequest\nRationale: The fromXContent() method is responsible for parsing and building a response from XContent, which is closely related to the reindexing process. Moving it to ReindexRequest aligns with the Single Responsibility Principle, as it centralizes the parsing logic related to reindexing. This enhances cohesion within the ReindexRequest class. However, care must be taken to ensure that existing references to the method are updated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":210,"lineEnd":212,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class Status","description":"move method fromXContent to PsiClass:Status\nRationale: The fromXContent() method deals with content parsing, which is a common concern for classes that represent a status or response. Moving it to the Status class would improve cohesion, as it would encapsulate the logic for creating a Status object from XContent. This adheres to the Open/Closed Principle by allowing the Status class to be extended with new parsing capabilities without modifying existing code. However, this may lead to additional complexity in the Status class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":210,"lineEnd":212,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class StatusOrException","description":"move method fromXContent to PsiClass:StatusOrException\nRationale: The fromXContent() method could be pertinent to the StatusOrException class, which deals with both status and exception handling. This move would enhance the encapsulation of parsing logic related to statuses, adhering to the Single Responsibility Principle. The class would become more cohesive, focusing on its responsibilities. However, the method\u0027s static nature may require additional refactoring to fit within the instance methods of this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":214,"lineEnd":261,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseFailure to class StatusOrException","description":"move method parseFailure to PsiClass:StatusOrException\nRationale: The parseFailure() method deals with parsing failure information, which is directly related to the StatusOrException class that encapsulates both status and exception data. Moving this method here aligns with the Single Responsibility Principle, as it centralizes failure handling logic, improving cohesion. However, it may require changes in how exceptions are managed in the overall application.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":214,"lineEnd":261,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseFailure to class Status","description":"move method parseFailure to PsiClass:Status\nRationale: The method\u0027s functionality revolves around parsing and interpreting statuses and exceptions, making the Status class a suitable candidate. This move would enhance the encapsulation of status-related logic and adhere to the Open/Closed Principle, allowing for future extensions of status handling without modifying existing code. One consideration is that it may increase the complexity of the Status class if it becomes too overloaded.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":214,"lineEnd":261,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseFailure to class ReindexRequest","description":"move method parseFailure to PsiClass:ReindexRequest\nRationale: The parseFailure() method can be related to reindexing operations, where failure handling is critical. Moving it to ReindexRequest would ensure that failure parsing is closely tied to the operations that may generate such failures, promoting better organization. This aligns with the Interface Segregation Principle by keeping related functionalities together, but it may introduce tight coupling between reindexing and failure parsing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseFailure","method_signature":"private static parseFailure(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseFailure","method_signature":"private static parseFailure(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.5166734121691366},"private static parseFailure(XContentParser parser)":{"first":{"method_name":"parseFailure","method_signature":"private static parseFailure(XContentParser parser)","target_class":"","rationale":""},"second":0.6028058352336259}},"llmMethodPriority":{"priority_method_names":["fromXContent","parseFailure"],"llm_response_time":930},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.23354968324845685},{"class_name":"DocValuesForUtil","similarity_score":0.3642665216327859},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.6268237823899445},{"class_name":"TranslogOperationsUtils","similarity_score":0.27971546389275787},{"class_name":"PForUtil","similarity_score":0.23642082432047912},{"class_name":"ShardUtils","similarity_score":0.37595579019845615},{"class_name":"MapperTestUtils","similarity_score":0.29417420270727607},{"class_name":"StoreUtils","similarity_score":0.3551329370602994},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.2120066237423687},{"class_name":"BinaryRangeUtilTests","similarity_score":0.21113552436360172},{"class_name":"ForUtil","similarity_score":0.11998539740272272},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.41017111471633333},{"class_name":"GeoUtilsTests","similarity_score":0.270229326815727},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.34102052295537294},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.2739941142223066},{"class_name":"ClientScrollableHitSource","similarity_score":0.48705243785456737},{"class_name":"StatusOrException","similarity_score":0.4847960126826988},{"class_name":"Status","similarity_score":0.42796166496889143},{"class_name":"BulkByScrollResponseTests","similarity_score":0.4061889396020238},{"class_name":"BulkByScrollTaskStatusOrExceptionTests","similarity_score":0.40415247446334035},{"class_name":"BulkByScrollTaskStatusTests","similarity_score":0.39575999184249816},{"class_name":"ReindexClientYamlTestSuiteIT","similarity_score":0.5304671043874534},{"class_name":"ReindexRequest","similarity_score":0.4203057881730166},{"class_name":"RemoteInfo","similarity_score":0.45179082408985055},{"class_name":"RestResponseUtils","similarity_score":0.4922885417981453},{"class_name":"JwkValidateUtil","similarity_score":0.32819272417501305},{"class_name":"JwkValidateUtilTests","similarity_score":0.42474977473098274},{"class_name":"RestTestUtil","similarity_score":0.32627307781423887},{"class_name":"JwtUtil","similarity_score":0.4089637343048351}],"target_classes_sorted_by_llm":["ReindexRequest","Status","StatusOrException","RestResponseUtils","ClientScrollableHitSource","RemoteInfo","ReindexClientYamlTestSuiteIT","JwkValidateUtilTests","LiveVersionMapTestUtils","IndexLongFieldRangeTestUtils"],"llm_response_time":12196,"similarity_computation_time":32,"similarity_metric":"voyage"},"parseFailure":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.253558492243661},{"class_name":"GeoUtilsTests","similarity_score":0.6117041363072825},{"class_name":"DocValuesForUtil","similarity_score":0.6160778310022008},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.5060808657892385},{"class_name":"BinaryRangeUtilTests","similarity_score":0.5961977743880778},{"class_name":"ShardUtils","similarity_score":0.4449572299702945},{"class_name":"ForUtil","similarity_score":0.3658810593845531},{"class_name":"MapperTestUtils","similarity_score":0.5433905090018093},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.6545273257429499},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.7182891287315509},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.5587847768517996},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.31869662231165274},{"class_name":"PForUtil","similarity_score":0.5215765170596772},{"class_name":"StoreUtils","similarity_score":0.36091245739042166},{"class_name":"TranslogOperationsUtils","similarity_score":0.23688968483956713},{"class_name":"ClientScrollableHitSource","similarity_score":0.6446827376954489},{"class_name":"BulkByScrollResponseTests","similarity_score":0.7156196074391158},{"class_name":"BulkByScrollTaskStatusOrExceptionTests","similarity_score":0.5242906895774013},{"class_name":"BulkByScrollTaskStatusTests","similarity_score":0.6872923442672801},{"class_name":"Status","similarity_score":0.727495787682109},{"class_name":"StatusOrException","similarity_score":0.7317442208470682},{"class_name":"ReindexClientYamlTestSuiteIT","similarity_score":0.3937744726247417},{"class_name":"ReindexRequest","similarity_score":0.6899388110141774},{"class_name":"RemoteInfo","similarity_score":0.6857857994003311},{"class_name":"RestResponseUtils","similarity_score":0.6535784031403742},{"class_name":"FunctionTestUtils","similarity_score":0.5719412868955477},{"class_name":"RestTestUtil","similarity_score":0.3486972846990852},{"class_name":"FutureUtils","similarity_score":0.4240266595041517},{"class_name":"RestUtils","similarity_score":0.5848917663942781}],"target_classes_sorted_by_llm":["StatusOrException","Status","ReindexRequest","RemoteInfo","BulkByScrollResponseTests","BulkByScrollTaskStatusTests","ClientScrollableHitSource","RestResponseUtils","IpPrefixAutomatonUtil","IndexLongFieldRangeTestUtils"],"llm_response_time":9838,"similarity_computation_time":8,"similarity_metric":"voyage"}}}
{"id":"833ca980-f48e-4855-8b92-17211b106811","methodCount":20,"hostFunctionTelemetryData":{"hostFunctionSize":228,"lineStart":39,"lineEnd":266,"bodyLineStart":39,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/rest/RestResponse.java","sourceCode":"public final class RestResponse {\n\n    public static final String TEXT_CONTENT_TYPE \u003d \"text/plain; charset\u003dUTF-8\";\n\n    private static final String STATUS \u003d \"status\";\n\n    private static final Logger SUPPRESSED_ERROR_LOGGER \u003d LogManager.getLogger(\"rest.suppressed\");\n\n    private final RestStatus status;\n\n    @Nullable\n    private final BytesReference content;\n\n    @Nullable\n    private final ChunkedRestResponseBody chunkedResponseBody;\n    private final String responseMediaType;\n    private Map\u003cString, List\u003cString\u003e\u003e customHeaders;\n\n    /**\n     * Creates a new response based on {@link XContentBuilder}.\n     */\n    public RestResponse(RestStatus status, XContentBuilder builder) {\n        this(status, builder.getResponseContentTypeString(), BytesReference.bytes(builder));\n    }\n\n    /**\n     * Creates a new plain text response.\n     */\n    public RestResponse(RestStatus status, String content) {\n        this(status, TEXT_CONTENT_TYPE, new BytesArray(content));\n    }\n\n    /**\n     * Creates a new plain text response.\n     */\n    public RestResponse(RestStatus status, String responseMediaType, String content) {\n        this(status, responseMediaType, new BytesArray(content));\n    }\n\n    public RestResponse(RestStatus status, String responseMediaType, BytesReference content) {\n        this(status, responseMediaType, content, null);\n    }\n\n    public static RestResponse chunked(RestStatus restStatus, ChunkedRestResponseBody content) {\n        if (content.isDone()) {\n            return new RestResponse(\n                restStatus,\n                content.getResponseContentTypeString(),\n                new ReleasableBytesReference(BytesArray.EMPTY, content)\n            );\n        } else {\n            return new RestResponse(restStatus, content.getResponseContentTypeString(), null, content);\n        }\n    }\n\n    /**\n     * Creates a binary response.\n     */\n    private RestResponse(\n        RestStatus status,\n        String responseMediaType,\n        @Nullable BytesReference content,\n        @Nullable ChunkedRestResponseBody chunkedResponseBody\n    ) {\n        this.status \u003d status;\n        this.content \u003d content;\n        this.responseMediaType \u003d responseMediaType;\n        this.chunkedResponseBody \u003d chunkedResponseBody;\n        assert (content \u003d\u003d null) !\u003d (chunkedResponseBody \u003d\u003d null);\n    }\n\n    public RestResponse(RestChannel channel, Exception e) throws IOException {\n        this(channel, ExceptionsHelper.status(e), e);\n    }\n\n    public RestResponse(RestChannel channel, RestStatus status, Exception e) throws IOException {\n        this.status \u003d status;\n        ToXContent.Params params \u003d channel.request();\n        if (e !\u003d null) {\n            Supplier\u003c?\u003e messageSupplier \u003d () -\u003e String.format(\n                Locale.ROOT,\n                \"path: %s, params: %s, status: %d\",\n                channel.request().rawPath(),\n                channel.request().params(),\n                status.getStatus()\n            );\n            if (status.getStatus() \u003c 500) {\n                SUPPRESSED_ERROR_LOGGER.debug(messageSupplier, e);\n            } else {\n                SUPPRESSED_ERROR_LOGGER.warn(messageSupplier, e);\n            }\n        }\n        // if \"error_trace\" is turned on in the request, we want to render it in the rest response\n        // for that the REST_EXCEPTION_SKIP_STACK_TRACE flag that if \"true\" omits the stack traces is\n        // switched in the xcontent rendering parameters.\n        // For authorization problems (RestStatus.UNAUTHORIZED) we don\u0027t want to do this since this could\n        // leak information to the caller who is unauthorized to make this call\n        if (params.paramAsBoolean(\"error_trace\", false) \u0026\u0026 status !\u003d RestStatus.UNAUTHORIZED) {\n            params \u003d new ToXContent.DelegatingMapParams(singletonMap(REST_EXCEPTION_SKIP_STACK_TRACE, \"false\"), params);\n        }\n        try (XContentBuilder builder \u003d channel.newErrorBuilder()) {\n            build(builder, params, status, channel.detailedErrorsEnabled(), e);\n            this.content \u003d BytesReference.bytes(builder);\n            this.responseMediaType \u003d builder.getResponseContentTypeString();\n        }\n        if (e instanceof ElasticsearchException) {\n            copyHeaders(((ElasticsearchException) e));\n        }\n        this.chunkedResponseBody \u003d null;\n    }\n\n    public String contentType() {\n        return this.responseMediaType;\n    }\n\n    @Nullable\n    public BytesReference content() {\n        return this.content;\n    }\n\n    @Nullable\n    public ChunkedRestResponseBody chunkedContent() {\n        return chunkedResponseBody;\n    }\n\n    public boolean isChunked() {\n        return chunkedResponseBody !\u003d null;\n    }\n\n    public RestStatus status() {\n        return this.status;\n    }\n\n    private static void build(\n        XContentBuilder builder,\n        ToXContent.Params params,\n        RestStatus status,\n        boolean detailedErrorsEnabled,\n        Exception e\n    ) throws IOException {\n        builder.startObject();\n        ElasticsearchException.generateFailureXContent(builder, params, e, detailedErrorsEnabled);\n        builder.field(STATUS, status.getStatus());\n        builder.endObject();\n    }\n\n    static RestResponse createSimpleErrorResponse(RestChannel channel, RestStatus status, String errorMessage) throws IOException {\n        return new RestResponse(\n            status,\n            channel.newErrorBuilder().startObject().field(\"error\", errorMessage).field(\"status\", status.getStatus()).endObject()\n        );\n    }\n\n    public static ElasticsearchStatusException errorFromXContent(XContentParser parser) throws IOException {\n        XContentParser.Token token \u003d parser.nextToken();\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser);\n\n        ElasticsearchException exception \u003d null;\n        RestStatus status \u003d null;\n\n        String currentFieldName \u003d null;\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            if (token \u003d\u003d XContentParser.Token.FIELD_NAME) {\n                currentFieldName \u003d parser.currentName();\n            }\n            if (STATUS.equals(currentFieldName)) {\n                if (token !\u003d XContentParser.Token.FIELD_NAME) {\n                    ensureExpectedToken(XContentParser.Token.VALUE_NUMBER, token, parser);\n                    status \u003d RestStatus.fromCode(parser.intValue());\n                }\n            } else {\n                exception \u003d ElasticsearchException.failureFromXContent(parser);\n            }\n        }\n\n        if (exception \u003d\u003d null) {\n            throw new IllegalStateException(\"Failed to parse elasticsearch status exception: no exception was found\");\n        }\n\n        ElasticsearchStatusException result \u003d new ElasticsearchStatusException(exception.getMessage(), status, exception.getCause());\n        for (String header : exception.getHeaderKeys()) {\n            result.addHeader(header, exception.getHeader(header));\n        }\n        for (String metadata : exception.getMetadataKeys()) {\n            result.addMetadata(metadata, exception.getMetadata(metadata));\n        }\n        return result;\n    }\n\n    public void copyHeaders(ElasticsearchException ex) {\n        Set\u003cString\u003e headerKeySet \u003d ex.getHeaderKeys();\n        if (customHeaders \u003d\u003d null) {\n            customHeaders \u003d Maps.newMapWithExpectedSize(headerKeySet.size());\n        }\n        for (String key : headerKeySet) {\n            customHeaders.computeIfAbsent(key, k -\u003e new ArrayList\u003c\u003e()).addAll(ex.getHeader(key));\n        }\n    }\n\n    /**\n     * Add a custom header.\n     */\n    public void addHeader(String name, String value) {\n        if (customHeaders \u003d\u003d null) {\n            customHeaders \u003d Maps.newMapWithExpectedSize(2);\n        }\n        customHeaders.computeIfAbsent(name, k -\u003e new ArrayList\u003c\u003e()).add(value);\n    }\n\n    /**\n     * Returns custom headers that have been added. This method should not be used to mutate headers.\n     */\n    public Map\u003cString, List\u003cString\u003e\u003e getHeaders() {\n        return Objects.requireNonNullElse(customHeaders, Map.of());\n    }\n\n    public Map\u003cString, List\u003cString\u003e\u003e filterHeaders(Map\u003cString, List\u003cString\u003e\u003e headers) {\n        if (status() \u003d\u003d RestStatus.UNAUTHORIZED || status() \u003d\u003d RestStatus.FORBIDDEN) {\n            if (headers.containsKey(\"Warning\")) {\n                headers \u003d Maps.copyMapWithRemovedEntry(headers, \"Warning\");\n            }\n            if (headers.containsKey(ELASTIC_PRODUCT_HTTP_HEADER)) {\n                headers \u003d Maps.copyMapWithRemovedEntry(headers, ELASTIC_PRODUCT_HTTP_HEADER);\n            }\n        }\n        return headers;\n    }\n}","methodCount":20},"candidatesTelemetryData":{"numberOfSuggestions":8,"candidates":[{"lineStart":171,"lineEnd":182,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method build to class RestValidateQueryAction","description":"move method build to PsiClass:RestValidateQueryAction\nRationale: The build() method is responsible for constructing error responses, which aligns closely with the responsibilities of RestValidateQueryAction, as it handles query validation and related exceptions. Moving this method here would enhance cohesion, as it directly relates to the action\u0027s purpose. This aligns with the Single Responsibility Principle by keeping error handling logic within the context of query validation. However, care should be taken to ensure that dependencies on XContentBuilder are properly managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":171,"lineEnd":182,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method build to class RestTasksAction","description":"move method build to PsiClass:RestTasksAction\nRationale: RestTasksAction deals with RESTful tasks and responses, making it a suitable candidate for the build() method, which constructs response content. This move would improve the separation of concerns by placing response-building logic in the class that handles task-related requests. It adheres to the Open/Closed Principle, as the class can be extended without modifying existing code. However, it might clutter the class with additional responsibilities if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":171,"lineEnd":182,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method build to class RestTable","description":"move method build to PsiClass:RestTable\nRationale: RestTable is focused on building and rendering response tables. The build() method\u0027s functionality for generating error responses could fit well here, enhancing the table\u0027s capability to handle error scenarios. This adheres to the Single Responsibility Principle by consolidating response-building logic. However, it may introduce complexity if the table class becomes overloaded with various response types.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":184,"lineEnd":189,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createSimpleErrorResponse to class RestResponseUtils","description":"move method createSimpleErrorResponse to PsiClass:RestResponseUtils\nRationale: The createSimpleErrorResponse() method is responsible for creating a specific type of response object, which aligns closely with the purpose of RestResponseUtils, a class likely focused on utility methods for handling RestResponse objects. Moving this method here adheres to the Single Responsibility Principle, as it centralizes response-related logic. This enhances code cohesion and reusability. However, it\u0027s essential to ensure that RestResponseUtils is not overloaded with too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":184,"lineEnd":189,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createSimpleErrorResponse to class RestValidateQueryAction","description":"move method createSimpleErrorResponse to PsiClass:RestValidateQueryAction\nRationale: RestValidateQueryAction appears to handle various operations related to REST validation and error handling. The createSimpleErrorResponse() method fits well within this context, as it deals with error response creation. This move would improve the organization of error handling logic and maintain a cohesive class structure. However, care must be taken to avoid tightly coupling this utility with validation logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":184,"lineEnd":189,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createSimpleErrorResponse to class RestRolloverIndexAction","description":"move method createSimpleErrorResponse to PsiClass:RestRolloverIndexAction\nRationale: RestRolloverIndexAction may require error responses while handling rollover operations. By moving createSimpleErrorResponse() here, we can keep related functionality together, enhancing maintainability. This aligns with the Open/Closed Principle, allowing the class to be extended with error handling without modifying existing code. However, the relevance of this method to rollover operations should be carefully evaluated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":163,"lineEnd":165,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method isChunked to class ChunkedRestResponseBody","description":"Move method isChunked to org.elasticsearch.rest.ChunkedRestResponseBody\nRationale: The isChunked() method checks if the chunkedResponseBody is not null, which directly relates to the state of a chunked response. Moving this method to ChunkedRestResponseBody enhances cohesion, as this class is responsible for chunked responses. This aligns with the Single Responsibility Principle, as it centralizes chunked response logic. By relocating the method, we improve the clarity of the codebase, making it easier to maintain. However, we should consider that if there are existing dependencies on the method in its current class, it may require updates to those call sites.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":163,"lineEnd":165,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method isChunked to class BytesReference","description":"Move method isChunked to org.elasticsearch.common.bytes.BytesReference\nRationale: Although BytesReference does not inherently manage the concept of chunked responses, relocating isChunked() here could be justified if BytesReference is used to represent the underlying data of the chunked response. This move could enhance the utility of BytesReference by providing a method that checks for chunked data. However, this may dilute the class\u0027s focus on byte manipulation, potentially violating the Single Responsibility Principle. Careful consideration of how the method interacts with the state of BytesReference is necessary to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"chunked","method_signature":"public static chunked(RestStatus restStatus, ChunkedRestResponseBody content)","target_class":"","rationale":""},{"method_name":"isChunked","method_signature":"public isChunked()","target_class":"","rationale":""},{"method_name":"build","method_signature":"private static build(\n        XContentBuilder builder,\n        ToXContent.Params params,\n        RestStatus status,\n        boolean detailedErrorsEnabled,\n        Exception e\n    )","target_class":"","rationale":""},{"method_name":"createSimpleErrorResponse","method_signature":"static createSimpleErrorResponse(RestChannel channel, RestStatus status, String errorMessage)","target_class":"","rationale":""},{"method_name":"errorFromXContent","method_signature":"public static errorFromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"copyHeaders","method_signature":"public copyHeaders(ElasticsearchException ex)","target_class":"","rationale":""},{"method_name":"addHeader","method_signature":"public addHeader(String name, String value)","target_class":"","rationale":""},{"method_name":"filterHeaders","method_signature":"public filterHeaders(Map\u003cString, List\u003cString\u003e\u003e headers)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"build","method_signature":"private static build(\n        XContentBuilder builder,\n        ToXContent.Params params,\n        RestStatus status,\n        boolean detailedErrorsEnabled,\n        Exception e\n    )","target_class":"","rationale":""},{"method_name":"createSimpleErrorResponse","method_signature":"static createSimpleErrorResponse(RestChannel channel, RestStatus status, String errorMessage)","target_class":"","rationale":""},{"method_name":"isChunked","method_signature":"public isChunked()","target_class":"","rationale":""},{"method_name":"chunked","method_signature":"public static chunked(RestStatus restStatus, ChunkedRestResponseBody content)","target_class":"","rationale":""},{"method_name":"addHeader","method_signature":"public addHeader(String name, String value)","target_class":"","rationale":""},{"method_name":"filterHeaders","method_signature":"public filterHeaders(Map\u003cString, List\u003cString\u003e\u003e headers)","target_class":"","rationale":""},{"method_name":"copyHeaders","method_signature":"public copyHeaders(ElasticsearchException ex)","target_class":"","rationale":""},{"method_name":"errorFromXContent","method_signature":"public static errorFromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static build(\n        XContentBuilder builder,\n        ToXContent.Params params,\n        RestStatus status,\n        boolean detailedErrorsEnabled,\n        Exception e\n    )":{"first":{"method_name":"build","method_signature":"private static build(\n        XContentBuilder builder,\n        ToXContent.Params params,\n        RestStatus status,\n        boolean detailedErrorsEnabled,\n        Exception e\n    )","target_class":"","rationale":""},"second":0.32293490288470633},"static createSimpleErrorResponse(RestChannel channel, RestStatus status, String errorMessage)":{"first":{"method_name":"createSimpleErrorResponse","method_signature":"static createSimpleErrorResponse(RestChannel channel, RestStatus status, String errorMessage)","target_class":"","rationale":""},"second":0.45759548833410224},"public isChunked()":{"first":{"method_name":"isChunked","method_signature":"public isChunked()","target_class":"","rationale":""},"second":0.5084860290023433},"public static chunked(RestStatus restStatus, ChunkedRestResponseBody content)":{"first":{"method_name":"chunked","method_signature":"public static chunked(RestStatus restStatus, ChunkedRestResponseBody content)","target_class":"","rationale":""},"second":0.5771360701354629},"public addHeader(String name, String value)":{"first":{"method_name":"addHeader","method_signature":"public addHeader(String name, String value)","target_class":"","rationale":""},"second":0.6485866577165891},"public filterHeaders(Map\u003cString, List\u003cString\u003e\u003e headers)":{"first":{"method_name":"filterHeaders","method_signature":"public filterHeaders(Map\u003cString, List\u003cString\u003e\u003e headers)","target_class":"","rationale":""},"second":0.6599595713083224},"public copyHeaders(ElasticsearchException ex)":{"first":{"method_name":"copyHeaders","method_signature":"public copyHeaders(ElasticsearchException ex)","target_class":"","rationale":""},"second":0.6728283975590812},"public static errorFromXContent(XContentParser parser)":{"first":{"method_name":"errorFromXContent","method_signature":"public static errorFromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.7156114060114472}},"llmMethodPriority":{"priority_method_names":["build","createSimpleErrorResponse","isChunked","chunked","addHeader","filterHeaders","copyHeaders","errorFromXContent"],"llm_response_time":2334},"targetClassMap":{"build":{"target_classes":[{"class_name":"RestResponseUtils","similarity_score":0.2295649473717813},{"class_name":"RestUtils","similarity_score":0.17250746371786277},{"class_name":"RestUtilsTests","similarity_score":0.12174744156040981},{"class_name":"RestPutMappingAction","similarity_score":0.177479490409833},{"class_name":"CreateHandler","similarity_score":0.23084959616632805},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.1152158142035587},{"class_name":"RestRequest","similarity_score":0.23064974985457157},{"class_name":"RestRequestTests","similarity_score":0.28128809510654534},{"class_name":"RestResponseTests","similarity_score":0.21830173819734208},{"class_name":"FunctionTestUtils","similarity_score":0.23451172019395863},{"class_name":"RestRolloverIndexAction","similarity_score":0.2372055739681903},{"class_name":"RestSearchAction","similarity_score":0.2199843441366424},{"class_name":"FutureUtils","similarity_score":0.17754835227559765},{"class_name":"JwkValidateUtil","similarity_score":0.18230403036922407},{"class_name":"JwkValidateUtilTests","similarity_score":0.30643232017494254},{"class_name":"RestShardsAction","similarity_score":0.11020583059370541},{"class_name":"RestSimulateIngestAction","similarity_score":0.22019666280186495},{"class_name":"RestTable","similarity_score":0.2475193713264402},{"class_name":"RestTableTests","similarity_score":0.24523839345548698},{"class_name":"RestTasksAction","similarity_score":0.2589237238101102},{"class_name":"RestTermVectorsAction","similarity_score":0.22266361107641236},{"class_name":"JwtUtil","similarity_score":0.22308515031097964},{"class_name":"GceMockUtils","similarity_score":0.27893738259911915},{"class_name":"RestTestUtil","similarity_score":0.16570304724394835},{"class_name":"CredentialsRedaction","similarity_score":0.222110327843415},{"class_name":"RestValidateQueryAction","similarity_score":0.3142829868339866},{"class_name":"CryptUtils","similarity_score":0.2350271983231432},{"class_name":"GeneratorUtils","similarity_score":0.2886262206204471},{"class_name":"CheckedFunctionUtils","similarity_score":0.07994139778789369}],"target_classes_sorted_by_llm":["RestValidateQueryAction","RestTasksAction","RestTable","RestRolloverIndexAction","GeneratorUtils","GceMockUtils","CryptUtils","RestRequestTests","RestTableTests","JwkValidateUtilTests"],"llm_response_time":13885,"similarity_computation_time":37,"similarity_metric":"voyage"},"createSimpleErrorResponse":{"target_classes":[{"class_name":"RestResponseUtils","similarity_score":0.3319008671725395},{"class_name":"RestUtils","similarity_score":0.24037983415179073},{"class_name":"RestUtilsTests","similarity_score":0.14754639334070024},{"class_name":"RestPutMappingAction","similarity_score":0.31201964135144505},{"class_name":"MapperTestUtils","similarity_score":0.2908872369413698},{"class_name":"RestRequest","similarity_score":0.3316684567767075},{"class_name":"RestRequestTests","similarity_score":0.2780982164717499},{"class_name":"RestResponseTests","similarity_score":0.34500613353834636},{"class_name":"RestRolloverIndexAction","similarity_score":0.32907834523264495},{"class_name":"RestSearchAction","similarity_score":0.28864987883530596},{"class_name":"RestShardsAction","similarity_score":0.19197598705106303},{"class_name":"RestSimulateIngestAction","similarity_score":0.2765135750759098},{"class_name":"FunctionTestUtils","similarity_score":0.33491803172797313},{"class_name":"RestTable","similarity_score":0.3410186241404018},{"class_name":"RestTableTests","similarity_score":0.2750532129833276},{"class_name":"RestTasksAction","similarity_score":0.27604178020685777},{"class_name":"RestTermVectorsAction","similarity_score":0.35059853705761496},{"class_name":"FutureUtils","similarity_score":0.2562647884338478},{"class_name":"JwkValidateUtil","similarity_score":0.2631289064327066},{"class_name":"JwkValidateUtilTests","similarity_score":0.30273002483091715},{"class_name":"RestTestUtil","similarity_score":0.19024714740568088},{"class_name":"RestValidateQueryAction","similarity_score":0.40760978927249747},{"class_name":"GceMockUtils","similarity_score":0.4530420531158197},{"class_name":"JwtUtil","similarity_score":0.31071355908330844},{"class_name":"ExceptionUtils","similarity_score":0.27695585470349865},{"class_name":"MathUtils","similarity_score":0.14382062372263343},{"class_name":"RetentionLeaseUtils","similarity_score":0.14433756729740643},{"class_name":"GeneratorUtils","similarity_score":0.3012525667990101},{"class_name":"ExecutionUtils","similarity_score":0.335012605086404}],"target_classes_sorted_by_llm":["RestResponseUtils","RestValidateQueryAction","RestRolloverIndexAction","RestTermVectorsAction","RestResponseTests","RestTable","GceMockUtils","ExecutionUtils","FunctionTestUtils","RestRequest"],"llm_response_time":14836,"similarity_computation_time":6,"similarity_metric":"voyage"},"isChunked":{"target_classes":[{"class_name":"BytesReference","similarity_score":0.23885231210229393},{"class_name":"ChunkedRestResponseBody","similarity_score":0.4858215540788367}],"target_classes_sorted_by_llm":["ChunkedRestResponseBody","BytesReference"],"llm_response_time":3413,"similarity_computation_time":2,"similarity_metric":"voyage"}}}
{"id":"a5358a43-4bcc-498d-bbb7-0b613f2b0331","methodCount":7,"hostFunctionTelemetryData":{"hostFunctionSize":74,"lineStart":32,"lineEnd":105,"bodyLineStart":32,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/inference/src/main/java/org/elasticsearch/xpack/inference/external/request/openai/OpenAiEmbeddingsRequest.java","sourceCode":"public class OpenAiEmbeddingsRequest implements Request {\n\n    private final Truncator truncator;\n    private final OpenAiAccount account;\n    private final Truncator.TruncationResult truncationResult;\n    private final URI uri;\n    private final OpenAiEmbeddingsTaskSettings taskSettings;\n\n    public OpenAiEmbeddingsRequest(\n        Truncator truncator,\n        OpenAiAccount account,\n        Truncator.TruncationResult input,\n        OpenAiEmbeddingsTaskSettings taskSettings\n    ) {\n        this.truncator \u003d Objects.requireNonNull(truncator);\n        this.account \u003d Objects.requireNonNull(account);\n        this.truncationResult \u003d Objects.requireNonNull(input);\n        this.uri \u003d buildUri(this.account.url());\n        this.taskSettings \u003d Objects.requireNonNull(taskSettings);\n    }\n\n    private static URI buildUri(URI accountUri) {\n        try {\n            return accountUri \u003d\u003d null ? buildDefaultUri() : accountUri;\n        } catch (URISyntaxException e) {\n            throw new ElasticsearchStatusException(\"Failed to construct OpenAI URL\", RestStatus.INTERNAL_SERVER_ERROR, e);\n        }\n    }\n\n    public HttpRequestBase createRequest() {\n        HttpPost httpPost \u003d new HttpPost(uri);\n\n        ByteArrayEntity byteEntity \u003d new ByteArrayEntity(\n            Strings.toString(new OpenAiEmbeddingsRequestEntity(truncationResult.input(), taskSettings.model(), taskSettings.user()))\n                .getBytes(StandardCharsets.UTF_8)\n        );\n        httpPost.setEntity(byteEntity);\n\n        httpPost.setHeader(HttpHeaders.CONTENT_TYPE, XContentType.JSON.mediaType());\n        httpPost.setHeader(createAuthBearerHeader(account.apiKey()));\n\n        var org \u003d account.organizationId();\n        if (org !\u003d null) {\n            httpPost.setHeader(createOrgHeader(org));\n        }\n\n        return httpPost;\n    }\n\n    @Override\n    public URI getURI() {\n        return uri;\n    }\n\n    @Override\n    public Request truncate() {\n        var truncatedInput \u003d truncator.truncate(truncationResult.input());\n\n        return new OpenAiEmbeddingsRequest(truncator, account, truncatedInput, taskSettings);\n    }\n\n    @Override\n    public boolean[] getTruncationInfo() {\n        return truncationResult.truncated().clone();\n    }\n\n    // default for testing\n    static URI buildDefaultUri() throws URISyntaxException {\n        return new URIBuilder().setScheme(\"https\")\n            .setHost(OpenAiUtils.HOST)\n            .setPathSegments(OpenAiUtils.VERSION_1, OpenAiUtils.EMBEDDINGS_PATH)\n            .build();\n    }\n}","methodCount":7},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":97,"lineEnd":103,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildDefaultUri to class ServiceUtils","description":"move method buildDefaultUri to PsiClass:ServiceUtils\nRationale: The buildDefaultUri() method is concerned with constructing a URI, which aligns with the responsibilities of ServiceUtils, particularly with methods like createUri. Moving it here adheres to the Single Responsibility Principle, as it centralizes URI creation logic. This enhances cohesion and makes it easier to manage URI-related utilities. However, care must be taken to ensure that the method\u0027s dependencies are properly handled.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":97,"lineEnd":103,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildDefaultUri to class HttpUtils","description":"move method buildDefaultUri to PsiClass:HttpUtils\nRationale: HttpUtils is designed for handling HTTP-related operations, making it a suitable candidate for buildDefaultUri(). The method\u0027s purpose of creating a URI for HTTP requests fits well within this class, promoting better organization of HTTP utilities. This move would also align with the Interface Segregation Principle by keeping HTTP-related methods together. One potential drawback is that the class may become too broad if it accumulates too many unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":97,"lineEnd":103,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildDefaultUri to class Utils","description":"move method buildDefaultUri to PsiClass:Utils\nRationale: The Utils class serves as a general-purpose utility class, making it a reasonable target for buildDefaultUri(). This method is a utility function for URI construction, which aligns with the class\u0027s intended use. Moving it here enhances reusability across various components. However, this may lead to a bloated Utils class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":52,"lineEnd":58,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildUri to class ServiceUtils","description":"move method buildUri to PsiClass:ServiceUtils\nRationale: The buildUri() method is responsible for constructing URIs, which aligns closely with the responsibilities of ServiceUtils, particularly the createUri method. Moving it here adheres to the Single Responsibility Principle by placing URI construction logic in a dedicated utility class. This enhances cohesion and reusability. However, it may require refactoring existing calls to ensure they reference the new location.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":52,"lineEnd":58,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildUri to class HttpUtils","description":"move method buildUri to PsiClass:HttpUtils\nRationale: HttpUtils deals with HTTP-related utilities, and since URIs are fundamental to HTTP requests, this method fits well here. This move improves the organization of HTTP-related functionalities, adhering to the Open/Closed Principle by allowing for future enhancements related to URI handling without modifying existing code. A potential drawback is that it may blur the line between HTTP utilities and general URI construction.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":52,"lineEnd":58,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildUri to class OpenAiEmbeddingsAction","description":"move method buildUri to PsiClass:OpenAiEmbeddingsAction\nRationale: As the method relates to constructing a URI that could be used in OpenAI interactions, moving it to OpenAiEmbeddingsAction could enhance the class\u0027s encapsulation of OpenAI-specific logic. This aligns with the Single Responsibility Principle by ensuring that all OpenAI-related functionalities are in one place. However, this could lead to a bloated class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"buildUri","method_signature":"private static buildUri(URI accountUri)","target_class":"","rationale":""},{"method_name":"createRequest","method_signature":"public createRequest()","target_class":"","rationale":""},{"method_name":"buildDefaultUri","method_signature":"static buildDefaultUri()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"buildDefaultUri","method_signature":"static buildDefaultUri()","target_class":"","rationale":""},{"method_name":"buildUri","method_signature":"private static buildUri(URI accountUri)","target_class":"","rationale":""},{"method_name":"createRequest","method_signature":"public createRequest()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static buildDefaultUri()":{"first":{"method_name":"buildDefaultUri","method_signature":"static buildDefaultUri()","target_class":"","rationale":""},"second":0.41181384541422816},"private static buildUri(URI accountUri)":{"first":{"method_name":"buildUri","method_signature":"private static buildUri(URI accountUri)","target_class":"","rationale":""},"second":0.43350024501984585},"public createRequest()":{"first":{"method_name":"createRequest","method_signature":"public createRequest()","target_class":"","rationale":""},"second":0.4479649473944039}},"llmMethodPriority":{"priority_method_names":["buildDefaultUri","buildUri","createRequest"],"llm_response_time":1017},"targetClassMap":{"buildDefaultUri":{"target_classes":[{"class_name":"OpenAiUtils","similarity_score":0.2215114342210649},{"class_name":"RequestUtils","similarity_score":0.31180478223116176},{"class_name":"ActionUtils","similarity_score":0.34426518632954817},{"class_name":"HttpUtils","similarity_score":0.34176827757349804},{"class_name":"Utils","similarity_score":0.3826106591091121},{"class_name":"XContentUtils","similarity_score":0.22124616267552527},{"class_name":"OpenAiEmbeddingsRequestTests","similarity_score":0.18086891559485352},{"class_name":"ServiceUtils","similarity_score":0.3641332684813158},{"class_name":"ServiceUtilsTests","similarity_score":0.17771506862546305},{"class_name":"OpenAiEmbeddingsAction","similarity_score":0.274510701715116},{"class_name":"OpenAiEmbeddingsResponseEntity","similarity_score":0.17391639824998367},{"class_name":"OpenAiErrorResponseEntity","similarity_score":0.2360262499098192},{"class_name":"HuggingFaceInferenceRequestTests","similarity_score":0.21581265312817066},{"class_name":"JwkValidateUtil","similarity_score":0.3074283577062325},{"class_name":"JwkValidateUtilTests","similarity_score":0.37990774789048004},{"class_name":"JwtUtil","similarity_score":0.3713586640559489},{"class_name":"ProcessBuilderUtils","similarity_score":0.25719617182421983},{"class_name":"MathUtils","similarity_score":0.24733283866815067},{"class_name":"MlConfigVersionUtils","similarity_score":0.3180680983297402},{"class_name":"NumericUtilsTests","similarity_score":0.11215993622202693},{"class_name":"MlIndicesUtils","similarity_score":0.2182178902359924},{"class_name":"MlParserUtils","similarity_score":0.2415472446438463},{"class_name":"MlPlatformArchitecturesUtil","similarity_score":0.3052954924178079},{"class_name":"ModelLoaderUtils","similarity_score":0.41320573786735093},{"class_name":"MetadataUtils","similarity_score":0.27888667551135854},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.3360301749227812},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.20079410351733457},{"class_name":"NativeRealmValidationUtil","similarity_score":0.17141982574219336},{"class_name":"MonitoringTemplateUtils","similarity_score":0.10335051907928562}],"target_classes_sorted_by_llm":["ServiceUtils","HttpUtils","Utils","JwtUtil","RequestUtils","ModelLoaderUtils","ActionUtils","MlConfigVersionUtils","RollupJobIdentifierUtils","JwkValidateUtilTests"],"llm_response_time":14554,"similarity_computation_time":23,"similarity_metric":"voyage"},"buildUri":{"target_classes":[{"class_name":"OpenAiUtils","similarity_score":0.2575985261284894},{"class_name":"RequestUtils","similarity_score":0.4558423058385518},{"class_name":"ActionUtils","similarity_score":0.5642439296272598},{"class_name":"Utils","similarity_score":0.4894371996441298},{"class_name":"XContentUtils","similarity_score":0.38290811597191543},{"class_name":"HttpUtils","similarity_score":0.49749371855331004},{"class_name":"OpenAiEmbeddingsRequestTests","similarity_score":0.21690777583847928},{"class_name":"ServiceUtils","similarity_score":0.5549967480754564},{"class_name":"ServiceUtilsTests","similarity_score":0.26230832264862824},{"class_name":"OpenAiEmbeddingsAction","similarity_score":0.5420005246903077},{"class_name":"OpenAiEmbeddingsResponseEntity","similarity_score":0.23836564731139812},{"class_name":"OpenAiErrorResponseEntity","similarity_score":0.4025677244760143},{"class_name":"HuggingFaceInferenceRequestTests","similarity_score":0.24005954215059574},{"class_name":"JwkValidateUtil","similarity_score":0.4418930559038226},{"class_name":"JwkValidateUtilTests","similarity_score":0.49755056742425285},{"class_name":"JwtUtil","similarity_score":0.5373930716057974},{"class_name":"MathUtils","similarity_score":0.2937899995586196},{"class_name":"TemplateUtils","similarity_score":0.45403500503393},{"class_name":"TemplateUtilsTests","similarity_score":0.4749086662572845},{"class_name":"Term","similarity_score":0.40975858490347444},{"class_name":"NumericUtilsTests","similarity_score":0.1781872803549726},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.4751810116196501},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.20765596404059292},{"class_name":"SourceUtils","similarity_score":0.4587843755885224},{"class_name":"MetadataUtils","similarity_score":0.35675303400633784},{"class_name":"RuntimeUtils","similarity_score":0.5750671542522984},{"class_name":"SqlTestUtils","similarity_score":0.5193582807616579},{"class_name":"TestUtils","similarity_score":0.5366477283049864},{"class_name":"SSLEngineUtils","similarity_score":0.5476832251610341}],"target_classes_sorted_by_llm":["ServiceUtils","HttpUtils","OpenAiEmbeddingsAction","RuntimeUtils","JwtUtil","ActionUtils","SSLEngineUtils","TestUtils","SqlTestUtils","JwkValidateUtilTests"],"llm_response_time":12575,"similarity_computation_time":12,"similarity_metric":"voyage"},"createRequest":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":1702,"similarity_computation_time":2,"similarity_metric":"voyage"}}}
{"id":"71fc59db-2893-47f6-bb50-32ab77ea3d93","methodCount":16,"hostFunctionTelemetryData":{"hostFunctionSize":172,"lineStart":36,"lineEnd":207,"bodyLineStart":36,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/inference/src/main/java/org/elasticsearch/xpack/inference/services/openai/OpenAiServiceSettings.java","sourceCode":"/**\n * Defines the base settings for interacting with OpenAI.\n */\npublic class OpenAiServiceSettings implements ServiceSettings {\n\n    public static final String NAME \u003d \"openai_service_settings\";\n\n    public static final String ORGANIZATION \u003d \"organization_id\";\n\n    public static OpenAiServiceSettings fromMap(Map\u003cString, Object\u003e map) {\n        ValidationException validationException \u003d new ValidationException();\n\n        String url \u003d extractOptionalString(map, URL, ModelConfigurations.SERVICE_SETTINGS, validationException);\n        String organizationId \u003d extractOptionalString(map, ORGANIZATION, ModelConfigurations.SERVICE_SETTINGS, validationException);\n        SimilarityMeasure similarity \u003d extractSimilarity(map, ModelConfigurations.SERVICE_SETTINGS, validationException);\n        Integer dims \u003d removeAsType(map, DIMENSIONS, Integer.class);\n        Integer maxInputTokens \u003d removeAsType(map, MAX_INPUT_TOKENS, Integer.class);\n\n        // Throw if any of the settings were empty strings or invalid\n        if (validationException.validationErrors().isEmpty() \u003d\u003d false) {\n            throw validationException;\n        }\n\n        // the url is optional and only for testing\n        if (url \u003d\u003d null) {\n            return new OpenAiServiceSettings((URI) null, organizationId, similarity, dims, maxInputTokens);\n        }\n\n        URI uri \u003d convertToUri(url, URL, ModelConfigurations.SERVICE_SETTINGS, validationException);\n\n        if (validationException.validationErrors().isEmpty() \u003d\u003d false) {\n            throw validationException;\n        }\n\n        return new OpenAiServiceSettings(uri, organizationId, similarity, dims, maxInputTokens);\n    }\n\n    private final URI uri;\n    private final String organizationId;\n    private final SimilarityMeasure similarity;\n    private final Integer dimensions;\n    private final Integer maxInputTokens;\n\n    public OpenAiServiceSettings(\n        @Nullable URI uri,\n        @Nullable String organizationId,\n        @Nullable SimilarityMeasure similarity,\n        @Nullable Integer dimensions,\n        @Nullable Integer maxInputTokens\n    ) {\n        this.uri \u003d uri;\n        this.organizationId \u003d organizationId;\n        this.similarity \u003d similarity;\n        this.dimensions \u003d dimensions;\n        this.maxInputTokens \u003d maxInputTokens;\n    }\n\n    public OpenAiServiceSettings(\n        @Nullable String uri,\n        @Nullable String organizationId,\n        @Nullable SimilarityMeasure similarity,\n        @Nullable Integer dimensions,\n        @Nullable Integer maxInputTokens\n    ) {\n        this(createOptionalUri(uri), organizationId, similarity, dimensions, maxInputTokens);\n    }\n\n    private static URI createOptionalUri(String url) {\n        if (url \u003d\u003d null) {\n            return null;\n        }\n\n        return createUri(url);\n    }\n\n    public OpenAiServiceSettings(StreamInput in) throws IOException {\n        uri \u003d createOptionalUri(in.readOptionalString());\n        organizationId \u003d in.readOptionalString();\n        if (in.getTransportVersion().onOrAfter(TransportVersions.INFERENCE_SERVICE_EMBEDDING_SIZE_ADDED)) {\n            similarity \u003d in.readOptionalEnum(SimilarityMeasure.class);\n            dimensions \u003d in.readOptionalVInt();\n            maxInputTokens \u003d in.readOptionalVInt();\n        } else {\n            similarity \u003d null;\n            dimensions \u003d null;\n            maxInputTokens \u003d null;\n        }\n    }\n\n    public URI uri() {\n        return uri;\n    }\n\n    public String organizationId() {\n        return organizationId;\n    }\n\n    public SimilarityMeasure similarity() {\n        return similarity;\n    }\n\n    public Integer dimensions() {\n        return dimensions;\n    }\n\n    public Integer maxInputTokens() {\n        return maxInputTokens;\n    }\n\n    @Override\n    public String getWriteableName() {\n        return NAME;\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject();\n\n        if (uri !\u003d null) {\n            builder.field(URL, uri.toString());\n        }\n        if (organizationId !\u003d null) {\n            builder.field(ORGANIZATION, organizationId);\n        }\n        if (similarity !\u003d null) {\n            builder.field(SIMILARITY, similarity);\n        }\n        if (dimensions !\u003d null) {\n            builder.field(DIMENSIONS, dimensions);\n        }\n        if (maxInputTokens !\u003d null) {\n            builder.field(MAX_INPUT_TOKENS, maxInputTokens);\n        }\n\n        builder.endObject();\n        return builder;\n    }\n\n    @Override\n    public TransportVersion getMinimalSupportedVersion() {\n        return TransportVersions.ML_INFERENCE_OPENAI_ADDED;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        var uriToWrite \u003d uri !\u003d null ? uri.toString() : null;\n        out.writeOptionalString(uriToWrite);\n        out.writeOptionalString(organizationId);\n        if (out.getTransportVersion().onOrAfter(TransportVersions.INFERENCE_SERVICE_EMBEDDING_SIZE_ADDED)) {\n            out.writeOptionalEnum(similarity);\n            out.writeOptionalVInt(dimensions);\n            out.writeOptionalVInt(maxInputTokens);\n        }\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this \u003d\u003d o) return true;\n        if (o \u003d\u003d null || getClass() !\u003d o.getClass()) return false;\n        OpenAiServiceSettings that \u003d (OpenAiServiceSettings) o;\n        return Objects.equals(uri, that.uri)\n            \u0026\u0026 Objects.equals(organizationId, that.organizationId)\n            \u0026\u0026 Objects.equals(similarity, that.similarity)\n            \u0026\u0026 Objects.equals(dimensions, that.dimensions)\n            \u0026\u0026 Objects.equals(maxInputTokens, that.maxInputTokens);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(uri, organizationId, similarity, dimensions, maxInputTokens);\n    }\n}","methodCount":16},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":44,"lineEnd":70,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromMap to class ServiceUtils","description":"move method fromMap to PsiClass:ServiceUtils\nRationale: The fromMap() method utilizes multiple utility methods such as extractOptionalString() and convertToUri(), which are already defined in ServiceUtils. This class serves as a centralized location for utility functions, and moving the method here would enhance cohesion and maintainability. It aligns with the Single Responsibility Principle by grouping related functionalities together. However, this could lead to ServiceUtils becoming too large if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":44,"lineEnd":70,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromMap to class OpenAiEmbeddingsTaskSettings","description":"move method fromMap to PsiClass:OpenAiEmbeddingsTaskSettings\nRationale: If OpenAiEmbeddingsTaskSettings shares similar settings or configuration needs, relocating fromMap() here could provide a consistent approach to handling settings across different OpenAI-related classes. This would promote code reuse and adherence to the DRY principle. However, it may introduce confusion if the responsibilities of this class are not clearly defined.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":44,"lineEnd":70,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromMap to class AggregationResultUtils","description":"move method fromMap to PsiClass:AggregationResultUtils\nRationale: Although primarily focused on aggregation results, this class contains utility methods that could be relevant for processing settings. Moving fromMap() here could allow for a more generic utility class. This aligns with the Open/Closed Principle by allowing future extensions for other types of settings. However, it may dilute the class\u0027s purpose, making it less cohesive.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":102,"lineEnd":108,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createOptionalUri to class ServiceUtils","description":"move method createOptionalUri to PsiClass:ServiceUtils\nRationale: The createOptionalUri() method is concerned with URL handling, which aligns closely with the existing methods in ServiceUtils, such as convertToUri and createUri. Moving it here adheres to the Single Responsibility Principle as it consolidates URL-related functionalities in one class, enhancing cohesion. This change improves the overall design by centralizing URI management, but care should be taken to ensure that the method\u0027s static nature is appropriate within this context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":102,"lineEnd":108,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createOptionalUri to class HttpUtils","description":"move method createOptionalUri to PsiClass:HttpUtils\nRationale: HttpUtils is focused on HTTP-related operations, and creating a URI is often a preliminary step for making HTTP requests. Relocating the method here would enhance the class\u0027s utility for HTTP operations, adhering to the Interface Segregation Principle by keeping HTTP-related methods together. However, the method\u0027s static nature may not align perfectly with the instance methods in HttpUtils.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":102,"lineEnd":108,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createOptionalUri to class JwtUtil","description":"move method createOptionalUri to PsiClass:JwtUtil\nRationale: JwtUtil includes methods that deal with URIs in the context of JWTs (JSON Web Tokens). Since JWT handling often involves URLs, moving createOptionalUri() here could enhance the utility of JwtUtil. This aligns with the Single Responsibility Principle by grouping URI-related functionalities relevant to JWTs. However, this move may dilute the class\u0027s focus if it becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromMap","method_signature":"public static fromMap(Map\u003cString, Object\u003e map)","target_class":"","rationale":""},{"method_name":"createOptionalUri","method_signature":"private static createOptionalUri(String url)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromMap","method_signature":"public static fromMap(Map\u003cString, Object\u003e map)","target_class":"","rationale":""},{"method_name":"createOptionalUri","method_signature":"private static createOptionalUri(String url)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromMap(Map\u003cString, Object\u003e map)":{"first":{"method_name":"fromMap","method_signature":"public static fromMap(Map\u003cString, Object\u003e map)","target_class":"","rationale":""},"second":0.5552715682864727},"private static createOptionalUri(String url)":{"first":{"method_name":"createOptionalUri","method_signature":"private static createOptionalUri(String url)","target_class":"","rationale":""},"second":0.6265391119151368}},"llmMethodPriority":{"priority_method_names":["fromMap","createOptionalUri"],"llm_response_time":885},"targetClassMap":{"fromMap":{"target_classes":[{"class_name":"ServiceUtils","similarity_score":0.5387731975372827},{"class_name":"ServiceUtilsTests","similarity_score":0.46340156997349674},{"class_name":"Utils","similarity_score":0.37156385923894336},{"class_name":"ActionUtils","similarity_score":0.3959135163616051},{"class_name":"HttpUtils","similarity_score":0.43675576357379114},{"class_name":"OpenAiEmbeddingsModelTests","similarity_score":0.3835201410377413},{"class_name":"OpenAiEmbeddingsRequestTaskSettings","similarity_score":0.4311921313688108},{"class_name":"OpenAiEmbeddingsRequestTaskSettingsTests","similarity_score":0.4332178239794664},{"class_name":"OpenAiEmbeddingsTaskSettings","similarity_score":0.5288662171050424},{"class_name":"OpenAiEmbeddingsTaskSettingsTests","similarity_score":0.4404761116947262},{"class_name":"OpenAiService","similarity_score":0.4287093654100227},{"class_name":"OpenAiServiceSettingsTests","similarity_score":0.5200468566728389},{"class_name":"OpenAiUtils","similarity_score":0.3548797611043577},{"class_name":"RequestUtils","similarity_score":0.27705425792376603},{"class_name":"XContentUtils","similarity_score":0.3541481522245493},{"class_name":"AuditUtil","similarity_score":0.47750397564775665},{"class_name":"AggregationResultUtils","similarity_score":0.5656461086827318},{"class_name":"AggregationResultUtilsTests","similarity_score":0.5050921799396823},{"class_name":"AggregationTestUtils","similarity_score":0.49846914173062895},{"class_name":"FunctionTestUtils","similarity_score":0.43087151117326034},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.49249512414734625},{"class_name":"AuthorizationUtils","similarity_score":0.3047176980216019},{"class_name":"JwkValidateUtil","similarity_score":0.45490881570079433},{"class_name":"JwkValidateUtilTests","similarity_score":0.452433781792912},{"class_name":"JwtUtil","similarity_score":0.5140900516715255},{"class_name":"GeneratorUtils","similarity_score":0.4110642310199707},{"class_name":"AnalysisUtils","similarity_score":0.37309816153427133},{"class_name":"AnalyticsEventTestUtils","similarity_score":0.43021722510619775},{"class_name":"AnalyticsTestsUtils","similarity_score":0.4233396838437053}],"target_classes_sorted_by_llm":["ServiceUtils","OpenAiEmbeddingsTaskSettings","AggregationResultUtils","JwtUtil","OpenAiServiceSettingsTests","ServiceUtilsTests","AggregationTestUtils","AuditUtil","AuthorizationStatePersistenceUtils","AggregationResultUtilsTests"],"llm_response_time":12098,"similarity_computation_time":16,"similarity_metric":"voyage"},"createOptionalUri":{"target_classes":[{"class_name":"ServiceUtils","similarity_score":0.6168468416855157},{"class_name":"ServiceUtilsTests","similarity_score":0.21042749446168477},{"class_name":"Utils","similarity_score":0.3770751436050836},{"class_name":"ActionUtils","similarity_score":0.5710402407201608},{"class_name":"HttpUtils","similarity_score":0.5317117558455406},{"class_name":"RequestUtils","similarity_score":0.47286624374346037},{"class_name":"OpenAiEmbeddingsModelTests","similarity_score":0.2340038668219235},{"class_name":"OpenAiEmbeddingsRequestTaskSettings","similarity_score":0.24220916196414502},{"class_name":"OpenAiEmbeddingsRequestTaskSettingsTests","similarity_score":0.4436403613134579},{"class_name":"OpenAiEmbeddingsTaskSettings","similarity_score":0.447826277100192},{"class_name":"OpenAiEmbeddingsTaskSettingsTests","similarity_score":0.4120916311910182},{"class_name":"OpenAiService","similarity_score":0.3778088395553542},{"class_name":"OpenAiServiceSettingsTests","similarity_score":0.42907545877519104},{"class_name":"OpenAiUtils","similarity_score":0.2850334182303764},{"class_name":"XContentUtils","similarity_score":0.3914516041997284},{"class_name":"IndexerUtils","similarity_score":0.39888458782369923},{"class_name":"FunctionTestUtils","similarity_score":0.5973085413805316},{"class_name":"JwkValidateUtil","similarity_score":0.4591271377237429},{"class_name":"JwkValidateUtilTests","similarity_score":0.5041290735663648},{"class_name":"JwtUtil","similarity_score":0.54480078624161},{"class_name":"ExceptionUtils","similarity_score":0.1898245326253182},{"class_name":"GeneratorUtils","similarity_score":0.6187247275636462},{"class_name":"ExecutionUtils","similarity_score":0.4095609893191588},{"class_name":"InferenceModelTestUtils","similarity_score":0.37383358970942016},{"class_name":"GeoTestUtils","similarity_score":0.450135961593703},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.5004940395292176},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.12759542921874936},{"class_name":"ExtractorUtils","similarity_score":0.6257699404490314},{"class_name":"RuntimeUtils","similarity_score":0.6068543081741079}],"target_classes_sorted_by_llm":["ServiceUtils","HttpUtils","JwtUtil","ExtractorUtils","GeneratorUtils","ActionUtils","RuntimeUtils","FunctionTestUtils","RollupJobIdentifierUtils","JwkValidateUtilTests"],"llm_response_time":11691,"similarity_computation_time":8,"similarity_metric":"voyage"}}}
{"id":"9a20aef7-3cc4-4ccd-8a9a-f28969494569","methodCount":5,"hostFunctionTelemetryData":{"hostFunctionSize":273,"lineStart":25,"lineEnd":297,"bodyLineStart":25,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/TransportVersions.java","sourceCode":"/**\n * \u003cp\u003eTransport version is used to coordinate compatible wire protocol communication between nodes, at a fine-grained level.  This replaces\n * and supersedes the old Version constants.\u003c/p\u003e\n *\n * \u003cp\u003eBefore adding a new version constant, please read the block comment at the end of the list of constants.\u003c/p\u003e\n */\npublic class TransportVersions {\n\n    /*\n     * NOTE: IntelliJ lies!\n     * This map is used during class construction, referenced by the registerTransportVersion method.\n     * When all the transport version constants have been registered, the map is cleared \u0026 never touched again.\n     */\n    static TreeSet\u003cInteger\u003e IDS \u003d new TreeSet\u003c\u003e();\n\n    static TransportVersion def(int id) {\n        if (IDS \u003d\u003d null) throw new IllegalStateException(\"The IDS map needs to be present to call this method\");\n\n        if (IDS.add(id) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" defined twice\");\n        }\n        if (id \u003c IDS.last()) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" is not defined in the right location. Keep constants sorted\");\n        }\n        return new TransportVersion(id);\n    }\n\n    @UpdateForV9 // remove the transport versions with which v9 will not need to interact\n    public static final TransportVersion ZERO \u003d def(0);\n    public static final TransportVersion V_7_0_0 \u003d def(7_00_00_99);\n    public static final TransportVersion V_7_0_1 \u003d def(7_00_01_99);\n    public static final TransportVersion V_7_1_0 \u003d def(7_01_00_99);\n    public static final TransportVersion V_7_2_0 \u003d def(7_02_00_99);\n    public static final TransportVersion V_7_2_1 \u003d def(7_02_01_99);\n    public static final TransportVersion V_7_3_0 \u003d def(7_03_00_99);\n    public static final TransportVersion V_7_3_2 \u003d def(7_03_02_99);\n    public static final TransportVersion V_7_4_0 \u003d def(7_04_00_99);\n    public static final TransportVersion V_7_5_0 \u003d def(7_05_00_99);\n    public static final TransportVersion V_7_6_0 \u003d def(7_06_00_99);\n    public static final TransportVersion V_7_7_0 \u003d def(7_07_00_99);\n    public static final TransportVersion V_7_8_0 \u003d def(7_08_00_99);\n    public static final TransportVersion V_7_8_1 \u003d def(7_08_01_99);\n    public static final TransportVersion V_7_9_0 \u003d def(7_09_00_99);\n    public static final TransportVersion V_7_10_0 \u003d def(7_10_00_99);\n    public static final TransportVersion V_7_10_1 \u003d def(7_10_01_99);\n    public static final TransportVersion V_7_11_0 \u003d def(7_11_00_99);\n    public static final TransportVersion V_7_12_0 \u003d def(7_12_00_99);\n    public static final TransportVersion V_7_13_0 \u003d def(7_13_00_99);\n    public static final TransportVersion V_7_14_0 \u003d def(7_14_00_99);\n    public static final TransportVersion V_7_15_0 \u003d def(7_15_00_99);\n    public static final TransportVersion V_7_15_1 \u003d def(7_15_01_99);\n    public static final TransportVersion V_7_16_0 \u003d def(7_16_00_99);\n    public static final TransportVersion V_7_17_0 \u003d def(7_17_00_99);\n    public static final TransportVersion V_7_17_1 \u003d def(7_17_01_99);\n    public static final TransportVersion V_7_17_8 \u003d def(7_17_08_99);\n    public static final TransportVersion V_8_0_0 \u003d def(8_00_00_99);\n    public static final TransportVersion V_8_1_0 \u003d def(8_01_00_99);\n    public static final TransportVersion V_8_2_0 \u003d def(8_02_00_99);\n    public static final TransportVersion V_8_3_0 \u003d def(8_03_00_99);\n    public static final TransportVersion V_8_4_0 \u003d def(8_04_00_99);\n    public static final TransportVersion V_8_5_0 \u003d def(8_05_00_99);\n    public static final TransportVersion V_8_6_0 \u003d def(8_06_00_99);\n    public static final TransportVersion V_8_6_1 \u003d def(8_06_01_99);\n    public static final TransportVersion V_8_7_0 \u003d def(8_07_00_99);\n    public static final TransportVersion V_8_7_1 \u003d def(8_07_01_99);\n    public static final TransportVersion V_8_8_0 \u003d def(8_08_00_99);\n    public static final TransportVersion V_8_8_1 \u003d def(8_08_01_99);\n    /*\n     * READ THE COMMENT BELOW THIS BLOCK OF DECLARATIONS BEFORE ADDING NEW TRANSPORT VERSIONS\n     * Detached transport versions added below here.\n     */\n    public static final TransportVersion V_8_9_X \u003d def(8_500_020);\n    public static final TransportVersion V_8_10_X \u003d def(8_500_061);\n    public static final TransportVersion V_8_11_X \u003d def(8_512_00_1);\n    public static final TransportVersion PLUGIN_DESCRIPTOR_OPTIONAL_CLASSNAME \u003d def(8_513_00_0);\n    public static final TransportVersion UNIVERSAL_PROFILING_LICENSE_ADDED \u003d def(8_514_00_0);\n    public static final TransportVersion ELSER_SERVICE_MODEL_VERSION_ADDED \u003d def(8_515_00_0);\n    public static final TransportVersion NODE_STATS_HTTP_ROUTE_STATS_ADDED \u003d def(8_516_00_0);\n    public static final TransportVersion INCLUDE_SHARDS_STATS_ADDED \u003d def(8_517_00_0);\n    public static final TransportVersion BUILD_QUALIFIER_SEPARATED \u003d def(8_518_00_0);\n    public static final TransportVersion PIPELINES_IN_BULK_RESPONSE_ADDED \u003d def(8_519_00_0);\n    public static final TransportVersion PLUGIN_DESCRIPTOR_STRING_VERSION \u003d def(8_520_00_0);\n    public static final TransportVersion TOO_MANY_SCROLL_CONTEXTS_EXCEPTION_ADDED \u003d def(8_521_00_0);\n    public static final TransportVersion UNCONTENDED_REGISTER_ANALYSIS_ADDED \u003d def(8_522_00_0);\n    public static final TransportVersion TRANSFORM_GET_CHECKPOINT_TIMEOUT_ADDED \u003d def(8_523_00_0);\n    public static final TransportVersion IP_ADDRESS_WRITEABLE \u003d def(8_524_00_0);\n    public static final TransportVersion PRIMARY_TERM_ADDED \u003d def(8_525_00_0);\n    public static final TransportVersion CLUSTER_FEATURES_ADDED \u003d def(8_526_00_0);\n    public static final TransportVersion DSL_ERROR_STORE_INFORMATION_ENHANCED \u003d def(8_527_00_0);\n    public static final TransportVersion INVALID_BUCKET_PATH_EXCEPTION_INTRODUCED \u003d def(8_528_00_0);\n    public static final TransportVersion KNN_AS_QUERY_ADDED \u003d def(8_529_00_0);\n    public static final TransportVersion UNDESIRED_SHARD_ALLOCATIONS_COUNT_ADDED \u003d def(8_530_00_0);\n    public static final TransportVersion ML_INFERENCE_TASK_SETTINGS_OPTIONAL_ADDED \u003d def(8_531_00_0);\n    public static final TransportVersion DEPRECATED_COMPONENT_TEMPLATES_ADDED \u003d def(8_532_00_0);\n    public static final TransportVersion UPDATE_NON_DYNAMIC_SETTINGS_ADDED \u003d def(8_533_00_0);\n    public static final TransportVersion REPO_ANALYSIS_REGISTER_OP_COUNT_ADDED \u003d def(8_534_00_0);\n    public static final TransportVersion ML_TRAINED_MODEL_PREFIX_STRINGS_ADDED \u003d def(8_535_00_0);\n    public static final TransportVersion COUNTED_KEYWORD_ADDED \u003d def(8_536_00_0);\n    public static final TransportVersion SHAPE_VALUE_SERIALIZATION_ADDED \u003d def(8_537_00_0);\n    public static final TransportVersion INFERENCE_MULTIPLE_INPUTS \u003d def(8_538_00_0);\n    public static final TransportVersion ADDITIONAL_DESIRED_BALANCE_RECONCILIATION_STATS \u003d def(8_539_00_0);\n    public static final TransportVersion ML_STATE_CHANGE_TIMESTAMPS \u003d def(8_540_00_0);\n    public static final TransportVersion DATA_STREAM_FAILURE_STORE_ADDED \u003d def(8_541_00_0);\n    public static final TransportVersion ML_INFERENCE_OPENAI_ADDED \u003d def(8_542_00_0);\n    public static final TransportVersion SHUTDOWN_MIGRATION_STATUS_INCLUDE_COUNTS \u003d def(8_543_00_0);\n    public static final TransportVersion TRANSFORM_GET_CHECKPOINT_QUERY_AND_CLUSTER_ADDED \u003d def(8_544_00_0);\n    public static final TransportVersion GRANT_API_KEY_CLIENT_AUTHENTICATION_ADDED \u003d def(8_545_00_0);\n    public static final TransportVersion PIT_WITH_INDEX_FILTER \u003d def(8_546_00_0);\n    public static final TransportVersion NODE_INFO_VERSION_AS_STRING \u003d def(8_547_00_0);\n    public static final TransportVersion GET_API_KEY_INVALIDATION_TIME_ADDED \u003d def(8_548_00_0);\n    public static final TransportVersion ML_INFERENCE_GET_MULTIPLE_MODELS \u003d def(8_549_00_0);\n    public static final TransportVersion INFERENCE_SERVICE_RESULTS_ADDED \u003d def(8_550_00_0);\n    public static final TransportVersion ESQL_PROFILE \u003d def(8_551_00_0);\n    public static final TransportVersion CLUSTER_STATS_RESCORER_USAGE_ADDED \u003d def(8_552_00_0);\n    public static final TransportVersion ML_INFERENCE_HF_SERVICE_ADDED \u003d def(8_553_00_0);\n    public static final TransportVersion INFERENCE_USAGE_ADDED \u003d def(8_554_00_0);\n    public static final TransportVersion UPGRADE_TO_LUCENE_9_9 \u003d def(8_555_00_0);\n    public static final TransportVersion HEALTH_INFO_ENRICHED_WITH_DSL_STATUS \u003d def(8_556_00_0);\n    public static final TransportVersion SOURCE_IN_SINGLE_VALUE_QUERY_ADDED \u003d def(8_557_00_0);\n    public static final TransportVersion MISSED_INDICES_UPDATE_EXCEPTION_ADDED \u003d def(8_558_00_0);\n    public static final TransportVersion INFERENCE_SERVICE_EMBEDDING_SIZE_ADDED \u003d def(8_559_00_0);\n    public static final TransportVersion ENRICH_ELASTICSEARCH_VERSION_REMOVED \u003d def(8_560_00_0);\n    public static final TransportVersion DATE_HISTOGRAM_SUPPORT_DOWNSAMPLED_TZ_8_12_PATCH \u003d def(8_560_00_1);\n    public static final TransportVersion NODE_STATS_REQUEST_SIMPLIFIED \u003d def(8_561_00_0);\n    public static final TransportVersion TEXT_EXPANSION_TOKEN_PRUNING_CONFIG_ADDED \u003d def(8_562_00_0);\n    public static final TransportVersion ESQL_ASYNC_QUERY \u003d def(8_563_00_0);\n    public static final TransportVersion ESQL_STATUS_INCLUDE_LUCENE_QUERIES \u003d def(8_564_00_0);\n    public static final TransportVersion ESQL_CLUSTER_ALIAS \u003d def(8_565_00_0);\n    public static final TransportVersion SNAPSHOTS_IN_PROGRESS_TRACKING_REMOVING_NODES_ADDED \u003d def(8_566_00_0);\n    public static final TransportVersion SMALLER_RELOAD_SECURE_SETTINGS_REQUEST \u003d def(8_567_00_0);\n    public static final TransportVersion UPDATE_API_KEY_EXPIRATION_TIME_ADDED \u003d def(8_568_00_0);\n    public static final TransportVersion LAZY_ROLLOVER_ADDED \u003d def(8_569_00_0);\n    public static final TransportVersion ESQL_PLAN_POINT_LITERAL_WKB \u003d def(8_570_00_0);\n    public static final TransportVersion HOT_THREADS_AS_BYTES \u003d def(8_571_00_0);\n    public static final TransportVersion ML_INFERENCE_REQUEST_INPUT_TYPE_ADDED \u003d def(8_572_00_0);\n    public static final TransportVersion ESQL_ENRICH_POLICY_CCQ_MODE \u003d def(8_573_00_0);\n    public static final TransportVersion DATE_HISTOGRAM_SUPPORT_DOWNSAMPLED_TZ \u003d def(8_574_00_0);\n    public static final TransportVersion PEERFINDER_REPORTS_PEERS_MASTERS \u003d def(8_575_00_0);\n    public static final TransportVersion ESQL_MULTI_CLUSTERS_ENRICH \u003d def(8_576_00_0);\n    public static final TransportVersion NESTED_KNN_MORE_INNER_HITS \u003d def(8_577_00_0);\n    public static final TransportVersion REQUIRE_DATA_STREAM_ADDED \u003d def(8_578_00_0);\n    public static final TransportVersion ML_INFERENCE_COHERE_EMBEDDINGS_ADDED \u003d def(8_579_00_0);\n    public static final TransportVersion DESIRED_NODE_VERSION_OPTIONAL_STRING \u003d def(8_580_00_0);\n\n    /*\n     * STOP! READ THIS FIRST! No, really,\n     *        ____ _____ ___  ____  _        ____  _____    _    ____    _____ _   _ ___ ____    _____ ___ ____  ____ _____ _\n     *       / ___|_   _/ _ \\|  _ \\| |      |  _ \\| ____|  / \\  |  _ \\  |_   _| | | |_ _/ ___|  |  ___|_ _|  _ \\/ ___|_   _| |\n     *       \\___ \\ | || | | | |_) | |      | |_) |  _|   / _ \\ | | | |   | | | |_| || |\\___ \\  | |_   | || |_) \\___ \\ | | | |\n     *        ___) || || |_| |  __/|_|      |  _ \u003c| |___ / ___ \\| |_| |   | | |  _  || | ___) | |  _|  | ||  _ \u003c ___) || | |_|\n     *       |____/ |_| \\___/|_|   (_)      |_| \\_\\_____/_/   \\_\\____/    |_| |_| |_|___|____/  |_|   |___|_| \\_\\____/ |_| (_)\n     *\n     * A new transport version should be added EVERY TIME a change is made to the serialization protocol of one or more classes. Each\n     * transport version should only be used in a single merged commit (apart from the BwC versions copied from o.e.Version, V_8_8_1).\n     *\n     * ADDING A TRANSPORT VERSION\n     * To add a new transport version, add a new constant at the bottom of the list, above this comment. Don\u0027t add other lines,\n     * comments, etc. The version id has the following layout:\n     *\n     * M_NNN_SS_P\n     *\n     * M - The major version of Elasticsearch\n     * NNN - The server version part\n     * SS - The serverless version part. It should always be 00 here, it is used by serverless only.\n     * P - The patch version part\n     *\n     * To determine the id of the next TransportVersion constant, do the following:\n     * - Use the same major version, unless bumping majors\n     * - Bump the server version part by 1, unless creating a patch version\n     * - Leave the serverless part as 00\n     * - Bump the patch part if creating a patch version\n     *\n     * If a patch version is created, it should be placed sorted among the other existing constants.\n     *\n     * REVERTING A TRANSPORT VERSION\n     *\n     * If you revert a commit with a transport version change, you MUST ensure there is a NEW transport version representing the reverted\n     * change. DO NOT let the transport version go backwards, it must ALWAYS be incremented.\n     *\n     * DETERMINING TRANSPORT VERSIONS FROM GIT HISTORY\n     *\n     * If your git checkout has the expected minor-version-numbered branches and the expected release-version tags then you can find the\n     * transport versions known by a particular release ...\n     *\n     *     git show v8.11.0:server/src/main/java/org/elasticsearch/TransportVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... or by a particular branch ...\n     *\n     *     git show 8.11:server/src/main/java/org/elasticsearch/TransportVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... and you can see which versions were added in between two versions too ...\n     *\n     *     git diff v8.11.0..main -- server/src/main/java/org/elasticsearch/TransportVersions.java\n     *\n     * In branches 8.7-8.10 see server/src/main/java/org/elasticsearch/TransportVersion.java for the equivalent definitions.\n     */\n\n    /**\n     * Reference to the earliest compatible transport version to this version of the codebase.\n     * This should be the transport version used by the highest minor version of the previous major.\n     */\n    public static final TransportVersion MINIMUM_COMPATIBLE \u003d V_7_17_0;\n\n    /**\n     * Reference to the minimum transport version that can be used with CCS.\n     * This should be the transport version used by the previous minor release.\n     */\n    public static final TransportVersion MINIMUM_CCS_VERSION \u003d V_8_11_X;\n\n    static final NavigableMap\u003cInteger, TransportVersion\u003e VERSION_IDS \u003d getAllVersionIds(TransportVersions.class);\n\n    // the highest transport version constant defined in this file, used as a fallback for TransportVersion.current()\n    static final TransportVersion LATEST_DEFINED;\n    static {\n        LATEST_DEFINED \u003d VERSION_IDS.lastEntry().getValue();\n\n        // see comment on IDS field\n        // now we\u0027re registered all the transport versions, we can clear the map\n        IDS \u003d null;\n    }\n\n    public static NavigableMap\u003cInteger, TransportVersion\u003e getAllVersionIds(Class\u003c?\u003e cls) {\n        Map\u003cInteger, String\u003e versionIdFields \u003d new HashMap\u003c\u003e();\n        NavigableMap\u003cInteger, TransportVersion\u003e builder \u003d new TreeMap\u003c\u003e();\n\n        Set\u003cString\u003e ignore \u003d Set.of(\"ZERO\", \"CURRENT\", \"MINIMUM_COMPATIBLE\", \"MINIMUM_CCS_VERSION\");\n\n        for (Field declaredField : cls.getFields()) {\n            if (declaredField.getType().equals(TransportVersion.class)) {\n                String fieldName \u003d declaredField.getName();\n                if (ignore.contains(fieldName)) {\n                    continue;\n                }\n\n                TransportVersion version;\n                try {\n                    version \u003d (TransportVersion) declaredField.get(null);\n                } catch (IllegalAccessException e) {\n                    throw new AssertionError(e);\n                }\n                builder.put(version.id(), version);\n\n                if (Assertions.ENABLED) {\n                    // check the version number is unique\n                    var sameVersionNumber \u003d versionIdFields.put(version.id(), fieldName);\n                    assert sameVersionNumber \u003d\u003d null\n                        : \"Versions [\"\n                            + sameVersionNumber\n                            + \"] and [\"\n                            + fieldName\n                            + \"] have the same version number [\"\n                            + version.id()\n                            + \"]. Each TransportVersion should have a different version number\";\n                }\n            }\n        }\n\n        return Collections.unmodifiableNavigableMap(builder);\n    }\n\n    static Collection\u003cTransportVersion\u003e getAllVersions() {\n        return VERSION_IDS.values();\n    }\n\n    private static final IntFunction\u003cString\u003e VERSION_LOOKUP \u003d ReleaseVersions.generateVersionsLookup(TransportVersions.class);\n\n    public static String toReleaseVersion(TransportVersion version) {\n        return VERSION_LOOKUP.apply(version.id());\n    }\n\n    // no instance\n    private TransportVersions() {}\n}","methodCount":5},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":290,"lineEnd":292,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class AuditUtil","description":"move method toReleaseVersion to PsiClass:AuditUtil\nRationale: The toReleaseVersion() method translates a TransportVersion into a version string, which can be considered part of an audit trail. Moving it to AuditUtil enhances the cohesion of audit-related functionalities. This aligns with the Single Responsibility Principle as it centralizes versioning logic related to auditing. However, ensure that the method\u0027s usage in audit contexts is prevalent to justify this move.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":290,"lineEnd":292,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class JwtUtil","description":"move method toReleaseVersion to PsiClass:JwtUtil\nRationale: The method toReleaseVersion() can be relevant in contexts where JWTs are issued with versioning information. Placing it in JwtUtil allows for better organization of utility methods related to token management. This move adheres to the Open/Closed Principle, as it allows for extensions in version handling without modifying existing classes. However, consider if versioning is a core aspect of JWT handling in this context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":290,"lineEnd":292,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class RestResponseUtils","description":"move method toReleaseVersion to PsiClass:RestResponseUtils\nRationale: If toReleaseVersion() is used to construct responses that include version information, it could be logical to place it in RestResponseUtils. This aligns with the Interface Segregation Principle, as it keeps related response formatting logic together. However, ensure that this utility does not become bloated with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class ConfigurationUtils","description":"move method def to PsiClass:ConfigurationUtils\nRationale: The def() method is responsible for defining version IDs, which aligns with configuration management. Moving it to ConfigurationUtils adheres to the Single Responsibility Principle, as it centralizes configuration-related methods. This enhances cohesion, as ConfigurationUtils already handles various configuration properties. However, consider potential dependencies on the IDS map within the current class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class BuildUtils","description":"move method def to PsiClass:BuildUtils\nRationale: The def() method\u0027s purpose of defining versions can be seen as part of the build configuration process. Moving it to BuildUtils aligns with the Open/Closed Principle, allowing for future enhancements related to versioning without altering existing code. This enhances modularity but may require careful integration with build processes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class KeyStoreUtil","description":"move method def to PsiClass:KeyStoreUtil\nRationale: If the versioning is related to key management (e.g., versioning keys), then KeyStoreUtil is an appropriate candidate. This move supports the Interface Segregation Principle, as it separates concerns related to versioning from other functionalities. However, ensure that the method\u0027s context remains relevant to key management.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":245,"lineEnd":282,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class AggregationResultUtils","description":"move method getAllVersionIds to PsiClass:AggregationResultUtils\nRationale: The getAllVersionIds() method deals with versioning and types that could be related to aggregation results. Moving it here adheres to the Single Responsibility Principle by grouping related functionalities. This class already handles extraction and document updates, which may involve versioning. However, care should be taken to ensure that this class does not become overloaded with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":245,"lineEnd":282,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class AuditUtil","description":"move method getAllVersionIds to PsiClass:AuditUtil\nRationale: The method involves handling TransportVersion which may relate to auditing and tracking different versions of transport data. By moving it to AuditUtil, we can maintain a cohesive design that focuses on auditing functionalities. This aligns with the Open/Closed Principle, allowing for future enhancements without modifying existing code. However, the class may become too focused on versioning, which might dilute its original purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":245,"lineEnd":282,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class GeometryTestUtils","description":"move method getAllVersionIds to PsiClass:GeometryTestUtils\nRationale: This class primarily focuses on geometric utilities. If TransportVersion has a significant role in geometry-related operations, the method could be appropriate here. However, this may lead to an unclear separation of concerns, as the class could become too broad in scope.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""},{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static toReleaseVersion(TransportVersion version)":{"first":{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""},"second":0.05018472858889806},"static def(int id)":{"first":{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},"second":0.0781650615673603},"public static getAllVersionIds(Class\u003c?\u003e cls)":{"first":{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},"second":0.27580535813054147}},"llmMethodPriority":{"priority_method_names":["toReleaseVersion","def","getAllVersionIds"],"llm_response_time":1313},"targetClassMap":{"toReleaseVersion":{"target_classes":[{"class_name":"BootstrapUtil","similarity_score":0.46193488543715594},{"class_name":"AuditUtil","similarity_score":0.6747808815196579},{"class_name":"AggregationResultUtils","similarity_score":0.5226376960403452},{"class_name":"AggregationResultUtilsTests","similarity_score":0.35021575082334083},{"class_name":"AggregationTestUtils","similarity_score":0.5064418313919596},{"class_name":"BreakerTestUtil","similarity_score":0.3119162007740179},{"class_name":"JwkValidateUtil","similarity_score":0.3693202030233661},{"class_name":"JwkValidateUtilTests","similarity_score":0.4605177338720018},{"class_name":"RestResponseUtils","similarity_score":0.5341799709115684},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.2974711032000541},{"class_name":"AuthorizationUtils","similarity_score":0.19831733396829512},{"class_name":"JwtUtil","similarity_score":0.4682859094646369},{"class_name":"CheckedFunctionUtils","similarity_score":0.1554574673890713},{"class_name":"RestTestUtil","similarity_score":0.36251240124655426},{"class_name":"RestUtils","similarity_score":0.3731804509515294},{"class_name":"RestUtilsTests","similarity_score":0.21247269738650393},{"class_name":"BucketUtils","similarity_score":0.1967604453669851},{"class_name":"KeyStoreUtil","similarity_score":0.4285671874853539},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.32533773078899525},{"class_name":"AwsEc2Utils","similarity_score":0.3959901074002933},{"class_name":"DiffableTestUtils","similarity_score":0.3309315178638468},{"class_name":"DiffableUtils","similarity_score":0.49709736592315956},{"class_name":"AnalysisUtils","similarity_score":0.2439169738615454},{"class_name":"AnalyticsEventTestUtils","similarity_score":0.6680313900328463},{"class_name":"CIDRUtils","similarity_score":0.39218400444584306},{"class_name":"RetentionLeaseUtils","similarity_score":0.24618298195866545},{"class_name":"AnalyticsTestsUtils","similarity_score":0.40427154303592927},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.28060220165757305},{"class_name":"CircleUtils","similarity_score":0.22133480036720254},{"class_name":"AnalyzerTestUtils","similarity_score":0.5153471216826172}],"target_classes_sorted_by_llm":["AuditUtil","JwtUtil","RestResponseUtils","AggregationResultUtils","DiffableUtils","BootstrapUtil","AnalyticsEventTestUtils","AggregationTestUtils","AnalyzerTestUtils","JwkValidateUtilTests"],"llm_response_time":12810,"similarity_computation_time":21,"similarity_metric":"voyage"},"def":{"target_classes":[{"class_name":"BootstrapUtil","similarity_score":0.30668734128934194},{"class_name":"AuditUtil","similarity_score":0.4531198376018793},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.24323640259351698},{"class_name":"BreakerTestUtil","similarity_score":0.4219505076868091},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.29595320327004154},{"class_name":"JwkValidateUtil","similarity_score":0.45421617233866024},{"class_name":"JwkValidateUtilTests","similarity_score":0.31860723156484283},{"class_name":"AuthorizationUtils","similarity_score":0.26207931898933023},{"class_name":"JwtUtil","similarity_score":0.511559378709225},{"class_name":"CredentialsRedaction","similarity_score":0.42638287023725246},{"class_name":"BucketUtils","similarity_score":0.2717166308647008},{"class_name":"CryptUtils","similarity_score":0.34332087022322333},{"class_name":"CheckedFunctionUtils","similarity_score":0.12975117797815766},{"class_name":"CsvTestUtils","similarity_score":0.39086144827840663},{"class_name":"AwsEc2Utils","similarity_score":0.3793348636496733},{"class_name":"KeyStoreUtil","similarity_score":0.3829329981926565},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.4384542023153874},{"class_name":"BuildUtils","similarity_score":0.43281047964251756},{"class_name":"CIDRUtils","similarity_score":0.3694397626541088},{"class_name":"CircleUtils","similarity_score":0.3473325262508327},{"class_name":"DiffableTestUtils","similarity_score":0.2211292131269157},{"class_name":"DiffableUtils","similarity_score":0.3579737713782125},{"class_name":"ConfigurationUtils","similarity_score":0.3835450062887874},{"class_name":"ClasspathUtils","similarity_score":0.30713957630810024},{"class_name":"ConnectorSecretsTestUtils","similarity_score":0.3804935592056778},{"class_name":"ConnectorSyncJobTestUtils","similarity_score":0.34992095425349545},{"class_name":"ConnectorTestUtils","similarity_score":0.3723919134016418},{"class_name":"ConnectorUtils","similarity_score":0.19897976431070005},{"class_name":"DiscoveryNodeUtils","similarity_score":0.3044041064269429},{"class_name":"DataExtractorUtils","similarity_score":0.20751903162321098}],"target_classes_sorted_by_llm":["ConfigurationUtils","BuildUtils","KeyStoreUtil","JwtUtil","AuditUtil","CredentialsRedaction","ChunkedLoggingStreamTestUtils","BreakerTestUtil","CsvTestUtils","JwkValidateUtil"],"llm_response_time":9657,"similarity_computation_time":13,"similarity_metric":"voyage"},"getAllVersionIds":{"target_classes":[{"class_name":"AuditUtil","similarity_score":0.591231734034315},{"class_name":"AggregationResultUtils","similarity_score":0.6697187650857238},{"class_name":"AggregationResultUtilsTests","similarity_score":0.5508996878144414},{"class_name":"AggregationTestUtils","similarity_score":0.5831144457993841},{"class_name":"FunctionTestUtils","similarity_score":0.5760952533789586},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.48567386027718573},{"class_name":"AuthorizationUtils","similarity_score":0.3333015193384314},{"class_name":"FutureUtils","similarity_score":0.4541608361241388},{"class_name":"JwkValidateUtil","similarity_score":0.6506503163376719},{"class_name":"JwkValidateUtilTests","similarity_score":0.5323931205692574},{"class_name":"GceMockUtils","similarity_score":0.5844004915614751},{"class_name":"JwtUtil","similarity_score":0.6894940885045573},{"class_name":"ExceptionUtils","similarity_score":0.4620879100269341},{"class_name":"CheckedFunctionUtils","similarity_score":0.15917943203865367},{"class_name":"GeneratorUtils","similarity_score":0.5376773783366607},{"class_name":"AwsEc2Utils","similarity_score":0.5440495721663374},{"class_name":"ExecutionUtils","similarity_score":0.525121527910861},{"class_name":"AnalysisUtils","similarity_score":0.6575876218196661},{"class_name":"AnalyticsEventTestUtils","similarity_score":0.5242133220084088},{"class_name":"AnalyticsTestsUtils","similarity_score":0.5108884202461974},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.24714843081710244},{"class_name":"AnalyzerTestUtils","similarity_score":0.35664101520470765},{"class_name":"KeyStoreUtil","similarity_score":0.542529276136968},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.5991774483100757},{"class_name":"CIDRUtils","similarity_score":0.5788760828622791},{"class_name":"GeometryTestUtils","similarity_score":0.594240576667327},{"class_name":"CircleUtils","similarity_score":0.5500894896616898},{"class_name":"GeoTestUtils","similarity_score":0.5076289500467781},{"class_name":"GeoTileUtils","similarity_score":0.41454610233478745},{"class_name":"GeoUtils","similarity_score":0.43587977647556064}],"target_classes_sorted_by_llm":["AggregationResultUtils","AuditUtil","GeometryTestUtils","CIDRUtils","ChunkedLoggingStreamTestUtils","JwkValidateUtil","AggregationTestUtils","AnalysisUtils","GceMockUtils","JwtUtil"],"llm_response_time":11747,"similarity_computation_time":22,"similarity_metric":"voyage"}}}
{"id":"e0564703-3398-4e1e-9ad7-81e58f8d9ff1","methodCount":4,"hostFunctionTelemetryData":{"hostFunctionSize":189,"lineStart":27,"lineEnd":215,"bodyLineStart":27,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/index/IndexVersions.java","sourceCode":"@SuppressWarnings(\"deprecation\")\npublic class IndexVersions {\n\n    /*\n     * NOTE: IntelliJ lies!\n     * This map is used during class construction, referenced by the registerIndexVersion method.\n     * When all the index version constants have been registered, the map is cleared \u0026 never touched again.\n     */\n    @SuppressWarnings(\"UnusedAssignment\")\n    static TreeSet\u003cInteger\u003e IDS \u003d new TreeSet\u003c\u003e();\n\n    private static IndexVersion def(int id, Version luceneVersion) {\n        if (IDS \u003d\u003d null) throw new IllegalStateException(\"The IDS map needs to be present to call this method\");\n\n        if (IDS.add(id) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" defined twice\");\n        }\n        if (id \u003c IDS.last()) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" is not defined in the right location. Keep constants sorted\");\n        }\n        return new IndexVersion(id, luceneVersion);\n    }\n\n    @UpdateForV9 // remove the index versions with which v9 will not need to interact\n    public static final IndexVersion ZERO \u003d def(0, Version.LATEST);\n    public static final IndexVersion V_7_0_0 \u003d def(7_00_00_99, Version.LUCENE_8_0_0);\n\n    public static final IndexVersion V_7_1_0 \u003d def(7_01_00_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_2_0 \u003d def(7_02_00_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_2_1 \u003d def(7_02_01_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_3_0 \u003d def(7_03_00_99, Version.LUCENE_8_1_0);\n    public static final IndexVersion V_7_4_0 \u003d def(7_04_00_99, Version.LUCENE_8_2_0);\n    public static final IndexVersion V_7_5_0 \u003d def(7_05_00_99, Version.LUCENE_8_3_0);\n    public static final IndexVersion V_7_5_2 \u003d def(7_05_02_99, Version.LUCENE_8_3_0);\n    public static final IndexVersion V_7_6_0 \u003d def(7_06_00_99, Version.LUCENE_8_4_0);\n    public static final IndexVersion V_7_7_0 \u003d def(7_07_00_99, Version.LUCENE_8_5_1);\n    public static final IndexVersion V_7_8_0 \u003d def(7_08_00_99, Version.LUCENE_8_5_1);\n    public static final IndexVersion V_7_9_0 \u003d def(7_09_00_99, Version.LUCENE_8_6_0);\n    public static final IndexVersion V_7_10_0 \u003d def(7_10_00_99, Version.LUCENE_8_7_0);\n    public static final IndexVersion V_7_11_0 \u003d def(7_11_00_99, Version.LUCENE_8_7_0);\n    public static final IndexVersion V_7_12_0 \u003d def(7_12_00_99, Version.LUCENE_8_8_0);\n    public static final IndexVersion V_7_13_0 \u003d def(7_13_00_99, Version.LUCENE_8_8_2);\n    public static final IndexVersion V_7_14_0 \u003d def(7_14_00_99, Version.LUCENE_8_9_0);\n    public static final IndexVersion V_7_15_0 \u003d def(7_15_00_99, Version.LUCENE_8_9_0);\n    public static final IndexVersion V_7_16_0 \u003d def(7_16_00_99, Version.LUCENE_8_10_1);\n    public static final IndexVersion V_7_17_0 \u003d def(7_17_00_99, Version.LUCENE_8_11_1);\n    public static final IndexVersion V_8_0_0 \u003d def(8_00_00_99, Version.LUCENE_9_0_0);\n    public static final IndexVersion V_8_1_0 \u003d def(8_01_00_99, Version.LUCENE_9_0_0);\n    public static final IndexVersion V_8_2_0 \u003d def(8_02_00_99, Version.LUCENE_9_1_0);\n    public static final IndexVersion V_8_3_0 \u003d def(8_03_00_99, Version.LUCENE_9_2_0);\n    public static final IndexVersion V_8_4_0 \u003d def(8_04_00_99, Version.LUCENE_9_3_0);\n    public static final IndexVersion V_8_5_0 \u003d def(8_05_00_99, Version.LUCENE_9_4_1);\n    public static final IndexVersion V_8_6_0 \u003d def(8_06_00_99, Version.LUCENE_9_4_2);\n    public static final IndexVersion V_8_7_0 \u003d def(8_07_00_99, Version.LUCENE_9_5_0);\n    public static final IndexVersion V_8_8_0 \u003d def(8_08_00_99, Version.LUCENE_9_6_0);\n    public static final IndexVersion V_8_8_2 \u003d def(8_08_02_99, Version.LUCENE_9_6_0);\n    public static final IndexVersion V_8_9_0 \u003d def(8_09_00_99, Version.LUCENE_9_7_0);\n    public static final IndexVersion V_8_9_1 \u003d def(8_09_01_99, Version.LUCENE_9_7_0);\n    public static final IndexVersion V_8_10_0 \u003d def(8_10_00_99, Version.LUCENE_9_7_0);\n    /*\n     * READ THE COMMENT BELOW THIS BLOCK OF DECLARATIONS BEFORE ADDING NEW INDEX VERSIONS\n     * Detached index versions added below here.\n     */\n    public static final IndexVersion FIRST_DETACHED_INDEX_VERSION \u003d def(8_500_000, Version.LUCENE_9_7_0);\n    public static final IndexVersion NEW_SPARSE_VECTOR \u003d def(8_500_001, Version.LUCENE_9_7_0);\n    public static final IndexVersion SPARSE_VECTOR_IN_FIELD_NAMES_SUPPORT \u003d def(8_500_002, Version.LUCENE_9_7_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_8 \u003d def(8_500_003, Version.LUCENE_9_8_0);\n    public static final IndexVersion ES_VERSION_8_12 \u003d def(8_500_004, Version.LUCENE_9_8_0);\n    public static final IndexVersion NORMALIZED_VECTOR_COSINE \u003d def(8_500_005, Version.LUCENE_9_8_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_9 \u003d def(8_500_006, Version.LUCENE_9_9_0);\n    public static final IndexVersion NORI_DUPLICATES \u003d def(8_500_007, Version.LUCENE_9_9_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_9_1 \u003d def(8_500_008, Version.LUCENE_9_9_1);\n    public static final IndexVersion ES_VERSION_8_12_1 \u003d def(8_500_009, Version.LUCENE_9_9_1);\n    public static final IndexVersion NEW_INDEXVERSION_FORMAT \u003d def(8_501_00_0, Version.LUCENE_9_9_1);\n\n    /*\n     * STOP! READ THIS FIRST! No, really,\n     *        ____ _____ ___  ____  _        ____  _____    _    ____    _____ _   _ ___ ____    _____ ___ ____  ____ _____ _\n     *       / ___|_   _/ _ \\|  _ \\| |      |  _ \\| ____|  / \\  |  _ \\  |_   _| | | |_ _/ ___|  |  ___|_ _|  _ \\/ ___|_   _| |\n     *       \\___ \\ | || | | | |_) | |      | |_) |  _|   / _ \\ | | | |   | | | |_| || |\\___ \\  | |_   | || |_) \\___ \\ | | | |\n     *        ___) || || |_| |  __/|_|      |  _ \u003c| |___ / ___ \\| |_| |   | | |  _  || | ___) | |  _|  | ||  _ \u003c ___) || | |_|\n     *       |____/ |_| \\___/|_|   (_)      |_| \\_\\_____/_/   \\_\\____/    |_| |_| |_|___|____/  |_|   |___|_| \\_\\____/ |_| (_)\n     *\n     * A new index version should be added EVERY TIME a change is made to index metadata or data storage.\n     * Each index version should only be used in a single merged commit (apart from the BwC versions copied from o.e.Version, V_8_11_0).\n     *\n     * ADDING AN INDEX VERSION\n     * To add a new index version, add a new constant at the bottom of the list, above this comment. Don\u0027t add other lines,\n     * comments, etc. The version id has the following layout:\n     *\n     * M_NNN_SS_P\n     *\n     * M - The major version of Elasticsearch\n     * NNN - The server version part\n     * SS - The serverless version part. It should always be 00 here, it is used by serverless only.\n     * P - The patch version part\n     *\n     * To determine the id of the next IndexVersion constant, do the following:\n     * - Use the same major version, unless bumping majors\n     * - Bump the server version part by 1, unless creating a patch version\n     * - Leave the serverless part as 00\n     * - Bump the patch part if creating a patch version\n     *\n     * If a patch version is created, it should be placed sorted among the other existing constants.\n     *\n     * REVERTING AN INDEX VERSION\n     *\n     * If you revert a commit with an index version change, you MUST ensure there is a NEW index version representing the reverted\n     * change. DO NOT let the index version go backwards, it must ALWAYS be incremented.\n     *\n     * DETERMINING INDEX VERSIONS FROM GIT HISTORY\n     *\n     * If your git checkout has the expected minor-version-numbered branches and the expected release-version tags then you can find the\n     * index versions known by a particular release ...\n     *\n     *     git show v8.12.0:server/src/main/java/org/elasticsearch/index/IndexVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... or by a particular branch ...\n     *\n     *     git show 8.12:server/src/main/java/org/elasticsearch/index/IndexVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... and you can see which versions were added in between two versions too ...\n     *\n     *     git diff v8.12.0..main -- server/src/main/java/org/elasticsearch/index/IndexVersions.java\n     *\n     * In branches 8.7-8.11 see server/src/main/java/org/elasticsearch/index/IndexVersion.java for the equivalent definitions.\n     */\n\n    public static final IndexVersion MINIMUM_COMPATIBLE \u003d V_7_0_0;\n\n    static final NavigableMap\u003cInteger, IndexVersion\u003e VERSION_IDS \u003d getAllVersionIds(IndexVersions.class);\n    static final IndexVersion LATEST_DEFINED;\n    static {\n        LATEST_DEFINED \u003d VERSION_IDS.lastEntry().getValue();\n\n        // see comment on IDS field\n        // now we\u0027re registered the index versions, we can clear the map\n        IDS \u003d null;\n    }\n\n    static NavigableMap\u003cInteger, IndexVersion\u003e getAllVersionIds(Class\u003c?\u003e cls) {\n        Map\u003cInteger, String\u003e versionIdFields \u003d new HashMap\u003c\u003e();\n        NavigableMap\u003cInteger, IndexVersion\u003e builder \u003d new TreeMap\u003c\u003e();\n\n        Set\u003cString\u003e ignore \u003d Set.of(\"ZERO\", \"MINIMUM_COMPATIBLE\");\n\n        for (Field declaredField : cls.getFields()) {\n            if (declaredField.getType().equals(IndexVersion.class)) {\n                String fieldName \u003d declaredField.getName();\n                if (ignore.contains(fieldName)) {\n                    continue;\n                }\n\n                IndexVersion version;\n                try {\n                    version \u003d (IndexVersion) declaredField.get(null);\n                } catch (IllegalAccessException e) {\n                    throw new AssertionError(e);\n                }\n                builder.put(version.id(), version);\n\n                if (Assertions.ENABLED) {\n                    // check the version number is unique\n                    var sameVersionNumber \u003d versionIdFields.put(version.id(), fieldName);\n                    assert sameVersionNumber \u003d\u003d null\n                        : \"Versions [\"\n                            + sameVersionNumber\n                            + \"] and [\"\n                            + fieldName\n                            + \"] have the same version number [\"\n                            + version.id()\n                            + \"]. Each IndexVersion should have a different version number\";\n                }\n            }\n        }\n\n        return Collections.unmodifiableNavigableMap(builder);\n    }\n\n    static Collection\u003cIndexVersion\u003e getAllVersions() {\n        return VERSION_IDS.values();\n    }\n\n    private static final IntFunction\u003cString\u003e VERSION_LOOKUP \u003d ReleaseVersions.generateVersionsLookup(IndexVersions.class);\n\n    public static String toReleaseVersion(IndexVersion version) {\n        return VERSION_LOOKUP.apply(version.id());\n    }\n}","methodCount":4},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":211,"lineEnd":213,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class LiveVersionMapTestUtils","description":"move method toReleaseVersion to PsiClass:LiveVersionMapTestUtils\nRationale: The toReleaseVersion() method performs a lookup based on the version ID, which seems closely related to the operations in LiveVersionMapTestUtils that deal with version management. Moving it here enhances cohesion by placing version-related functionality together. This aligns with the Single Responsibility Principle, as it centralizes version handling. However, it may introduce dependencies on test utility classes, which could complicate testing scenarios.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":211,"lineEnd":213,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class Index","description":"move method toReleaseVersion to PsiClass:Index\nRationale: The toReleaseVersion() method is directly related to versioning, which is a core aspect of the Index class. By relocating it here, we enhance encapsulation, as the Index class is responsible for managing its own state and versioning. This adheres to the Single Responsibility Principle and makes the Index class more cohesive. However, it may increase the size of the Index class, potentially violating the Interface Segregation Principle if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":211,"lineEnd":213,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class FunctionTestUtils","description":"move method toReleaseVersion to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils might benefit from having the toReleaseVersion() method, as it could be used in various functional tests related to versioning. This move would help consolidate testing utilities and improve code organization. However, it may dilute the purpose of FunctionTestUtils if it becomes too focused on versioning rather than function-related utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class FunctionScoreQueryBuilder","description":"move method def to PsiClass:FunctionScoreQueryBuilder\nRationale: The def() method is related to defining and managing version IDs, which could be relevant in the context of building function score queries. Moving it here would enhance cohesion, as function score queries often need to manage versions. This aligns with the Single Responsibility Principle, as it separates version management from the current class\u0027s responsibilities. However, ensure that the method\u0027s static nature is compatible with the instance-based nature of this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class FuzzyQueryBuilder","description":"move method def to PsiClass:FuzzyQueryBuilder\nRationale: The def() method could fit within the FuzzyQueryBuilder, as it may also require versioning for fuzzy queries. This move would encapsulate version management within a class that deals with query construction, adhering to the Open/Closed Principle by allowing future extensions related to versioning. However, the context of usage must be carefully considered to avoid unnecessary coupling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class RetentionLeaseUtils","description":"move method def to PsiClass:RetentionLeaseUtils\nRationale: The method\u0027s functionality of defining versions can relate to retention leases, which may also require versioning for their management. Moving it here could improve the utility of this class and align with the Interface Segregation Principle by keeping version-related operations within a dedicated utility class. However, the direct relevance of version management to retention leases should be evaluated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":166,"lineEnd":203,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class RetentionLeaseSyncAction","description":"move method getAllVersionIds to PsiClass:RetentionLeaseSyncAction\nRationale: The getAllVersionIds() method is responsible for gathering version information, which could be relevant to synchronization actions. Moving it here would align it with the class\u0027s responsibilities related to lease management. This adheres to the Single Responsibility Principle by ensuring that version management is encapsulated where it is most applicable. However, it may introduce unnecessary dependencies if the class is not directly related to version handling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":166,"lineEnd":203,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class JwtUtil","description":"move method getAllVersionIds to PsiClass:JwtUtil\nRationale: The getAllVersionIds() method could be useful in scenarios where JWTs (JSON Web Tokens) are versioned or managed. By relocating it to JwtUtil, we maintain a cohesive utility for JWT-related functionalities. This move enhances the cohesion of the JwtUtil class, but it may dilute its focus on JWTs alone.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":166,"lineEnd":203,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class RestResponseUtils","description":"move method getAllVersionIds to PsiClass:RestResponseUtils\nRationale: If version information is essential for constructing REST responses, moving getAllVersionIds() to RestResponseUtils would centralize version management for API responses. This change would support the Interface Segregation Principle by allowing consumers to access version data without coupling it to unrelated classes. The drawback may include a bloated utility class with mixed responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""},{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static toReleaseVersion(IndexVersion version)":{"first":{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""},"second":0.09611083112158286},"private static def(int id, Version luceneVersion)":{"first":{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},"second":0.12941359837414174},"static getAllVersionIds(Class\u003c?\u003e cls)":{"first":{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},"second":0.2976438911868046}},"llmMethodPriority":{"priority_method_names":["toReleaseVersion","def","getAllVersionIds"],"llm_response_time":1286},"targetClassMap":{"toReleaseVersion":{"target_classes":[{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.4323583176379408},{"class_name":"RetentionLeaseUtils","similarity_score":0.24618298195866545},{"class_name":"GeoUtilsTests","similarity_score":0.28411793079176595},{"class_name":"DocValuesForUtil","similarity_score":0.3839706279022002},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.37165252240363583},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.3135707402292122},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.7047789667249661},{"class_name":"ForUtil","similarity_score":0.12647571391768506},{"class_name":"ShardUtils","similarity_score":0.3962921988518427},{"class_name":"MapperTestUtils","similarity_score":0.35143174800275734},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.2406649574603851},{"class_name":"BinaryRangeUtilTests","similarity_score":0.22564744487636884},{"class_name":"TranslogOperationsUtils","similarity_score":0.3175264481385601},{"class_name":"StoreUtils","similarity_score":0.37434298441858943},{"class_name":"PForUtil","similarity_score":0.24920943038241472},{"class_name":"RestRankEvalAction","similarity_score":0.2551551815399144},{"class_name":"RestResponseUtils","similarity_score":0.5341799709115684},{"class_name":"HdfsUtils","similarity_score":0.507368418378762},{"class_name":"Index","similarity_score":0.46179743620872726},{"class_name":"FunctionScoreQueryBuilder","similarity_score":0.4587753465852896},{"class_name":"FunctionScoreQueryBuilderTests","similarity_score":0.4211111522599127},{"class_name":"FunctionScoreTests","similarity_score":0.36345116246406844},{"class_name":"FunctionTestUtils","similarity_score":0.6057737519064692},{"class_name":"FutureUtils","similarity_score":0.4097687735311148},{"class_name":"Fuzzy","similarity_score":0.5270882930595464},{"class_name":"RestTestUtil","similarity_score":0.36251240124655426},{"class_name":"IndexerUtils","similarity_score":0.285848076388856},{"class_name":"FuzzyQueryBuilder","similarity_score":0.4543280890922301},{"class_name":"JwkValidateUtil","similarity_score":0.3693202030233661},{"class_name":"JwkValidateUtilTests","similarity_score":0.4605177338720018}],"target_classes_sorted_by_llm":["LiveVersionMapTestUtils","Index","FunctionTestUtils","FuzzyQueryBuilder","Fuzzy","HdfsUtils","RestResponseUtils","FunctionScoreQueryBuilder","IndexLongFieldRangeTestUtils","JwkValidateUtilTests"],"llm_response_time":12792,"similarity_computation_time":38,"similarity_metric":"voyage"},"def":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.39936153191543583},{"class_name":"GeoUtilsTests","similarity_score":0.27817319776069427},{"class_name":"DocValuesForUtil","similarity_score":0.36143582987457723},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.33839711075769596},{"class_name":"TranslogOperationsUtils","similarity_score":0.25386870177080006},{"class_name":"ShardUtils","similarity_score":0.37125790825650834},{"class_name":"ForUtil","similarity_score":0.24934314243640046},{"class_name":"MapperTestUtils","similarity_score":0.23139254551834096},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.3494364432545739},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.3848328268108964},{"class_name":"BinaryRangeUtilTests","similarity_score":0.24745880919862429},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.3750828710370748},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.21384593694802698},{"class_name":"StoreUtils","similarity_score":0.28027592733560525},{"class_name":"PForUtil","similarity_score":0.29930895523256223},{"class_name":"RestRankEvalAction","similarity_score":0.20833790199668917},{"class_name":"EvalQueryQuality","similarity_score":0.3339425961670144},{"class_name":"EvalQueryQualityTests","similarity_score":0.33914325707630794},{"class_name":"RestResponseUtils","similarity_score":0.3676666272028088},{"class_name":"FunctionScoreQueryBuilder","similarity_score":0.4641656769097169},{"class_name":"FunctionScoreQueryBuilderTests","similarity_score":0.4065289838386301},{"class_name":"FunctionScoreTests","similarity_score":0.36601888678507977},{"class_name":"FunctionTestUtils","similarity_score":0.37975324056440274},{"class_name":"RestTestUtil","similarity_score":0.2465381993439922},{"class_name":"RestUtils","similarity_score":0.44308563624472597},{"class_name":"RestUtilsTests","similarity_score":0.2437353335164991},{"class_name":"FutureUtils","similarity_score":0.3633872245155078},{"class_name":"Fuzzy","similarity_score":0.35436097740748457},{"class_name":"FuzzyQueryBuilder","similarity_score":0.3860179964752081},{"class_name":"JwkValidateUtil","similarity_score":0.4493373614006415}],"target_classes_sorted_by_llm":["FunctionScoreQueryBuilder","FuzzyQueryBuilder","RetentionLeaseUtils","ShardUtils","SpanQueryBuilderUtil","RestUtils","JwkValidateUtil","FunctionScoreQueryBuilderTests","FunctionTestUtils","IpPrefixAutomatonUtil"],"llm_response_time":14307,"similarity_computation_time":10,"similarity_metric":"voyage"},"getAllVersionIds":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.3021707796612132},{"class_name":"DocValuesForUtil","similarity_score":0.5619610456697409},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.4836678224002255},{"class_name":"TranslogOperationsUtils","similarity_score":0.2611062172976518},{"class_name":"PForUtil","similarity_score":0.4973905536023055},{"class_name":"ShardUtils","similarity_score":0.3857800797691074},{"class_name":"MapperTestUtils","similarity_score":0.409481573743763},{"class_name":"StoreUtils","similarity_score":0.4095076911385495},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.4772930401315485},{"class_name":"BinaryRangeUtilTests","similarity_score":0.5086631256802449},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.5176156609873632},{"class_name":"ForUtil","similarity_score":0.43824805104509357},{"class_name":"GeoUtilsTests","similarity_score":0.5488071214946735},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.6369431073948892},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.49036050286905675},{"class_name":"NoriClientYamlTestSuiteIT","similarity_score":0.3786636568415178},{"class_name":"RestRankEvalAction","similarity_score":0.30238403841456},{"class_name":"RestResponseUtils","similarity_score":0.6046329960966023},{"class_name":"RestTestUtil","similarity_score":0.3572239339548838},{"class_name":"RestUtils","similarity_score":0.5511392166702873},{"class_name":"RestUtilsTests","similarity_score":0.4481031604623742},{"class_name":"JwkValidateUtil","similarity_score":0.6513767309147852},{"class_name":"JwkValidateUtilTests","similarity_score":0.524101804268313},{"class_name":"Detail","similarity_score":0.5105770896385643},{"class_name":"RetentionLease","similarity_score":0.4256699176090045},{"class_name":"RetentionLeaseBackgroundSyncAction","similarity_score":0.5664740127369684},{"class_name":"RetentionLeaseIT","similarity_score":0.4283987838830049},{"class_name":"JwtUtil","similarity_score":0.6838887257920059},{"class_name":"RetentionLeases","similarity_score":0.458543535799561},{"class_name":"RetentionLeaseSyncAction","similarity_score":0.5667592063368625}],"target_classes_sorted_by_llm":["RetentionLeaseSyncAction","JwtUtil","RestResponseUtils","DocValuesForUtil","IpPrefixAutomatonUtil","GeoUtilsTests","JwkValidateUtil","RetentionLeaseBackgroundSyncAction","RestUtils","JwkValidateUtilTests"],"llm_response_time":13146,"similarity_computation_time":16,"similarity_metric":"voyage"}}}
{"id":"9c8c9d8b-d02d-4e99-bcbd-194aeb158271","methodCount":5,"hostFunctionTelemetryData":{"hostFunctionSize":276,"lineStart":25,"lineEnd":300,"bodyLineStart":25,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/TransportVersions.java","sourceCode":"/**\n * \u003cp\u003eTransport version is used to coordinate compatible wire protocol communication between nodes, at a fine-grained level.  This replaces\n * and supersedes the old Version constants.\u003c/p\u003e\n *\n * \u003cp\u003eBefore adding a new version constant, please read the block comment at the end of the list of constants.\u003c/p\u003e\n */\npublic class TransportVersions {\n\n    /*\n     * NOTE: IntelliJ lies!\n     * This map is used during class construction, referenced by the registerTransportVersion method.\n     * When all the transport version constants have been registered, the map is cleared \u0026 never touched again.\n     */\n    static TreeSet\u003cInteger\u003e IDS \u003d new TreeSet\u003c\u003e();\n\n    static TransportVersion def(int id) {\n        if (IDS \u003d\u003d null) throw new IllegalStateException(\"The IDS map needs to be present to call this method\");\n\n        if (IDS.add(id) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" defined twice\");\n        }\n        if (id \u003c IDS.last()) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" is not defined in the right location. Keep constants sorted\");\n        }\n        return new TransportVersion(id);\n    }\n\n    @UpdateForV9 // remove the transport versions with which v9 will not need to interact\n    public static final TransportVersion ZERO \u003d def(0);\n    public static final TransportVersion V_7_0_0 \u003d def(7_00_00_99);\n    public static final TransportVersion V_7_0_1 \u003d def(7_00_01_99);\n    public static final TransportVersion V_7_1_0 \u003d def(7_01_00_99);\n    public static final TransportVersion V_7_2_0 \u003d def(7_02_00_99);\n    public static final TransportVersion V_7_2_1 \u003d def(7_02_01_99);\n    public static final TransportVersion V_7_3_0 \u003d def(7_03_00_99);\n    public static final TransportVersion V_7_3_2 \u003d def(7_03_02_99);\n    public static final TransportVersion V_7_4_0 \u003d def(7_04_00_99);\n    public static final TransportVersion V_7_5_0 \u003d def(7_05_00_99);\n    public static final TransportVersion V_7_6_0 \u003d def(7_06_00_99);\n    public static final TransportVersion V_7_7_0 \u003d def(7_07_00_99);\n    public static final TransportVersion V_7_8_0 \u003d def(7_08_00_99);\n    public static final TransportVersion V_7_8_1 \u003d def(7_08_01_99);\n    public static final TransportVersion V_7_9_0 \u003d def(7_09_00_99);\n    public static final TransportVersion V_7_10_0 \u003d def(7_10_00_99);\n    public static final TransportVersion V_7_10_1 \u003d def(7_10_01_99);\n    public static final TransportVersion V_7_11_0 \u003d def(7_11_00_99);\n    public static final TransportVersion V_7_12_0 \u003d def(7_12_00_99);\n    public static final TransportVersion V_7_13_0 \u003d def(7_13_00_99);\n    public static final TransportVersion V_7_14_0 \u003d def(7_14_00_99);\n    public static final TransportVersion V_7_15_0 \u003d def(7_15_00_99);\n    public static final TransportVersion V_7_15_1 \u003d def(7_15_01_99);\n    public static final TransportVersion V_7_16_0 \u003d def(7_16_00_99);\n    public static final TransportVersion V_7_17_0 \u003d def(7_17_00_99);\n    public static final TransportVersion V_7_17_1 \u003d def(7_17_01_99);\n    public static final TransportVersion V_7_17_8 \u003d def(7_17_08_99);\n    public static final TransportVersion V_8_0_0 \u003d def(8_00_00_99);\n    public static final TransportVersion V_8_1_0 \u003d def(8_01_00_99);\n    public static final TransportVersion V_8_2_0 \u003d def(8_02_00_99);\n    public static final TransportVersion V_8_3_0 \u003d def(8_03_00_99);\n    public static final TransportVersion V_8_4_0 \u003d def(8_04_00_99);\n    public static final TransportVersion V_8_5_0 \u003d def(8_05_00_99);\n    public static final TransportVersion V_8_6_0 \u003d def(8_06_00_99);\n    public static final TransportVersion V_8_6_1 \u003d def(8_06_01_99);\n    public static final TransportVersion V_8_7_0 \u003d def(8_07_00_99);\n    public static final TransportVersion V_8_7_1 \u003d def(8_07_01_99);\n    public static final TransportVersion V_8_8_0 \u003d def(8_08_00_99);\n    public static final TransportVersion V_8_8_1 \u003d def(8_08_01_99);\n    /*\n     * READ THE COMMENT BELOW THIS BLOCK OF DECLARATIONS BEFORE ADDING NEW TRANSPORT VERSIONS\n     * Detached transport versions added below here.\n     */\n    public static final TransportVersion V_8_9_X \u003d def(8_500_020);\n    public static final TransportVersion V_8_10_X \u003d def(8_500_061);\n    public static final TransportVersion V_8_11_X \u003d def(8_512_00_1);\n    public static final TransportVersion PLUGIN_DESCRIPTOR_OPTIONAL_CLASSNAME \u003d def(8_513_00_0);\n    public static final TransportVersion UNIVERSAL_PROFILING_LICENSE_ADDED \u003d def(8_514_00_0);\n    public static final TransportVersion ELSER_SERVICE_MODEL_VERSION_ADDED \u003d def(8_515_00_0);\n    public static final TransportVersion NODE_STATS_HTTP_ROUTE_STATS_ADDED \u003d def(8_516_00_0);\n    public static final TransportVersion INCLUDE_SHARDS_STATS_ADDED \u003d def(8_517_00_0);\n    public static final TransportVersion BUILD_QUALIFIER_SEPARATED \u003d def(8_518_00_0);\n    public static final TransportVersion PIPELINES_IN_BULK_RESPONSE_ADDED \u003d def(8_519_00_0);\n    public static final TransportVersion PLUGIN_DESCRIPTOR_STRING_VERSION \u003d def(8_520_00_0);\n    public static final TransportVersion TOO_MANY_SCROLL_CONTEXTS_EXCEPTION_ADDED \u003d def(8_521_00_0);\n    public static final TransportVersion UNCONTENDED_REGISTER_ANALYSIS_ADDED \u003d def(8_522_00_0);\n    public static final TransportVersion TRANSFORM_GET_CHECKPOINT_TIMEOUT_ADDED \u003d def(8_523_00_0);\n    public static final TransportVersion IP_ADDRESS_WRITEABLE \u003d def(8_524_00_0);\n    public static final TransportVersion PRIMARY_TERM_ADDED \u003d def(8_525_00_0);\n    public static final TransportVersion CLUSTER_FEATURES_ADDED \u003d def(8_526_00_0);\n    public static final TransportVersion DSL_ERROR_STORE_INFORMATION_ENHANCED \u003d def(8_527_00_0);\n    public static final TransportVersion INVALID_BUCKET_PATH_EXCEPTION_INTRODUCED \u003d def(8_528_00_0);\n    public static final TransportVersion KNN_AS_QUERY_ADDED \u003d def(8_529_00_0);\n    public static final TransportVersion UNDESIRED_SHARD_ALLOCATIONS_COUNT_ADDED \u003d def(8_530_00_0);\n    public static final TransportVersion ML_INFERENCE_TASK_SETTINGS_OPTIONAL_ADDED \u003d def(8_531_00_0);\n    public static final TransportVersion DEPRECATED_COMPONENT_TEMPLATES_ADDED \u003d def(8_532_00_0);\n    public static final TransportVersion UPDATE_NON_DYNAMIC_SETTINGS_ADDED \u003d def(8_533_00_0);\n    public static final TransportVersion REPO_ANALYSIS_REGISTER_OP_COUNT_ADDED \u003d def(8_534_00_0);\n    public static final TransportVersion ML_TRAINED_MODEL_PREFIX_STRINGS_ADDED \u003d def(8_535_00_0);\n    public static final TransportVersion COUNTED_KEYWORD_ADDED \u003d def(8_536_00_0);\n    public static final TransportVersion SHAPE_VALUE_SERIALIZATION_ADDED \u003d def(8_537_00_0);\n    public static final TransportVersion INFERENCE_MULTIPLE_INPUTS \u003d def(8_538_00_0);\n    public static final TransportVersion ADDITIONAL_DESIRED_BALANCE_RECONCILIATION_STATS \u003d def(8_539_00_0);\n    public static final TransportVersion ML_STATE_CHANGE_TIMESTAMPS \u003d def(8_540_00_0);\n    public static final TransportVersion DATA_STREAM_FAILURE_STORE_ADDED \u003d def(8_541_00_0);\n    public static final TransportVersion ML_INFERENCE_OPENAI_ADDED \u003d def(8_542_00_0);\n    public static final TransportVersion SHUTDOWN_MIGRATION_STATUS_INCLUDE_COUNTS \u003d def(8_543_00_0);\n    public static final TransportVersion TRANSFORM_GET_CHECKPOINT_QUERY_AND_CLUSTER_ADDED \u003d def(8_544_00_0);\n    public static final TransportVersion GRANT_API_KEY_CLIENT_AUTHENTICATION_ADDED \u003d def(8_545_00_0);\n    public static final TransportVersion PIT_WITH_INDEX_FILTER \u003d def(8_546_00_0);\n    public static final TransportVersion NODE_INFO_VERSION_AS_STRING \u003d def(8_547_00_0);\n    public static final TransportVersion GET_API_KEY_INVALIDATION_TIME_ADDED \u003d def(8_548_00_0);\n    public static final TransportVersion ML_INFERENCE_GET_MULTIPLE_MODELS \u003d def(8_549_00_0);\n    public static final TransportVersion INFERENCE_SERVICE_RESULTS_ADDED \u003d def(8_550_00_0);\n    public static final TransportVersion ESQL_PROFILE \u003d def(8_551_00_0);\n    public static final TransportVersion CLUSTER_STATS_RESCORER_USAGE_ADDED \u003d def(8_552_00_0);\n    public static final TransportVersion ML_INFERENCE_HF_SERVICE_ADDED \u003d def(8_553_00_0);\n    public static final TransportVersion INFERENCE_USAGE_ADDED \u003d def(8_554_00_0);\n    public static final TransportVersion UPGRADE_TO_LUCENE_9_9 \u003d def(8_555_00_0);\n    public static final TransportVersion HEALTH_INFO_ENRICHED_WITH_DSL_STATUS \u003d def(8_556_00_0);\n    public static final TransportVersion SOURCE_IN_SINGLE_VALUE_QUERY_ADDED \u003d def(8_557_00_0);\n    public static final TransportVersion MISSED_INDICES_UPDATE_EXCEPTION_ADDED \u003d def(8_558_00_0);\n    public static final TransportVersion INFERENCE_SERVICE_EMBEDDING_SIZE_ADDED \u003d def(8_559_00_0);\n    public static final TransportVersion ENRICH_ELASTICSEARCH_VERSION_REMOVED \u003d def(8_560_00_0);\n    public static final TransportVersion DATE_HISTOGRAM_SUPPORT_DOWNSAMPLED_TZ_8_12_PATCH \u003d def(8_560_00_1);\n    public static final TransportVersion NODE_STATS_REQUEST_SIMPLIFIED \u003d def(8_561_00_0);\n    public static final TransportVersion TEXT_EXPANSION_TOKEN_PRUNING_CONFIG_ADDED \u003d def(8_562_00_0);\n    public static final TransportVersion ESQL_ASYNC_QUERY \u003d def(8_563_00_0);\n    public static final TransportVersion ESQL_STATUS_INCLUDE_LUCENE_QUERIES \u003d def(8_564_00_0);\n    public static final TransportVersion ESQL_CLUSTER_ALIAS \u003d def(8_565_00_0);\n    public static final TransportVersion SNAPSHOTS_IN_PROGRESS_TRACKING_REMOVING_NODES_ADDED \u003d def(8_566_00_0);\n    public static final TransportVersion SMALLER_RELOAD_SECURE_SETTINGS_REQUEST \u003d def(8_567_00_0);\n    public static final TransportVersion UPDATE_API_KEY_EXPIRATION_TIME_ADDED \u003d def(8_568_00_0);\n    public static final TransportVersion LAZY_ROLLOVER_ADDED \u003d def(8_569_00_0);\n    public static final TransportVersion ESQL_PLAN_POINT_LITERAL_WKB \u003d def(8_570_00_0);\n    public static final TransportVersion HOT_THREADS_AS_BYTES \u003d def(8_571_00_0);\n    public static final TransportVersion ML_INFERENCE_REQUEST_INPUT_TYPE_ADDED \u003d def(8_572_00_0);\n    public static final TransportVersion ESQL_ENRICH_POLICY_CCQ_MODE \u003d def(8_573_00_0);\n    public static final TransportVersion DATE_HISTOGRAM_SUPPORT_DOWNSAMPLED_TZ \u003d def(8_574_00_0);\n    public static final TransportVersion PEERFINDER_REPORTS_PEERS_MASTERS \u003d def(8_575_00_0);\n    public static final TransportVersion ESQL_MULTI_CLUSTERS_ENRICH \u003d def(8_576_00_0);\n    public static final TransportVersion NESTED_KNN_MORE_INNER_HITS \u003d def(8_577_00_0);\n    public static final TransportVersion REQUIRE_DATA_STREAM_ADDED \u003d def(8_578_00_0);\n    public static final TransportVersion ML_INFERENCE_COHERE_EMBEDDINGS_ADDED \u003d def(8_579_00_0);\n    public static final TransportVersion DESIRED_NODE_VERSION_OPTIONAL_STRING \u003d def(8_580_00_0);\n\n    /*\n     * STOP! READ THIS FIRST! No, really,\n     *        ____ _____ ___  ____  _        ____  _____    _    ____    _____ _   _ ___ ____    _____ ___ ____  ____ _____ _\n     *       / ___|_   _/ _ \\|  _ \\| |      |  _ \\| ____|  / \\  |  _ \\  |_   _| | | |_ _/ ___|  |  ___|_ _|  _ \\/ ___|_   _| |\n     *       \\___ \\ | || | | | |_) | |      | |_) |  _|   / _ \\ | | | |   | | | |_| || |\\___ \\  | |_   | || |_) \\___ \\ | | | |\n     *        ___) || || |_| |  __/|_|      |  _ \u003c| |___ / ___ \\| |_| |   | | |  _  || | ___) | |  _|  | ||  _ \u003c ___) || | |_|\n     *       |____/ |_| \\___/|_|   (_)      |_| \\_\\_____/_/   \\_\\____/    |_| |_| |_|___|____/  |_|   |___|_| \\_\\____/ |_| (_)\n     *\n     * A new transport version should be added EVERY TIME a change is made to the serialization protocol of one or more classes. Each\n     * transport version should only be used in a single merged commit (apart from the BwC versions copied from o.e.Version, V_8_8_1).\n     *\n     * ADDING A TRANSPORT VERSION\n     * To add a new transport version, add a new constant at the bottom of the list, above this comment. Don\u0027t add other lines,\n     * comments, etc. The version id has the following layout:\n     *\n     * M_NNN_SS_P\n     *\n     * M - The major version of Elasticsearch\n     * NNN - The server version part\n     * SS - The serverless version part. It should always be 00 here, it is used by serverless only.\n     * P - The patch version part\n     *\n     * To determine the id of the next TransportVersion constant, do the following:\n     * - Use the same major version, unless bumping majors\n     * - Bump the server version part by 1, unless creating a patch version\n     * - Leave the serverless part as 00\n     * - Bump the patch part if creating a patch version\n     *\n     * If a patch version is created, it should be placed sorted among the other existing constants.\n     *\n     * REVERTING A TRANSPORT VERSION\n     *\n     * If you revert a commit with a transport version change, you MUST ensure there is a NEW transport version representing the reverted\n     * change. DO NOT let the transport version go backwards, it must ALWAYS be incremented.\n     *\n     * DETERMINING TRANSPORT VERSIONS FROM GIT HISTORY\n     *\n     * If your git checkout has the expected minor-version-numbered branches and the expected release-version tags then you can find the\n     * transport versions known by a particular release ...\n     *\n     *     git show v8.11.0:server/src/main/java/org/elasticsearch/TransportVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... or by a particular branch ...\n     *\n     *     git show 8.11:server/src/main/java/org/elasticsearch/TransportVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... and you can see which versions were added in between two versions too ...\n     *\n     *     git diff v8.11.0..main -- server/src/main/java/org/elasticsearch/TransportVersions.java\n     *\n     * In branches 8.7-8.10 see server/src/main/java/org/elasticsearch/TransportVersion.java for the equivalent definitions.\n     */\n\n    // Placeholder for features that require the next lucene version. Its id needs to be adjusted when merging lucene_snapshot into main.\n    public static final TransportVersion UPGRADE_TO_LUCENE_9_10 \u003d def(8_900_00_0);\n\n    /**\n     * Reference to the earliest compatible transport version to this version of the codebase.\n     * This should be the transport version used by the highest minor version of the previous major.\n     */\n    public static final TransportVersion MINIMUM_COMPATIBLE \u003d V_7_17_0;\n\n    /**\n     * Reference to the minimum transport version that can be used with CCS.\n     * This should be the transport version used by the previous minor release.\n     */\n    public static final TransportVersion MINIMUM_CCS_VERSION \u003d V_8_11_X;\n\n    static final NavigableMap\u003cInteger, TransportVersion\u003e VERSION_IDS \u003d getAllVersionIds(TransportVersions.class);\n\n    // the highest transport version constant defined in this file, used as a fallback for TransportVersion.current()\n    static final TransportVersion LATEST_DEFINED;\n    static {\n        LATEST_DEFINED \u003d VERSION_IDS.lastEntry().getValue();\n\n        // see comment on IDS field\n        // now we\u0027re registered all the transport versions, we can clear the map\n        IDS \u003d null;\n    }\n\n    public static NavigableMap\u003cInteger, TransportVersion\u003e getAllVersionIds(Class\u003c?\u003e cls) {\n        Map\u003cInteger, String\u003e versionIdFields \u003d new HashMap\u003c\u003e();\n        NavigableMap\u003cInteger, TransportVersion\u003e builder \u003d new TreeMap\u003c\u003e();\n\n        Set\u003cString\u003e ignore \u003d Set.of(\"ZERO\", \"CURRENT\", \"MINIMUM_COMPATIBLE\", \"MINIMUM_CCS_VERSION\");\n\n        for (Field declaredField : cls.getFields()) {\n            if (declaredField.getType().equals(TransportVersion.class)) {\n                String fieldName \u003d declaredField.getName();\n                if (ignore.contains(fieldName)) {\n                    continue;\n                }\n\n                TransportVersion version;\n                try {\n                    version \u003d (TransportVersion) declaredField.get(null);\n                } catch (IllegalAccessException e) {\n                    throw new AssertionError(e);\n                }\n                builder.put(version.id(), version);\n\n                if (Assertions.ENABLED) {\n                    // check the version number is unique\n                    var sameVersionNumber \u003d versionIdFields.put(version.id(), fieldName);\n                    assert sameVersionNumber \u003d\u003d null\n                        : \"Versions [\"\n                            + sameVersionNumber\n                            + \"] and [\"\n                            + fieldName\n                            + \"] have the same version number [\"\n                            + version.id()\n                            + \"]. Each TransportVersion should have a different version number\";\n                }\n            }\n        }\n\n        return Collections.unmodifiableNavigableMap(builder);\n    }\n\n    static Collection\u003cTransportVersion\u003e getAllVersions() {\n        return VERSION_IDS.values();\n    }\n\n    private static final IntFunction\u003cString\u003e VERSION_LOOKUP \u003d ReleaseVersions.generateVersionsLookup(TransportVersions.class);\n\n    public static String toReleaseVersion(TransportVersion version) {\n        return VERSION_LOOKUP.apply(version.id());\n    }\n\n    // no instance\n    private TransportVersions() {}\n}","methodCount":5},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":293,"lineEnd":295,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class RestResponseUtils","description":"move method toReleaseVersion to PsiClass:RestResponseUtils\nRationale: If toReleaseVersion() is used to construct responses that include version information, it could be logical to place it in RestResponseUtils. This aligns with the Interface Segregation Principle, as it keeps related response formatting logic together. However, ensure that this utility does not become bloated with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":293,"lineEnd":295,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class DiffableUtils","description":"move method toReleaseVersion to PsiClass:DiffableUtils\nRationale: If the TransportVersion is used to compare versions of data or configurations, DiffableUtils could be a fitting home for the method. This adheres to the Single Responsibility Principle by grouping version comparison logic. However, ensure that the method does not dilute the primary purpose of the DiffableUtils class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":293,"lineEnd":295,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class DiscoveryNodeUtils","description":"move method toReleaseVersion to PsiClass:DiscoveryNodeUtils\nRationale: null","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class KeyStoreUtil","description":"move method def to PsiClass:KeyStoreUtil\nRationale: If the versioning is related to key management (e.g., versioning keys), then KeyStoreUtil is an appropriate candidate. This move supports the Interface Segregation Principle, as it separates concerns related to versioning from other functionalities. However, ensure that the method\u0027s context remains relevant to key management.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class JwtUtil","description":"move method def to PsiClass:JwtUtil\nRationale: Given that the method handles version IDs, which could be relevant to JWTs, moving it to JwtUtil aligns with the Single Responsibility Principle. It centralizes version management for JWTs. However, this may create a tight coupling between version management and JWT processing, which should be considered.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":39,"lineEnd":49,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class AuditUtil","description":"move method def to PsiClass:AuditUtil\nRationale: If versioning is tied to audit trails or logging of versioned actions, then AuditUtil could be a suitable target. This move would help maintain a clear separation of concerns, adhering to the Single Responsibility Principle. However, ensure that the method\u0027s logic is relevant to auditing, as it may introduce unnecessary complexity.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":248,"lineEnd":285,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class GeometryTestUtils","description":"move method getAllVersionIds to PsiClass:GeometryTestUtils\nRationale: This class primarily focuses on geometric utilities. If TransportVersion has a significant role in geometry-related operations, the method could be appropriate here. However, this may lead to an unclear separation of concerns, as the class could become too broad in scope.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":248,"lineEnd":285,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class JwkValidateUtil","description":"move method getAllVersionIds to PsiClass:JwkValidateUtil\nRationale: Since this class deals with validation, moving getAllVersionIds() here could help in managing version validation for JWTs or similar transport mechanisms. This adheres to the Interface Segregation Principle by ensuring that classes only have methods they use. However, it might lead to a clash of responsibilities if the class becomes overloaded with unrelated validation tasks.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":248,"lineEnd":285,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class GceMockUtils","description":"move method getAllVersionIds to PsiClass:GceMockUtils\nRationale: If TransportVersion relates to Google Cloud environments, this class could be an appropriate target. Moving the method here can improve cohesion in handling versions relevant to cloud services. However, it risks overloading GceMockUtils with unrelated functionalities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""},{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static toReleaseVersion(TransportVersion version)":{"first":{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(TransportVersion version)","target_class":"","rationale":""},"second":0.04977325217369346},"static def(int id)":{"first":{"method_name":"def","method_signature":"static def(int id)","target_class":"","rationale":""},"second":0.0801119478048192},"public static getAllVersionIds(Class\u003c?\u003e cls)":{"first":{"method_name":"getAllVersionIds","method_signature":"public static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},"second":0.27589488602856754}},"llmMethodPriority":{"priority_method_names":["toReleaseVersion","def","getAllVersionIds"],"llm_response_time":1132},"targetClassMap":{"toReleaseVersion":{"target_classes":[{"class_name":"MapperTestUtils","similarity_score":0.35143174800275734},{"class_name":"RestResponseUtils","similarity_score":0.5341799709115684},{"class_name":"JwkValidateUtil","similarity_score":0.3693202030233661},{"class_name":"JwkValidateUtilTests","similarity_score":0.4605177338720018},{"class_name":"FunctionTestUtils","similarity_score":0.6057737519064692},{"class_name":"FutureUtils","similarity_score":0.4097687735311148},{"class_name":"JwtUtil","similarity_score":0.4682859094646369},{"class_name":"GceMockUtils","similarity_score":0.5984070327819713},{"class_name":"MathUtils","similarity_score":0.2498438963319538},{"class_name":"RestTestUtil","similarity_score":0.36251240124655426},{"class_name":"GeneratorUtils","similarity_score":0.4327311847691595},{"class_name":"RestUtils","similarity_score":0.3731804509515294},{"class_name":"RestUtilsTests","similarity_score":0.21247269738650393},{"class_name":"NumericUtilsTests","similarity_score":0.2200186589446435},{"class_name":"TemplateUtils","similarity_score":0.4841862805868116},{"class_name":"TemplateUtilsTests","similarity_score":0.47580960223169094},{"class_name":"Term","similarity_score":0.36980013081681945},{"class_name":"KeyStoreUtil","similarity_score":0.4285671874853539},{"class_name":"DiffableTestUtils","similarity_score":0.3309315178638468},{"class_name":"DiffableUtils","similarity_score":0.49709736592315956},{"class_name":"RetentionLeaseUtils","similarity_score":0.24618298195866545},{"class_name":"GeometryTestUtils","similarity_score":0.5292620865139949},{"class_name":"GeoTestUtils","similarity_score":0.5181062962530634},{"class_name":"DiscoveryNodeUtils","similarity_score":0.6091903023413275},{"class_name":"GeoTileUtils","similarity_score":0.3334498199631966},{"class_name":"GeoUtils","similarity_score":0.3688903996096243},{"class_name":"GeoUtilsTests","similarity_score":0.28411793079176595},{"class_name":"OpenAiUtils","similarity_score":0.5695717718111739},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.31354899562671606},{"class_name":"MetadataUtils","similarity_score":0.6009985811402784}],"target_classes_sorted_by_llm":["RestResponseUtils","DiffableUtils","DiscoveryNodeUtils","FunctionTestUtils","MetadataUtils","GceMockUtils","OpenAiUtils","GeometryTestUtils","GeoTestUtils","TemplateUtils"],"llm_response_time":0,"similarity_computation_time":17,"similarity_metric":"voyage"},"def":{"target_classes":[{"class_name":"RestResponseUtils","similarity_score":0.36883831427800173},{"class_name":"AuditUtil","similarity_score":0.4531198376018793},{"class_name":"MapperTestUtils","similarity_score":0.2344986247072784},{"class_name":"RestTestUtil","similarity_score":0.2475554053177393},{"class_name":"RestUtils","similarity_score":0.44446470720062153},{"class_name":"RestUtilsTests","similarity_score":0.24251605703234483},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.29595320327004154},{"class_name":"AuthorizationUtils","similarity_score":0.26207931898933023},{"class_name":"JwkValidateUtil","similarity_score":0.45421617233866024},{"class_name":"JwkValidateUtilTests","similarity_score":0.31860723156484283},{"class_name":"RetentionLeaseUtils","similarity_score":0.3996633001424493},{"class_name":"MathUtils","similarity_score":0.35734452681016154},{"class_name":"JwtUtil","similarity_score":0.511559378709225},{"class_name":"CheckedFunctionUtils","similarity_score":0.12975117797815766},{"class_name":"AwsEc2Utils","similarity_score":0.3793348636496733},{"class_name":"NumericUtilsTests","similarity_score":0.08832415570865416},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.4384542023153874},{"class_name":"KeyStoreUtil","similarity_score":0.3829329981926565},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.4802583175406127},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.27517071015687183},{"class_name":"CIDRUtils","similarity_score":0.3694397626541088},{"class_name":"CircleUtils","similarity_score":0.3473325262508327},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.1784323985249216},{"class_name":"MetadataUtils","similarity_score":0.2547279232560005},{"class_name":"MetaStateWriterUtils","similarity_score":0.3367994474544599},{"class_name":"DiffableTestUtils","similarity_score":0.2211292131269157},{"class_name":"DiffableUtils","similarity_score":0.3579737713782125},{"class_name":"ClasspathUtils","similarity_score":0.30713957630810024},{"class_name":"OpenAiUtils","similarity_score":0.15450108709773383},{"class_name":"RuntimeUtils","similarity_score":0.4424612633602685}],"target_classes_sorted_by_llm":["KeyStoreUtil","JwtUtil","AuditUtil","ChunkedLoggingStreamTestUtils","JwkValidateUtil","RollupJobIdentifierUtils","RestUtils","RuntimeUtils","RetentionLeaseUtils","AwsEc2Utils"],"llm_response_time":0,"similarity_computation_time":14,"similarity_metric":"voyage"},"getAllVersionIds":{"target_classes":[{"class_name":"RestResponseUtils","similarity_score":0.6094800933316928},{"class_name":"MapperTestUtils","similarity_score":0.4179890848219992},{"class_name":"RestTestUtil","similarity_score":0.3664930489080661},{"class_name":"LevelUtil","similarity_score":0.16511200151027827},{"class_name":"RestUtils","similarity_score":0.5516467904589053},{"class_name":"RestUtilsTests","similarity_score":0.45211506659204803},{"class_name":"FunctionTestUtils","similarity_score":0.5760952533789586},{"class_name":"FutureUtils","similarity_score":0.4541608361241388},{"class_name":"JwkValidateUtil","similarity_score":0.6506503163376719},{"class_name":"JwkValidateUtilTests","similarity_score":0.5323931205692574},{"class_name":"LicenseUtils","similarity_score":0.5618127242375072},{"class_name":"RetentionLeaseUtils","similarity_score":0.3076510573997831},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.2554891523649131},{"class_name":"LifecyclePolicyTestsUtils","similarity_score":0.3185745499261599},{"class_name":"LifecyclePolicyUtils","similarity_score":0.6332647125541064},{"class_name":"MathUtils","similarity_score":0.42097893756142174},{"class_name":"GceMockUtils","similarity_score":0.5844004915614751},{"class_name":"JwtUtil","similarity_score":0.6894940885045573},{"class_name":"GeneratorUtils","similarity_score":0.5376773783366607},{"class_name":"NumericUtilsTests","similarity_score":0.17587853874370266},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.6245676734797437},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.4322432137700632},{"class_name":"KeyStoreUtil","similarity_score":0.542529276136968},{"class_name":"GeometryTestUtils","similarity_score":0.594240576667327},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.5015193295878273},{"class_name":"GeoTestUtils","similarity_score":0.5076289500467781},{"class_name":"GeoTileUtils","similarity_score":0.41454610233478745},{"class_name":"GeoUtils","similarity_score":0.43587977647556064},{"class_name":"GeoUtilsTests","similarity_score":0.5546854987335111},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.21539199305231596}],"target_classes_sorted_by_llm":["GeometryTestUtils","JwkValidateUtil","GceMockUtils","JwtUtil","LifecyclePolicyUtils","RollupJobIdentifierUtils","RestResponseUtils","FunctionTestUtils","LicenseUtils","GeoUtilsTests"],"llm_response_time":0,"similarity_computation_time":7,"similarity_metric":"voyage"}}}
{"id":"8d3edb46-9a73-4d9e-b055-cc42d7259043","methodCount":4,"hostFunctionTelemetryData":{"hostFunctionSize":191,"lineStart":27,"lineEnd":217,"bodyLineStart":27,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/index/IndexVersions.java","sourceCode":"@SuppressWarnings(\"deprecation\")\npublic class IndexVersions {\n\n    /*\n     * NOTE: IntelliJ lies!\n     * This map is used during class construction, referenced by the registerIndexVersion method.\n     * When all the index version constants have been registered, the map is cleared \u0026 never touched again.\n     */\n    @SuppressWarnings(\"UnusedAssignment\")\n    static TreeSet\u003cInteger\u003e IDS \u003d new TreeSet\u003c\u003e();\n\n    private static IndexVersion def(int id, Version luceneVersion) {\n        if (IDS \u003d\u003d null) throw new IllegalStateException(\"The IDS map needs to be present to call this method\");\n\n        if (IDS.add(id) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" defined twice\");\n        }\n        if (id \u003c IDS.last()) {\n            throw new IllegalArgumentException(\"Version id \" + id + \" is not defined in the right location. Keep constants sorted\");\n        }\n        return new IndexVersion(id, luceneVersion);\n    }\n\n    @UpdateForV9 // remove the index versions with which v9 will not need to interact\n    public static final IndexVersion ZERO \u003d def(0, Version.LATEST);\n    public static final IndexVersion V_7_0_0 \u003d def(7_00_00_99, Version.LUCENE_8_0_0);\n\n    public static final IndexVersion V_7_1_0 \u003d def(7_01_00_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_2_0 \u003d def(7_02_00_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_2_1 \u003d def(7_02_01_99, Version.LUCENE_8_0_0);\n    public static final IndexVersion V_7_3_0 \u003d def(7_03_00_99, Version.LUCENE_8_1_0);\n    public static final IndexVersion V_7_4_0 \u003d def(7_04_00_99, Version.LUCENE_8_2_0);\n    public static final IndexVersion V_7_5_0 \u003d def(7_05_00_99, Version.LUCENE_8_3_0);\n    public static final IndexVersion V_7_5_2 \u003d def(7_05_02_99, Version.LUCENE_8_3_0);\n    public static final IndexVersion V_7_6_0 \u003d def(7_06_00_99, Version.LUCENE_8_4_0);\n    public static final IndexVersion V_7_7_0 \u003d def(7_07_00_99, Version.LUCENE_8_5_1);\n    public static final IndexVersion V_7_8_0 \u003d def(7_08_00_99, Version.LUCENE_8_5_1);\n    public static final IndexVersion V_7_9_0 \u003d def(7_09_00_99, Version.LUCENE_8_6_0);\n    public static final IndexVersion V_7_10_0 \u003d def(7_10_00_99, Version.LUCENE_8_7_0);\n    public static final IndexVersion V_7_11_0 \u003d def(7_11_00_99, Version.LUCENE_8_7_0);\n    public static final IndexVersion V_7_12_0 \u003d def(7_12_00_99, Version.LUCENE_8_8_0);\n    public static final IndexVersion V_7_13_0 \u003d def(7_13_00_99, Version.LUCENE_8_8_2);\n    public static final IndexVersion V_7_14_0 \u003d def(7_14_00_99, Version.LUCENE_8_9_0);\n    public static final IndexVersion V_7_15_0 \u003d def(7_15_00_99, Version.LUCENE_8_9_0);\n    public static final IndexVersion V_7_16_0 \u003d def(7_16_00_99, Version.LUCENE_8_10_1);\n    public static final IndexVersion V_7_17_0 \u003d def(7_17_00_99, Version.LUCENE_8_11_1);\n    public static final IndexVersion V_8_0_0 \u003d def(8_00_00_99, Version.LUCENE_9_0_0);\n    public static final IndexVersion V_8_1_0 \u003d def(8_01_00_99, Version.LUCENE_9_0_0);\n    public static final IndexVersion V_8_2_0 \u003d def(8_02_00_99, Version.LUCENE_9_1_0);\n    public static final IndexVersion V_8_3_0 \u003d def(8_03_00_99, Version.LUCENE_9_2_0);\n    public static final IndexVersion V_8_4_0 \u003d def(8_04_00_99, Version.LUCENE_9_3_0);\n    public static final IndexVersion V_8_5_0 \u003d def(8_05_00_99, Version.LUCENE_9_4_1);\n    public static final IndexVersion V_8_6_0 \u003d def(8_06_00_99, Version.LUCENE_9_4_2);\n    public static final IndexVersion V_8_7_0 \u003d def(8_07_00_99, Version.LUCENE_9_5_0);\n    public static final IndexVersion V_8_8_0 \u003d def(8_08_00_99, Version.LUCENE_9_6_0);\n    public static final IndexVersion V_8_8_2 \u003d def(8_08_02_99, Version.LUCENE_9_6_0);\n    public static final IndexVersion V_8_9_0 \u003d def(8_09_00_99, Version.LUCENE_9_7_0);\n    public static final IndexVersion V_8_9_1 \u003d def(8_09_01_99, Version.LUCENE_9_7_0);\n    public static final IndexVersion V_8_10_0 \u003d def(8_10_00_99, Version.LUCENE_9_7_0);\n    /*\n     * READ THE COMMENT BELOW THIS BLOCK OF DECLARATIONS BEFORE ADDING NEW INDEX VERSIONS\n     * Detached index versions added below here.\n     */\n    public static final IndexVersion FIRST_DETACHED_INDEX_VERSION \u003d def(8_500_000, Version.LUCENE_9_7_0);\n    public static final IndexVersion NEW_SPARSE_VECTOR \u003d def(8_500_001, Version.LUCENE_9_7_0);\n    public static final IndexVersion SPARSE_VECTOR_IN_FIELD_NAMES_SUPPORT \u003d def(8_500_002, Version.LUCENE_9_7_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_8 \u003d def(8_500_003, Version.LUCENE_9_8_0);\n    public static final IndexVersion ES_VERSION_8_12 \u003d def(8_500_004, Version.LUCENE_9_8_0);\n    public static final IndexVersion NORMALIZED_VECTOR_COSINE \u003d def(8_500_005, Version.LUCENE_9_8_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_9 \u003d def(8_500_006, Version.LUCENE_9_9_0);\n    public static final IndexVersion NORI_DUPLICATES \u003d def(8_500_007, Version.LUCENE_9_9_0);\n    public static final IndexVersion UPGRADE_LUCENE_9_9_1 \u003d def(8_500_008, Version.LUCENE_9_9_1);\n    public static final IndexVersion ES_VERSION_8_12_1 \u003d def(8_500_009, Version.LUCENE_9_9_1);\n    public static final IndexVersion NEW_INDEXVERSION_FORMAT \u003d def(8_501_00_0, Version.LUCENE_9_9_1);\n\n    public static final IndexVersion UPGRADE_TO_LUCENE_9_10 \u003d def(8_502_00_0, Version.LUCENE_9_10_0);\n\n    /*\n     * STOP! READ THIS FIRST! No, really,\n     *        ____ _____ ___  ____  _        ____  _____    _    ____    _____ _   _ ___ ____    _____ ___ ____  ____ _____ _\n     *       / ___|_   _/ _ \\|  _ \\| |      |  _ \\| ____|  / \\  |  _ \\  |_   _| | | |_ _/ ___|  |  ___|_ _|  _ \\/ ___|_   _| |\n     *       \\___ \\ | || | | | |_) | |      | |_) |  _|   / _ \\ | | | |   | | | |_| || |\\___ \\  | |_   | || |_) \\___ \\ | | | |\n     *        ___) || || |_| |  __/|_|      |  _ \u003c| |___ / ___ \\| |_| |   | | |  _  || | ___) | |  _|  | ||  _ \u003c ___) || | |_|\n     *       |____/ |_| \\___/|_|   (_)      |_| \\_\\_____/_/   \\_\\____/    |_| |_| |_|___|____/  |_|   |___|_| \\_\\____/ |_| (_)\n     *\n     * A new index version should be added EVERY TIME a change is made to index metadata or data storage.\n     * Each index version should only be used in a single merged commit (apart from the BwC versions copied from o.e.Version, V_8_11_0).\n     *\n     * ADDING AN INDEX VERSION\n     * To add a new index version, add a new constant at the bottom of the list, above this comment. Don\u0027t add other lines,\n     * comments, etc. The version id has the following layout:\n     *\n     * M_NNN_SS_P\n     *\n     * M - The major version of Elasticsearch\n     * NNN - The server version part\n     * SS - The serverless version part. It should always be 00 here, it is used by serverless only.\n     * P - The patch version part\n     *\n     * To determine the id of the next IndexVersion constant, do the following:\n     * - Use the same major version, unless bumping majors\n     * - Bump the server version part by 1, unless creating a patch version\n     * - Leave the serverless part as 00\n     * - Bump the patch part if creating a patch version\n     *\n     * If a patch version is created, it should be placed sorted among the other existing constants.\n     *\n     * REVERTING AN INDEX VERSION\n     *\n     * If you revert a commit with an index version change, you MUST ensure there is a NEW index version representing the reverted\n     * change. DO NOT let the index version go backwards, it must ALWAYS be incremented.\n     *\n     * DETERMINING INDEX VERSIONS FROM GIT HISTORY\n     *\n     * If your git checkout has the expected minor-version-numbered branches and the expected release-version tags then you can find the\n     * index versions known by a particular release ...\n     *\n     *     git show v8.12.0:server/src/main/java/org/elasticsearch/index/IndexVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... or by a particular branch ...\n     *\n     *     git show 8.12:server/src/main/java/org/elasticsearch/index/IndexVersions.java | grep \u0027\u003d def\u0027\n     *\n     * ... and you can see which versions were added in between two versions too ...\n     *\n     *     git diff v8.12.0..main -- server/src/main/java/org/elasticsearch/index/IndexVersions.java\n     *\n     * In branches 8.7-8.11 see server/src/main/java/org/elasticsearch/index/IndexVersion.java for the equivalent definitions.\n     */\n\n    public static final IndexVersion MINIMUM_COMPATIBLE \u003d V_7_0_0;\n\n    static final NavigableMap\u003cInteger, IndexVersion\u003e VERSION_IDS \u003d getAllVersionIds(IndexVersions.class);\n    static final IndexVersion LATEST_DEFINED;\n    static {\n        LATEST_DEFINED \u003d VERSION_IDS.lastEntry().getValue();\n\n        // see comment on IDS field\n        // now we\u0027re registered the index versions, we can clear the map\n        IDS \u003d null;\n    }\n\n    static NavigableMap\u003cInteger, IndexVersion\u003e getAllVersionIds(Class\u003c?\u003e cls) {\n        Map\u003cInteger, String\u003e versionIdFields \u003d new HashMap\u003c\u003e();\n        NavigableMap\u003cInteger, IndexVersion\u003e builder \u003d new TreeMap\u003c\u003e();\n\n        Set\u003cString\u003e ignore \u003d Set.of(\"ZERO\", \"MINIMUM_COMPATIBLE\");\n\n        for (Field declaredField : cls.getFields()) {\n            if (declaredField.getType().equals(IndexVersion.class)) {\n                String fieldName \u003d declaredField.getName();\n                if (ignore.contains(fieldName)) {\n                    continue;\n                }\n\n                IndexVersion version;\n                try {\n                    version \u003d (IndexVersion) declaredField.get(null);\n                } catch (IllegalAccessException e) {\n                    throw new AssertionError(e);\n                }\n                builder.put(version.id(), version);\n\n                if (Assertions.ENABLED) {\n                    // check the version number is unique\n                    var sameVersionNumber \u003d versionIdFields.put(version.id(), fieldName);\n                    assert sameVersionNumber \u003d\u003d null\n                        : \"Versions [\"\n                            + sameVersionNumber\n                            + \"] and [\"\n                            + fieldName\n                            + \"] have the same version number [\"\n                            + version.id()\n                            + \"]. Each IndexVersion should have a different version number\";\n                }\n            }\n        }\n\n        return Collections.unmodifiableNavigableMap(builder);\n    }\n\n    static Collection\u003cIndexVersion\u003e getAllVersions() {\n        return VERSION_IDS.values();\n    }\n\n    private static final IntFunction\u003cString\u003e VERSION_LOOKUP \u003d ReleaseVersions.generateVersionsLookup(IndexVersions.class);\n\n    public static String toReleaseVersion(IndexVersion version) {\n        return VERSION_LOOKUP.apply(version.id());\n    }\n}","methodCount":4},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":213,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class LiveVersionMapTestUtils","description":"move method toReleaseVersion to PsiClass:LiveVersionMapTestUtils\nRationale: The toReleaseVersion() method performs a lookup based on the version ID, which seems closely related to the operations in LiveVersionMapTestUtils that deal with version management. Moving it here enhances cohesion by placing version-related functionality together. This aligns with the Single Responsibility Principle, as it centralizes version handling. However, it may introduce dependencies on test utility classes, which could complicate testing scenarios.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":213,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class FunctionTestUtils","description":"move method toReleaseVersion to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils might benefit from having the toReleaseVersion() method, as it could be used in various functional tests related to versioning. This move would help consolidate testing utilities and improve code organization. However, it may dilute the purpose of FunctionTestUtils if it becomes too focused on versioning rather than function-related utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":213,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toReleaseVersion to class RestResponseUtils","description":"move method toReleaseVersion to PsiClass:RestResponseUtils\nRationale: If the toReleaseVersion() method is used to format or respond with version information in REST APIs, moving it to RestResponseUtils makes sense. This aligns with the Single Responsibility Principle by keeping response formatting and versioning together. However, if not all responses require versioning, it could introduce unnecessary complexity.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class FunctionScoreQueryBuilder","description":"move method def to PsiClass:FunctionScoreQueryBuilder\nRationale: The def() method is related to defining and managing version IDs, which could be relevant in the context of building function score queries. Moving it here would enhance cohesion, as function score queries often need to manage versions. This aligns with the Single Responsibility Principle, as it separates version management from the current class\u0027s responsibilities. However, ensure that the method\u0027s static nature is compatible with the instance-based nature of this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class RetentionLeaseUtils","description":"move method def to PsiClass:RetentionLeaseUtils\nRationale: The method\u0027s functionality of defining versions can relate to retention leases, which may also require versioning for their management. Moving it here could improve the utility of this class and align with the Interface Segregation Principle by keeping version-related operations within a dedicated utility class. However, the direct relevance of version management to retention leases should be evaluated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":37,"lineEnd":47,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method def to class ShardUtils","description":"move method def to PsiClass:ShardUtils\nRationale: ShardUtils could benefit from the def() method if it deals with versioning in the context of shards. This move enhances cohesion by keeping related functionalities together, aligning with the Single Responsibility Principle. However, the method\u0027s focus on version IDs should be clearly relevant to shard management to justify this relocation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":168,"lineEnd":205,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class RestResponseUtils","description":"move method getAllVersionIds to PsiClass:RestResponseUtils\nRationale: If version information is essential for constructing REST responses, moving getAllVersionIds() to RestResponseUtils would centralize version management for API responses. This change would support the Interface Segregation Principle by allowing consumers to access version data without coupling it to unrelated classes. The drawback may include a bloated utility class with mixed responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":168,"lineEnd":205,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class DocValuesForUtil","description":"move method getAllVersionIds to PsiClass:DocValuesForUtil\nRationale: The method could be beneficial in contexts where document values need to be versioned. By placing it in DocValuesForUtil, we align it with data handling utilities, enhancing cohesion. This adheres to the Single Responsibility Principle, but the move might lead to confusion if document values and index versions are not closely related.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":168,"lineEnd":205,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getAllVersionIds to class IpPrefixAutomatonUtil","description":"move method getAllVersionIds to PsiClass:IpPrefixAutomatonUtil\nRationale: Although primarily focused on IP handling, if versioning is relevant to IP automata management, this class could benefit from the method. This would allow for a more comprehensive utility for managing versions related to network configurations. However, the relevance of versioning in this context is questionable, which could dilute the class\u0027s purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""},{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static toReleaseVersion(IndexVersion version)":{"first":{"method_name":"toReleaseVersion","method_signature":"public static toReleaseVersion(IndexVersion version)","target_class":"","rationale":""},"second":0.09502325020914204},"private static def(int id, Version luceneVersion)":{"first":{"method_name":"def","method_signature":"private static def(int id, Version luceneVersion)","target_class":"","rationale":""},"second":0.12791040587965863},"static getAllVersionIds(Class\u003c?\u003e cls)":{"first":{"method_name":"getAllVersionIds","method_signature":"static getAllVersionIds(Class\u003c?\u003e cls)","target_class":"","rationale":""},"second":0.29722643494031925}},"llmMethodPriority":{"priority_method_names":["toReleaseVersion","def","getAllVersionIds"],"llm_response_time":1599},"targetClassMap":{"toReleaseVersion":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.24618298195866545},{"class_name":"GeoUtilsTests","similarity_score":0.28411793079176595},{"class_name":"BinaryRangeUtilTests","similarity_score":0.22564744487636884},{"class_name":"DocValuesForUtil","similarity_score":0.3839706279022002},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.7047789667249661},{"class_name":"ShardUtils","similarity_score":0.3962921988518427},{"class_name":"MapperTestUtils","similarity_score":0.35143174800275734},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.4323583176379408},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.2406649574603851},{"class_name":"ForUtil","similarity_score":0.12647571391768506},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.37165252240363583},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.3135707402292122},{"class_name":"StoreUtils","similarity_score":0.37434298441858943},{"class_name":"PForUtil","similarity_score":0.24920943038241472},{"class_name":"TranslogOperationsUtils","similarity_score":0.3175264481385601},{"class_name":"RestRankEvalAction","similarity_score":0.2551551815399144},{"class_name":"AuditUtil","similarity_score":0.6747808815196579},{"class_name":"AggregationResultUtils","similarity_score":0.5226376960403452},{"class_name":"AggregationResultUtilsTests","similarity_score":0.35021575082334083},{"class_name":"RestResponseUtils","similarity_score":0.5341799709115684},{"class_name":"AggregationTestUtils","similarity_score":0.5064418313919596},{"class_name":"FunctionScoreQueryBuilder","similarity_score":0.4587753465852896},{"class_name":"FunctionScoreQueryBuilderTests","similarity_score":0.4211111522599127},{"class_name":"FunctionScoreTests","similarity_score":0.36345116246406844},{"class_name":"RestTestUtil","similarity_score":0.36251240124655426},{"class_name":"FunctionTestUtils","similarity_score":0.6057737519064692},{"class_name":"RestUtils","similarity_score":0.3731804509515294},{"class_name":"RestUtilsTests","similarity_score":0.21247269738650393},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.2974711032000541},{"class_name":"AuthorizationUtils","similarity_score":0.19831733396829512}],"target_classes_sorted_by_llm":["LiveVersionMapTestUtils","FunctionTestUtils","RestResponseUtils","FunctionScoreQueryBuilder","IndexLongFieldRangeTestUtils","AuditUtil","AggregationResultUtils","AggregationTestUtils","FunctionScoreQueryBuilderTests","ShardUtils"],"llm_response_time":0,"similarity_computation_time":75,"similarity_metric":"voyage"},"def":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.39936153191543583},{"class_name":"GeoUtilsTests","similarity_score":0.27817319776069427},{"class_name":"BinaryRangeUtilTests","similarity_score":0.24745880919862429},{"class_name":"DocValuesForUtil","similarity_score":0.36143582987457723},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.33839711075769596},{"class_name":"ShardUtils","similarity_score":0.37125790825650834},{"class_name":"MapperTestUtils","similarity_score":0.23139254551834096},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.3494364432545739},{"class_name":"PForUtil","similarity_score":0.29930895523256223},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.3848328268108964},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.3750828710370748},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.21384593694802698},{"class_name":"StoreUtils","similarity_score":0.28027592733560525},{"class_name":"ForUtil","similarity_score":0.24934314243640046},{"class_name":"TranslogOperationsUtils","similarity_score":0.25386870177080006},{"class_name":"RestRankEvalAction","similarity_score":0.20833790199668917},{"class_name":"RestResponseUtils","similarity_score":0.3676666272028088},{"class_name":"AuditUtil","similarity_score":0.45217016598013343},{"class_name":"AggregationResultUtils","similarity_score":0.4692302165862639},{"class_name":"AggregationResultUtilsTests","similarity_score":0.2651912001022869},{"class_name":"AggregationTestUtils","similarity_score":0.3258843306469299},{"class_name":"RestTestUtil","similarity_score":0.2465381993439922},{"class_name":"RestUtils","similarity_score":0.44308563624472597},{"class_name":"RestUtilsTests","similarity_score":0.2437353335164991},{"class_name":"FunctionScoreQueryBuilder","similarity_score":0.4641656769097169},{"class_name":"FunctionScoreQueryBuilderTests","similarity_score":0.4065289838386301},{"class_name":"FunctionScoreTests","similarity_score":0.36601888678507977},{"class_name":"FunctionTestUtils","similarity_score":0.37975324056440274},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.29452912978763396},{"class_name":"AuthorizationUtils","similarity_score":0.26108263336551485}],"target_classes_sorted_by_llm":["FunctionScoreQueryBuilder","RetentionLeaseUtils","ShardUtils","SpanQueryBuilderUtil","RestUtils","FunctionScoreQueryBuilderTests","FunctionTestUtils","IpPrefixAutomatonUtil","AggregationResultUtils","AuditUtil"],"llm_response_time":0,"similarity_computation_time":8,"similarity_metric":"voyage"},"getAllVersionIds":{"target_classes":[{"class_name":"MapperTestUtils","similarity_score":0.409481573743763},{"class_name":"RetentionLeaseUtils","similarity_score":0.3021707796612132},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.4836678224002255},{"class_name":"DocValuesForUtil","similarity_score":0.5619610456697409},{"class_name":"PForUtil","similarity_score":0.4973905536023055},{"class_name":"BinaryRangeUtilTests","similarity_score":0.5086631256802449},{"class_name":"ShardUtils","similarity_score":0.3857800797691074},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.5176156609873632},{"class_name":"GeoUtilsTests","similarity_score":0.5488071214946735},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.4772930401315485},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.6369431073948892},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.49036050286905675},{"class_name":"StoreUtils","similarity_score":0.4095076911385495},{"class_name":"ForUtil","similarity_score":0.43824805104509357},{"class_name":"TranslogOperationsUtils","similarity_score":0.2611062172976518},{"class_name":"NoriClientYamlTestSuiteIT","similarity_score":0.3786636568415178},{"class_name":"RestRankEvalAction","similarity_score":0.30238403841456},{"class_name":"MapperBuilderContext","similarity_score":0.39777046675647654},{"class_name":"MapperErrors","similarity_score":0.4872918298888144},{"class_name":"MapperExtrasClientYamlTestSuiteIT","similarity_score":0.35472337873223453},{"class_name":"MapperMergeContext","similarity_score":0.3803547912699766},{"class_name":"RestResponseUtils","similarity_score":0.6046329960966023},{"class_name":"MapperMurmur3ClientYamlTestSuiteIT","similarity_score":0.3786636568415178},{"class_name":"MapperService","similarity_score":0.5820420966269141},{"class_name":"MapperServiceTests","similarity_score":0.631526487908977},{"class_name":"MapperSizeClientYamlTestSuiteIT","similarity_score":0.42273186454224504},{"class_name":"MappingLookup","similarity_score":0.638511687435308},{"class_name":"MappingLookupTests","similarity_score":0.5791701429770086},{"class_name":"MappingParser","similarity_score":0.5491663499072263},{"class_name":"MappingParserTests","similarity_score":0.5430960921803982}],"target_classes_sorted_by_llm":["RestResponseUtils","DocValuesForUtil","IpPrefixAutomatonUtil","GeoUtilsTests","MappingLookup","MapperServiceTests","MapperService","MappingLookupTests","MappingParser","MappingParserTests"],"llm_response_time":0,"similarity_computation_time":21,"similarity_metric":"voyage"}}}
{"id":"93183ff8-a348-4b4c-b01c-0c5fff129617","methodCount":3,"hostFunctionTelemetryData":{"hostFunctionSize":117,"lineStart":35,"lineEnd":151,"bodyLineStart":35,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/action/apikey/TransportQueryApiKeyAction.java","sourceCode":"public final class TransportQueryApiKeyAction extends TransportAction\u003cQueryApiKeyRequest, QueryApiKeyResponse\u003e {\n\n    // API keys with no \"type\" field are implicitly of type \"rest\" (this is the case for all API Keys created before v8.9).\n    // The below runtime field ensures that the \"type\" field can be used by the {@link RestQueryApiKeyAction},\n    // while making the implicit \"rest\" type feature transparent to the caller (hence all keys are either \"rest\"\n    // or \"cross_cluster\", and the \"type\" is always set).\n    // This can be improved, to get rid of the runtime performance impact of the runtime field, by reindexing\n    // the api key docs and setting the \"type\" to \"rest\" if empty. But the infrastructure to run such a maintenance\n    // task on a system index (once the cluster version permits) is not currently available.\n    public static final String API_KEY_TYPE_RUNTIME_MAPPING_FIELD \u003d \"runtime_key_type\";\n    private static final Map\u003cString, Object\u003e API_KEY_TYPE_RUNTIME_MAPPING \u003d Map.of(\n        API_KEY_TYPE_RUNTIME_MAPPING_FIELD,\n        Map.of(\"type\", \"keyword\", \"script\", Map.of(\"source\", \"emit(field(\u0027type\u0027).get(\\\"rest\\\"));\"))\n    );\n\n    private final ApiKeyService apiKeyService;\n    private final SecurityContext securityContext;\n\n    @Inject\n    public TransportQueryApiKeyAction(\n        TransportService transportService,\n        ActionFilters actionFilters,\n        ApiKeyService apiKeyService,\n        SecurityContext context\n    ) {\n        super(QueryApiKeyAction.NAME, actionFilters, transportService.getTaskManager());\n        this.apiKeyService \u003d apiKeyService;\n        this.securityContext \u003d context;\n    }\n\n    @Override\n    protected void doExecute(Task task, QueryApiKeyRequest request, ActionListener\u003cQueryApiKeyResponse\u003e listener) {\n        final Authentication authentication \u003d securityContext.getAuthentication();\n        if (authentication \u003d\u003d null) {\n            listener.onFailure(new IllegalStateException(\"authentication is required\"));\n        }\n\n        final SearchSourceBuilder searchSourceBuilder \u003d SearchSourceBuilder.searchSource()\n            .version(false)\n            .fetchSource(true)\n            .trackTotalHits(true);\n\n        if (request.getFrom() !\u003d null) {\n            searchSourceBuilder.from(request.getFrom());\n        }\n        if (request.getSize() !\u003d null) {\n            searchSourceBuilder.size(request.getSize());\n        }\n\n        final AtomicBoolean accessesApiKeyTypeField \u003d new AtomicBoolean(false);\n        searchSourceBuilder.query(ApiKeyBoolQueryBuilder.build(request.getQueryBuilder(), fieldName -\u003e {\n            if (API_KEY_TYPE_RUNTIME_MAPPING_FIELD.equals(fieldName)) {\n                accessesApiKeyTypeField.set(true);\n            }\n        }, request.isFilterForCurrentUser() ? authentication : null));\n\n        if (request.getFieldSortBuilders() !\u003d null) {\n            translateFieldSortBuilders(request.getFieldSortBuilders(), searchSourceBuilder, fieldName -\u003e {\n                if (API_KEY_TYPE_RUNTIME_MAPPING_FIELD.equals(fieldName)) {\n                    accessesApiKeyTypeField.set(true);\n                }\n            });\n        }\n\n        // only add the query-level runtime field to the search request if it\u0027s actually referring the \"type\" field\n        if (accessesApiKeyTypeField.get()) {\n            searchSourceBuilder.runtimeMappings(API_KEY_TYPE_RUNTIME_MAPPING);\n        }\n\n        if (request.getSearchAfterBuilder() !\u003d null) {\n            searchSourceBuilder.searchAfter(request.getSearchAfterBuilder().getSortValues());\n        }\n\n        final SearchRequest searchRequest \u003d new SearchRequest(new String[] { SECURITY_MAIN_ALIAS }, searchSourceBuilder);\n        apiKeyService.queryApiKeys(searchRequest, request.withLimitedBy(), listener);\n    }\n\n    // package private for testing\n    static void translateFieldSortBuilders(\n        List\u003cFieldSortBuilder\u003e fieldSortBuilders,\n        SearchSourceBuilder searchSourceBuilder,\n        Consumer\u003cString\u003e fieldNameVisitor\n    ) {\n        fieldSortBuilders.forEach(fieldSortBuilder -\u003e {\n            if (fieldSortBuilder.getNestedSort() !\u003d null) {\n                throw new IllegalArgumentException(\"nested sorting is not supported for API Key query\");\n            }\n            if (FieldSortBuilder.DOC_FIELD_NAME.equals(fieldSortBuilder.getFieldName())) {\n                searchSourceBuilder.sort(fieldSortBuilder);\n            } else {\n                final String translatedFieldName \u003d ApiKeyFieldNameTranslators.translate(fieldSortBuilder.getFieldName());\n                fieldNameVisitor.accept(translatedFieldName);\n                if (translatedFieldName.equals(fieldSortBuilder.getFieldName())) {\n                    searchSourceBuilder.sort(fieldSortBuilder);\n                } else {\n                    final FieldSortBuilder translatedFieldSortBuilder \u003d new FieldSortBuilder(translatedFieldName).order(\n                        fieldSortBuilder.order()\n                    )\n                        .missing(fieldSortBuilder.missing())\n                        .unmappedType(fieldSortBuilder.unmappedType())\n                        .setFormat(fieldSortBuilder.getFormat());\n\n                    if (fieldSortBuilder.sortMode() !\u003d null) {\n                        translatedFieldSortBuilder.sortMode(fieldSortBuilder.sortMode());\n                    }\n                    if (fieldSortBuilder.getNestedSort() !\u003d null) {\n                        translatedFieldSortBuilder.setNestedSort(fieldSortBuilder.getNestedSort());\n                    }\n                    if (fieldSortBuilder.getNumericType() !\u003d null) {\n                        translatedFieldSortBuilder.setNumericType(fieldSortBuilder.getNumericType());\n                    }\n                    searchSourceBuilder.sort(translatedFieldSortBuilder);\n                }\n            }\n        });\n    }\n}","methodCount":3},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":111,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method translateFieldSortBuilders to class GeneratorUtils","description":"move method translateFieldSortBuilders to PsiClass:GeneratorUtils\nRationale: The translateFieldSortBuilders() method performs transformations on FieldSortBuilder objects, which aligns with utility methods typically found in GeneratorUtils. Moving it here would adhere to the Single Responsibility Principle, as it centralizes field sorting logic. This enhances cohesion within the class. However, care must be taken to ensure that the method\u0027s dependencies are appropriately managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":111,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method translateFieldSortBuilders to class AuditUtil","description":"move method translateFieldSortBuilders to PsiClass:AuditUtil\nRationale: The method involves processing and translating field names, which could be considered part of an auditing process in some contexts. Placing it in AuditUtil could improve the organization of related utilities. This move would enhance the class\u0027s utility for logging and auditing purposes, but it may dilute the class\u0027s focus if the method doesn\u0027t directly relate to auditing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":111,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method translateFieldSortBuilders to class SqlTestUtils","description":"move method translateFieldSortBuilders to PsiClass:SqlTestUtils\nRationale: Given that the method manipulates field sorting, which can be critical in SQL contexts, moving it to SqlTestUtils can provide a clear linkage between SQL operations and sorting logic. This aligns with the Open/Closed Principle, allowing the method to be extended for SQL-related functionalities. However, it might lead to an overcrowded utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"translateFieldSortBuilders","method_signature":"static translateFieldSortBuilders(\n        List\u003cFieldSortBuilder\u003e fieldSortBuilders,\n        SearchSourceBuilder searchSourceBuilder,\n        Consumer\u003cString\u003e fieldNameVisitor\n    )","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"translateFieldSortBuilders","method_signature":"static translateFieldSortBuilders(\n        List\u003cFieldSortBuilder\u003e fieldSortBuilders,\n        SearchSourceBuilder searchSourceBuilder,\n        Consumer\u003cString\u003e fieldNameVisitor\n    )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static translateFieldSortBuilders(\n        List\u003cFieldSortBuilder\u003e fieldSortBuilders,\n        SearchSourceBuilder searchSourceBuilder,\n        Consumer\u003cString\u003e fieldNameVisitor\n    )":{"first":{"method_name":"translateFieldSortBuilders","method_signature":"static translateFieldSortBuilders(\n        List\u003cFieldSortBuilder\u003e fieldSortBuilders,\n        SearchSourceBuilder searchSourceBuilder,\n        Consumer\u003cString\u003e fieldNameVisitor\n    )","target_class":"","rationale":""},"second":0.6091149380036648}},"llmMethodPriority":{"priority_method_names":["translateFieldSortBuilders"],"llm_response_time":1167},"targetClassMap":{"translateFieldSortBuilders":{"target_classes":[{"class_name":"JwkValidateUtil","similarity_score":0.5741322073906632},{"class_name":"JwkValidateUtilTests","similarity_score":0.6279794734706599},{"class_name":"LdapTestUtils","similarity_score":0.342225444523707},{"class_name":"LdapUtils","similarity_score":0.6371331185254553},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.2887979489524622},{"class_name":"SamlUtils","similarity_score":0.6412219764053785},{"class_name":"CommandUtils","similarity_score":0.3555956424540569},{"class_name":"AuditUtil","similarity_score":0.6495563485748457},{"class_name":"AuthorizationUtils","similarity_score":0.2868635316826101},{"class_name":"SecurityTestUtils","similarity_score":0.5695897275988362},{"class_name":"CertGenUtils","similarity_score":0.3539549875157128},{"class_name":"CertGenUtilsTests","similarity_score":0.5323884989137375},{"class_name":"ResponseValueUtils","similarity_score":0.4961531917414514},{"class_name":"ResponseXContentUtils","similarity_score":0.561043830001126},{"class_name":"SqlTestUtils","similarity_score":0.6685704340900565},{"class_name":"SSLEngineUtils","similarity_score":0.6762811392946413},{"class_name":"PreAuthorizationUtils","similarity_score":0.5882798551566878},{"class_name":"Utils","similarity_score":0.4826193305333274},{"class_name":"TransportCreateApiKeyAction","similarity_score":0.5895089806736045},{"class_name":"ChangePasswordRequestBuilder","similarity_score":0.6943323508979883},{"class_name":"FunctionTestUtils","similarity_score":0.5809208058163118},{"class_name":"JwtUtil","similarity_score":0.6594704519295478},{"class_name":"ExceptionUtils","similarity_score":0.18821999101000433},{"class_name":"GeneratorUtils","similarity_score":0.753909217362057},{"class_name":"ExecutionUtils","similarity_score":0.5229763603684908},{"class_name":"GeoTestUtils","similarity_score":0.4486534424410299},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.6447268611345958},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.3098847113981375},{"class_name":"ForUtil","similarity_score":0.40681624984052966}],"target_classes_sorted_by_llm":["GeneratorUtils","AuditUtil","SqlTestUtils","JwtUtil","LdapUtils","ChangePasswordRequestBuilder","SamlUtils","RollupJobIdentifierUtils","SSLEngineUtils","JwkValidateUtilTests"],"llm_response_time":10878,"similarity_computation_time":36,"similarity_metric":"voyage"}}}
{"id":"be638c16-3b2a-4efc-8a8d-6a2ee8137510","methodCount":55,"hostFunctionTelemetryData":{"hostFunctionSize":857,"lineStart":67,"lineEnd":923,"bodyLineStart":67,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/plugins/PluginsService.java","sourceCode":"public class PluginsService implements ReportingService\u003cPluginsAndModules\u003e {\n\n    public StablePluginsRegistry getStablePluginRegistry() {\n        return stablePluginsRegistry;\n    }\n\n    /**\n     * A loaded plugin is one for which Elasticsearch has successfully constructed an instance of the plugin\u0027s class\n     * @param descriptor Metadata about the plugin, usually loaded from plugin properties\n     * @param instance The constructed instance of the plugin\u0027s main class\n     * @param loader   The classloader for the plugin\n     * @param layer   The module layer for the plugin\n     */\n    record LoadedPlugin(PluginDescriptor descriptor, Plugin instance, ClassLoader loader, ModuleLayer layer) {\n\n        LoadedPlugin {\n            Objects.requireNonNull(descriptor);\n            Objects.requireNonNull(instance);\n            Objects.requireNonNull(loader);\n            Objects.requireNonNull(layer);\n        }\n\n        /**\n         * Creates a loaded \u003ci\u003eclasspath plugin\u003c/i\u003e. A \u003ci\u003eclasspath plugin\u003c/i\u003e is a plugin loaded\n         * by the system classloader and defined to the unnamed module of the boot layer.\n         */\n        LoadedPlugin(PluginDescriptor descriptor, Plugin instance) {\n            this(descriptor, instance, PluginsService.class.getClassLoader(), ModuleLayer.boot());\n        }\n    }\n\n    private static final Logger logger \u003d LogManager.getLogger(PluginsService.class);\n    private static final DeprecationLogger deprecationLogger \u003d DeprecationLogger.getLogger(PluginsService.class);\n\n    private static final Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e exportsServices;\n\n    static {\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports \u003d new HashMap\u003c\u003e();\n        var loader \u003d ServiceLoader.load(ModuleQualifiedExportsService.class, PluginsService.class.getClassLoader());\n        for (var exportsService : loader) {\n            addExportsService(qualifiedExports, exportsService, exportsService.getClass().getModule().getName());\n        }\n        exportsServices \u003d Map.copyOf(qualifiedExports);\n    }\n\n    private final Settings settings;\n    private final Path configPath;\n\n    /**\n     * We keep around a list of plugins and modules. The order of\n     * this list is that which the plugins and modules were loaded in.\n     */\n    private final List\u003cLoadedPlugin\u003e plugins;\n    private final PluginsAndModules info;\n    private final StablePluginsRegistry stablePluginsRegistry \u003d new StablePluginsRegistry();\n\n    public static final Setting\u003cList\u003cString\u003e\u003e MANDATORY_SETTING \u003d Setting.stringListSetting(\"plugin.mandatory\", Property.NodeScope);\n\n    /**\n     * Constructs a new PluginService\n     *\n     * @param settings         The settings of the system\n     * @param modulesDirectory The directory modules exist in, or null if modules should not be loaded from the filesystem\n     * @param pluginsDirectory The directory plugins exist in, or null if plugins should not be loaded from the filesystem\n     */\n    @SuppressWarnings(\"this-escape\")\n    public PluginsService(Settings settings, Path configPath, Path modulesDirectory, Path pluginsDirectory) {\n        this.settings \u003d settings;\n        this.configPath \u003d configPath;\n\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports \u003d new HashMap\u003c\u003e(exportsServices);\n        addServerExportsService(qualifiedExports);\n\n        Set\u003cPluginBundle\u003e seenBundles \u003d new LinkedHashSet\u003c\u003e();\n\n        // load modules\n        List\u003cPluginDescriptor\u003e modulesList \u003d new ArrayList\u003c\u003e();\n        Set\u003cString\u003e moduleNameList \u003d new HashSet\u003c\u003e();\n        if (modulesDirectory !\u003d null) {\n            try {\n                Set\u003cPluginBundle\u003e modules \u003d PluginsUtils.getModuleBundles(modulesDirectory);\n                modules.stream().map(PluginBundle::pluginDescriptor).forEach(m -\u003e {\n                    modulesList.add(m);\n                    moduleNameList.add(m.getName());\n                });\n                seenBundles.addAll(modules);\n            } catch (IOException ex) {\n                throw new IllegalStateException(\"Unable to initialize modules\", ex);\n            }\n        }\n\n        // load plugins\n        List\u003cPluginDescriptor\u003e pluginsList \u003d new ArrayList\u003c\u003e();\n        if (pluginsDirectory !\u003d null) {\n            try {\n                // TODO: remove this leniency, but tests bogusly rely on it\n                if (isAccessibleDirectory(pluginsDirectory, logger)) {\n                    PluginsUtils.checkForFailedPluginRemovals(pluginsDirectory);\n                    Set\u003cPluginBundle\u003e plugins \u003d PluginsUtils.getPluginBundles(pluginsDirectory);\n                    plugins.stream().map(PluginBundle::pluginDescriptor).forEach(pluginsList::add);\n                    seenBundles.addAll(plugins);\n                }\n            } catch (IOException ex) {\n                throw new IllegalStateException(\"Unable to initialize plugins\", ex);\n            }\n        }\n\n        LinkedHashMap\u003cString, LoadedPlugin\u003e loadedPlugins \u003d loadBundles(seenBundles, qualifiedExports);\n\n        var inspector \u003d PluginIntrospector.getInstance();\n        this.info \u003d new PluginsAndModules(getRuntimeInfos(inspector, pluginsList, loadedPlugins), modulesList);\n        this.plugins \u003d List.copyOf(loadedPlugins.values());\n\n        checkDeprecations(inspector, pluginsList, loadedPlugins);\n\n        checkMandatoryPlugins(\n            pluginsList.stream().map(PluginDescriptor::getName).collect(Collectors.toSet()),\n            new HashSet\u003c\u003e(MANDATORY_SETTING.get(settings))\n        );\n\n        // we don\u0027t log jars in lib/ we really shouldn\u0027t log modules,\n        // but for now: just be transparent so we can debug any potential issues\n        for (String name : loadedPlugins.keySet()) {\n            if (moduleNameList.contains(name)) {\n                logger.info(\"loaded module [{}]\", name);\n            } else {\n                logger.info(\"loaded plugin [{}]\", name);\n            }\n        }\n    }\n\n    // package-private for testing\n    static void checkMandatoryPlugins(Set\u003cString\u003e existingPlugins, Set\u003cString\u003e mandatoryPlugins) {\n        if (mandatoryPlugins.isEmpty()) {\n            return;\n        }\n\n        Set\u003cString\u003e missingPlugins \u003d Sets.difference(mandatoryPlugins, existingPlugins);\n        if (missingPlugins.isEmpty() \u003d\u003d false) {\n            final String message \u003d \"missing mandatory plugins [\"\n                + String.join(\", \", missingPlugins)\n                + \"], found plugins [\"\n                + String.join(\", \", existingPlugins)\n                + \"]\";\n            throw new IllegalStateException(message);\n        }\n    }\n\n    private static final Set\u003cString\u003e officialPlugins;\n\n    static {\n        try (var stream \u003d PluginsService.class.getResourceAsStream(\"/plugins.txt\")) {\n            officialPlugins \u003d Streams.readAllLines(stream).stream().map(String::trim).collect(Collectors.toUnmodifiableSet());\n        } catch (final IOException e) {\n            throw new AssertionError(e);\n        }\n    }\n\n    private static List\u003cPluginRuntimeInfo\u003e getRuntimeInfos(\n        PluginIntrospector inspector,\n        List\u003cPluginDescriptor\u003e pluginDescriptors,\n        Map\u003cString, LoadedPlugin\u003e plugins\n    ) {\n        List\u003cPluginRuntimeInfo\u003e runtimeInfos \u003d new ArrayList\u003c\u003e();\n        for (PluginDescriptor descriptor : pluginDescriptors) {\n            LoadedPlugin plugin \u003d plugins.get(descriptor.getName());\n            assert plugin !\u003d null;\n            Class\u003c?\u003e pluginClazz \u003d plugin.instance.getClass();\n            boolean isOfficial \u003d officialPlugins.contains(descriptor.getName());\n            PluginApiInfo apiInfo \u003d null;\n            if (isOfficial \u003d\u003d false) {\n                apiInfo \u003d new PluginApiInfo(inspector.interfaces(pluginClazz), inspector.overriddenMethods(pluginClazz));\n            }\n            runtimeInfos.add(new PluginRuntimeInfo(descriptor, isOfficial, apiInfo));\n        }\n        return runtimeInfos;\n    }\n\n    /**\n     * Map a function over all plugins\n     * @param function a function that takes a plugin and returns a result\n     * @return A stream of results\n     * @param \u003cT\u003e The generic type of the result\n     */\n    public final \u003cT\u003e Stream\u003cT\u003e map(Function\u003cPlugin, T\u003e function) {\n        return plugins().stream().map(LoadedPlugin::instance).map(function);\n    }\n\n    /**\n     * FlatMap a function over all plugins\n     * @param function a function that takes a plugin and returns a collection\n     * @return A stream of results\n     * @param \u003cT\u003e The generic type of the collection\n     */\n    public final \u003cT\u003e Stream\u003cT\u003e flatMap(Function\u003cPlugin, Collection\u003cT\u003e\u003e function) {\n        return plugins().stream().map(LoadedPlugin::instance).flatMap(p -\u003e function.apply(p).stream());\n    }\n\n    /**\n     * Apply a consumer action to each plugin\n     * @param consumer An action that consumes a plugin\n     */\n    public final void forEach(Consumer\u003cPlugin\u003e consumer) {\n        plugins().stream().map(LoadedPlugin::instance).forEach(consumer);\n    }\n\n    /**\n     * Sometimes we want the plugin name for error handling.\n     * @return A map of plugin names to plugin instances.\n     */\n    public final Map\u003cString, Plugin\u003e pluginMap() {\n        return plugins().stream().collect(Collectors.toMap(p -\u003e p.descriptor().getName(), LoadedPlugin::instance));\n    }\n\n    /**\n     * Get information about plugins and modules\n     */\n    @Override\n    public PluginsAndModules info() {\n        return info;\n    }\n\n    protected List\u003cLoadedPlugin\u003e plugins() {\n        return this.plugins;\n    }\n\n    private LinkedHashMap\u003cString, LoadedPlugin\u003e loadBundles(\n        Set\u003cPluginBundle\u003e bundles,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        LinkedHashMap\u003cString, LoadedPlugin\u003e loaded \u003d new LinkedHashMap\u003c\u003e();\n        Map\u003cString, Set\u003cURL\u003e\u003e transitiveUrls \u003d new HashMap\u003c\u003e();\n        List\u003cPluginBundle\u003e sortedBundles \u003d PluginsUtils.sortBundles(bundles);\n        if (sortedBundles.isEmpty() \u003d\u003d false) {\n            Set\u003cURL\u003e systemLoaderURLs \u003d JarHell.parseModulesAndClassPath();\n            for (PluginBundle bundle : sortedBundles) {\n                PluginsUtils.checkBundleJarHell(systemLoaderURLs, bundle, transitiveUrls);\n                loadBundle(bundle, loaded, qualifiedExports);\n            }\n        }\n\n        loadExtensions(loaded.values());\n        return loaded;\n    }\n\n    // package-private for test visibility\n    static void loadExtensions(Collection\u003cLoadedPlugin\u003e plugins) {\n        Map\u003cString, List\u003cPlugin\u003e\u003e extendingPluginsByName \u003d plugins.stream()\n            .flatMap(t -\u003e t.descriptor().getExtendedPlugins().stream().map(extendedPlugin -\u003e Tuple.tuple(extendedPlugin, t.instance())))\n            .collect(Collectors.groupingBy(Tuple::v1, Collectors.mapping(Tuple::v2, Collectors.toList())));\n        for (LoadedPlugin pluginTuple : plugins) {\n            if (pluginTuple.instance() instanceof ExtensiblePlugin) {\n                loadExtensionsForPlugin(\n                    (ExtensiblePlugin) pluginTuple.instance(),\n                    extendingPluginsByName.getOrDefault(pluginTuple.descriptor().getName(), List.of())\n                );\n            }\n        }\n    }\n\n    /**\n     * SPI convenience method that uses the {@link ServiceLoader} JDK class to load various SPI providers\n     * from plugins/modules.\n     * \u003cp\u003e\n     * For example:\n     *\n     * \u003cpre\u003e\n     * var pluginHandlers \u003d pluginsService.loadServiceProviders(OperatorHandlerProvider.class);\n     * \u003c/pre\u003e\n     * @param service A templated service class to look for providers in plugins\n     * @return an immutable {@link List} of discovered providers in the plugins/modules\n     */\n    public \u003cT\u003e List\u003c? extends T\u003e loadServiceProviders(Class\u003cT\u003e service) {\n        List\u003cT\u003e result \u003d new ArrayList\u003c\u003e();\n\n        for (LoadedPlugin pluginTuple : plugins()) {\n            result.addAll(createExtensions(service, pluginTuple.instance));\n        }\n\n        return Collections.unmodifiableList(result);\n    }\n\n    /**\n     * Loads a single SPI extension.\n     *\n     * There should be no more than one extension found. If no service providers\n     * are found, the supplied fallback is used.\n     *\n     * @param service the SPI class that should be loaded\n     * @param fallback a supplier for an instance if no providers are found\n     * @return an instance of the service\n     * @param \u003cT\u003e the SPI service type\n     */\n    public \u003cT\u003e T loadSingletonServiceProvider(Class\u003cT\u003e service, Supplier\u003cT\u003e fallback) {\n        var services \u003d loadServiceProviders(service);\n        if (services.size() \u003e 1) {\n            throw new IllegalStateException(String.format(Locale.ROOT, \"More than one extension found for %s\", service.getSimpleName()));\n        } else if (services.isEmpty()) {\n            return fallback.get();\n        }\n        return services.get(0);\n    }\n\n    private static void loadExtensionsForPlugin(ExtensiblePlugin extensiblePlugin, List\u003cPlugin\u003e extendingPlugins) {\n        ExtensiblePlugin.ExtensionLoader extensionLoader \u003d new ExtensiblePlugin.ExtensionLoader() {\n            @Override\n            public \u003cT\u003e List\u003cT\u003e loadExtensions(Class\u003cT\u003e extensionPointType) {\n                List\u003cT\u003e result \u003d new ArrayList\u003c\u003e();\n                for (Plugin extendingPlugin : extendingPlugins) {\n                    result.addAll(createExtensions(extensionPointType, extendingPlugin));\n                }\n                return Collections.unmodifiableList(result);\n            }\n        };\n\n        extensiblePlugin.loadExtensions(extensionLoader);\n    }\n\n    private static \u003cT\u003e List\u003c? extends T\u003e createExtensions(Class\u003cT\u003e extensionPointType, Plugin plugin) {\n        SPIClassIterator\u003cT\u003e classIterator \u003d SPIClassIterator.get(extensionPointType, plugin.getClass().getClassLoader());\n        List\u003cT\u003e extensions \u003d new ArrayList\u003c\u003e();\n        while (classIterator.hasNext()) {\n            Class\u003c? extends T\u003e extensionClass \u003d classIterator.next();\n            extensions.add(createExtension(extensionClass, extensionPointType, plugin));\n        }\n        return extensions;\n    }\n\n    // package-private for test visibility\n    static \u003cT\u003e T createExtension(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin) {\n        @SuppressWarnings(\"unchecked\")\n        Constructor\u003cT\u003e[] constructors \u003d (Constructor\u003cT\u003e[]) extensionClass.getConstructors();\n        if (constructors.length \u003d\u003d 0) {\n            throw new IllegalStateException(\"no public \" + extensionConstructorMessage(extensionClass, extensionPointType));\n        }\n\n        Constructor\u003cT\u003e constructor \u003d constructors[0];\n        // Using modules and SPI requires that we declare the default no-arg constructor apart from our custom\n        // one arg constructor with a plugin.\n        if (constructors.length \u003d\u003d 2) {\n            // we prefer the one arg constructor in this case\n            if (constructors[1].getParameterCount() \u003e 0) {\n                constructor \u003d constructors[1];\n            }\n        } else if (constructors.length \u003e 1) {\n            throw new IllegalStateException(\"no unique public \" + extensionConstructorMessage(extensionClass, extensionPointType));\n        }\n\n        if (constructor.getParameterCount() \u003e 1) {\n            throw new IllegalStateException(extensionSignatureMessage(extensionClass, extensionPointType, plugin));\n        }\n\n        if (constructor.getParameterCount() \u003d\u003d 1 \u0026\u0026 constructor.getParameterTypes()[0] !\u003d plugin.getClass()) {\n            throw new IllegalStateException(\n                extensionSignatureMessage(extensionClass, extensionPointType, plugin)\n                    + \", not (\"\n                    + constructor.getParameterTypes()[0].getName()\n                    + \")\"\n            );\n        }\n\n        try {\n            if (constructor.getParameterCount() \u003d\u003d 0) {\n                return constructor.newInstance();\n            } else {\n                return constructor.newInstance(plugin);\n            }\n        } catch (ReflectiveOperationException e) {\n            throw new IllegalStateException(\n                \"failed to create extension [\" + extensionClass.getName() + \"] of type [\" + extensionPointType.getName() + \"]\",\n                e\n            );\n        }\n    }\n\n    private static \u003cT\u003e String extensionSignatureMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin) {\n        return \"signature of \"\n            + extensionConstructorMessage(extensionClass, extensionPointType)\n            + \" must be either () or (\"\n            + plugin.getClass().getName()\n            + \")\";\n    }\n\n    private static \u003cT\u003e String extensionConstructorMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType) {\n        return \"constructor for extension [\" + extensionClass.getName() + \"] of type [\" + extensionPointType.getName() + \"]\";\n    }\n\n    private void loadBundle(\n        PluginBundle bundle,\n        Map\u003cString, LoadedPlugin\u003e loaded,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        String name \u003d bundle.plugin.getName();\n        logger.debug(() -\u003e \"Loading bundle: \" + name);\n\n        PluginsUtils.verifyCompatibility(bundle.plugin);\n\n        // collect the list of extended plugins\n        List\u003cLoadedPlugin\u003e extendedPlugins \u003d new ArrayList\u003c\u003e();\n        for (String extendedPluginName : bundle.plugin.getExtendedPlugins()) {\n            LoadedPlugin extendedPlugin \u003d loaded.get(extendedPluginName);\n            assert extendedPlugin !\u003d null;\n            if (ExtensiblePlugin.class.isInstance(extendedPlugin.instance()) \u003d\u003d false) {\n                throw new IllegalStateException(\"Plugin [\" + name + \"] cannot extend non-extensible plugin [\" + extendedPluginName + \"]\");\n            }\n            assert extendedPlugin.loader() !\u003d null : \"All non-classpath plugins should be loaded with a classloader\";\n            extendedPlugins.add(extendedPlugin);\n            logger.debug(\n                () -\u003e \"Loading bundle: \" + name + \", ext plugins: \" + extendedPlugins.stream().map(lp -\u003e lp.descriptor().getName()).toList()\n            );\n        }\n\n        final ClassLoader parentLoader \u003d PluginLoaderIndirection.createLoader(\n            getClass().getClassLoader(),\n            extendedPlugins.stream().map(LoadedPlugin::loader).toList()\n        );\n        LayerAndLoader spiLayerAndLoader \u003d null;\n        if (bundle.hasSPI()) {\n            spiLayerAndLoader \u003d createSPI(bundle, parentLoader, extendedPlugins, qualifiedExports);\n        }\n\n        final ClassLoader pluginParentLoader \u003d spiLayerAndLoader \u003d\u003d null ? parentLoader : spiLayerAndLoader.loader();\n        final LayerAndLoader pluginLayerAndLoader \u003d createPlugin(\n            bundle,\n            pluginParentLoader,\n            extendedPlugins,\n            spiLayerAndLoader,\n            qualifiedExports\n        );\n        final ClassLoader pluginClassLoader \u003d pluginLayerAndLoader.loader();\n\n        if (spiLayerAndLoader \u003d\u003d null) {\n            // use full implementation for plugins extending this one\n            spiLayerAndLoader \u003d pluginLayerAndLoader;\n        }\n\n        // reload SPI with any new services from the plugin\n        reloadLuceneSPI(pluginClassLoader);\n\n        ClassLoader cl \u003d Thread.currentThread().getContextClassLoader();\n        try {\n            // Set context class loader to plugin\u0027s class loader so that plugins\n            // that have dependencies with their own SPI endpoints have a chance to load\n            // and initialize them appropriately.\n            privilegedSetContextClassLoader(pluginClassLoader);\n\n            Plugin plugin;\n            if (bundle.pluginDescriptor().isStable()) {\n                stablePluginsRegistry.scanBundleForStablePlugins(bundle, pluginClassLoader);\n                /*\n                Contrary to old plugins we don\u0027t need an instance of the plugin here.\n                Stable plugin register components (like CharFilterFactory) in stable plugin registry, which is then used in AnalysisModule\n                when registering char filter factories and other analysis components.\n                We don\u0027t have to support for settings, additional components and other methods\n                that are in org.elasticsearch.plugins.Plugin\n                We need to pass a name though so that we can show that a plugin was loaded (via cluster state api)\n                This might need to be revisited once support for settings is added\n                 */\n                plugin \u003d new StablePluginPlaceHolder(bundle.plugin.getName());\n            } else {\n\n                Class\u003c? extends Plugin\u003e pluginClass \u003d loadPluginClass(bundle.plugin.getClassname(), pluginClassLoader);\n                if (pluginClassLoader !\u003d pluginClass.getClassLoader()) {\n                    throw new IllegalStateException(\n                        \"Plugin [\"\n                            + name\n                            + \"] must reference a class loader local Plugin class [\"\n                            + bundle.plugin.getClassname()\n                            + \"] (class loader [\"\n                            + pluginClass.getClassLoader()\n                            + \"])\"\n                    );\n                }\n                plugin \u003d loadPlugin(pluginClass, settings, configPath);\n            }\n            loaded.put(name, new LoadedPlugin(bundle.plugin, plugin, spiLayerAndLoader.loader(), spiLayerAndLoader.layer()));\n        } finally {\n            privilegedSetContextClassLoader(cl);\n        }\n    }\n\n    static LayerAndLoader createSPI(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cLoadedPlugin\u003e extendedPlugins,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        final PluginDescriptor plugin \u003d bundle.plugin;\n        if (plugin.getModuleName().isPresent()) {\n            logger.debug(() -\u003e \"Loading bundle: \" + plugin.getName() + \", creating spi, modular\");\n            return createSpiModuleLayer(\n                bundle.spiUrls,\n                parentLoader,\n                extendedPlugins.stream().map(LoadedPlugin::layer).toList(),\n                qualifiedExports\n            );\n        } else {\n            logger.debug(() -\u003e \"Loading bundle: \" + plugin.getName() + \", creating spi, non-modular\");\n            return LayerAndLoader.ofLoader(URLClassLoader.newInstance(bundle.spiUrls.toArray(new URL[0]), parentLoader));\n        }\n    }\n\n    static LayerAndLoader createPlugin(\n        PluginBundle bundle,\n        ClassLoader pluginParentLoader,\n        List\u003cLoadedPlugin\u003e extendedPlugins,\n        LayerAndLoader spiLayerAndLoader,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        final PluginDescriptor plugin \u003d bundle.plugin;\n        if (plugin.getModuleName().isPresent()) {\n            logger.debug(() -\u003e \"Loading bundle: \" + plugin.getName() + \", modular\");\n            var parentLayers \u003d Stream.concat(\n                Stream.ofNullable(spiLayerAndLoader !\u003d null ? spiLayerAndLoader.layer() : null),\n                extendedPlugins.stream().map(LoadedPlugin::layer)\n            ).toList();\n            return createPluginModuleLayer(bundle, pluginParentLoader, parentLayers, qualifiedExports);\n        } else if (plugin.isStable()) {\n            logger.debug(() -\u003e \"Loading bundle: \" + plugin.getName() + \", non-modular as synthetic module\");\n            return LayerAndLoader.ofLoader(\n                UberModuleClassLoader.getInstance(\n                    pluginParentLoader,\n                    ModuleLayer.boot(),\n                    \"synthetic.\" + toModuleName(plugin.getName()),\n                    bundle.allUrls,\n                    Set.of(\"org.elasticsearch.server\") // TODO: instead of denying server, allow only jvm + stable API modules\n                )\n            );\n        } else {\n            logger.debug(() -\u003e \"Loading bundle: \" + plugin.getName() + \", non-modular\");\n            return LayerAndLoader.ofLoader(URLClassLoader.newInstance(bundle.urls.toArray(URL[]::new), pluginParentLoader));\n        }\n    }\n\n    // package-visible for testing\n    static String toModuleName(String name) {\n        String result \u003d name.replaceAll(\"\\\\W+\", \".\") // replace non-alphanumeric character strings with dots\n            .replaceAll(\"(^[^A-Za-z_]*)\", \"\") // trim non-alpha or underscore characters from start\n            .replaceAll(\"\\\\.$\", \"\") // trim trailing dot\n            .toLowerCase(Locale.getDefault());\n        assert ModuleSupport.isPackageName(result);\n        return result;\n    }\n\n    private static void checkDeprecations(\n        PluginIntrospector inspector,\n        List\u003cPluginDescriptor\u003e pluginDescriptors,\n        Map\u003cString, LoadedPlugin\u003e plugins\n    ) {\n        for (PluginDescriptor descriptor : pluginDescriptors) {\n            LoadedPlugin plugin \u003d plugins.get(descriptor.getName());\n            Class\u003c?\u003e pluginClazz \u003d plugin.instance.getClass();\n            for (String deprecatedInterface : inspector.deprecatedInterfaces(pluginClazz)) {\n                deprecationLogger.warn(\n                    DeprecationCategory.PLUGINS,\n                    pluginClazz.getName() + deprecatedInterface,\n                    \"Plugin class {} from plugin {} implements deprecated plugin interface {}. \"\n                        + \"This plugin interface will be removed in a future release.\",\n                    pluginClazz.getName(),\n                    descriptor.getName(),\n                    deprecatedInterface\n                );\n            }\n            for (var deprecatedMethodInInterface : inspector.deprecatedMethods(pluginClazz).entrySet()) {\n                String methodName \u003d deprecatedMethodInInterface.getKey();\n                String interfaceName \u003d deprecatedMethodInInterface.getValue();\n                deprecationLogger.warn(\n                    DeprecationCategory.PLUGINS,\n                    pluginClazz.getName() + methodName + interfaceName,\n                    \"Plugin class {} from plugin {} implements deprecated method {} from plugin interface {}. \"\n                        + \"This method will be removed in a future release.\",\n                    pluginClazz.getName(),\n                    descriptor.getName(),\n                    methodName,\n                    interfaceName\n                );\n            }\n        }\n    }\n\n    /**\n     * Reloads all Lucene SPI implementations using the new classloader.\n     * This method must be called after the new classloader has been created to\n     * register the services for use.\n     */\n    static void reloadLuceneSPI(ClassLoader loader) {\n        // do NOT change the order of these method calls!\n\n        // Codecs:\n        PostingsFormat.reloadPostingsFormats(loader);\n        DocValuesFormat.reloadDocValuesFormats(loader);\n        Codec.reloadCodecs(loader);\n    }\n\n    private static Class\u003c? extends Plugin\u003e loadPluginClass(String className, ClassLoader loader) {\n        try {\n            return Class.forName(className, false, loader).asSubclass(Plugin.class);\n        } catch (ClassNotFoundException e) {\n            throw new ElasticsearchException(\"Could not find plugin class [\" + className + \"]\", e);\n        }\n    }\n\n    // package-private for testing\n    static Plugin loadPlugin(Class\u003c? extends Plugin\u003e pluginClass, Settings settings, Path configPath) {\n        final Constructor\u003c?\u003e[] constructors \u003d pluginClass.getConstructors();\n        if (constructors.length \u003d\u003d 0) {\n            throw new IllegalStateException(\"no public constructor for [\" + pluginClass.getName() + \"]\");\n        }\n\n        if (constructors.length \u003e 1) {\n            throw new IllegalStateException(\"no unique public constructor for [\" + pluginClass.getName() + \"]\");\n        }\n\n        final Constructor\u003c?\u003e constructor \u003d constructors[0];\n        if (constructor.getParameterCount() \u003e 2) {\n            throw new IllegalStateException(signatureMessage(pluginClass));\n        }\n\n        final Class\u003c?\u003e[] parameterTypes \u003d constructor.getParameterTypes();\n        try {\n            if (constructor.getParameterCount() \u003d\u003d 2 \u0026\u0026 parameterTypes[0] \u003d\u003d Settings.class \u0026\u0026 parameterTypes[1] \u003d\u003d Path.class) {\n                return (Plugin) constructor.newInstance(settings, configPath);\n            } else if (constructor.getParameterCount() \u003d\u003d 1 \u0026\u0026 parameterTypes[0] \u003d\u003d Settings.class) {\n                return (Plugin) constructor.newInstance(settings);\n            } else if (constructor.getParameterCount() \u003d\u003d 0) {\n                return (Plugin) constructor.newInstance();\n            } else {\n                throw new IllegalStateException(signatureMessage(pluginClass));\n            }\n        } catch (final ReflectiveOperationException e) {\n            throw new IllegalStateException(\"failed to load plugin class [\" + pluginClass.getName() + \"]\", e);\n        }\n    }\n\n    private static String signatureMessage(final Class\u003c? extends Plugin\u003e clazz) {\n        return String.format(\n            Locale.ROOT,\n            \"no public constructor of correct signature for [%s]; must be [%s], [%s], or [%s]\",\n            clazz.getName(),\n            \"(org.elasticsearch.common.settings.Settings,java.nio.file.Path)\",\n            \"(org.elasticsearch.common.settings.Settings)\",\n            \"()\"\n        );\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    public final \u003cT\u003e Stream\u003cT\u003e filterPlugins(Class\u003cT\u003e type) {\n        return plugins().stream().filter(x -\u003e type.isAssignableFrom(x.instance().getClass())).map(p -\u003e ((T) p.instance()));\n    }\n\n    static LayerAndLoader createPluginModuleLayer(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        assert bundle.plugin.getModuleName().isPresent();\n        return createModuleLayer(\n            bundle.plugin.getClassname(),\n            bundle.plugin.getModuleName().get(),\n            urlsToPaths(bundle.urls),\n            parentLoader,\n            parentLayers,\n            qualifiedExports\n        );\n    }\n\n    static final LayerAndLoader createSpiModuleLayer(\n        Set\u003cURL\u003e urls,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        // assert bundle.plugin.getModuleName().isPresent();\n        return createModuleLayer(\n            null,  // no entry point\n            spiModuleName(urls),\n            urlsToPaths(urls),\n            parentLoader,\n            parentLayers,\n            qualifiedExports\n        );\n    }\n\n    private static final Module serverModule \u003d PluginsService.class.getModule();\n\n    static LayerAndLoader createModuleLayer(\n        String className,\n        String moduleName,\n        Path[] paths,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    ) {\n        logger.debug(() -\u003e \"Loading bundle: creating module layer and loader for module \" + moduleName);\n        var finder \u003d ModuleFinder.of(paths);\n\n        var configuration \u003d Configuration.resolveAndBind(\n            ModuleFinder.of(),\n            parentConfigurationOrBoot(parentLayers),\n            finder,\n            Set.of(moduleName)\n        );\n        var controller \u003d privilegedDefineModulesWithOneLoader(configuration, parentLayersOrBoot(parentLayers), parentLoader);\n        var pluginModule \u003d controller.layer().findModule(moduleName).get();\n        ensureEntryPointAccessible(controller, pluginModule, className);\n        // export/open upstream modules to this plugin module\n        exposeQualifiedExportsAndOpens(pluginModule, qualifiedExports);\n        // configure qualified exports/opens to other modules/plugins\n        addPluginExportsServices(qualifiedExports, controller);\n        logger.debug(() -\u003e \"Loading bundle: created module layer and loader for module \" + moduleName);\n        return new LayerAndLoader(controller.layer(), privilegedFindLoader(controller.layer(), moduleName));\n    }\n\n    private static List\u003cModuleLayer\u003e parentLayersOrBoot(List\u003cModuleLayer\u003e parentLayers) {\n        if (parentLayers \u003d\u003d null || parentLayers.isEmpty()) {\n            return List.of(ModuleLayer.boot());\n        } else {\n            return parentLayers;\n        }\n    }\n\n    private static List\u003cConfiguration\u003e parentConfigurationOrBoot(List\u003cModuleLayer\u003e parentLayers) {\n        if (parentLayers \u003d\u003d null || parentLayers.isEmpty()) {\n            return List.of(ModuleLayer.boot().configuration());\n        } else {\n            return parentLayers.stream().map(ModuleLayer::configuration).toList();\n        }\n    }\n\n    /** Ensures that the plugins main class (its entry point), if any, is accessible to the server. */\n    private static void ensureEntryPointAccessible(Controller controller, Module pluginModule, String className) {\n        if (className !\u003d null) {\n            controller.addOpens(pluginModule, toPackageName(className), serverModule);\n        }\n    }\n\n    /**\n     * Adds qualified exports and opens declared in other upstream modules to the target module.\n     * This is required since qualified statements targeting yet-to-be-created modules, i.e. plugins,\n     * are silently dropped when the boot layer is created.\n     */\n    private static void exposeQualifiedExportsAndOpens(Module target, Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports) {\n        qualifiedExports.getOrDefault(target.getName(), List.of()).forEach(exportService -\u003e exportService.addExportsAndOpens(target));\n    }\n\n    private static void addExportsService(\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports,\n        ModuleQualifiedExportsService exportsService,\n        String moduleName\n    ) {\n        for (String targetName : exportsService.getTargets()) {\n            logger.debug(\"Registered qualified export from module \" + moduleName + \" to \" + targetName);\n            qualifiedExports.computeIfAbsent(targetName, k -\u003e new ArrayList\u003c\u003e()).add(exportsService);\n        }\n    }\n\n    protected void addServerExportsService(Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports) {\n        final Module serverModule \u003d PluginsService.class.getModule();\n        var exportsService \u003d new ModuleQualifiedExportsService(serverModule) {\n            @Override\n            protected void addExports(String pkg, Module target) {\n                serverModule.addExports(pkg, target);\n            }\n\n            @Override\n            protected void addOpens(String pkg, Module target) {\n                serverModule.addOpens(pkg, target);\n            }\n        };\n        addExportsService(qualifiedExports, exportsService, serverModule.getName());\n    }\n\n    private static void addPluginExportsServices(Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports, Controller controller) {\n        for (Module module : controller.layer().modules()) {\n            var exportsService \u003d new ModuleQualifiedExportsService(module) {\n                @Override\n                protected void addExports(String pkg, Module target) {\n                    controller.addExports(module, pkg, target);\n                }\n\n                @Override\n                protected void addOpens(String pkg, Module target) {\n                    controller.addOpens(module, pkg, target);\n                }\n            };\n            addExportsService(qualifiedExports, exportsService, module.getName());\n        }\n    }\n\n    /** Determines the module name of the SPI module, given its URL. */\n    static String spiModuleName(Set\u003cURL\u003e spiURLS) {\n        ModuleFinder finder \u003d ModuleFinder.of(urlsToPaths(spiURLS));\n        var mrefs \u003d finder.findAll();\n        assert mrefs.size() \u003d\u003d 1 : \"Expected a single module, got:\" + mrefs;\n        return mrefs.stream().findFirst().get().descriptor().name();\n    }\n\n    /**\n     * Tuple of module layer and loader.\n     * Modular Plugins have a plugin specific loader and layer.\n     * Non-Modular plugins have a plugin specific loader and the boot layer.\n     */\n    record LayerAndLoader(ModuleLayer layer, ClassLoader loader) {\n\n        LayerAndLoader {\n            Objects.requireNonNull(layer);\n            Objects.requireNonNull(loader);\n        }\n\n        static LayerAndLoader ofLoader(ClassLoader loader) {\n            return new LayerAndLoader(ModuleLayer.boot(), loader);\n        }\n    }\n\n    @SuppressForbidden(reason \u003d \"I need to convert URL\u0027s to Paths\")\n    static final Path[] urlsToPaths(Set\u003cURL\u003e urls) {\n        return urls.stream().map(PluginsService::uncheckedToURI).map(PathUtils::get).toArray(Path[]::new);\n    }\n\n    static final URI uncheckedToURI(URL url) {\n        try {\n            return url.toURI();\n        } catch (URISyntaxException e) {\n            throw new AssertionError(new IOException(e));\n        }\n    }\n\n    static final String toPackageName(String className) {\n        assert className.endsWith(\".\") \u003d\u003d false;\n        int index \u003d className.lastIndexOf(\".\");\n        if (index \u003d\u003d -1) {\n            throw new IllegalStateException(\"invalid class name:\" + className);\n        }\n        return className.substring(0, index);\n    }\n\n    @SuppressWarnings(\"removal\")\n    private static void privilegedSetContextClassLoader(ClassLoader loader) {\n        AccessController.doPrivileged((PrivilegedAction\u003cVoid\u003e) () -\u003e {\n            Thread.currentThread().setContextClassLoader(loader);\n            return null;\n        });\n    }\n\n    @SuppressWarnings(\"removal\")\n    static Controller privilegedDefineModulesWithOneLoader(Configuration cf, List\u003cModuleLayer\u003e parentLayers, ClassLoader parentLoader) {\n        return AccessController.doPrivileged(\n            (PrivilegedAction\u003cController\u003e) () -\u003e ModuleLayer.defineModulesWithOneLoader(cf, parentLayers, parentLoader)\n        );\n    }\n\n    @SuppressWarnings(\"removal\")\n    static ClassLoader privilegedFindLoader(ModuleLayer layer, String name) {\n        return AccessController.doPrivileged((PrivilegedAction\u003cClassLoader\u003e) () -\u003e layer.findLoader(name));\n    }\n}","methodCount":55},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":600,"lineEnd":608,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toModuleName to class PluginsUtils","description":"move method toModuleName to PsiClass:PluginsUtils\nRationale: The toModuleName() method is concerned with transforming a string into a module name, which is closely related to plugin management and module identification. Moving it to PluginsUtils adheres to the Single Responsibility Principle by ensuring that all plugin-related utilities are housed in one class. This improves cohesion and reusability of the method for any future plugin-related operations. However, it may introduce dependencies on the PluginsUtils class where it wasn\u0027t previously needed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":600,"lineEnd":608,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toModuleName to class JwtUtil","description":"move method toModuleName to PsiClass:JwtUtil\nRationale: JwtUtil deals with various string manipulations and validations related to JWTs (JSON Web Tokens). The toModuleName() method\u0027s string transformation aligns well with the utility functions in JwtUtil. This move enhances the utility of JwtUtil by centralizing string manipulation methods. However, it might dilute the focus of JwtUtil if it becomes overloaded with unrelated string operations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":600,"lineEnd":608,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toModuleName to class RestUtils","description":"move method toModuleName to PsiClass:RestUtils\nRationale: RestUtils is focused on handling REST-related operations, including decoding and parameter management. The toModuleName() method can be seen as a utility for preparing names that might be used in RESTful services. Moving it here could promote better organization of utility methods related to REST. However, it may introduce a concern of RestUtils becoming a catch-all for unrelated utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":700,"lineEnd":709,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method signatureMessage to class PluginTestUtil","description":"move method signatureMessage to PsiClass:PluginTestUtil\nRationale: The signatureMessage() method is specifically about validating the constructor signatures of Plugin classes. Moving it to PluginTestUtil aligns with the Single Responsibility Principle, as this class appears to focus on utility functions related to plugins. This change increases cohesion by keeping plugin-related logic together, making it easier to maintain and understand. The drawback is that if PluginTestUtil becomes too crowded with utility methods, it may violate the Interface Segregation Principle.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":700,"lineEnd":709,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method signatureMessage to class ExceptionUtils","description":"move method signatureMessage to PsiClass:ExceptionUtils\nRationale: While ExceptionUtils primarily deals with exceptions, the signatureMessage() method serves as a utility that addresses issues related to constructor signatures, which can be considered a form of validation. This move would improve the organization of utility methods related to error handling in plugin instantiation. However, it may dilute the focus of ExceptionUtils if too many unrelated utilities are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":700,"lineEnd":709,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method signatureMessage to class FunctionTestUtils","description":"move method signatureMessage to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils encompasses various utility methods for testing functions. Since signatureMessage() can be used in the context of testing plugins, moving it here could centralize testing utilities. This adheres to the Open/Closed Principle by allowing for future extensions related to function testing without modifying existing code. The potential drawback is that it may introduce confusion if the class is not primarily focused on plugin-related functionalities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":646,"lineEnd":658,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method reloadLuceneSPI to class PluginsUtils","description":"move method reloadLuceneSPI to PsiClass:PluginsUtils\nRationale: The reloadLuceneSPI() method is related to registering and managing Lucene service implementations, which aligns closely with the responsibilities of the PluginsUtils class. This move adheres to the Single Responsibility Principle, as it centralizes plugin-related functionalities, improving cohesion. Additionally, it enhances the reusability of the method within the context of plugin management. However, care must be taken to ensure that any dependencies or interactions with the current class are properly managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":646,"lineEnd":658,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method reloadLuceneSPI to class KeyStoreUtil","description":"move method reloadLuceneSPI to PsiClass:KeyStoreUtil\nRationale: KeyStoreUtil is focused on managing security-related functionalities, which may include loading and configuring various services. Since the reloadLuceneSPI() method deals with reloading service implementations, it could fit within this class. This move would adhere to the Open/Closed Principle, as it allows for extension of service management without modifying existing classes. However, it may dilute the class\u0027s focus if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":646,"lineEnd":658,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method reloadLuceneSPI to class AuthorizationUtils","description":"move method reloadLuceneSPI to PsiClass:AuthorizationUtils\nRationale: AuthorizationUtils deals with user permissions and security, which can be related to the loading of services that may require specific access controls. Moving reloadLuceneSPI() here can enhance the security context of service loading. This adheres to the Dependency Inversion Principle by promoting a clear separation of concerns. However, the connection between service reloading and authorization needs to be justified to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"checkMandatoryPlugins","method_signature":"static checkMandatoryPlugins(Set\u003cString\u003e existingPlugins, Set\u003cString\u003e mandatoryPlugins)","target_class":"","rationale":""},{"method_name":"getRuntimeInfos","method_signature":"private static getRuntimeInfos(\n        PluginIntrospector inspector,\n        List\u003cPluginDescriptor\u003e pluginDescriptors,\n        Map\u003cString, LoadedPlugin\u003e plugins\n    )","target_class":"","rationale":""},{"method_name":"map","method_signature":"public final map(Function\u003cPlugin, T\u003e function)","target_class":"","rationale":""},{"method_name":"flatMap","method_signature":"public final flatMap(Function\u003cPlugin, Collection\u003cT\u003e\u003e function)","target_class":"","rationale":""},{"method_name":"forEach","method_signature":"public final forEach(Consumer\u003cPlugin\u003e consumer)","target_class":"","rationale":""},{"method_name":"pluginMap","method_signature":"public final pluginMap()","target_class":"","rationale":""},{"method_name":"loadBundles","method_signature":"private loadBundles(\n        Set\u003cPluginBundle\u003e bundles,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"loadExtensions","method_signature":"static loadExtensions(Collection\u003cLoadedPlugin\u003e plugins)","target_class":"","rationale":""},{"method_name":"loadServiceProviders","method_signature":"public loadServiceProviders(Class\u003cT\u003e service)","target_class":"","rationale":""},{"method_name":"loadSingletonServiceProvider","method_signature":"public loadSingletonServiceProvider(Class\u003cT\u003e service, Supplier\u003cT\u003e fallback)","target_class":"","rationale":""},{"method_name":"createExtensions","method_signature":"private static createExtensions(Class\u003cT\u003e extensionPointType, Plugin plugin)","target_class":"","rationale":""},{"method_name":"createExtension","method_signature":"static createExtension(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin)","target_class":"","rationale":""},{"method_name":"extensionSignatureMessage","method_signature":"private static extensionSignatureMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin)","target_class":"","rationale":""},{"method_name":"extensionConstructorMessage","method_signature":"private static extensionConstructorMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType)","target_class":"","rationale":""},{"method_name":"loadBundle","method_signature":"private loadBundle(\n        PluginBundle bundle,\n        Map\u003cString, LoadedPlugin\u003e loaded,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"createSPI","method_signature":"static createSPI(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cLoadedPlugin\u003e extendedPlugins,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"createPlugin","method_signature":"static createPlugin(\n        PluginBundle bundle,\n        ClassLoader pluginParentLoader,\n        List\u003cLoadedPlugin\u003e extendedPlugins,\n        LayerAndLoader spiLayerAndLoader,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"toModuleName","method_signature":"static toModuleName(String name)","target_class":"","rationale":""},{"method_name":"checkDeprecations","method_signature":"private static checkDeprecations(\n        PluginIntrospector inspector,\n        List\u003cPluginDescriptor\u003e pluginDescriptors,\n        Map\u003cString, LoadedPlugin\u003e plugins\n    )","target_class":"","rationale":""},{"method_name":"reloadLuceneSPI","method_signature":"static reloadLuceneSPI(ClassLoader loader)","target_class":"","rationale":""},{"method_name":"loadPluginClass","method_signature":"private static loadPluginClass(String className, ClassLoader loader)","target_class":"","rationale":""},{"method_name":"loadPlugin","method_signature":"static loadPlugin(Class\u003c? extends Plugin\u003e pluginClass, Settings settings, Path configPath)","target_class":"","rationale":""},{"method_name":"signatureMessage","method_signature":"private static signatureMessage(final Class\u003c? extends Plugin\u003e clazz)","target_class":"","rationale":""},{"method_name":"filterPlugins","method_signature":"@SuppressWarnings(\"unchecked\")\n    public final filterPlugins(Class\u003cT\u003e type)","target_class":"","rationale":""},{"method_name":"createPluginModuleLayer","method_signature":"static createPluginModuleLayer(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"createSpiModuleLayer","method_signature":"static final createSpiModuleLayer(\n        Set\u003cURL\u003e urls,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"createModuleLayer","method_signature":"static createModuleLayer(\n        String className,\n        String moduleName,\n        Path[] paths,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"parentLayersOrBoot","method_signature":"private static parentLayersOrBoot(List\u003cModuleLayer\u003e parentLayers)","target_class":"","rationale":""},{"method_name":"parentConfigurationOrBoot","method_signature":"private static parentConfigurationOrBoot(List\u003cModuleLayer\u003e parentLayers)","target_class":"","rationale":""},{"method_name":"ensureEntryPointAccessible","method_signature":"private static ensureEntryPointAccessible(Controller controller, Module pluginModule, String className)","target_class":"","rationale":""},{"method_name":"exposeQualifiedExportsAndOpens","method_signature":"private static exposeQualifiedExportsAndOpens(Module target, Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports)","target_class":"","rationale":""},{"method_name":"addExportsService","method_signature":"private static addExportsService(\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports,\n        ModuleQualifiedExportsService exportsService,\n        String moduleName\n    )","target_class":"","rationale":""},{"method_name":"spiModuleName","method_signature":"static spiModuleName(Set\u003cURL\u003e spiURLS)","target_class":"","rationale":""},{"method_name":"ofLoader","method_signature":"static ofLoader(ClassLoader loader)","target_class":"","rationale":""},{"method_name":"urlsToPaths","method_signature":"@SuppressForbidden(reason \u003d \"I need to convert URL\u0027s to Paths\")\n    static final urlsToPaths(Set\u003cURL\u003e urls)","target_class":"","rationale":""},{"method_name":"uncheckedToURI","method_signature":"static final uncheckedToURI(URL url)","target_class":"","rationale":""},{"method_name":"toPackageName","method_signature":"static final toPackageName(String className)","target_class":"","rationale":""},{"method_name":"privilegedSetContextClassLoader","method_signature":"@SuppressWarnings(\"removal\")\n    private static privilegedSetContextClassLoader(ClassLoader loader)","target_class":"","rationale":""},{"method_name":"privilegedDefineModulesWithOneLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedDefineModulesWithOneLoader(Configuration cf, List\u003cModuleLayer\u003e parentLayers, ClassLoader parentLoader)","target_class":"","rationale":""},{"method_name":"privilegedFindLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedFindLoader(ModuleLayer layer, String name)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"toModuleName","method_signature":"static toModuleName(String name)","target_class":"","rationale":""},{"method_name":"signatureMessage","method_signature":"private static signatureMessage(final Class\u003c? extends Plugin\u003e clazz)","target_class":"","rationale":""},{"method_name":"reloadLuceneSPI","method_signature":"static reloadLuceneSPI(ClassLoader loader)","target_class":"","rationale":""},{"method_name":"createSpiModuleLayer","method_signature":"static final createSpiModuleLayer(\n        Set\u003cURL\u003e urls,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"createPluginModuleLayer","method_signature":"static createPluginModuleLayer(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"filterPlugins","method_signature":"@SuppressWarnings(\"unchecked\")\n    public final filterPlugins(Class\u003cT\u003e type)","target_class":"","rationale":""},{"method_name":"privilegedDefineModulesWithOneLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedDefineModulesWithOneLoader(Configuration cf, List\u003cModuleLayer\u003e parentLayers, ClassLoader parentLoader)","target_class":"","rationale":""},{"method_name":"extensionSignatureMessage","method_signature":"private static extensionSignatureMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin)","target_class":"","rationale":""},{"method_name":"createModuleLayer","method_signature":"static createModuleLayer(\n        String className,\n        String moduleName,\n        Path[] paths,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},{"method_name":"extensionConstructorMessage","method_signature":"private static extensionConstructorMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType)","target_class":"","rationale":""},{"method_name":"exposeQualifiedExportsAndOpens","method_signature":"private static exposeQualifiedExportsAndOpens(Module target, Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports)","target_class":"","rationale":""},{"method_name":"spiModuleName","method_signature":"static spiModuleName(Set\u003cURL\u003e spiURLS)","target_class":"","rationale":""},{"method_name":"pluginMap","method_signature":"public final pluginMap()","target_class":"","rationale":""},{"method_name":"privilegedFindLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedFindLoader(ModuleLayer layer, String name)","target_class":"","rationale":""},{"method_name":"flatMap","method_signature":"public final flatMap(Function\u003cPlugin, Collection\u003cT\u003e\u003e function)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static toModuleName(String name)":{"first":{"method_name":"toModuleName","method_signature":"static toModuleName(String name)","target_class":"","rationale":""},"second":0.26915624847840147},"private static signatureMessage(final Class\u003c? extends Plugin\u003e clazz)":{"first":{"method_name":"signatureMessage","method_signature":"private static signatureMessage(final Class\u003c? extends Plugin\u003e clazz)","target_class":"","rationale":""},"second":0.29648958032388756},"static reloadLuceneSPI(ClassLoader loader)":{"first":{"method_name":"reloadLuceneSPI","method_signature":"static reloadLuceneSPI(ClassLoader loader)","target_class":"","rationale":""},"second":0.3213494241568327},"static final createSpiModuleLayer(\n        Set\u003cURL\u003e urls,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )":{"first":{"method_name":"createSpiModuleLayer","method_signature":"static final createSpiModuleLayer(\n        Set\u003cURL\u003e urls,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},"second":0.33045077995861577},"static createPluginModuleLayer(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )":{"first":{"method_name":"createPluginModuleLayer","method_signature":"static createPluginModuleLayer(\n        PluginBundle bundle,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},"second":0.35303267439418273},"@SuppressWarnings(\"unchecked\")\n    public final filterPlugins(Class\u003cT\u003e type)":{"first":{"method_name":"filterPlugins","method_signature":"@SuppressWarnings(\"unchecked\")\n    public final filterPlugins(Class\u003cT\u003e type)","target_class":"","rationale":""},"second":0.3738397599330778},"@SuppressWarnings(\"removal\")\n    static privilegedDefineModulesWithOneLoader(Configuration cf, List\u003cModuleLayer\u003e parentLayers, ClassLoader parentLoader)":{"first":{"method_name":"privilegedDefineModulesWithOneLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedDefineModulesWithOneLoader(Configuration cf, List\u003cModuleLayer\u003e parentLayers, ClassLoader parentLoader)","target_class":"","rationale":""},"second":0.38131628143128204},"private static extensionSignatureMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin)":{"first":{"method_name":"extensionSignatureMessage","method_signature":"private static extensionSignatureMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType, Plugin plugin)","target_class":"","rationale":""},"second":0.38617785118157905},"static createModuleLayer(\n        String className,\n        String moduleName,\n        Path[] paths,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )":{"first":{"method_name":"createModuleLayer","method_signature":"static createModuleLayer(\n        String className,\n        String moduleName,\n        Path[] paths,\n        ClassLoader parentLoader,\n        List\u003cModuleLayer\u003e parentLayers,\n        Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports\n    )","target_class":"","rationale":""},"second":0.3876349392662165},"private static extensionConstructorMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType)":{"first":{"method_name":"extensionConstructorMessage","method_signature":"private static extensionConstructorMessage(Class\u003c? extends T\u003e extensionClass, Class\u003cT\u003e extensionPointType)","target_class":"","rationale":""},"second":0.41302222861635457},"private static exposeQualifiedExportsAndOpens(Module target, Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports)":{"first":{"method_name":"exposeQualifiedExportsAndOpens","method_signature":"private static exposeQualifiedExportsAndOpens(Module target, Map\u003cString, List\u003cModuleQualifiedExportsService\u003e\u003e qualifiedExports)","target_class":"","rationale":""},"second":0.41950645706730955},"static spiModuleName(Set\u003cURL\u003e spiURLS)":{"first":{"method_name":"spiModuleName","method_signature":"static spiModuleName(Set\u003cURL\u003e spiURLS)","target_class":"","rationale":""},"second":0.43728882085383586},"public final pluginMap()":{"first":{"method_name":"pluginMap","method_signature":"public final pluginMap()","target_class":"","rationale":""},"second":0.445882602656208},"@SuppressWarnings(\"removal\")\n    static privilegedFindLoader(ModuleLayer layer, String name)":{"first":{"method_name":"privilegedFindLoader","method_signature":"@SuppressWarnings(\"removal\")\n    static privilegedFindLoader(ModuleLayer layer, String name)","target_class":"","rationale":""},"second":0.4487535921815288},"public final flatMap(Function\u003cPlugin, Collection\u003cT\u003e\u003e function)":{"first":{"method_name":"flatMap","method_signature":"public final flatMap(Function\u003cPlugin, Collection\u003cT\u003e\u003e function)","target_class":"","rationale":""},"second":0.4830661228457022}},"llmMethodPriority":{"priority_method_names":["reloadLuceneSPI","signatureMessage","extensionSignatureMessage","extensionConstructorMessage","exposeQualifiedExportsAndOpens","spiModuleName","toModuleName","createSpiModuleLayer","createPluginModuleLayer","filterPlugins","privilegedDefineModulesWithOneLoader","createModuleLayer","pluginMap","privilegedFindLoader","flatMap"],"llm_response_time":4869},"targetClassMap":{"toModuleName":{"target_classes":[{"class_name":"ProxyUtils","similarity_score":0.14040071386781186},{"class_name":"PluginsUtils","similarity_score":0.28468320209792575},{"class_name":"PluginsUtilsTests","similarity_score":0.18285910001133934},{"class_name":"PluginTestUtil","similarity_score":0.2308939335061044},{"class_name":"JwkValidateUtil","similarity_score":0.22805312750865295},{"class_name":"JwkValidateUtilTests","similarity_score":0.2653346420943247},{"class_name":"OpenAiUtils","similarity_score":0.24065643544982854},{"class_name":"RestResponseUtils","similarity_score":0.23449624045084236},{"class_name":"JwtUtil","similarity_score":0.25720243780238633},{"class_name":"ProcessBuilderUtils","similarity_score":0.23576515386577845},{"class_name":"ProcessUtil","similarity_score":0.17536701524760429},{"class_name":"ProcessUtils","similarity_score":0.2681340187765524},{"class_name":"ParserUtils","similarity_score":0.2515296313545942},{"class_name":"RestTestUtil","similarity_score":0.2142228775042656},{"class_name":"NumericUtilsTests","similarity_score":0.1100614986016994},{"class_name":"RestUtils","similarity_score":0.2724525667786887},{"class_name":"RestUtilsTests","similarity_score":0.14223984136302473},{"class_name":"KeyStoreUtil","similarity_score":0.2009612773854807},{"class_name":"DiffableTestUtils","similarity_score":0.17221939730199323},{"class_name":"DiffableUtils","similarity_score":0.21202582880567303},{"class_name":"PathUtils","similarity_score":0.15301527745388696},{"class_name":"PathUtilsForTesting","similarity_score":0.1788766050054885},{"class_name":"RetentionLeaseUtils","similarity_score":0.1260820036102558},{"class_name":"ProtocolUtils","similarity_score":0.24631454853898016},{"class_name":"DiscoveryNodeUtils","similarity_score":0.25862768487479754},{"class_name":"PemUtils","similarity_score":0.24266265041237686},{"class_name":"ProxyMatcher","similarity_score":0.22186236327800551},{"class_name":"MapperTestUtils","similarity_score":0.18263173483123168},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.3099800898457035},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.14164291718683855}],"target_classes_sorted_by_llm":["PluginsUtils","JwtUtil","RestUtils","ParserUtils","RollupJobIdentifierUtils","DiscoveryNodeUtils","PemUtils","ProcessUtils","ProtocolUtils","JwkValidateUtilTests"],"llm_response_time":15001,"similarity_computation_time":20,"similarity_metric":"voyage"},"signatureMessage":{"target_classes":[{"class_name":"PluginsUtils","similarity_score":0.23819023232486625},{"class_name":"PluginsUtilsTests","similarity_score":0.11780371718669017},{"class_name":"PluginTestUtil","similarity_score":0.2783431199005694},{"class_name":"ProxyUtils","similarity_score":0.1813428796108763},{"class_name":"RestResponseUtils","similarity_score":0.28268570845892727},{"class_name":"FunctionTestUtils","similarity_score":0.32223304187156676},{"class_name":"RestTestUtil","similarity_score":0.23433444858534447},{"class_name":"JwkValidateUtil","similarity_score":0.23330793233377162},{"class_name":"JwkValidateUtilTests","similarity_score":0.2698419776229493},{"class_name":"RestUtils","similarity_score":0.24919117530656637},{"class_name":"RestUtilsTests","similarity_score":0.1467961755608828},{"class_name":"FutureUtils","similarity_score":0.23893420064696885},{"class_name":"JwtUtil","similarity_score":0.29046835088078155},{"class_name":"GceMockUtils","similarity_score":0.32672754440783375},{"class_name":"ExceptionUtils","similarity_score":0.2970442628930023},{"class_name":"RetentionLeaseUtils","similarity_score":0.13721510754924343},{"class_name":"GeneratorUtils","similarity_score":0.26050202409820034},{"class_name":"ExecutionUtils","similarity_score":0.25600982642724035},{"class_name":"TemplateUtils","similarity_score":0.28567865389696784},{"class_name":"TemplateUtilsTests","similarity_score":0.2954507146860436},{"class_name":"Term","similarity_score":0.2092866574279774},{"class_name":"NumericUtilsTests","similarity_score":0.1289938288593467},{"class_name":"KeyStoreUtil","similarity_score":0.26774514149316914},{"class_name":"GeometryTestUtils","similarity_score":0.29979523662316426},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.2391633666338683},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.09300961257838508},{"class_name":"GeoTestUtils","similarity_score":0.2813725730759487},{"class_name":"GeoTileUtils","similarity_score":0.24744016877760225},{"class_name":"GeoUtils","similarity_score":0.24828207120729612},{"class_name":"GeoUtilsTests","similarity_score":0.17437705999316633}],"target_classes_sorted_by_llm":["PluginTestUtil","ExceptionUtils","FunctionTestUtils","GeoTestUtils","TemplateUtils","RestResponseUtils","JwtUtil","TemplateUtilsTests","GeometryTestUtils","GceMockUtils"],"llm_response_time":14324,"similarity_computation_time":13,"similarity_metric":"voyage"},"reloadLuceneSPI":{"target_classes":[{"class_name":"PluginsUtils","similarity_score":0.4357943065042659},{"class_name":"PluginsUtilsTests","similarity_score":0.13684992499107465},{"class_name":"PluginTestUtil","similarity_score":0.20037184311856088},{"class_name":"ProxyUtils","similarity_score":0.4953975088125799},{"class_name":"AuditUtil","similarity_score":0.202301992605674},{"class_name":"RestResponseUtils","similarity_score":0.1565368905041356},{"class_name":"RestTestUtil","similarity_score":0.4766783333056719},{"class_name":"FunctionTestUtils","similarity_score":0.16147011837373376},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.24548260221241894},{"class_name":"AuthorizationUtils","similarity_score":0.41571368280271914},{"class_name":"RestUtils","similarity_score":0.4614725159593831},{"class_name":"RestUtilsTests","similarity_score":0.09339497129352933},{"class_name":"FutureUtils","similarity_score":0.47631435359699964},{"class_name":"JwkValidateUtil","similarity_score":0.22216040922637717},{"class_name":"JwkValidateUtilTests","similarity_score":0.19680324908227295},{"class_name":"GceMockUtils","similarity_score":0.22128520113714795},{"class_name":"JwtUtil","similarity_score":0.3486254803847717},{"class_name":"RetentionLeaseUtils","similarity_score":0.33666185446274594},{"class_name":"GeneratorUtils","similarity_score":0.21335980809982386},{"class_name":"CheckedFunctionUtils","similarity_score":0.4170079165519895},{"class_name":"AwsEc2Utils","similarity_score":0.28117754875721235},{"class_name":"NumericUtilsTests","similarity_score":0.08571622374803683},{"class_name":"KeyStoreUtil","similarity_score":0.448120689357864},{"class_name":"GeometryTestUtils","similarity_score":0.22270158453181157},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.367307853415771},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.45432100247626583},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.30382782949331844},{"class_name":"CIDRUtils","similarity_score":0.24134498221444642},{"class_name":"GeoTestUtils","similarity_score":0.20993312778086065},{"class_name":"GeoTileUtils","similarity_score":0.5159248922034244}],"target_classes_sorted_by_llm":["PluginsUtils","KeyStoreUtil","AuthorizationUtils","RestUtils","FutureUtils","RollupJobIdentifierUtils","CheckedFunctionUtils","GeoTileUtils","RestTestUtil","ProxyUtils"],"llm_response_time":13911,"similarity_computation_time":7,"similarity_metric":"voyage"}}}
{"id":"b6b9af8e-bf16-4e28-a77a-47fda1e125b2","methodCount":15,"hostFunctionTelemetryData":{"hostFunctionSize":141,"lineStart":27,"lineEnd":167,"bodyLineStart":27,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/modules/rank-eval/src/main/java/org/elasticsearch/index/rankeval/EvalQueryQuality.java","sourceCode":"/**\n * Result of the evaluation metric calculation on one particular query alone.\n */\npublic class EvalQueryQuality implements ToXContentFragment, Writeable {\n\n    private final String queryId;\n    private final double metricScore;\n    private MetricDetail optionalMetricDetails;\n    private final List\u003cRatedSearchHit\u003e ratedHits;\n\n    public EvalQueryQuality(String id, double metricScore) {\n        this.queryId \u003d id;\n        this.metricScore \u003d metricScore;\n        this.ratedHits \u003d new ArrayList\u003c\u003e();\n    }\n\n    public EvalQueryQuality(StreamInput in) throws IOException {\n        this.queryId \u003d in.readString();\n        this.metricScore \u003d in.readDouble();\n        this.ratedHits \u003d in.readCollectionAsList(RatedSearchHit::new);\n        this.optionalMetricDetails \u003d in.readOptionalNamedWriteable(MetricDetail.class);\n    }\n\n    // only used for parsing internally\n    private EvalQueryQuality(String queryId, ParsedEvalQueryQuality builder) {\n        this.queryId \u003d queryId;\n        this.metricScore \u003d builder.evaluationResult;\n        this.optionalMetricDetails \u003d builder.optionalMetricDetails;\n        this.ratedHits \u003d builder.ratedHits;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeString(queryId);\n        out.writeDouble(metricScore);\n        out.writeCollection(ratedHits);\n        out.writeOptionalNamedWriteable(this.optionalMetricDetails);\n    }\n\n    public String getId() {\n        return queryId;\n    }\n\n    public double metricScore() {\n        return metricScore;\n    }\n\n    public void setMetricDetails(MetricDetail breakdown) {\n        this.optionalMetricDetails \u003d breakdown;\n    }\n\n    public MetricDetail getMetricDetails() {\n        return this.optionalMetricDetails;\n    }\n\n    public void addHitsAndRatings(List\u003cRatedSearchHit\u003e hits) {\n        this.ratedHits.addAll(hits);\n    }\n\n    public List\u003cRatedSearchHit\u003e getHitsAndRatings() {\n        return this.ratedHits;\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(queryId);\n        builder.field(METRIC_SCORE_FIELD.getPreferredName(), this.metricScore);\n        builder.startArray(UNRATED_DOCS_FIELD.getPreferredName());\n        for (DocumentKey key : EvaluationMetric.filterUnratedDocuments(ratedHits)) {\n            builder.startObject();\n            builder.field(RatedDocument.INDEX_FIELD.getPreferredName(), key.index());\n            builder.field(RatedDocument.DOC_ID_FIELD.getPreferredName(), key.docId());\n            builder.endObject();\n        }\n        builder.endArray();\n        builder.startArray(HITS_FIELD.getPreferredName());\n        for (RatedSearchHit hit : ratedHits) {\n            hit.toXContent(builder, params);\n        }\n        builder.endArray();\n        if (optionalMetricDetails !\u003d null) {\n            builder.field(METRIC_DETAILS_FIELD.getPreferredName(), optionalMetricDetails);\n        }\n        builder.endObject();\n        return builder;\n    }\n\n    static final ParseField METRIC_SCORE_FIELD \u003d new ParseField(\"metric_score\");\n    private static final ParseField UNRATED_DOCS_FIELD \u003d new ParseField(\"unrated_docs\");\n    private static final ParseField HITS_FIELD \u003d new ParseField(\"hits\");\n    private static final ParseField METRIC_DETAILS_FIELD \u003d new ParseField(\"metric_details\");\n    private static final ObjectParser\u003cParsedEvalQueryQuality, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\n        \"eval_query_quality\",\n        true,\n        ParsedEvalQueryQuality::new\n    );\n\n    private static class ParsedEvalQueryQuality {\n        double evaluationResult;\n        MetricDetail optionalMetricDetails;\n        List\u003cRatedSearchHit\u003e ratedHits \u003d new ArrayList\u003c\u003e();\n    }\n\n    static {\n        PARSER.declareDouble((obj, value) -\u003e obj.evaluationResult \u003d value, METRIC_SCORE_FIELD);\n        PARSER.declareObject((obj, value) -\u003e obj.optionalMetricDetails \u003d value, (p, c) -\u003e parseMetricDetail(p), METRIC_DETAILS_FIELD);\n        PARSER.declareObjectArray((obj, list) -\u003e obj.ratedHits \u003d list, (p, c) -\u003e RatedSearchHit.parse(p), HITS_FIELD);\n    }\n\n    private static MetricDetail parseMetricDetail(XContentParser parser) throws IOException {\n        XContentParserUtils.ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.currentToken(), parser);\n        XContentParserUtils.ensureExpectedToken(XContentParser.Token.FIELD_NAME, parser.nextToken(), parser);\n        MetricDetail metricDetail \u003d parser.namedObject(MetricDetail.class, parser.currentName(), null);\n        XContentParserUtils.ensureExpectedToken(XContentParser.Token.END_OBJECT, parser.nextToken(), parser);\n        return metricDetail;\n    }\n\n    public static EvalQueryQuality fromXContent(XContentParser parser, String queryId) throws IOException {\n        return new EvalQueryQuality(queryId, PARSER.apply(parser, null));\n    }\n\n    @Override\n    public final boolean equals(Object obj) {\n        if (this \u003d\u003d obj) {\n            return true;\n        }\n        if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n            return false;\n        }\n        EvalQueryQuality other \u003d (EvalQueryQuality) obj;\n        return Objects.equals(queryId, other.queryId)\n            \u0026\u0026 Objects.equals(metricScore, other.metricScore)\n            \u0026\u0026 Objects.equals(ratedHits, other.ratedHits)\n            \u0026\u0026 Objects.equals(optionalMetricDetails, other.optionalMetricDetails);\n    }\n\n    @Override\n    public final int hashCode() {\n        return Objects.hash(queryId, metricScore, ratedHits, optionalMetricDetails);\n    }\n}","methodCount":15},"candidatesTelemetryData":{"numberOfSuggestions":7,"candidates":[{"lineStart":135,"lineEnd":141,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseMetricDetail to class Detail","description":"move method parseMetricDetail to PsiClass:Detail\nRationale: The parseMetricDetail() method is responsible for parsing a MetricDetail object from an XContentParser, which aligns closely with the functionality of the Detail class that includes methods for serialization and deserialization. Moving it here supports the Single Responsibility Principle by keeping parsing logic within the class that represents the data structure being parsed, enhancing cohesion. However, this could introduce a dependency on the XContentParser in Detail, which may not be ideal if Detail is meant to be agnostic of parsing concerns.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":135,"lineEnd":141,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseMetricDetail to class MeanReciprocalRank","description":"move method parseMetricDetail to PsiClass:MeanReciprocalRank\nRationale: Given that MeanReciprocalRank has a fromXContent method, it indicates a relationship with parsing XContent. This method could be relocated here to streamline the parsing process for MetricDetail, thereby improving the cohesion of parsing-related functions. This aligns with the Open/Closed Principle, allowing for extension of parsing capabilities without modifying existing classes. However, it may increase the complexity of MeanReciprocalRank if it becomes burdened with too many unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":135,"lineEnd":141,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseMetricDetail to class DiscountedCumulativeGain","description":"move method parseMetricDetail to PsiClass:DiscountedCumulativeGain\nRationale: Similar to MeanReciprocalRank, DiscountedCumulativeGain also has methods related to parsing from XContent. Relocating parseMetricDetail() here could enhance the parsing capabilities of this class. This adheres to the Interface Segregation Principle by allowing classes to only implement parsing methods relevant to their context. A potential drawback is that it may lead to an unnecessary coupling between unrelated metrics, which could complicate the design.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":145,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class MeanReciprocalRank","description":"move method fromXContent to PsiClass:MeanReciprocalRank\nRationale: The fromXContent() method is responsible for parsing and creating an instance of EvalQueryQuality from an XContentParser, which closely relates to the evaluation of query quality metrics. Moving it to MeanReciprocalRank aligns with the Single Responsibility Principle as this class deals with evaluating ranking metrics. This enhances cohesion and reusability of the method within the context of ranking evaluations. A potential drawback is that it may introduce dependencies on the MeanReciprocalRank class that could complicate testing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":145,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class ExpectedReciprocalRank","description":"move method fromXContent to PsiClass:ExpectedReciprocalRank\nRationale: Similar to MeanReciprocalRank, ExpectedReciprocalRank is focused on evaluating ranking performance. The fromXContent() method fits well here as it pertains to creating evaluation metrics from parsed content. This move would encapsulate the logic related to ranking evaluations, improving class cohesion. However, it may increase the complexity of the ExpectedReciprocalRank class if too many responsibilities are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":145,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RankEvalSpec","description":"move method fromXContent to PsiClass:RankEvalSpec\nRationale: RankEvalSpec is concerned with the specifications for ranking evaluations, which includes parsing and managing metrics. Moving fromXContent() here would enhance the alignment of the method with the class\u0027s purpose, adhering to the Single Responsibility Principle. This would also improve the organization of evaluation-related logic. However, it may lead to a bloated class if too many parsing methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":83,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method addHitsAndRatings to class MetricDetail","description":"Move method addHitsAndRatings to org.elasticsearch.index.rankeval.MetricDetail\nRationale: The addHitsAndRatings() method is responsible for adding search hits to a collection, which seems to relate more closely to the concept of metrics and ratings. Moving this method to the MetricDetail class adheres to the Single Responsibility Principle, as it centralizes the logic related to metrics and their ratings in one location. This enhances cohesion within the MetricDetail class, making it more intuitive and easier to maintain. Additionally, it aligns with the Open/Closed Principle, as new functionality related to metrics can be added without modifying existing classes. However, consider the potential impact on existing instances where the method is called, as this relocation may require adjustments in multiple areas of the codebase.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"addHitsAndRatings","method_signature":"public addHitsAndRatings(List\u003cRatedSearchHit\u003e hits)","target_class":"","rationale":""},{"method_name":"parseMetricDetail","method_signature":"private static parseMetricDetail(XContentParser parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String queryId)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"parseMetricDetail","method_signature":"private static parseMetricDetail(XContentParser parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String queryId)","target_class":"","rationale":""},{"method_name":"addHitsAndRatings","method_signature":"public addHitsAndRatings(List\u003cRatedSearchHit\u003e hits)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static parseMetricDetail(XContentParser parser)":{"first":{"method_name":"parseMetricDetail","method_signature":"private static parseMetricDetail(XContentParser parser)","target_class":"","rationale":""},"second":0.3035704784064213},"public static fromXContent(XContentParser parser, String queryId)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String queryId)","target_class":"","rationale":""},"second":0.45443999220546877},"public addHitsAndRatings(List\u003cRatedSearchHit\u003e hits)":{"first":{"method_name":"addHitsAndRatings","method_signature":"public addHitsAndRatings(List\u003cRatedSearchHit\u003e hits)","target_class":"","rationale":""},"second":0.4932004045263986}},"llmMethodPriority":{"priority_method_names":["parseMetricDetail","fromXContent","addHitsAndRatings"],"llm_response_time":4688},"targetClassMap":{"parseMetricDetail":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.10704360482220938},{"class_name":"GeoUtilsTests","similarity_score":0.22178515174934416},{"class_name":"DocValuesForUtil","similarity_score":0.2684069106767896},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.27162363903564263},{"class_name":"PForUtil","similarity_score":0.20171685010829868},{"class_name":"MapperTestUtils","similarity_score":0.22553355540891162},{"class_name":"ForUtil","similarity_score":0.16300647739251475},{"class_name":"ShardUtils","similarity_score":0.18797789509922808},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.23438349412361906},{"class_name":"BinaryRangeUtilTests","similarity_score":0.21260174328279338},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.11415741278435237},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.2615454010801801},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.20745268648260354},{"class_name":"StoreUtils","similarity_score":0.15024855029474207},{"class_name":"TranslogOperationsUtils","similarity_score":0.11834115780078217},{"class_name":"RestRankEvalAction","similarity_score":0.13447858840997973},{"class_name":"EvalQueryQualityTests","similarity_score":0.3593736569190295},{"class_name":"Detail","similarity_score":0.3456664492218576},{"class_name":"ExpectedReciprocalRank","similarity_score":0.3119997402708758},{"class_name":"ExpectedReciprocalRankTests","similarity_score":0.20951726416186367},{"class_name":"DiscountedCumulativeGain","similarity_score":0.3154466340720224},{"class_name":"DiscountedCumulativeGainTests","similarity_score":0.10957593430446225},{"class_name":"ScriptWithId","similarity_score":0.31182069023261244},{"class_name":"PrecisionAtK","similarity_score":0.3094774499884663},{"class_name":"PrecisionAtKTests","similarity_score":0.23475345434910536},{"class_name":"MeanReciprocalRank","similarity_score":0.3227733126479362},{"class_name":"MeanReciprocalRankTests","similarity_score":0.26197526511386293},{"class_name":"RankEvalRequestIT","similarity_score":0.16592770586159444},{"class_name":"RankEvalRequestTests","similarity_score":0.2528536989730834}],"target_classes_sorted_by_llm":["Detail","MeanReciprocalRank","DiscountedCumulativeGain","ExpectedReciprocalRank","PrecisionAtK","EvalQueryQualityTests","MeanReciprocalRankTests","LiveVersionMapTestUtils","DocValuesForUtil","ScriptWithId"],"llm_response_time":15095,"similarity_computation_time":18,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"RetentionLeaseUtils","similarity_score":0.20002367284141567},{"class_name":"GeoUtilsTests","similarity_score":0.28439757442443503},{"class_name":"ForUtil","similarity_score":0.11357851940634217},{"class_name":"DocValuesForUtil","similarity_score":0.3296589930344548},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.5427427310716815},{"class_name":"TranslogOperationsUtils","similarity_score":0.30618621784789724},{"class_name":"ShardUtils","similarity_score":0.31208010659582613},{"class_name":"MapperTestUtils","similarity_score":0.3721042037676254},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.33584976459375765},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.20628424925175867},{"class_name":"BinaryRangeUtilTests","similarity_score":0.25269422765264593},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.29016313736841237},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.2630280880212142},{"class_name":"StoreUtils","similarity_score":0.28075723831394206},{"class_name":"PForUtil","similarity_score":0.21091348580530053},{"class_name":"RestRankEvalAction","similarity_score":0.22538707702692437},{"class_name":"EvalQueryQualityTests","similarity_score":0.40740276323836205},{"class_name":"Detail","similarity_score":0.5465466451220039},{"class_name":"ExpectedReciprocalRank","similarity_score":0.4694448283030541},{"class_name":"ExpectedReciprocalRankTests","similarity_score":0.30627392858541763},{"class_name":"DiscountedCumulativeGain","similarity_score":0.46022399616353865},{"class_name":"DiscountedCumulativeGainTests","similarity_score":0.15300420767356734},{"class_name":"ScriptWithId","similarity_score":0.4482107285003976},{"class_name":"MeanReciprocalRank","similarity_score":0.5134424447179656},{"class_name":"MeanReciprocalRankTests","similarity_score":0.3589900289673782},{"class_name":"RankEvalRequestIT","similarity_score":0.25463842287971516},{"class_name":"RankEvalRequestTests","similarity_score":0.39049920173544095},{"class_name":"RankEvalResponseTests","similarity_score":0.4063304160585391},{"class_name":"RankEvalSpec","similarity_score":0.4618403509506834}],"target_classes_sorted_by_llm":["MeanReciprocalRank","ExpectedReciprocalRank","RankEvalSpec","DiscountedCumulativeGain","ScriptWithId","EvalQueryQualityTests","RankEvalResponseTests","RankEvalRequestTests","LiveVersionMapTestUtils","Detail"],"llm_response_time":14076,"similarity_computation_time":6,"similarity_metric":"voyage"},"addHitsAndRatings":{"target_classes":[{"class_name":"MetricDetail","similarity_score":0.25112360116696136}],"target_classes_sorted_by_llm":["MetricDetail"],"llm_response_time":1572,"similarity_computation_time":1,"similarity_metric":"voyage"}}}
{"id":"b16fa682-3726-4153-b6bf-065a3ecfc066","methodCount":3,"hostFunctionTelemetryData":{"hostFunctionSize":48,"lineStart":39,"lineEnd":86,"bodyLineStart":39,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/support/IndicesOptions.java","sourceCode":"public enum WildcardStates {\n        OPEN,\n        CLOSED,\n        HIDDEN;\n\n        public static final EnumSet\u003cWildcardStates\u003e NONE \u003d EnumSet.noneOf(WildcardStates.class);\n\n        public static EnumSet\u003cWildcardStates\u003e parseParameter(Object value, EnumSet\u003cWildcardStates\u003e defaultStates) {\n            if (value \u003d\u003d null) {\n                return defaultStates;\n            }\n\n            EnumSet\u003cWildcardStates\u003e states \u003d EnumSet.noneOf(WildcardStates.class);\n            String[] wildcards \u003d nodeStringArrayValue(value);\n            // TODO why do we let patterns like \"none,all\" or \"open,none,closed\" get used. The location of \u0027none\u0027 in the array changes the\n            // meaning of the resulting value\n            for (String wildcard : wildcards) {\n                updateSetForValue(states, wildcard);\n            }\n\n            return states;\n        }\n\n        public static XContentBuilder toXContent(EnumSet\u003cWildcardStates\u003e states, XContentBuilder builder) throws IOException {\n            if (states.isEmpty()) {\n                builder.field(\"expand_wildcards\", \"none\");\n            } else if (states.containsAll(EnumSet.allOf(WildcardStates.class))) {\n                builder.field(\"expand_wildcards\", \"all\");\n            } else {\n                builder.field(\n                    \"expand_wildcards\",\n                    states.stream().map(state -\u003e state.toString().toLowerCase(Locale.ROOT)).collect(Collectors.joining(\",\"))\n                );\n            }\n            return builder;\n        }\n\n        private static void updateSetForValue(EnumSet\u003cWildcardStates\u003e states, String wildcard) {\n            switch (wildcard) {\n                case \"open\" -\u003e states.add(OPEN);\n                case \"closed\" -\u003e states.add(CLOSED);\n                case \"hidden\" -\u003e states.add(HIDDEN);\n                case \"none\" -\u003e states.clear();\n                case \"all\" -\u003e states.addAll(EnumSet.allOf(WildcardStates.class));\n                default -\u003e throw new IllegalArgumentException(\"No valid expand wildcard value [\" + wildcard + \"]\");\n            }\n        }\n    }","methodCount":3},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":75,"lineEnd":84,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method updateSetForValue to class IndicesOptions","description":"move method updateSetForValue to PsiClass:IndicesOptions\nRationale: The updateSetForValue() method directly manipulates EnumSet\u003cWildcardStates\u003e, which is a part of the IndicesOptions class, specifically in the context of expanding wildcards. Moving it here aligns with the Single Responsibility Principle, as it centralizes wildcard management logic within a class that already deals with index options. This enhances cohesion and reusability. However, care must be taken to ensure that the method\u0027s static nature does not conflict with instance-based operations in IndicesOptions.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":75,"lineEnd":84,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method updateSetForValue to class ActiveShardCount","description":"move method updateSetForValue to PsiClass:ActiveShardCount\nRationale: The method\u0027s functionality of updating states based on wildcard values can be relevant to shard management, which is a concern of ActiveShardCount. This move would enhance the logical grouping of related functionalities, improving maintainability. It aligns with the Open/Closed Principle by allowing the class to extend its capabilities without modifying existing code. A potential drawback is that it may introduce unnecessary dependencies between classes if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":75,"lineEnd":84,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method updateSetForValue to class AutoCreateIndex","description":"move method updateSetForValue to PsiClass:AutoCreateIndex\nRationale: The updateSetForValue() method can be linked to the auto-creation logic of indices, where wildcard states might influence index creation strategies. Moving it here would keep related logic together, enhancing cohesion. This aligns with the Interface Segregation Principle by ensuring that classes only have methods relevant to their specific behavior. However, this could lead to increased complexity if the AutoCreateIndex class becomes overloaded with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":45,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseParameter to class IndicesOptions","description":"move method parseParameter to PsiClass:IndicesOptions\nRationale: The parseParameter() method deals with parsing and updating wildcard states, which aligns closely with the functionality of IndicesOptions that handles various wildcard options. Moving this method here enhances cohesion by grouping related parsing logic together. This aligns with the Single Responsibility Principle, as IndicesOptions can manage its own parsing logic. The main consideration is ensuring that the method doesn\u0027t introduce circular dependencies with other parsing methods in IndicesOptions.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":45,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseParameter to class ActiveShardCount","description":"move method parseParameter to PsiClass:ActiveShardCount\nRationale: The method\u0027s functionality of parsing and updating wildcard states can be relevant in determining active shard counts based on certain criteria. Moving it here could help centralize logic related to shard operations. This supports the Open/Closed Principle by allowing ActiveShardCount to be extended with more parsing logic without modifying the existing codebase. However, care must be taken to ensure that the method is not tightly coupled with shard count logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":45,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseParameter to class AutoCreateIndex","description":"move method parseParameter to PsiClass:AutoCreateIndex\nRationale: The parseParameter() method could be relevant for determining whether to auto-create indices based on wildcard states. This aligns with the method\u0027s intent of interpreting string values into meaningful states. This move supports the Interface Segregation Principle by allowing AutoCreateIndex to handle its own configuration parsing. A potential drawback is that the method might not be directly related to auto-creation logic, which could dilute the class\u0027s focus.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":61,"lineEnd":73,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toXContent to class IndicesOptions","description":"move method toXContent to PsiClass:IndicesOptions\nRationale: The toXContent method deals with the representation of wildcard states, which directly relates to the options and configurations of indices. Moving it to IndicesOptions adheres to the Single Responsibility Principle, as this class manages various options related to indices, including wildcard expansion. This enhances cohesion by keeping related functionalities together. However, care must be taken to ensure that existing functionalities relying on the current class are not adversely affected.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":61,"lineEnd":73,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toXContent to class ShardInfo","description":"move method toXContent to PsiClass:ShardInfo\nRationale: ShardInfo contains methods related to shard management and representation, making it a suitable candidate for the toXContent method, which deals with the serialization of wildcard states. This move aligns with the Open/Closed Principle, as it allows for extending the functionality of ShardInfo without modifying its existing code. The drawback might be that it could add complexity to ShardInfo if not properly managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":61,"lineEnd":73,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toXContent to class DefaultShardOperationFailedException","description":"move method toXContent to PsiClass:DefaultShardOperationFailedException\nRationale: This class deals with exceptions related to shard operations, and the toXContent method could be relevant for providing detailed error information when dealing with wildcard states in shard operations. This move supports the Interface Segregation Principle by keeping exception-related serialization methods together. However, it may dilute the focus of the class if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"parseParameter","method_signature":"public static parseParameter(Object value, EnumSet\u003cWildcardStates\u003e defaultStates)","target_class":"","rationale":""},{"method_name":"toXContent","method_signature":"public static toXContent(EnumSet\u003cWildcardStates\u003e states, XContentBuilder builder)","target_class":"","rationale":""},{"method_name":"updateSetForValue","method_signature":"private static updateSetForValue(EnumSet\u003cWildcardStates\u003e states, String wildcard)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"updateSetForValue","method_signature":"private static updateSetForValue(EnumSet\u003cWildcardStates\u003e states, String wildcard)","target_class":"","rationale":""},{"method_name":"parseParameter","method_signature":"public static parseParameter(Object value, EnumSet\u003cWildcardStates\u003e defaultStates)","target_class":"","rationale":""},{"method_name":"toXContent","method_signature":"public static toXContent(EnumSet\u003cWildcardStates\u003e states, XContentBuilder builder)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static updateSetForValue(EnumSet\u003cWildcardStates\u003e states, String wildcard)":{"first":{"method_name":"updateSetForValue","method_signature":"private static updateSetForValue(EnumSet\u003cWildcardStates\u003e states, String wildcard)","target_class":"","rationale":""},"second":0.23991791958057612},"public static parseParameter(Object value, EnumSet\u003cWildcardStates\u003e defaultStates)":{"first":{"method_name":"parseParameter","method_signature":"public static parseParameter(Object value, EnumSet\u003cWildcardStates\u003e defaultStates)","target_class":"","rationale":""},"second":0.3425348203764015},"public static toXContent(EnumSet\u003cWildcardStates\u003e states, XContentBuilder builder)":{"first":{"method_name":"toXContent","method_signature":"public static toXContent(EnumSet\u003cWildcardStates\u003e states, XContentBuilder builder)","target_class":"","rationale":""},"second":0.45049308035087005}},"llmMethodPriority":{"priority_method_names":["updateSetForValue","parseParameter","toXContent"],"llm_response_time":2794},"targetClassMap":{"updateSetForValue":{"target_classes":[{"class_name":"IndicesOptions","similarity_score":0.29593232617744253},{"class_name":"ClusterStateCreationUtils","similarity_score":0.14594554939641632},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.10647942749999},{"class_name":"ActionTestUtils","similarity_score":0.22772163458297687},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.20163700371364957},{"class_name":"SynonymsTestUtils","similarity_score":0.306697048856629},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.24619462704662917},{"class_name":"AutoCreateIndex","similarity_score":0.3102266937317925},{"class_name":"AutoCreateIndexTests","similarity_score":0.2120583375519657},{"class_name":"DestructiveOperations","similarity_score":0.23147798561230234},{"class_name":"BaseBroadcastResponse","similarity_score":0.23210466755036113},{"class_name":"ListenerTimeouts","similarity_score":0.1762225474415803},{"class_name":"BroadcastReplicationTests","similarity_score":0.24626307984064164},{"class_name":"TransportActions","similarity_score":0.10127393670836667},{"class_name":"TransportBroadcastByNodeActionTests","similarity_score":0.3026531113049311},{"class_name":"TransportBroadcastUnpromotableActionTests","similarity_score":0.2997789444767578},{"class_name":"ContextPreservingActionListener","similarity_score":0.19245990836153543},{"class_name":"CancellableActionTestPlugin","similarity_score":0.20166786401191858},{"class_name":"CancellableFanOutTests","similarity_score":0.28749773282718116},{"class_name":"TransportInstanceSingleOperationActionTests","similarity_score":0.24155414020918817},{"class_name":"TransportMasterNodeActionTests","similarity_score":0.23281380082106665},{"class_name":"TransportNodesActionTests","similarity_score":0.3014276300768432},{"class_name":"TransportReplicationActionTests","similarity_score":0.20434579835446984},{"class_name":"TransportReplicationAllPermitsAcquisitionTests","similarity_score":0.25404308039082624},{"class_name":"TransportWriteActionTests","similarity_score":0.3050998985867022},{"class_name":"ShardInfo","similarity_score":0.24787338230153524},{"class_name":"ShardsAcknowledgedResponse","similarity_score":0.2449835892177906},{"class_name":"Failure","similarity_score":0.2057248372301065},{"class_name":"AcknowledgedResponse","similarity_score":0.226156518891634},{"class_name":"ActiveShardCount","similarity_score":0.2573251323347826}],"target_classes_sorted_by_llm":["IndicesOptions","ActiveShardCount","AutoCreateIndex","TransportWriteActionTests","TransportBroadcastByNodeActionTests","TransportNodesActionTests","CancellableFanOutTests","SynonymsTestUtils","TransportReplicationAllPermitsAcquisitionTests","TransportBroadcastUnpromotableActionTests"],"llm_response_time":11460,"similarity_computation_time":51,"similarity_metric":"voyage"},"parseParameter":{"target_classes":[{"class_name":"IndicesOptions","similarity_score":0.5027273130153712},{"class_name":"ClusterStateCreationUtils","similarity_score":0.44664830882777234},{"class_name":"ActionTestUtils","similarity_score":0.31856371911637227},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.19446111706564934},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.4373795672371632},{"class_name":"SynonymsTestUtils","similarity_score":0.39096297767291655},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.41094302790706944},{"class_name":"DestructiveOperations","similarity_score":0.44986770542121873},{"class_name":"Failure","similarity_score":0.4374218703768198},{"class_name":"AcknowledgedResponse","similarity_score":0.48672961815836385},{"class_name":"ActiveShardCount","similarity_score":0.5671041321058917},{"class_name":"ActiveShardCountTests","similarity_score":0.3570014244385253},{"class_name":"AutoCreateIndex","similarity_score":0.49690613166544456},{"class_name":"AutoCreateIndexTests","similarity_score":0.35547222833706255},{"class_name":"ListenerTimeouts","similarity_score":0.3349582375746721},{"class_name":"BaseBroadcastResponse","similarity_score":0.45337950127571175},{"class_name":"DefaultShardOperationFailedException","similarity_score":0.40624034053677355},{"class_name":"DefaultShardOperationFailedExceptionTests","similarity_score":0.3458420086007247},{"class_name":"BroadcastReplicationTests","similarity_score":0.39375583138017406},{"class_name":"ContextPreservingActionListener","similarity_score":0.4556292782687328},{"class_name":"CancellableActionTestPlugin","similarity_score":0.46977262383217167},{"class_name":"CancellableFanOutTests","similarity_score":0.36856769210913093},{"class_name":"TransportInstanceSingleOperationActionTests","similarity_score":0.4111683876529843},{"class_name":"TransportMasterNodeActionTests","similarity_score":0.4492935017903124},{"class_name":"TransportNodesActionTests","similarity_score":0.4809782352280332},{"class_name":"TransportReplicationActionTests","similarity_score":0.39280058969560094},{"class_name":"TransportReplicationAllPermitsAcquisitionTests","similarity_score":0.4923562441627842},{"class_name":"TransportWriteActionTests","similarity_score":0.41604077399387507},{"class_name":"TransportActions","similarity_score":0.24220224257629233},{"class_name":"TransportBroadcastByNodeActionTests","similarity_score":0.5134807202143206}],"target_classes_sorted_by_llm":["IndicesOptions","ActiveShardCount","AutoCreateIndex","BaseBroadcastResponse","AcknowledgedResponse","ContextPreservingActionListener","TransportBroadcastByNodeActionTests","TransportReplicationAllPermitsAcquisitionTests","CancellableActionTestPlugin","TransportNodesActionTests"],"llm_response_time":10097,"similarity_computation_time":10,"similarity_metric":"voyage"},"toXContent":{"target_classes":[{"class_name":"IndicesOptions","similarity_score":0.5611068653396709},{"class_name":"ClusterStateCreationUtils","similarity_score":0.3283895790103677},{"class_name":"ActionTestUtils","similarity_score":0.4621696076860276},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.26659558398736394},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.5309569630519783},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.5965205029898792},{"class_name":"SynonymsTestUtils","similarity_score":0.5709922738342834},{"class_name":"DestructiveOperations","similarity_score":0.5264999134364735},{"class_name":"AutoCreateIndex","similarity_score":0.5627648955067187},{"class_name":"AutoCreateIndexTests","similarity_score":0.2832253324971483},{"class_name":"BaseBroadcastResponse","similarity_score":0.48879848331255643},{"class_name":"ContextPreservingActionListener","similarity_score":0.4599643075055982},{"class_name":"AcknowledgedResponse","similarity_score":0.5147586691119289},{"class_name":"ActiveShardCount","similarity_score":0.48980536327222446},{"class_name":"ActiveShardCountTests","similarity_score":0.33071449088405036},{"class_name":"BroadcastReplicationTests","similarity_score":0.47615155119548785},{"class_name":"ListenerTimeouts","similarity_score":0.31275888386131745},{"class_name":"DefaultShardOperationFailedException","similarity_score":0.5853897955808843},{"class_name":"DefaultShardOperationFailedExceptionTests","similarity_score":0.4301312156569067},{"class_name":"ShardInfo","similarity_score":0.6024108374886862},{"class_name":"ShardsAcknowledgedResponse","similarity_score":0.6058922584149998},{"class_name":"CancellableActionTestPlugin","similarity_score":0.36323441009308316},{"class_name":"CancellableFanOutTests","similarity_score":0.5132264128991828},{"class_name":"Failure","similarity_score":0.5307554730489372},{"class_name":"ReplicationResponseTests","similarity_score":0.47095451919965126},{"class_name":"PlainActionFuture","similarity_score":0.3774423474100063},{"class_name":"PlainActionFutureTests","similarity_score":0.544823576104809},{"class_name":"SubscribableListener","similarity_score":0.3342631138571071},{"class_name":"SubscribableListenerTests","similarity_score":0.41139870644005483},{"class_name":"PostWriteRefresh","similarity_score":0.5764467913747062}],"target_classes_sorted_by_llm":["IndicesOptions","ShardInfo","DefaultShardOperationFailedException","ShardsAcknowledgedResponse","PostWriteRefresh","AutoCreateIndex","PlainActionFutureTests","ShardMultiGetFromTranslogUtil","PrevalidateShardPathRequestSerializationTestUtils","SynonymsTestUtils"],"llm_response_time":14069,"similarity_computation_time":16,"similarity_metric":"voyage"}}}
{"id":"7e9ad678-9ea3-43d4-9614-6c3cfc856e41","methodCount":16,"hostFunctionTelemetryData":{"hostFunctionSize":163,"lineStart":27,"lineEnd":189,"bodyLineStart":27,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/modules/transport-netty4/src/main/java/org/elasticsearch/transport/netty4/Netty4TcpChannel.java","sourceCode":"public class Netty4TcpChannel implements TcpChannel {\n\n    private final Channel channel;\n    private final boolean isServer;\n    private final String profile;\n    private final ListenableFuture\u003cVoid\u003e connectContext;\n    private final ListenableFuture\u003cVoid\u003e closeContext \u003d new ListenableFuture\u003c\u003e();\n    private final ChannelStats stats \u003d new ChannelStats();\n    private final boolean rstOnClose;\n\n    Netty4TcpChannel(Channel channel, boolean isServer, String profile, boolean rstOnClose, ChannelFuture connectFuture) {\n        this.channel \u003d channel;\n        this.isServer \u003d isServer;\n        this.profile \u003d profile;\n        this.connectContext \u003d new ListenableFuture\u003c\u003e();\n        this.rstOnClose \u003d rstOnClose;\n        addListener(this.channel.closeFuture(), closeContext);\n        addListener(connectFuture, connectContext);\n    }\n\n    /**\n     * Adds a listener that completes the given {@link ListenableFuture} to the given {@link ChannelFuture}.\n     * @param channelFuture Channel future\n     * @param listener Listener to complete\n     */\n    public static void addListener(ChannelFuture channelFuture, ListenableFuture\u003cVoid\u003e listener) {\n        channelFuture.addListener(f -\u003e {\n            if (f.isSuccess()) {\n                listener.onResponse(null);\n            } else {\n                Throwable cause \u003d f.cause();\n                if (cause instanceof Error) {\n                    ExceptionsHelper.maybeDieOnAnotherThread(cause);\n                    listener.onFailure(new Exception(cause));\n                } else {\n                    listener.onFailure((Exception) cause);\n                }\n            }\n        });\n    }\n\n    /**\n     * Creates a {@link ChannelPromise} for the given {@link Channel} and adds a listener that invokes the given {@link ActionListener}\n     * on its completion.\n     * @param listener lister to invoke\n     * @param channel channel\n     * @return write promise\n     */\n    public static ChannelPromise addPromise(ActionListener\u003cVoid\u003e listener, Channel channel) {\n        ChannelPromise writePromise \u003d channel.newPromise();\n        writePromise.addListener(f -\u003e {\n            if (f.isSuccess()) {\n                listener.onResponse(null);\n            } else {\n                final Throwable cause \u003d f.cause();\n                ExceptionsHelper.maybeDieOnAnotherThread(cause);\n                if (cause instanceof Error) {\n                    listener.onFailure(new Exception(cause));\n                } else {\n                    listener.onFailure((Exception) cause);\n                }\n            }\n        });\n        return writePromise;\n    }\n\n    @Override\n    public void close() {\n        if (rstOnClose) {\n            rstAndClose();\n        } else {\n            channel.close();\n        }\n    }\n\n    private void rstAndClose() {\n        Releasables.close(() -\u003e {\n            if (channel.isOpen()) {\n                try {\n                    channel.config().setOption(ChannelOption.SO_LINGER, 0);\n                } catch (Exception e) {\n                    if (IOUtils.MAC_OS_X) {\n                        // Just ignore on OSX for now, there is no reliably way of determining if the socket is still in a state that\n                        // accepts the setting because it could have already been reset from the other end which quietly does nothing on\n                        // Linux but throws OSX.\n                        // TODO: handle this cleaner?\n                        return;\n                    }\n                    if (channel.isOpen()) {\n                        throw e;\n                    }\n                }\n            }\n        }, channel::close);\n    }\n\n    @Override\n    public boolean isServerChannel() {\n        return isServer;\n    }\n\n    @Override\n    public String getProfile() {\n        return profile;\n    }\n\n    @Override\n    public void addCloseListener(ActionListener\u003cVoid\u003e listener) {\n        closeContext.addListener(listener);\n    }\n\n    @Override\n    public void addConnectListener(ActionListener\u003cVoid\u003e listener) {\n        connectContext.addListener(listener);\n    }\n\n    @Override\n    public ChannelStats getChannelStats() {\n        return stats;\n    }\n\n    @Override\n    public boolean isOpen() {\n        return channel.isOpen();\n    }\n\n    @Override\n    public InetSocketAddress getLocalAddress() {\n        return (InetSocketAddress) channel.localAddress();\n    }\n\n    @Override\n    public InetSocketAddress getRemoteAddress() {\n        return (InetSocketAddress) channel.remoteAddress();\n    }\n\n    @Override\n    public void sendMessage(BytesReference reference, ActionListener\u003cVoid\u003e listener) {\n        // We need to both guard against double resolving the listener and not resolving it in case of event loop shutdown so we need to\n        // use #notifyOnce here until https://github.com/netty/netty/issues/8007 is resolved.\n        var wrapped \u003d ActionListener.notifyOnce(listener);\n        channel.writeAndFlush(reference, addPromise(wrapped, channel));\n        if (channel.eventLoop().isShutdown()) {\n            wrapped.onFailure(new TransportException(\"Cannot send message, event loop is shutting down.\"));\n        }\n    }\n\n    public Channel getNettyChannel() {\n        return channel;\n    }\n\n    @Override\n    public String toString() {\n        return \"Netty4TcpChannel{\"\n            + \"localAddress\u003d\"\n            + getLocalAddress()\n            + \", remoteAddress\u003d\"\n            + channel.remoteAddress()\n            + \", profile\u003d\"\n            + profile\n            + \u0027}\u0027;\n    }\n}","methodCount":16},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":46,"lineEnd":65,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addListener to class Netty4Utils","description":"move method addListener to PsiClass:Netty4Utils\nRationale: The addListener() method interacts directly with Netty\u0027s ChannelFuture, making Netty4Utils a fitting target class as it likely contains utility methods related to Netty\u0027s functionality. Moving this method here adheres to the Single Responsibility Principle by grouping related functionalities, thus improving cohesion. It allows for better organization of Netty-related methods, but care should be taken to ensure that Netty4Utils does not become too bloated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":46,"lineEnd":65,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addListener to class FutureUtils","description":"move method addListener to PsiClass:FutureUtils\nRationale: The method primarily deals with futures and listeners, which aligns with the purpose of FutureUtils. Relocating it here enhances the cohesion of methods that handle future-related operations and adheres to the Open/Closed Principle by allowing FutureUtils to be extended with more future-related functionalities. However, it may require careful documentation to clarify the relationship between this method and other future-related utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":46,"lineEnd":65,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addListener to class Netty4Transport","description":"move method addListener to PsiClass:Netty4Transport\nRationale: Netty4Transport is likely to manage transport-level operations, including futures. Moving addListener() here would centralize Netty-related transport logic, improving the overall organization of the codebase. This move supports the Interface Segregation Principle by keeping transport-related functionalities in one place. However, it should be ensured that this class does not become overly complex as a result.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":67,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addPromise to class Netty4Transport","description":"move method addPromise to PsiClass:Netty4Transport\nRationale: The addPromise() method is closely related to Netty\u0027s channel operations, specifically creating promises for channels. Moving it to Netty4Transport aligns with the functionality of managing Netty channels, adhering to the Single Responsibility Principle by grouping related functionalities. This enhances cohesion and makes the promise handling more accessible within transport operations. However, care must be taken to ensure that the method\u0027s dependencies are properly managed in its new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":67,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addPromise to class Netty4Utils","description":"move method addPromise to PsiClass:Netty4Utils\nRationale: Netty4Utils appears to be a utility class for various Netty-related operations. Moving addPromise() here would consolidate utility methods related to channel operations, improving code organization and readability. This aligns with the Open/Closed Principle, as it allows for future enhancements without modifying existing classes. However, as a utility class, it may grow too large if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":67,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addPromise to class Netty4WriteThrottlingHandler","description":"move method addPromise to PsiClass:Netty4WriteThrottlingHandler\nRationale: Given that addPromise() deals with promises that are likely to be used in writing operations, it makes sense to place it in Netty4WriteThrottlingHandler. This adheres to the Interface Segregation Principle by keeping write-related functionalities together. However, it may introduce dependencies on write throttling logic that could complicate the method\u0027s use in other contexts.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"addListener","method_signature":"public static addListener(ChannelFuture channelFuture, ListenableFuture\u003cVoid\u003e listener)","target_class":"","rationale":""},{"method_name":"addPromise","method_signature":"public static addPromise(ActionListener\u003cVoid\u003e listener, Channel channel)","target_class":"","rationale":""},{"method_name":"rstAndClose","method_signature":"private rstAndClose()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"rstAndClose","method_signature":"private rstAndClose()","target_class":"","rationale":""},{"method_name":"addListener","method_signature":"public static addListener(ChannelFuture channelFuture, ListenableFuture\u003cVoid\u003e listener)","target_class":"","rationale":""},{"method_name":"addPromise","method_signature":"public static addPromise(ActionListener\u003cVoid\u003e listener, Channel channel)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private rstAndClose()":{"first":{"method_name":"rstAndClose","method_signature":"private rstAndClose()","target_class":"","rationale":""},"second":0.5647328402852081},"public static addListener(ChannelFuture channelFuture, ListenableFuture\u003cVoid\u003e listener)":{"first":{"method_name":"addListener","method_signature":"public static addListener(ChannelFuture channelFuture, ListenableFuture\u003cVoid\u003e listener)","target_class":"","rationale":""},"second":0.7246200725594438},"public static addPromise(ActionListener\u003cVoid\u003e listener, Channel channel)":{"first":{"method_name":"addPromise","method_signature":"public static addPromise(ActionListener\u003cVoid\u003e listener, Channel channel)","target_class":"","rationale":""},"second":0.7423753260512046}},"llmMethodPriority":{"priority_method_names":["rstAndClose","addListener","addPromise"],"llm_response_time":950},"targetClassMap":{"rstAndClose":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":467,"similarity_computation_time":0,"similarity_metric":"voyage"},"addListener":{"target_classes":[{"class_name":"Netty4Utils","similarity_score":0.6137055334407135},{"class_name":"NetUtils","similarity_score":0.5877354146194238},{"class_name":"NetUtilsTests","similarity_score":0.5229975846277624},{"class_name":"HttpHeadersAuthenticatorUtils","similarity_score":0.623076586315266},{"class_name":"CopyBytesSocketChannel","similarity_score":0.5752483893087659},{"class_name":"SSLExceptionHelper","similarity_score":0.35699667708065214},{"class_name":"TLSConfig","similarity_score":0.4445843968141257},{"class_name":"Netty4Transport","similarity_score":0.6100244374904507},{"class_name":"Netty4WriteThrottlingHandler","similarity_score":0.6506854631739897},{"class_name":"Netty4WriteThrottlingHandlerTests","similarity_score":0.3360177456741316},{"class_name":"NettyAllocator","similarity_score":0.5898572333754813},{"class_name":"RestResponseUtils","similarity_score":0.5551889247787697},{"class_name":"JwkValidateUtil","similarity_score":0.4726441168546788},{"class_name":"JwkValidateUtilTests","similarity_score":0.5263091764032788},{"class_name":"FunctionTestUtils","similarity_score":0.5177352480033778},{"class_name":"FutureUtils","similarity_score":0.6739095302044064},{"class_name":"DiscoveryNodeUtils","similarity_score":0.4826183901221739},{"class_name":"JwtUtil","similarity_score":0.6104573683315536},{"class_name":"ExceptionUtils","similarity_score":0.5190148908041626},{"class_name":"GceMockUtils","similarity_score":0.5024556023445297},{"class_name":"RestTestUtil","similarity_score":0.5433346698732564},{"class_name":"RestUtils","similarity_score":0.6228103868815272},{"class_name":"RestUtilsTests","similarity_score":0.24671942122737583},{"class_name":"GeneratorUtils","similarity_score":0.6336382456090773},{"class_name":"DiffableTestUtils","similarity_score":0.46331437662054964},{"class_name":"DiffableUtils","similarity_score":0.6246881713186307},{"class_name":"KeyStoreUtil","similarity_score":0.6590576817931775},{"class_name":"ExecutionUtils","similarity_score":0.45333950359163006},{"class_name":"RetentionLeaseUtils","similarity_score":0.4168838171168739}],"target_classes_sorted_by_llm":["Netty4Utils","FutureUtils","Netty4Transport","Netty4WriteThrottlingHandler","RestUtils","GeneratorUtils","HttpHeadersAuthenticatorUtils","KeyStoreUtil","DiffableUtils","JwtUtil"],"llm_response_time":11051,"similarity_computation_time":16,"similarity_metric":"voyage"},"addPromise":{"target_classes":[{"class_name":"Netty4Utils","similarity_score":0.6201685765465498},{"class_name":"NetUtils","similarity_score":0.5690621181387848},{"class_name":"NetUtilsTests","similarity_score":0.4833637894954397},{"class_name":"HttpHeadersAuthenticatorUtils","similarity_score":0.6302460233282714},{"class_name":"SSLExceptionHelper","similarity_score":0.3356507597993868},{"class_name":"TLSConfig","similarity_score":0.4149712502329819},{"class_name":"CopyBytesSocketChannel","similarity_score":0.5572117583666848},{"class_name":"Netty4Transport","similarity_score":0.6017433537628504},{"class_name":"Netty4WriteThrottlingHandler","similarity_score":0.6438644823976739},{"class_name":"Netty4WriteThrottlingHandlerTests","similarity_score":0.3868178225039313},{"class_name":"NettyAllocator","similarity_score":0.5776943352582186},{"class_name":"RestResponseUtils","similarity_score":0.5304463010805757},{"class_name":"RestTestUtil","similarity_score":0.5459266620463925},{"class_name":"FunctionTestUtils","similarity_score":0.4923565456743648},{"class_name":"RestUtils","similarity_score":0.6532168996719934},{"class_name":"RestUtilsTests","similarity_score":0.23903026922416779},{"class_name":"FutureUtils","similarity_score":0.6690176809011624},{"class_name":"JwkValidateUtil","similarity_score":0.4966928264670845},{"class_name":"JwkValidateUtilTests","similarity_score":0.500874178406378},{"class_name":"GceMockUtils","similarity_score":0.4889188476675163},{"class_name":"JwtUtil","similarity_score":0.6199804036334849},{"class_name":"RetentionLeaseUtils","similarity_score":0.4241987828412078},{"class_name":"GeneratorUtils","similarity_score":0.5724240955748344},{"class_name":"SnapshotInfoTestUtils","similarity_score":0.2870968889379319},{"class_name":"CheckedFunctionUtils","similarity_score":0.41824440774002464},{"class_name":"TemplateUtils","similarity_score":0.6028870124127774},{"class_name":"TemplateUtilsTests","similarity_score":0.4962524742246249},{"class_name":"Term","similarity_score":0.3701205848258483},{"class_name":"SnapshotUtils","similarity_score":0.6076890853465298}],"target_classes_sorted_by_llm":["Netty4Transport","Netty4Utils","Netty4WriteThrottlingHandler","FutureUtils","RestUtils","NettyAllocator","HttpHeadersAuthenticatorUtils","JwtUtil","TemplateUtils","SnapshotUtils"],"llm_response_time":13886,"similarity_computation_time":12,"similarity_metric":"voyage"}}}
{"id":"f8e4d05c-0df6-4217-adaa-3d97c4ef0ba5","methodCount":7,"hostFunctionTelemetryData":{"hostFunctionSize":106,"lineStart":42,"lineEnd":147,"bodyLineStart":42,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/rest/action/apikey/RestGrantApiKeyAction.java","sourceCode":"/**\n * Rest action to create an API key on behalf of another user. Loosely mimics the API of\n * {@link org.elasticsearch.xpack.security.rest.action.oauth2.RestGetTokenAction} combined with {@link RestCreateApiKeyAction}\n */\n@ServerlessScope(Scope.INTERNAL)\npublic final class RestGrantApiKeyAction extends ApiKeyBaseRestHandler implements RestRequestFilter {\n\n    private static final ConstructingObjectParser\u003cGrant.ClientAuthentication, Void\u003e CLIENT_AUTHENTICATION_PARSER \u003d\n        new ConstructingObjectParser\u003c\u003e(\"client_authentication\", a -\u003e new Grant.ClientAuthentication((String) a[0], (SecureString) a[1]));\n    static {\n        CLIENT_AUTHENTICATION_PARSER.declareString(ConstructingObjectParser.constructorArg(), new ParseField(\"scheme\"));\n        CLIENT_AUTHENTICATION_PARSER.declareField(\n            ConstructingObjectParser.constructorArg(),\n            RestGrantApiKeyAction::getSecureString,\n            new ParseField(\"value\"),\n            ObjectParser.ValueType.STRING\n        );\n    }\n\n    static final ObjectParser\u003cGrantApiKeyRequest, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\"grant_api_key_request\", GrantApiKeyRequest::new);\n    static {\n        PARSER.declareString((req, str) -\u003e req.getGrant().setType(str), new ParseField(\"grant_type\"));\n        PARSER.declareString((req, str) -\u003e req.getGrant().setUsername(str), new ParseField(\"username\"));\n        PARSER.declareField(\n            (req, secStr) -\u003e req.getGrant().setPassword(secStr),\n            RestGrantApiKeyAction::getSecureString,\n            new ParseField(\"password\"),\n            ObjectParser.ValueType.STRING\n        );\n        PARSER.declareField(\n            (req, secStr) -\u003e req.getGrant().setAccessToken(secStr),\n            RestGrantApiKeyAction::getSecureString,\n            new ParseField(\"access_token\"),\n            ObjectParser.ValueType.STRING\n        );\n        PARSER.declareString((req, str) -\u003e req.getGrant().setRunAsUsername(str), new ParseField(\"run_as\"));\n        PARSER.declareObject(\n            (req, clientAuthentication) -\u003e req.getGrant().setClientAuthentication(clientAuthentication),\n            CLIENT_AUTHENTICATION_PARSER,\n            new ParseField(\"client_authentication\")\n        );\n        PARSER.declareObject(\n            (req, api) -\u003e req.setApiKeyRequest(api),\n            (parser, ignore) -\u003e CreateApiKeyRequestBuilder.parse(parser),\n            new ParseField(\"api_key\")\n        );\n    }\n\n    private static SecureString getSecureString(XContentParser parser) throws IOException {\n        return new SecureString(\n            Arrays.copyOfRange(parser.textCharacters(), parser.textOffset(), parser.textOffset() + parser.textLength())\n        );\n    }\n\n    public RestGrantApiKeyAction(Settings settings, XPackLicenseState licenseState) {\n        super(settings, licenseState);\n    }\n\n    @Override\n    public List\u003cRoute\u003e routes() {\n        return List.of(new Route(POST, \"/_security/api_key/grant\"), new Route(PUT, \"/_security/api_key/grant\"));\n    }\n\n    @Override\n    public String getName() {\n        return \"xpack_security_grant_api_key\";\n    }\n\n    public static GrantApiKeyRequest fromXContent(XContentParser parser) throws IOException {\n        return PARSER.parse(parser, null);\n    }\n\n    @Override\n    protected RestChannelConsumer innerPrepareRequest(final RestRequest request, final NodeClient client) throws IOException {\n        String refresh \u003d request.param(\"refresh\");\n        try (XContentParser parser \u003d request.contentParser()) {\n            final GrantApiKeyRequest grantRequest \u003d fromXContent(parser);\n            if (refresh !\u003d null) {\n                grantRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.parse(refresh));\n            } else {\n                grantRequest.setRefreshPolicy(ApiKeyService.defaultCreateDocRefreshPolicy(settings));\n            }\n            return channel -\u003e client.execute(\n                GrantApiKeyAction.INSTANCE,\n                grantRequest,\n                new RestToXContentListener\u003cCreateApiKeyResponse\u003e(channel).delegateResponse((listener, ex) -\u003e {\n                    RestStatus status \u003d ExceptionsHelper.status(ex);\n                    if (status \u003d\u003d RestStatus.UNAUTHORIZED) {\n                        listener.onFailure(\n                            new ElasticsearchSecurityException(\"Failed to authenticate api key grant\", RestStatus.FORBIDDEN, ex)\n                        );\n                    } else {\n                        listener.onFailure(ex);\n                    }\n                })\n            );\n        }\n    }\n\n    private static final Set\u003cString\u003e FILTERED_FIELDS \u003d Set.of(\"password\", \"access_token\", \"client_authentication.value\");\n\n    @Override\n    public Set\u003cString\u003e getFilteredFields() {\n        return FILTERED_FIELDS;\n    }\n}","methodCount":7},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":109,"lineEnd":111,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestSamlAuthenticateAction","description":"move method fromXContent to PsiClass:RestSamlAuthenticateAction\nRationale: The fromXContent() method is responsible for parsing requests, which aligns well with the RestSamlAuthenticateAction\u0027s functionality of handling authentication requests. Moving it here enhances cohesion by placing parsing logic directly within the context of the action it supports. This adheres to the Single Responsibility Principle, as it centralizes request parsing related to SAML authentication. However, consider the potential need for additional dependencies in this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":109,"lineEnd":111,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestActivateProfileAction","description":"move method fromXContent to PsiClass:RestActivateProfileAction\nRationale: The fromXContent() method is a utility for creating request objects from input parsers, which is relevant for actions like RestActivateProfileAction that handle incoming requests. This relocation improves the organization of request handling logic within the action classes, enhancing maintainability. It follows the Open/Closed Principle by allowing future extensions for different request types without modifying existing implementations. However, it may lead to tighter coupling between the action and parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":109,"lineEnd":111,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class ActionUtils","description":"move method fromXContent to PsiClass:ActionUtils\nRationale: The fromXContent() method serves as a utility for parsing requests, which aligns with the utility nature of ActionUtils. This class is designed for common action-related functionalities, and moving the method here would encapsulate shared parsing logic. This adheres to the DRY principle, reducing code duplication across different actions. However, it may dilute the focus of ActionUtils if it becomes overloaded with diverse utility methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":89,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getSecureString to class SamlUtils","description":"move method getSecureString to PsiClass:SamlUtils\nRationale: The getSecureString() method is responsible for creating a SecureString from text characters, which aligns well with the security aspects of SAML operations. Moving it to SamlUtils adheres to the Single Responsibility Principle, as it centralizes security-related utilities. This enhances cohesion by grouping similar functionalities, making the codebase easier to maintain. However, it should be ensured that the method\u0027s dependencies on XContentParser are adequately managed within SamlUtils.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":89,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getSecureString to class JwtUtil","description":"move method getSecureString to PsiClass:JwtUtil\nRationale: getSecureString() deals with secure string generation, which can be relevant in the context of JWT operations where security is paramount. Relocating it to JwtUtil would enhance the utility of this class in handling security-related tasks. This move also adheres to the Open/Closed Principle by allowing JwtUtil to be extended for secure operations. However, care must be taken to ensure that the method does not introduce unnecessary dependencies on JWT-specific logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":89,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getSecureString to class AuditUtil","description":"move method getSecureString to PsiClass:AuditUtil\nRationale: Since getSecureString() is about creating secure strings, moving it to AuditUtil could enhance the security features related to auditing requests. This aligns with the Single Responsibility Principle, as AuditUtil can handle security-related tasks. However, the potential drawback is that it might lead to an overloading of AuditUtil with responsibilities that are only tangentially related to auditing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"getSecureString","method_signature":"private static getSecureString(XContentParser parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"getSecureString","method_signature":"private static getSecureString(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.419305962865181},"private static getSecureString(XContentParser parser)":{"first":{"method_name":"getSecureString","method_signature":"private static getSecureString(XContentParser parser)","target_class":"","rationale":""},"second":0.4732356815409323}},"llmMethodPriority":{"priority_method_names":["fromXContent","getSecureString"],"llm_response_time":970},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"RestInvalidateApiKeyAction","similarity_score":0.43092978905128787},{"class_name":"JwkValidateUtil","similarity_score":0.3117434455959207},{"class_name":"JwkValidateUtilTests","similarity_score":0.4431333960293278},{"class_name":"LdapTestUtils","similarity_score":0.21160368475757949},{"class_name":"LdapUtils","similarity_score":0.328587429046192},{"class_name":"ActionUtils","similarity_score":0.4775669329409193},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.14864362196288647},{"class_name":"SamlUtils","similarity_score":0.4654479266975149},{"class_name":"CommandUtils","similarity_score":0.21256643739415104},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.2430086349933022},{"class_name":"SecurityTestUtils","similarity_score":0.4057513356003446},{"class_name":"PreAuthorizationUtils","similarity_score":0.2786519913815596},{"class_name":"AuditUtil","similarity_score":0.5034635935616699},{"class_name":"AuthorizationUtils","similarity_score":0.15230064305321395},{"class_name":"ModelLoaderUtils","similarity_score":0.41896092161101767},{"class_name":"CertGenUtils","similarity_score":0.2298096520987102},{"class_name":"CertGenUtilsTests","similarity_score":0.2638702468322713},{"class_name":"SSLEngineUtils","similarity_score":0.3910531815971874},{"class_name":"VectorTileUtils","similarity_score":0.35456789308198466},{"class_name":"Utils","similarity_score":0.29673273237950815},{"class_name":"RestPutPrivilegesAction","similarity_score":0.46028324996028647},{"class_name":"RestSamlAuthenticateAction","similarity_score":0.49568159709660975},{"class_name":"CreateTokenResponseActionListener","similarity_score":0.35544913281861495},{"class_name":"RestActivateProfileAction","similarity_score":0.5148314238732346},{"class_name":"RestAuthenticateActionTests","similarity_score":0.4437321974201278},{"class_name":"RestGetPrivilegesAction","similarity_score":0.45256282220142047},{"class_name":"FunctionTestUtils","similarity_score":0.5246154580968143},{"class_name":"ProcessBuilderUtils","similarity_score":0.4134370962530329},{"class_name":"JwtUtil","similarity_score":0.3790163493744628}],"target_classes_sorted_by_llm":["RestSamlAuthenticateAction","RestActivateProfileAction","ActionUtils","SamlUtils","RestGetPrivilegesAction","RestPutPrivilegesAction","AuditUtil","FunctionTestUtils","RestAuthenticateActionTests","JwkValidateUtilTests"],"llm_response_time":13818,"similarity_computation_time":28,"similarity_metric":"voyage"},"getSecureString":{"target_classes":[{"class_name":"RestInvalidateApiKeyAction","similarity_score":0.4369783524561577},{"class_name":"JwkValidateUtil","similarity_score":0.36693062048808395},{"class_name":"JwkValidateUtilTests","similarity_score":0.33468063504637524},{"class_name":"Utils","similarity_score":0.36342189215581555},{"class_name":"VectorTileUtils","similarity_score":0.3060465279743702},{"class_name":"SamlUtils","similarity_score":0.42512573371857126},{"class_name":"SSLEngineUtils","similarity_score":0.33380693054114957},{"class_name":"ActionUtils","similarity_score":0.35993701653267807},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.16856529042973645},{"class_name":"ModelLoaderUtils","similarity_score":0.4267534669777559},{"class_name":"LdapTestUtils","similarity_score":0.25916052767440806},{"class_name":"LdapUtils","similarity_score":0.31902180923316203},{"class_name":"SecurityTestUtils","similarity_score":0.3220919510516358},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.1533212378788666},{"class_name":"PreAuthorizationUtils","similarity_score":0.2664360189819126},{"class_name":"AuditUtil","similarity_score":0.42575759929200013},{"class_name":"AuthorizationUtils","similarity_score":0.14211766208690654},{"class_name":"CommandUtils","similarity_score":0.21439736214109112},{"class_name":"CertGenUtils","similarity_score":0.2269120314080216},{"class_name":"CertGenUtilsTests","similarity_score":0.2274185518108327},{"class_name":"RestPutPrivilegesAction","similarity_score":0.36369648372665403},{"class_name":"RestSamlAuthenticateAction","similarity_score":0.41146770141247946},{"class_name":"CreateTokenResponseActionListener","similarity_score":0.3149228315669434},{"class_name":"RestActivateProfileAction","similarity_score":0.5641648148599763},{"class_name":"RestAuthenticateActionTests","similarity_score":0.3833090581014337},{"class_name":"RestGetPrivilegesAction","similarity_score":0.3510401971333391},{"class_name":"JwtUtil","similarity_score":0.4007578916270449},{"class_name":"MathUtils","similarity_score":0.19433294466783266},{"class_name":"TemplateUtils","similarity_score":0.2826919836003525}],"target_classes_sorted_by_llm":["SamlUtils","JwtUtil","AuditUtil","ModelLoaderUtils","RestActivateProfileAction","RestInvalidateApiKeyAction","RestSamlAuthenticateAction","RestPutPrivilegesAction","JwkValidateUtil","RestAuthenticateActionTests"],"llm_response_time":15305,"similarity_computation_time":6,"similarity_metric":"voyage"}}}
{"id":"5ffe84af-cdc6-4d88-b5ae-6254a607e719","methodCount":30,"hostFunctionTelemetryData":{"hostFunctionSize":827,"lineStart":63,"lineEnd":889,"bodyLineStart":63,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java","sourceCode":"/**\n * Transport Action for get snapshots operation\n */\npublic class TransportGetSnapshotsAction extends TransportMasterNodeAction\u003cGetSnapshotsRequest, GetSnapshotsResponse\u003e {\n\n    private final RepositoriesService repositoriesService;\n\n    @Inject\n    public TransportGetSnapshotsAction(\n        TransportService transportService,\n        ClusterService clusterService,\n        ThreadPool threadPool,\n        RepositoriesService repositoriesService,\n        ActionFilters actionFilters,\n        IndexNameExpressionResolver indexNameExpressionResolver\n    ) {\n        super(\n            GetSnapshotsAction.NAME,\n            transportService,\n            clusterService,\n            threadPool,\n            actionFilters,\n            GetSnapshotsRequest::new,\n            indexNameExpressionResolver,\n            GetSnapshotsResponse::new,\n            // Execute this on the management pool because creating the response can become fairly expensive\n            // for large repositories in the verbose\u003dfalse case when there are a lot of indices per snapshot.\n            // This is intentionally not using the snapshot_meta pool because that pool is sized rather large\n            // to accommodate concurrent IO and could consume excessive CPU resources through concurrent\n            // verbose\u003dfalse requests that are CPU bound only.\n            threadPool.executor(ThreadPool.Names.MANAGEMENT)\n        );\n        this.repositoriesService \u003d repositoriesService;\n    }\n\n    @Override\n    protected ClusterBlockException checkBlock(GetSnapshotsRequest request, ClusterState state) {\n        return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_READ);\n    }\n\n    @Override\n    protected void masterOperation(\n        Task task,\n        final GetSnapshotsRequest request,\n        final ClusterState state,\n        final ActionListener\u003cGetSnapshotsResponse\u003e listener\n    ) {\n        assert task instanceof CancellableTask : task + \" not cancellable\";\n\n        getMultipleReposSnapshotInfo(\n            request.isSingleRepositoryRequest() \u003d\u003d false,\n            SnapshotsInProgress.get(state),\n            TransportGetRepositoriesAction.getRepositories(state, request.repositories()),\n            request.snapshots(),\n            request.ignoreUnavailable(),\n            request.verbose(),\n            (CancellableTask) task,\n            request.sort(),\n            request.after(),\n            request.offset(),\n            request.size(),\n            request.order(),\n            request.fromSortValue(),\n            SnapshotPredicates.fromRequest(request),\n            request.includeIndexNames(),\n            listener\n        );\n    }\n\n    /**\n     * Filters the list of repositories that a request will fetch snapshots from in the special case of sorting by repository\n     * name and having a non-null value for {@link GetSnapshotsRequest#fromSortValue()} on the request to exclude repositories outside\n     * the sort value range if possible.\n     */\n    private static List\u003cRepositoryMetadata\u003e maybeFilterRepositories(\n        List\u003cRepositoryMetadata\u003e repositories,\n        GetSnapshotsRequest.SortBy sortBy,\n        SortOrder order,\n        @Nullable String fromSortValue\n    ) {\n        if (sortBy !\u003d GetSnapshotsRequest.SortBy.REPOSITORY || fromSortValue \u003d\u003d null) {\n            return repositories;\n        }\n        final Predicate\u003cRepositoryMetadata\u003e predicate \u003d order \u003d\u003d SortOrder.ASC\n            ? repositoryMetadata -\u003e fromSortValue.compareTo(repositoryMetadata.name()) \u003c\u003d 0\n            : repositoryMetadata -\u003e fromSortValue.compareTo(repositoryMetadata.name()) \u003e\u003d 0;\n        return repositories.stream().filter(predicate).toList();\n    }\n\n    private void getMultipleReposSnapshotInfo(\n        boolean isMultiRepoRequest,\n        SnapshotsInProgress snapshotsInProgress,\n        TransportGetRepositoriesAction.RepositoriesResult repositoriesResult,\n        String[] snapshots,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        CancellableTask cancellableTask,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order,\n        String fromSortValue,\n        SnapshotPredicates predicates,\n        boolean indices,\n        ActionListener\u003cGetSnapshotsResponse\u003e listener\n    ) {\n        // Process the missing repositories\n        final Map\u003cString, ElasticsearchException\u003e failures \u003d ConcurrentCollections.newConcurrentMap();\n        for (String missingRepo : repositoriesResult.missing()) {\n            failures.put(missingRepo, new RepositoryMissingException(missingRepo));\n        }\n\n        final Queue\u003cList\u003cSnapshotInfo\u003e\u003e allSnapshotInfos \u003d ConcurrentCollections.newQueue();\n        final var remaining \u003d new AtomicInteger();\n        final var totalCount \u003d new AtomicInteger();\n\n        List\u003cRepositoryMetadata\u003e repositories \u003d maybeFilterRepositories(repositoriesResult.metadata(), sortBy, order, fromSortValue);\n        try (var listeners \u003d new RefCountingListener(listener.map(ignored -\u003e {\n            cancellableTask.ensureNotCancelled();\n            final var sortedSnapshotsInRepos \u003d sortSnapshots(\n                allSnapshotInfos.stream().flatMap(Collection::stream),\n                totalCount.get(),\n                sortBy,\n                after,\n                offset,\n                size,\n                order\n            );\n            final var snapshotInfos \u003d sortedSnapshotsInRepos.snapshotInfos();\n            assert indices || snapshotInfos.stream().allMatch(snapshotInfo -\u003e snapshotInfo.indices().isEmpty());\n            final int finalRemaining \u003d sortedSnapshotsInRepos.remaining() + remaining.get();\n            return new GetSnapshotsResponse(\n                snapshotInfos,\n                failures,\n                finalRemaining \u003e 0\n                    ? GetSnapshotsRequest.After.from(snapshotInfos.get(snapshotInfos.size() - 1), sortBy).asQueryParam()\n                    : null,\n                totalCount.get(),\n                finalRemaining\n            );\n        }))) {\n            for (final RepositoryMetadata repository : repositories) {\n                final String repoName \u003d repository.name();\n                getSingleRepoSnapshotInfo(\n                    snapshotsInProgress,\n                    repoName,\n                    snapshots,\n                    predicates,\n                    ignoreUnavailable,\n                    verbose,\n                    cancellableTask,\n                    sortBy,\n                    after,\n                    order,\n                    indices,\n                    listeners.acquire((SnapshotsInRepo snapshotsInRepo) -\u003e {\n                        allSnapshotInfos.add(snapshotsInRepo.snapshotInfos());\n                        remaining.addAndGet(snapshotsInRepo.remaining());\n                        totalCount.addAndGet(snapshotsInRepo.totalCount());\n                    }).delegateResponse((l, e) -\u003e {\n                        if (isMultiRepoRequest \u0026\u0026 e instanceof ElasticsearchException elasticsearchException) {\n                            failures.put(repoName, elasticsearchException);\n                            l.onResponse(SnapshotsInRepo.EMPTY);\n                        } else {\n                            l.onFailure(e);\n                        }\n                    })\n                );\n            }\n        }\n    }\n\n    private void getSingleRepoSnapshotInfo(\n        SnapshotsInProgress snapshotsInProgress,\n        String repo,\n        String[] snapshots,\n        SnapshotPredicates predicates,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        SortOrder order,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    ) {\n        final Map\u003cString, Snapshot\u003e allSnapshotIds \u003d new HashMap\u003c\u003e();\n        final List\u003cSnapshotInfo\u003e currentSnapshots \u003d new ArrayList\u003c\u003e();\n        for (SnapshotInfo snapshotInfo : currentSnapshots(snapshotsInProgress, repo)) {\n            Snapshot snapshot \u003d snapshotInfo.snapshot();\n            allSnapshotIds.put(snapshot.getSnapshotId().getName(), snapshot);\n            currentSnapshots.add(snapshotInfo.maybeWithoutIndices(indices));\n        }\n\n        final ListenableFuture\u003cRepositoryData\u003e repositoryDataListener \u003d new ListenableFuture\u003c\u003e();\n        if (isCurrentSnapshotsOnly(snapshots)) {\n            repositoryDataListener.onResponse(null);\n        } else {\n            repositoriesService.getRepositoryData(repo, repositoryDataListener);\n        }\n\n        repositoryDataListener.addListener(\n            listener.delegateFailureAndWrap(\n                (l, repositoryData) -\u003e loadSnapshotInfos(\n                    snapshotsInProgress,\n                    repo,\n                    snapshots,\n                    ignoreUnavailable,\n                    verbose,\n                    allSnapshotIds,\n                    currentSnapshots,\n                    repositoryData,\n                    task,\n                    sortBy,\n                    after,\n                    order,\n                    predicates,\n                    indices,\n                    l\n                )\n            )\n        );\n    }\n\n    /**\n     * Returns a list of currently running snapshots from repository sorted by snapshot creation date\n     *\n     * @param snapshotsInProgress snapshots in progress in the cluster state\n     * @param repositoryName repository name\n     * @return list of snapshots\n     */\n    private static List\u003cSnapshotInfo\u003e currentSnapshots(SnapshotsInProgress snapshotsInProgress, String repositoryName) {\n        List\u003cSnapshotInfo\u003e snapshotList \u003d new ArrayList\u003c\u003e();\n        List\u003cSnapshotsInProgress.Entry\u003e entries \u003d SnapshotsService.currentSnapshots(\n            snapshotsInProgress,\n            repositoryName,\n            Collections.emptyList()\n        );\n        for (SnapshotsInProgress.Entry entry : entries) {\n            snapshotList.add(SnapshotInfo.inProgress(entry));\n        }\n        return snapshotList;\n    }\n\n    private void loadSnapshotInfos(\n        SnapshotsInProgress snapshotsInProgress,\n        String repo,\n        String[] snapshots,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        Map\u003cString, Snapshot\u003e allSnapshotIds,\n        List\u003cSnapshotInfo\u003e currentSnapshots,\n        @Nullable RepositoryData repositoryData,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        SortOrder order,\n        SnapshotPredicates predicates,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    ) {\n        if (task.notifyIfCancelled(listener)) {\n            return;\n        }\n\n        if (repositoryData !\u003d null) {\n            for (SnapshotId snapshotId : repositoryData.getSnapshotIds()) {\n                if (predicates.test(snapshotId, repositoryData)) {\n                    allSnapshotIds.put(snapshotId.getName(), new Snapshot(repo, snapshotId));\n                }\n            }\n        }\n\n        final Set\u003cSnapshot\u003e toResolve \u003d new HashSet\u003c\u003e();\n        if (TransportGetRepositoriesAction.isMatchAll(snapshots)) {\n            toResolve.addAll(allSnapshotIds.values());\n        } else {\n            final List\u003cString\u003e includePatterns \u003d new ArrayList\u003c\u003e();\n            final List\u003cString\u003e excludePatterns \u003d new ArrayList\u003c\u003e();\n            boolean hasCurrent \u003d false;\n            boolean seenWildcard \u003d false;\n            for (String snapshotOrPattern : snapshots) {\n                if (seenWildcard \u0026\u0026 snapshotOrPattern.length() \u003e 1 \u0026\u0026 snapshotOrPattern.startsWith(\"-\")) {\n                    excludePatterns.add(snapshotOrPattern.substring(1));\n                } else {\n                    if (Regex.isSimpleMatchPattern(snapshotOrPattern)) {\n                        seenWildcard \u003d true;\n                        includePatterns.add(snapshotOrPattern);\n                    } else if (GetSnapshotsRequest.CURRENT_SNAPSHOT.equalsIgnoreCase(snapshotOrPattern)) {\n                        hasCurrent \u003d true;\n                        seenWildcard \u003d true;\n                    } else {\n                        if (ignoreUnavailable \u003d\u003d false \u0026\u0026 allSnapshotIds.containsKey(snapshotOrPattern) \u003d\u003d false) {\n                            throw new SnapshotMissingException(repo, snapshotOrPattern);\n                        }\n                        includePatterns.add(snapshotOrPattern);\n                    }\n                }\n            }\n            final String[] includes \u003d includePatterns.toArray(Strings.EMPTY_ARRAY);\n            final String[] excludes \u003d excludePatterns.toArray(Strings.EMPTY_ARRAY);\n            for (Map.Entry\u003cString, Snapshot\u003e entry : allSnapshotIds.entrySet()) {\n                final Snapshot snapshot \u003d entry.getValue();\n                if (toResolve.contains(snapshot) \u003d\u003d false\n                    \u0026\u0026 Regex.simpleMatch(includes, entry.getKey())\n                    \u0026\u0026 Regex.simpleMatch(excludes, entry.getKey()) \u003d\u003d false) {\n                    toResolve.add(snapshot);\n                }\n            }\n            if (hasCurrent) {\n                for (SnapshotInfo snapshotInfo : currentSnapshots) {\n                    final Snapshot snapshot \u003d snapshotInfo.snapshot();\n                    if (Regex.simpleMatch(excludes, snapshot.getSnapshotId().getName()) \u003d\u003d false) {\n                        toResolve.add(snapshot);\n                    }\n                }\n            }\n            if (toResolve.isEmpty() \u0026\u0026 ignoreUnavailable \u003d\u003d false \u0026\u0026 isCurrentSnapshotsOnly(snapshots) \u003d\u003d false) {\n                throw new SnapshotMissingException(repo, snapshots[0]);\n            }\n        }\n\n        if (verbose) {\n            snapshots(\n                snapshotsInProgress,\n                repo,\n                toResolve.stream().map(Snapshot::getSnapshotId).toList(),\n                ignoreUnavailable,\n                task,\n                sortBy,\n                after,\n                order,\n                predicates,\n                indices,\n                listener\n            );\n        } else {\n            assert predicates.isMatchAll() : \"filtering is not supported in non-verbose mode\";\n            final SnapshotsInRepo snapshotInfos;\n            if (repositoryData !\u003d null) {\n                // want non-current snapshots as well, which are found in the repository data\n                snapshotInfos \u003d buildSimpleSnapshotInfos(toResolve, repo, repositoryData, currentSnapshots, sortBy, after, order, indices);\n            } else {\n                // only want current snapshots\n                snapshotInfos \u003d sortSnapshots(\n                    currentSnapshots.stream().map(SnapshotInfo::basic).toList(),\n                    sortBy,\n                    after,\n                    0,\n                    GetSnapshotsRequest.NO_LIMIT,\n                    order\n                );\n            }\n            listener.onResponse(snapshotInfos);\n        }\n    }\n\n    /**\n     * Returns a list of snapshots from repository sorted by snapshot creation date\n     *\n     * @param snapshotsInProgress snapshots in progress in the cluster state\n     * @param repositoryName      repository name\n     * @param snapshotIds         snapshots for which to fetch snapshot information\n     * @param ignoreUnavailable   if true, snapshots that could not be read will only be logged with a warning,\n     * @param indices             if false, drop the list of indices from each result\n     */\n    private void snapshots(\n        SnapshotsInProgress snapshotsInProgress,\n        String repositoryName,\n        Collection\u003cSnapshotId\u003e snapshotIds,\n        boolean ignoreUnavailable,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        SortOrder order,\n        SnapshotPredicates predicate,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    ) {\n        if (task.notifyIfCancelled(listener)) {\n            return;\n        }\n        final Set\u003cSnapshotInfo\u003e snapshotSet \u003d new HashSet\u003c\u003e();\n        final Set\u003cSnapshotId\u003e snapshotIdsToIterate \u003d new HashSet\u003c\u003e(snapshotIds);\n        // first, look at the snapshots in progress\n        final List\u003cSnapshotsInProgress.Entry\u003e entries \u003d SnapshotsService.currentSnapshots(\n            snapshotsInProgress,\n            repositoryName,\n            snapshotIdsToIterate.stream().map(SnapshotId::getName).toList()\n        );\n        for (SnapshotsInProgress.Entry entry : entries) {\n            if (snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId())) {\n                final SnapshotInfo snapshotInfo \u003d SnapshotInfo.inProgress(entry);\n                if (predicate.test(snapshotInfo)) {\n                    snapshotSet.add(snapshotInfo.maybeWithoutIndices(indices));\n                }\n            }\n        }\n        // then, look in the repository if there\u0027s any matching snapshots left\n        final List\u003cSnapshotInfo\u003e snapshotInfos;\n        if (snapshotIdsToIterate.isEmpty()) {\n            snapshotInfos \u003d Collections.emptyList();\n        } else {\n            snapshotInfos \u003d Collections.synchronizedList(new ArrayList\u003c\u003e());\n        }\n        final ActionListener\u003cVoid\u003e allDoneListener \u003d listener.safeMap(v -\u003e {\n            final ArrayList\u003cSnapshotInfo\u003e snapshotList \u003d new ArrayList\u003c\u003e(snapshotInfos);\n            snapshotList.addAll(snapshotSet);\n            return sortSnapshots(snapshotList, sortBy, after, 0, GetSnapshotsRequest.NO_LIMIT, order);\n        });\n        if (snapshotIdsToIterate.isEmpty()) {\n            allDoneListener.onResponse(null);\n            return;\n        }\n        final Repository repository;\n        try {\n            repository \u003d repositoriesService.repository(repositoryName);\n        } catch (RepositoryMissingException e) {\n            listener.onFailure(e);\n            return;\n        }\n        repository.getSnapshotInfo(\n            new GetSnapshotInfoContext(snapshotIdsToIterate, ignoreUnavailable \u003d\u003d false, task::isCancelled, (context, snapshotInfo) -\u003e {\n                if (predicate.test(snapshotInfo)) {\n                    snapshotInfos.add(snapshotInfo.maybeWithoutIndices(indices));\n                }\n            }, allDoneListener)\n        );\n    }\n\n    private static boolean isCurrentSnapshotsOnly(String[] snapshots) {\n        return (snapshots.length \u003d\u003d 1 \u0026\u0026 GetSnapshotsRequest.CURRENT_SNAPSHOT.equalsIgnoreCase(snapshots[0]));\n    }\n\n    private static SnapshotsInRepo buildSimpleSnapshotInfos(\n        final Set\u003cSnapshot\u003e toResolve,\n        final String repoName,\n        final RepositoryData repositoryData,\n        final List\u003cSnapshotInfo\u003e currentSnapshots,\n        final GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        final SortOrder order,\n        boolean indices\n    ) {\n        List\u003cSnapshotInfo\u003e snapshotInfos \u003d new ArrayList\u003c\u003e();\n        for (SnapshotInfo snapshotInfo : currentSnapshots) {\n            if (toResolve.remove(snapshotInfo.snapshot())) {\n                snapshotInfos.add(snapshotInfo.basic());\n            }\n        }\n        Map\u003cSnapshotId, List\u003cString\u003e\u003e snapshotsToIndices \u003d new HashMap\u003c\u003e();\n        if (indices) {\n            for (IndexId indexId : repositoryData.getIndices().values()) {\n                for (SnapshotId snapshotId : repositoryData.getSnapshots(indexId)) {\n                    if (toResolve.contains(new Snapshot(repoName, snapshotId))) {\n                        snapshotsToIndices.computeIfAbsent(snapshotId, (k) -\u003e new ArrayList\u003c\u003e()).add(indexId.getName());\n                    }\n                }\n            }\n        }\n        for (Snapshot snapshot : toResolve) {\n            snapshotInfos.add(\n                new SnapshotInfo(\n                    snapshot,\n                    snapshotsToIndices.getOrDefault(snapshot.getSnapshotId(), Collections.emptyList()),\n                    Collections.emptyList(),\n                    Collections.emptyList(),\n                    repositoryData.getSnapshotState(snapshot.getSnapshotId())\n                )\n            );\n        }\n        return sortSnapshots(snapshotInfos, sortBy, after, 0, GetSnapshotsRequest.NO_LIMIT, order);\n    }\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_START_TIME \u003d Comparator.comparingLong(SnapshotInfo::startTime)\n        .thenComparing(SnapshotInfo::snapshotId);\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_DURATION \u003d Comparator.\u003cSnapshotInfo\u003ecomparingLong(\n        sni -\u003e sni.endTime() - sni.startTime()\n    ).thenComparing(SnapshotInfo::snapshotId);\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_INDICES_COUNT \u003d Comparator.\u003cSnapshotInfo\u003ecomparingInt(sni -\u003e sni.indices().size())\n        .thenComparing(SnapshotInfo::snapshotId);\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_SHARDS_COUNT \u003d Comparator.comparingInt(SnapshotInfo::totalShards)\n        .thenComparing(SnapshotInfo::snapshotId);\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_FAILED_SHARDS_COUNT \u003d Comparator.comparingInt(SnapshotInfo::failedShards)\n        .thenComparing(SnapshotInfo::snapshotId);\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_NAME \u003d Comparator.comparing(sni -\u003e sni.snapshotId().getName());\n\n    private static final Comparator\u003cSnapshotInfo\u003e BY_REPOSITORY \u003d Comparator.comparing(SnapshotInfo::repository)\n        .thenComparing(SnapshotInfo::snapshotId);\n\n    private static long getDuration(SnapshotId snapshotId, RepositoryData repositoryData) {\n        final RepositoryData.SnapshotDetails details \u003d repositoryData.getSnapshotDetails(snapshotId);\n        if (details \u003d\u003d null) {\n            return -1;\n        }\n        final long startTime \u003d details.getStartTimeMillis();\n        if (startTime \u003d\u003d -1) {\n            return -1;\n        }\n        final long endTime \u003d details.getEndTimeMillis();\n        if (endTime \u003d\u003d -1) {\n            return -1;\n        }\n        return endTime - startTime;\n    }\n\n    private static long getStartTime(SnapshotId snapshotId, RepositoryData repositoryData) {\n        final RepositoryData.SnapshotDetails details \u003d repositoryData.getSnapshotDetails(snapshotId);\n        return details \u003d\u003d null ? -1 : details.getStartTimeMillis();\n    }\n\n    private static int indexCount(SnapshotId snapshotId, RepositoryData repositoryData) {\n        // TODO: this could be made more efficient by caching this number in RepositoryData\n        int indexCount \u003d 0;\n        for (IndexId idx : repositoryData.getIndices().values()) {\n            if (repositoryData.getSnapshots(idx).contains(snapshotId)) {\n                indexCount++;\n            }\n        }\n        return indexCount;\n    }\n\n    private static SnapshotsInRepo sortSnapshots(\n        List\u003cSnapshotInfo\u003e snapshotInfos,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    ) {\n        return sortSnapshots(snapshotInfos.stream(), snapshotInfos.size(), sortBy, after, offset, size, order);\n    }\n\n    private static SnapshotsInRepo sortSnapshots(\n        Stream\u003cSnapshotInfo\u003e infos,\n        int totalCount,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    ) {\n        final Comparator\u003cSnapshotInfo\u003e comparator \u003d switch (sortBy) {\n            case START_TIME -\u003e BY_START_TIME;\n            case NAME -\u003e BY_NAME;\n            case DURATION -\u003e BY_DURATION;\n            case INDICES -\u003e BY_INDICES_COUNT;\n            case SHARDS -\u003e BY_SHARDS_COUNT;\n            case FAILED_SHARDS -\u003e BY_FAILED_SHARDS_COUNT;\n            case REPOSITORY -\u003e BY_REPOSITORY;\n        };\n\n        if (after !\u003d null) {\n            assert offset \u003d\u003d 0 : \"can\u0027t combine after and offset but saw [\" + after + \"] and offset [\" + offset + \"]\";\n            infos \u003d infos.filter(buildAfterPredicate(sortBy, after, order));\n        }\n        infos \u003d infos.sorted(order \u003d\u003d SortOrder.DESC ? comparator.reversed() : comparator).skip(offset);\n        final List\u003cSnapshotInfo\u003e allSnapshots \u003d infos.toList();\n        final List\u003cSnapshotInfo\u003e snapshots;\n        if (size !\u003d GetSnapshotsRequest.NO_LIMIT) {\n            snapshots \u003d allSnapshots.stream().limit(size + 1).toList();\n        } else {\n            snapshots \u003d allSnapshots;\n        }\n        final List\u003cSnapshotInfo\u003e resultSet \u003d size !\u003d GetSnapshotsRequest.NO_LIMIT \u0026\u0026 size \u003c snapshots.size()\n            ? snapshots.subList(0, size)\n            : snapshots;\n        return new SnapshotsInRepo(resultSet, totalCount, allSnapshots.size() - resultSet.size());\n    }\n\n    private static Predicate\u003cSnapshotInfo\u003e buildAfterPredicate(\n        GetSnapshotsRequest.SortBy sortBy,\n        GetSnapshotsRequest.After after,\n        SortOrder order\n    ) {\n        final String snapshotName \u003d after.snapshotName();\n        final String repoName \u003d after.repoName();\n        final String value \u003d after.value();\n        return switch (sortBy) {\n            case START_TIME -\u003e filterByLongOffset(SnapshotInfo::startTime, Long.parseLong(value), snapshotName, repoName, order);\n            case NAME -\u003e\n                // TODO: cover via pre-flight predicate\n                order \u003d\u003d SortOrder.ASC\n                    ? (info -\u003e compareName(snapshotName, repoName, info) \u003c 0)\n                    : (info -\u003e compareName(snapshotName, repoName, info) \u003e 0);\n            case DURATION -\u003e filterByLongOffset(\n                info -\u003e info.endTime() - info.startTime(),\n                Long.parseLong(value),\n                snapshotName,\n                repoName,\n                order\n            );\n            case INDICES -\u003e\n                // TODO: cover via pre-flight predicate\n                filterByLongOffset(info -\u003e info.indices().size(), Integer.parseInt(value), snapshotName, repoName, order);\n            case SHARDS -\u003e filterByLongOffset(SnapshotInfo::totalShards, Integer.parseInt(value), snapshotName, repoName, order);\n            case FAILED_SHARDS -\u003e filterByLongOffset(SnapshotInfo::failedShards, Integer.parseInt(value), snapshotName, repoName, order);\n            case REPOSITORY -\u003e\n                // TODO: cover via pre-flight predicate\n                order \u003d\u003d SortOrder.ASC\n                    ? (info -\u003e compareRepositoryName(snapshotName, repoName, info) \u003c 0)\n                    : (info -\u003e compareRepositoryName(snapshotName, repoName, info) \u003e 0);\n        };\n    }\n\n    private static Predicate\u003cSnapshotInfo\u003e filterByLongOffset(\n        ToLongFunction\u003cSnapshotInfo\u003e extractor,\n        long after,\n        String snapshotName,\n        String repoName,\n        SortOrder order\n    ) {\n        return order \u003d\u003d SortOrder.ASC ? info -\u003e {\n            final long val \u003d extractor.applyAsLong(info);\n            return after \u003c val || (after \u003d\u003d val \u0026\u0026 compareName(snapshotName, repoName, info) \u003c 0);\n        } : info -\u003e {\n            final long val \u003d extractor.applyAsLong(info);\n            return after \u003e val || (after \u003d\u003d val \u0026\u0026 compareName(snapshotName, repoName, info) \u003e 0);\n        };\n    }\n\n    private static int compareRepositoryName(String name, String repoName, SnapshotInfo info) {\n        final int res \u003d repoName.compareTo(info.repository());\n        if (res !\u003d 0) {\n            return res;\n        }\n        return name.compareTo(info.snapshotId().getName());\n    }\n\n    private static int compareName(String name, String repoName, SnapshotInfo info) {\n        final int res \u003d name.compareTo(info.snapshotId().getName());\n        if (res !\u003d 0) {\n            return res;\n        }\n        return repoName.compareTo(info.repository());\n    }\n\n    /**\n     * A pair of predicates for the get snapshots action. The {@link #test(SnapshotId, RepositoryData)} predicate is applied to combinations\n     * of snapshot id and repository data to determine which snapshots to fully load from the repository and rules out all snapshots that do\n     * not match the given {@link GetSnapshotsRequest} that can be ruled out through the information in {@link RepositoryData}.\n     * The predicate returned by {@link #test(SnapshotInfo)} predicate is then applied the instances of {@link SnapshotInfo} that were\n     * loaded from the repository to filter out those remaining that did not match the request but could not be ruled out without loading\n     * their {@link SnapshotInfo}.\n     */\n    private static final class SnapshotPredicates {\n\n        private static final SnapshotPredicates MATCH_ALL \u003d new SnapshotPredicates(null, null);\n\n        @Nullable // if all snapshot IDs match\n        private final BiPredicate\u003cSnapshotId, RepositoryData\u003e preflightPredicate;\n\n        @Nullable // if all snapshots match\n        private final Predicate\u003cSnapshotInfo\u003e snapshotPredicate;\n\n        private SnapshotPredicates(\n            @Nullable BiPredicate\u003cSnapshotId, RepositoryData\u003e preflightPredicate,\n            @Nullable Predicate\u003cSnapshotInfo\u003e snapshotPredicate\n        ) {\n            this.snapshotPredicate \u003d snapshotPredicate;\n            this.preflightPredicate \u003d preflightPredicate;\n        }\n\n        boolean test(SnapshotId snapshotId, RepositoryData repositoryData) {\n            return preflightPredicate \u003d\u003d null || preflightPredicate.test(snapshotId, repositoryData);\n        }\n\n        boolean isMatchAll() {\n            return snapshotPredicate \u003d\u003d null;\n        }\n\n        boolean test(SnapshotInfo snapshotInfo) {\n            return snapshotPredicate \u003d\u003d null || snapshotPredicate.test(snapshotInfo);\n        }\n\n        private SnapshotPredicates and(SnapshotPredicates other) {\n            return this \u003d\u003d MATCH_ALL ? other\n                : other \u003d\u003d MATCH_ALL ? this\n                : new SnapshotPredicates(\n                    preflightPredicate \u003d\u003d null ? other.preflightPredicate : other.preflightPredicate \u003d\u003d null ? preflightPredicate : null,\n                    snapshotPredicate \u003d\u003d null ? other.snapshotPredicate : other.snapshotPredicate \u003d\u003d null ? snapshotPredicate : null\n                );\n        }\n\n        static SnapshotPredicates fromRequest(GetSnapshotsRequest request) {\n            return getSortValuePredicate(request.fromSortValue(), request.sort(), request.order()).and(\n                getSlmPredicates(request.policies())\n            );\n        }\n\n        private static SnapshotPredicates getSlmPredicates(String[] slmPolicies) {\n            if (slmPolicies.length \u003d\u003d 0) {\n                return MATCH_ALL;\n            }\n\n            final List\u003cString\u003e includePatterns \u003d new ArrayList\u003c\u003e();\n            final List\u003cString\u003e excludePatterns \u003d new ArrayList\u003c\u003e();\n            boolean seenWildcard \u003d false;\n            boolean matchNoPolicy \u003d false;\n            for (String slmPolicy : slmPolicies) {\n                if (seenWildcard \u0026\u0026 slmPolicy.length() \u003e 1 \u0026\u0026 slmPolicy.startsWith(\"-\")) {\n                    excludePatterns.add(slmPolicy.substring(1));\n                } else {\n                    if (Regex.isSimpleMatchPattern(slmPolicy)) {\n                        seenWildcard \u003d true;\n                    } else if (GetSnapshotsRequest.NO_POLICY_PATTERN.equals(slmPolicy)) {\n                        matchNoPolicy \u003d true;\n                    }\n                    includePatterns.add(slmPolicy);\n                }\n            }\n            final String[] includes \u003d includePatterns.toArray(Strings.EMPTY_ARRAY);\n            final String[] excludes \u003d excludePatterns.toArray(Strings.EMPTY_ARRAY);\n            final boolean matchWithoutPolicy \u003d matchNoPolicy;\n            return new SnapshotPredicates(((snapshotId, repositoryData) -\u003e {\n                final RepositoryData.SnapshotDetails details \u003d repositoryData.getSnapshotDetails(snapshotId);\n                final String policy;\n                if (details \u003d\u003d null || (details.getSlmPolicy() \u003d\u003d null)) {\n                    // no SLM policy recorded\n                    return true;\n                } else {\n                    final String policyFound \u003d details.getSlmPolicy();\n                    // empty string means that snapshot was not created by an SLM policy\n                    policy \u003d policyFound.isEmpty() ? null : policyFound;\n                }\n                return matchPolicy(includes, excludes, matchWithoutPolicy, policy);\n            }), snapshotInfo -\u003e {\n                final Map\u003cString, Object\u003e metadata \u003d snapshotInfo.userMetadata();\n                final String policy;\n                if (metadata \u003d\u003d null) {\n                    policy \u003d null;\n                } else {\n                    final Object policyFound \u003d metadata.get(SnapshotsService.POLICY_ID_METADATA_FIELD);\n                    policy \u003d policyFound instanceof String ? (String) policyFound : null;\n                }\n                return matchPolicy(includes, excludes, matchWithoutPolicy, policy);\n            });\n        }\n\n        private static boolean matchPolicy(String[] includes, String[] excludes, boolean matchWithoutPolicy, @Nullable String policy) {\n            if (policy \u003d\u003d null) {\n                return matchWithoutPolicy;\n            }\n            if (Regex.simpleMatch(includes, policy) \u003d\u003d false) {\n                return false;\n            }\n            return excludes.length \u003d\u003d 0 || Regex.simpleMatch(excludes, policy) \u003d\u003d false;\n        }\n\n        private static SnapshotPredicates getSortValuePredicate(String fromSortValue, GetSnapshotsRequest.SortBy sortBy, SortOrder order) {\n            if (fromSortValue \u003d\u003d null) {\n                return MATCH_ALL;\n            }\n\n            switch (sortBy) {\n                case START_TIME:\n                    final long after \u003d Long.parseLong(fromSortValue);\n                    return new SnapshotPredicates(order \u003d\u003d SortOrder.ASC ? (snapshotId, repositoryData) -\u003e {\n                        final long startTime \u003d getStartTime(snapshotId, repositoryData);\n                        return startTime \u003d\u003d -1 || after \u003c\u003d startTime;\n                    } : (snapshotId, repositoryData) -\u003e {\n                        final long startTime \u003d getStartTime(snapshotId, repositoryData);\n                        return startTime \u003d\u003d -1 || after \u003e\u003d startTime;\n                    }, filterByLongOffset(SnapshotInfo::startTime, after, order));\n\n                case NAME:\n                    return new SnapshotPredicates(\n                        order \u003d\u003d SortOrder.ASC\n                            ? (snapshotId, repositoryData) -\u003e fromSortValue.compareTo(snapshotId.getName()) \u003c\u003d 0\n                            : (snapshotId, repositoryData) -\u003e fromSortValue.compareTo(snapshotId.getName()) \u003e\u003d 0,\n                        null\n                    );\n\n                case DURATION:\n                    final long afterDuration \u003d Long.parseLong(fromSortValue);\n                    return new SnapshotPredicates(order \u003d\u003d SortOrder.ASC ? (snapshotId, repositoryData) -\u003e {\n                        final long duration \u003d getDuration(snapshotId, repositoryData);\n                        return duration \u003d\u003d -1 || afterDuration \u003c\u003d duration;\n                    } : (snapshotId, repositoryData) -\u003e {\n                        final long duration \u003d getDuration(snapshotId, repositoryData);\n                        return duration \u003d\u003d -1 || afterDuration \u003e\u003d duration;\n                    }, filterByLongOffset(info -\u003e info.endTime() - info.startTime(), afterDuration, order));\n\n                case INDICES:\n                    final int afterIndexCount \u003d Integer.parseInt(fromSortValue);\n                    return new SnapshotPredicates(\n                        order \u003d\u003d SortOrder.ASC\n                            ? (snapshotId, repositoryData) -\u003e afterIndexCount \u003c\u003d indexCount(snapshotId, repositoryData)\n                            : (snapshotId, repositoryData) -\u003e afterIndexCount \u003e\u003d indexCount(snapshotId, repositoryData),\n                        null\n                    );\n\n                case REPOSITORY:\n                    // already handled in #maybeFilterRepositories\n                    return MATCH_ALL;\n\n                case SHARDS:\n                    return new SnapshotPredicates(\n                        null,\n                        filterByLongOffset(SnapshotInfo::totalShards, Integer.parseInt(fromSortValue), order)\n                    );\n                case FAILED_SHARDS:\n                    return new SnapshotPredicates(\n                        null,\n                        filterByLongOffset(SnapshotInfo::failedShards, Integer.parseInt(fromSortValue), order)\n                    );\n                default:\n                    throw new AssertionError(\"unexpected sort column [\" + sortBy + \"]\");\n            }\n        }\n\n        private static Predicate\u003cSnapshotInfo\u003e filterByLongOffset(ToLongFunction\u003cSnapshotInfo\u003e extractor, long after, SortOrder order) {\n            return order \u003d\u003d SortOrder.ASC ? info -\u003e after \u003c\u003d extractor.applyAsLong(info) : info -\u003e after \u003e\u003d extractor.applyAsLong(info);\n        }\n\n    }\n\n    private record SnapshotsInRepo(List\u003cSnapshotInfo\u003e snapshotInfos, int totalCount, int remaining) {\n        private static final SnapshotsInRepo EMPTY \u003d new SnapshotsInRepo(List.of(), 0, 0);\n    }\n}","methodCount":30},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":638,"lineEnd":671,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAfterPredicate to class SnapshotPredicates","description":"move method buildAfterPredicate to PsiClass:SnapshotPredicates\nRationale: The buildAfterPredicate() method deals with filtering and predicates related to SnapshotInfo, which aligns closely with the responsibilities of the SnapshotPredicates class. Moving it here adheres to the Single Responsibility Principle, as it centralizes all snapshot-related predicates in one place, enhancing cohesion. This change also promotes better organization of code and facilitates easier testing. However, care must be taken to ensure that dependencies on external states are managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":638,"lineEnd":671,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAfterPredicate to class After","description":"move method buildAfterPredicate to PsiClass:After\nRationale: The buildAfterPredicate() method relies heavily on the After class for its parameters. Relocating the method here would make sense since it directly utilizes the properties of After for its logic. This move enhances encapsulation by keeping related functionality together. However, it may increase the complexity of the After class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":638,"lineEnd":671,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAfterPredicate to class SnapshotStatus","description":"move method buildAfterPredicate to PsiClass:SnapshotStatus\nRationale: SnapshotStatus manages various aspects of snapshots, including their state and metadata. The buildAfterPredicate() method can be relevant here, especially if it is used to filter snapshots based on their status. This aligns with the Open/Closed Principle by allowing SnapshotStatus to be extended with more filtering capabilities. However, it could potentially bloat the SnapshotStatus class with too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":590,"lineEnd":599,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sortSnapshots to class SnapshotPredicates","description":"move method sortSnapshots to PsiClass:SnapshotPredicates\nRationale: The sortSnapshots() method is closely related to the filtering and sorting of SnapshotInfo objects, which aligns well with the responsibilities of SnapshotPredicates. Moving it here adheres to the Single Responsibility Principle, as it consolidates snapshot-related logic into one class, improving cohesion. This enhances maintainability and reusability of the sorting logic. However, care must be taken to ensure that this class does not become too bloated with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":590,"lineEnd":599,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sortSnapshots to class SnapshotsStatusResponse","description":"move method sortSnapshots to PsiClass:SnapshotsStatusResponse\nRationale: SnapshotsStatusResponse deals with the representation and management of snapshot statuses. The sortSnapshots() method can be seen as a utility for organizing snapshot information, making it a good fit. This move enhances cohesion as it centralizes snapshot management functionality. Aligning with the Open/Closed Principle, this class can be extended with additional snapshot-related methods in the future. However, it may introduce complexity if not carefully managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":590,"lineEnd":599,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sortSnapshots to class TransportGetShardSnapshotAction","description":"move method sortSnapshots to PsiClass:TransportGetShardSnapshotAction\nRationale: This class is involved in operations related to shard snapshots, making it a suitable candidate for handling sorting logic as part of its operations. Moving sortSnapshots() here would streamline the process of obtaining sorted snapshots, adhering to the Single Responsibility Principle. However, it may lead to tight coupling between snapshot retrieval and sorting, which could complicate testing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"maybeFilterRepositories","method_signature":"private static maybeFilterRepositories(\n        List\u003cRepositoryMetadata\u003e repositories,\n        GetSnapshotsRequest.SortBy sortBy,\n        SortOrder order,\n        @Nullable String fromSortValue\n    )","target_class":"","rationale":""},{"method_name":"getMultipleReposSnapshotInfo","method_signature":"private getMultipleReposSnapshotInfo(\n        boolean isMultiRepoRequest,\n        SnapshotsInProgress snapshotsInProgress,\n        TransportGetRepositoriesAction.RepositoriesResult repositoriesResult,\n        String[] snapshots,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        CancellableTask cancellableTask,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order,\n        String fromSortValue,\n        SnapshotPredicates predicates,\n        boolean indices,\n        ActionListener\u003cGetSnapshotsResponse\u003e listener\n    )","target_class":"","rationale":""},{"method_name":"getSingleRepoSnapshotInfo","method_signature":"private getSingleRepoSnapshotInfo(\n        SnapshotsInProgress snapshotsInProgress,\n        String repo,\n        String[] snapshots,\n        SnapshotPredicates predicates,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        SortOrder order,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    )","target_class":"","rationale":""},{"method_name":"currentSnapshots","method_signature":"private static currentSnapshots(SnapshotsInProgress snapshotsInProgress, String repositoryName)","target_class":"","rationale":""},{"method_name":"loadSnapshotInfos","method_signature":"private loadSnapshotInfos(\n        SnapshotsInProgress snapshotsInProgress,\n        String repo,\n        String[] snapshots,\n        boolean ignoreUnavailable,\n        boolean verbose,\n        Map\u003cString, Snapshot\u003e allSnapshotIds,\n        List\u003cSnapshotInfo\u003e currentSnapshots,\n        @Nullable RepositoryData repositoryData,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        SortOrder order,\n        SnapshotPredicates predicates,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    )","target_class":"","rationale":""},{"method_name":"snapshots","method_signature":"private snapshots(\n        SnapshotsInProgress snapshotsInProgress,\n        String repositoryName,\n        Collection\u003cSnapshotId\u003e snapshotIds,\n        boolean ignoreUnavailable,\n        CancellableTask task,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        SortOrder order,\n        SnapshotPredicates predicate,\n        boolean indices,\n        ActionListener\u003cSnapshotsInRepo\u003e listener\n    )","target_class":"","rationale":""},{"method_name":"isCurrentSnapshotsOnly","method_signature":"private static isCurrentSnapshotsOnly(String[] snapshots)","target_class":"","rationale":""},{"method_name":"buildSimpleSnapshotInfos","method_signature":"private static buildSimpleSnapshotInfos(\n        final Set\u003cSnapshot\u003e toResolve,\n        final String repoName,\n        final RepositoryData repositoryData,\n        final List\u003cSnapshotInfo\u003e currentSnapshots,\n        final GetSnapshotsRequest.SortBy sortBy,\n        @Nullable final GetSnapshotsRequest.After after,\n        final SortOrder order,\n        boolean indices\n    )","target_class":"","rationale":""},{"method_name":"getDuration","method_signature":"private static getDuration(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"getStartTime","method_signature":"private static getStartTime(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"indexCount","method_signature":"private static indexCount(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"sortSnapshots","method_signature":"private static sortSnapshots(\n        List\u003cSnapshotInfo\u003e snapshotInfos,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"sortSnapshots","method_signature":"private static sortSnapshots(\n        Stream\u003cSnapshotInfo\u003e infos,\n        int totalCount,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"buildAfterPredicate","method_signature":"private static buildAfterPredicate(\n        GetSnapshotsRequest.SortBy sortBy,\n        GetSnapshotsRequest.After after,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n        ToLongFunction\u003cSnapshotInfo\u003e extractor,\n        long after,\n        String snapshotName,\n        String repoName,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"compareRepositoryName","method_signature":"private static compareRepositoryName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},{"method_name":"compareName","method_signature":"private static compareName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},{"method_name":"test","method_signature":" test(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"isMatchAll","method_signature":" isMatchAll()","target_class":"","rationale":""},{"method_name":"test","method_signature":" test(SnapshotInfo snapshotInfo)","target_class":"","rationale":""},{"method_name":"and","method_signature":"private and(SnapshotPredicates other)","target_class":"","rationale":""},{"method_name":"fromRequest","method_signature":"static fromRequest(GetSnapshotsRequest request)","target_class":"","rationale":""},{"method_name":"getSlmPredicates","method_signature":"private static getSlmPredicates(String[] slmPolicies)","target_class":"","rationale":""},{"method_name":"matchPolicy","method_signature":"private static matchPolicy(String[] includes, String[] excludes, boolean matchWithoutPolicy, @Nullable String policy)","target_class":"","rationale":""},{"method_name":"getSortValuePredicate","method_signature":"private static getSortValuePredicate(String fromSortValue, GetSnapshotsRequest.SortBy sortBy, SortOrder order)","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(ToLongFunction\u003cSnapshotInfo\u003e extractor, long after, SortOrder order)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"and","method_signature":"private and(SnapshotPredicates other)","target_class":"","rationale":""},{"method_name":"buildAfterPredicate","method_signature":"private static buildAfterPredicate(\n        GetSnapshotsRequest.SortBy sortBy,\n        GetSnapshotsRequest.After after,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"sortSnapshots","method_signature":"private static sortSnapshots(\n        List\u003cSnapshotInfo\u003e snapshotInfos,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"fromRequest","method_signature":"static fromRequest(GetSnapshotsRequest request)","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(ToLongFunction\u003cSnapshotInfo\u003e extractor, long after, SortOrder order)","target_class":"","rationale":""},{"method_name":"test","method_signature":" test(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"isCurrentSnapshotsOnly","method_signature":"private static isCurrentSnapshotsOnly(String[] snapshots)","target_class":"","rationale":""},{"method_name":"test","method_signature":" test(SnapshotInfo snapshotInfo)","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n        ToLongFunction\u003cSnapshotInfo\u003e extractor,\n        long after,\n        String snapshotName,\n        String repoName,\n        SortOrder order\n    )","target_class":"","rationale":""},{"method_name":"isMatchAll","method_signature":" isMatchAll()","target_class":"","rationale":""},{"method_name":"matchPolicy","method_signature":"private static matchPolicy(String[] includes, String[] excludes, boolean matchWithoutPolicy, @Nullable String policy)","target_class":"","rationale":""},{"method_name":"getStartTime","method_signature":"private static getStartTime(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"indexCount","method_signature":"private static indexCount(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},{"method_name":"currentSnapshots","method_signature":"private static currentSnapshots(SnapshotsInProgress snapshotsInProgress, String repositoryName)","target_class":"","rationale":""},{"method_name":"getSortValuePredicate","method_signature":"private static getSortValuePredicate(String fromSortValue, GetSnapshotsRequest.SortBy sortBy, SortOrder order)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private and(SnapshotPredicates other)":{"first":{"method_name":"and","method_signature":"private and(SnapshotPredicates other)","target_class":"","rationale":""},"second":0.2759617210955035},"private static buildAfterPredicate(\n        GetSnapshotsRequest.SortBy sortBy,\n        GetSnapshotsRequest.After after,\n        SortOrder order\n    )":{"first":{"method_name":"buildAfterPredicate","method_signature":"private static buildAfterPredicate(\n        GetSnapshotsRequest.SortBy sortBy,\n        GetSnapshotsRequest.After after,\n        SortOrder order\n    )","target_class":"","rationale":""},"second":0.3405631421862033},"private static sortSnapshots(\n        List\u003cSnapshotInfo\u003e snapshotInfos,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    )":{"first":{"method_name":"sortSnapshots","method_signature":"private static sortSnapshots(\n        List\u003cSnapshotInfo\u003e snapshotInfos,\n        GetSnapshotsRequest.SortBy sortBy,\n        @Nullable GetSnapshotsRequest.After after,\n        int offset,\n        int size,\n        SortOrder order\n    )","target_class":"","rationale":""},"second":0.3893685950628636},"static fromRequest(GetSnapshotsRequest request)":{"first":{"method_name":"fromRequest","method_signature":"static fromRequest(GetSnapshotsRequest request)","target_class":"","rationale":""},"second":0.3942350805794505},"private static filterByLongOffset(ToLongFunction\u003cSnapshotInfo\u003e extractor, long after, SortOrder order)":{"first":{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(ToLongFunction\u003cSnapshotInfo\u003e extractor, long after, SortOrder order)","target_class":"","rationale":""},"second":0.40742045084606165}," test(SnapshotId snapshotId, RepositoryData repositoryData)":{"first":{"method_name":"test","method_signature":" test(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},"second":0.44446003127498024},"private static isCurrentSnapshotsOnly(String[] snapshots)":{"first":{"method_name":"isCurrentSnapshotsOnly","method_signature":"private static isCurrentSnapshotsOnly(String[] snapshots)","target_class":"","rationale":""},"second":0.454381564901817}," test(SnapshotInfo snapshotInfo)":{"first":{"method_name":"test","method_signature":" test(SnapshotInfo snapshotInfo)","target_class":"","rationale":""},"second":0.4686050189333636},"private static filterByLongOffset(\n        ToLongFunction\u003cSnapshotInfo\u003e extractor,\n        long after,\n        String snapshotName,\n        String repoName,\n        SortOrder order\n    )":{"first":{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n        ToLongFunction\u003cSnapshotInfo\u003e extractor,\n        long after,\n        String snapshotName,\n        String repoName,\n        SortOrder order\n    )","target_class":"","rationale":""},"second":0.5036537252819643}," isMatchAll()":{"first":{"method_name":"isMatchAll","method_signature":" isMatchAll()","target_class":"","rationale":""},"second":0.5103669816547584},"private static matchPolicy(String[] includes, String[] excludes, boolean matchWithoutPolicy, @Nullable String policy)":{"first":{"method_name":"matchPolicy","method_signature":"private static matchPolicy(String[] includes, String[] excludes, boolean matchWithoutPolicy, @Nullable String policy)","target_class":"","rationale":""},"second":0.5369178080220456},"private static getStartTime(SnapshotId snapshotId, RepositoryData repositoryData)":{"first":{"method_name":"getStartTime","method_signature":"private static getStartTime(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},"second":0.5381679670840762},"private static indexCount(SnapshotId snapshotId, RepositoryData repositoryData)":{"first":{"method_name":"indexCount","method_signature":"private static indexCount(SnapshotId snapshotId, RepositoryData repositoryData)","target_class":"","rationale":""},"second":0.547819549977197},"private static currentSnapshots(SnapshotsInProgress snapshotsInProgress, String repositoryName)":{"first":{"method_name":"currentSnapshots","method_signature":"private static currentSnapshots(SnapshotsInProgress snapshotsInProgress, String repositoryName)","target_class":"","rationale":""},"second":0.5701015874860162},"private static getSortValuePredicate(String fromSortValue, GetSnapshotsRequest.SortBy sortBy, SortOrder order)":{"first":{"method_name":"getSortValuePredicate","method_signature":"private static getSortValuePredicate(String fromSortValue, GetSnapshotsRequest.SortBy sortBy, SortOrder order)","target_class":"","rationale":""},"second":0.5776499086037244}},"llmMethodPriority":{"priority_method_names":["filterByLongOffset","matchPolicy","getStartTime","indexCount","currentSnapshots","getSortValuePredicate","fromRequest","and","buildAfterPredicate","sortSnapshots","test","test","filterByLongOffset","isMatchAll"],"llm_response_time":6854},"targetClassMap":{"and":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":388,"similarity_computation_time":1,"similarity_metric":"voyage"},"buildAfterPredicate":{"target_classes":[{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.1095562808743208},{"class_name":"GetShardSnapshotRequest","similarity_score":0.16440495057395985},{"class_name":"After","similarity_score":0.38737470235603166},{"class_name":"SnapshotPredicates","similarity_score":0.35419932190265035},{"class_name":"TransportGetShardSnapshotAction","similarity_score":0.1838875337216223},{"class_name":"CreateSnapshotRequest","similarity_score":0.12425035590522755},{"class_name":"CreateSnapshotResponse","similarity_score":0.10910338884311893},{"class_name":"SnapshotIndexShardStatus","similarity_score":0.2844660162065844},{"class_name":"SnapshotIndexStatus","similarity_score":0.2289347448397952},{"class_name":"SnapshotShardsStats","similarity_score":0.23449314978576455},{"class_name":"SnapshotsStatusResponse","similarity_score":0.20807694975016083},{"class_name":"SnapshotStats","similarity_score":0.17586088456160856},{"class_name":"SnapshotStatus","similarity_score":0.2252543699842843},{"class_name":"TransportSnapshotsStatusAction","similarity_score":0.26557333206240424},{"class_name":"TransportGetRepositoriesAction","similarity_score":0.16374479905362904},{"class_name":"ResetFeatureStateRequest","similarity_score":0.08616926622356758},{"class_name":"ResetFeatureStateStatus","similarity_score":0.10176552802985082},{"class_name":"RestoreClusterStateListener","similarity_score":0.19771360840639682},{"class_name":"RestoreSnapshotResponseTests","similarity_score":0.3388922049054127},{"class_name":"ActionTestUtils","similarity_score":0.11304318228865862},{"class_name":"ClusterStateCreationUtils","similarity_score":0.15173865028621777},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.11090327906513221},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.07344396512638081},{"class_name":"SynonymsTestUtils","similarity_score":0.15255552100793057},{"class_name":"DesiredBalanceResponse","similarity_score":0.24544000386619677},{"class_name":"DesiredShards","similarity_score":0.17081782102429732},{"class_name":"Result","similarity_score":0.15030301141176594},{"class_name":"GetAliasesResponseTests","similarity_score":0.214288600390494},{"class_name":"GetFeatureUpgradeStatusResponseTests","similarity_score":0.11971997974008779}],"target_classes_sorted_by_llm":["SnapshotPredicates","After","SnapshotStatus","SnapshotIndexStatus","TransportSnapshotsStatusAction","SnapshotIndexShardStatus","SnapshotShardsStats","DesiredBalanceResponse","RestoreSnapshotResponseTests","GetAliasesResponseTests"],"llm_response_time":13480,"similarity_computation_time":23,"similarity_metric":"voyage"},"sortSnapshots":{"target_classes":[{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.22442366447883977},{"class_name":"GetShardSnapshotRequest","similarity_score":0.23287546848041762},{"class_name":"After","similarity_score":0.21030447747976558},{"class_name":"SnapshotPredicates","similarity_score":0.23474311440450726},{"class_name":"TransportGetShardSnapshotAction","similarity_score":0.24924632470425323},{"class_name":"CreateSnapshotRequest","similarity_score":0.1606299294123821},{"class_name":"CreateSnapshotResponse","similarity_score":0.23070547094575417},{"class_name":"SnapshotIndexShardStatus","similarity_score":0.2044640219405627},{"class_name":"SnapshotIndexStatus","similarity_score":0.220690756668935},{"class_name":"SnapshotShardsStats","similarity_score":0.31450295970388115},{"class_name":"SnapshotsStatusResponse","similarity_score":0.23560666795925447},{"class_name":"SnapshotStats","similarity_score":0.2106635914099598},{"class_name":"SnapshotStatus","similarity_score":0.19083607128183555},{"class_name":"RestoreClusterStateListener","similarity_score":0.17458983197476838},{"class_name":"ResetFeatureStateRequest","similarity_score":0.18986581228931068},{"class_name":"ResetFeatureStateStatus","similarity_score":0.17034580097289642},{"class_name":"RestoreSnapshotResponseTests","similarity_score":0.21444176445621135},{"class_name":"TransportSnapshotsStatusAction","similarity_score":0.16742858052226206},{"class_name":"TransportGetRepositoriesAction","similarity_score":0.2015894137004624},{"class_name":"ActionTestUtils","similarity_score":0.20647416048350561},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.23115595400826364},{"class_name":"ClusterStateCreationUtils","similarity_score":0.1530134437185612},{"class_name":"SynonymsTestUtils","similarity_score":0.27451566744840117},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.10619884881071831},{"class_name":"DesiredBalanceResponse","similarity_score":0.2573909248648448},{"class_name":"DesiredShards","similarity_score":0.17250790382314654},{"class_name":"Result","similarity_score":0.24648050725042014},{"class_name":"GetAliasesResponseTests","similarity_score":0.2517596529735418},{"class_name":"GetFeatureUpgradeStatusResponseTests","similarity_score":0.18329639002446185}],"target_classes_sorted_by_llm":["SnapshotPredicates","SnapshotsStatusResponse","TransportGetShardSnapshotAction","Result","GetShardSnapshotRequest","SnapshotShardsStats","DesiredBalanceResponse","ShardMultiGetFromTranslogUtil","GetAliasesResponseTests","SynonymsTestUtils"],"llm_response_time":11407,"similarity_computation_time":6,"similarity_metric":"voyage"}}}
{"id":"5fbcb537-1918-4382-ba53-fa72e0015fd8","methodCount":8,"hostFunctionTelemetryData":{"hostFunctionSize":139,"lineStart":32,"lineEnd":170,"bodyLineStart":32,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/write-load-forecaster/src/main/java/org/elasticsearch/xpack/writeloadforecaster/LicensedWriteLoadForecaster.java","sourceCode":"class LicensedWriteLoadForecaster implements WriteLoadForecaster {\n    public static final Setting\u003cTimeValue\u003e MAX_INDEX_AGE_SETTING \u003d Setting.timeSetting(\n        \"write_load_forecaster.max_index_age\",\n        TimeValue.timeValueDays(7),\n        TimeValue.timeValueHours(1),\n        Setting.Property.NodeScope,\n        Setting.Property.Dynamic\n    );\n    private final BooleanSupplier hasValidLicense;\n    private final ThreadPool threadPool;\n    private volatile TimeValue maxIndexAge;\n\n    LicensedWriteLoadForecaster(\n        BooleanSupplier hasValidLicense,\n        ThreadPool threadPool,\n        Settings settings,\n        ClusterSettings clusterSettings\n    ) {\n        this(hasValidLicense, threadPool, MAX_INDEX_AGE_SETTING.get(settings));\n        clusterSettings.addSettingsUpdateConsumer(MAX_INDEX_AGE_SETTING, this::setMaxIndexAgeSetting);\n    }\n\n    // exposed for tests only\n    LicensedWriteLoadForecaster(BooleanSupplier hasValidLicense, ThreadPool threadPool, TimeValue maxIndexAge) {\n        this.hasValidLicense \u003d hasValidLicense;\n        this.threadPool \u003d threadPool;\n        this.maxIndexAge \u003d maxIndexAge;\n    }\n\n    private void setMaxIndexAgeSetting(TimeValue updatedMaxIndexAge) {\n        this.maxIndexAge \u003d updatedMaxIndexAge;\n    }\n\n    @Override\n    public Metadata.Builder withWriteLoadForecastForWriteIndex(String dataStreamName, Metadata.Builder metadata) {\n        if (hasValidLicense.getAsBoolean() \u003d\u003d false) {\n            return metadata;\n        }\n\n        final DataStream dataStream \u003d metadata.dataStream(dataStreamName);\n\n        if (dataStream \u003d\u003d null) {\n            return metadata;\n        }\n\n        clearPreviousForecast(dataStream, metadata);\n\n        final List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange \u003d getIndicesWithinMaxAgeRange(dataStream, metadata).stream()\n            .filter(index -\u003e index.equals(dataStream.getWriteIndex()) \u003d\u003d false)\n            .map(metadata::getSafe)\n            .map(IndexMetadata::getStats)\n            .filter(Objects::nonNull)\n            .map(IndexMetadataStats::writeLoad)\n            .filter(Objects::nonNull)\n            .toList();\n\n        OptionalDouble forecastIndexWriteLoad \u003d forecastIndexWriteLoad(indicesWriteLoadWithinMaxAgeRange);\n\n        if (forecastIndexWriteLoad.isEmpty()) {\n            return metadata;\n        }\n\n        final IndexMetadata writeIndex \u003d metadata.getSafe(dataStream.getWriteIndex());\n        metadata.put(IndexMetadata.builder(writeIndex).indexWriteLoadForecast(forecastIndexWriteLoad.getAsDouble()).build(), false);\n\n        return metadata;\n    }\n\n    private static void clearPreviousForecast(DataStream dataStream, Metadata.Builder metadata) {\n        if (dataStream.getIndices().size() \u003e 1) {\n            final Index previousWriteIndex \u003d dataStream.getIndices().get(dataStream.getIndices().size() - 2);\n            final IndexMetadata previousWriteIndexMetadata \u003d metadata.getSafe(previousWriteIndex);\n            final IndexMetadata.Builder previousWriteIndexMetadataBuilder \u003d IndexMetadata.builder(previousWriteIndexMetadata)\n                .indexWriteLoadForecast(null);\n            if (previousWriteIndexMetadata.getSettings().hasValue(OVERRIDE_WRITE_LOAD_FORECAST_SETTING.getKey())) {\n                Settings.Builder previousWriteIndexSettings \u003d Settings.builder().put(previousWriteIndexMetadata.getSettings());\n                previousWriteIndexSettings.remove(OVERRIDE_WRITE_LOAD_FORECAST_SETTING.getKey());\n                previousWriteIndexMetadataBuilder.settings(previousWriteIndexSettings);\n                previousWriteIndexMetadataBuilder.settingsVersion(previousWriteIndexMetadata.getSettingsVersion() + 1);\n            }\n            metadata.put(previousWriteIndexMetadataBuilder.build(), false);\n        }\n    }\n\n    // Visible for testing\n    static OptionalDouble forecastIndexWriteLoad(List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange) {\n        double totalWeightedWriteLoad \u003d 0;\n        long totalShardUptime \u003d 0;\n        for (IndexWriteLoad writeLoad : indicesWriteLoadWithinMaxAgeRange) {\n            for (int shardId \u003d 0; shardId \u003c writeLoad.numberOfShards(); shardId++) {\n                final OptionalDouble writeLoadForShard \u003d writeLoad.getWriteLoadForShard(shardId);\n                final OptionalLong uptimeInMillisForShard \u003d writeLoad.getUptimeInMillisForShard(shardId);\n                if (writeLoadForShard.isPresent()) {\n                    assert uptimeInMillisForShard.isPresent();\n                    double shardWriteLoad \u003d writeLoadForShard.getAsDouble();\n                    long shardUptimeInMillis \u003d uptimeInMillisForShard.getAsLong();\n                    totalWeightedWriteLoad +\u003d shardWriteLoad * shardUptimeInMillis;\n                    totalShardUptime +\u003d shardUptimeInMillis;\n                }\n            }\n        }\n\n        return totalShardUptime \u003d\u003d 0 ? OptionalDouble.empty() : OptionalDouble.of(totalWeightedWriteLoad / totalShardUptime);\n    }\n\n    // Visible for testing\n    List\u003cIndex\u003e getIndicesWithinMaxAgeRange(DataStream dataStream, Metadata.Builder metadata) {\n        final List\u003cIndex\u003e dataStreamIndices \u003d dataStream.getIndices();\n        final long currentTimeMillis \u003d threadPool.absoluteTimeInMillis();\n        // Consider at least 1 index (including the write index) for cases where rollovers happen less often than maxIndexAge\n        int firstIndexWithinAgeRange \u003d Math.max(dataStreamIndices.size() - 2, 0);\n        for (int i \u003d 0; i \u003c dataStreamIndices.size(); i++) {\n            Index index \u003d dataStreamIndices.get(i);\n            final IndexMetadata indexMetadata \u003d metadata.getSafe(index);\n            final long indexAge \u003d currentTimeMillis - indexMetadata.getCreationDate();\n            if (indexAge \u003c maxIndexAge.getMillis()) {\n                // We need to consider the previous index too in order to cover the entire max-index-age range.\n                firstIndexWithinAgeRange \u003d i \u003d\u003d 0 ? 0 : i - 1;\n                break;\n            }\n        }\n        return dataStreamIndices.subList(firstIndexWithinAgeRange, dataStreamIndices.size());\n    }\n\n    @Override\n    @SuppressForbidden(reason \u003d \"This is the only place where IndexMetadata#getForecastedWriteLoad is allowed to be used\")\n    public OptionalDouble getForecastedWriteLoad(IndexMetadata indexMetadata) {\n        if (hasValidLicense.getAsBoolean() \u003d\u003d false) {\n            return OptionalDouble.empty();\n        }\n\n        if (OVERRIDE_WRITE_LOAD_FORECAST_SETTING.exists(indexMetadata.getSettings())) {\n            Double overrideWriteLoadForecast \u003d OVERRIDE_WRITE_LOAD_FORECAST_SETTING.get(indexMetadata.getSettings());\n            return OptionalDouble.of(overrideWriteLoadForecast);\n        }\n\n        return indexMetadata.getForecastedWriteLoad();\n    }\n}","methodCount":8},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":115,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method forecastIndexWriteLoad to class AggregationResultUtils","description":"move method forecastIndexWriteLoad to PsiClass:AggregationResultUtils\nRationale: The forecastIndexWriteLoad() method deals with calculating a weighted write load based on index write load data. This aligns closely with the responsibilities of AggregationResultUtils, which likely handles aggregation results. Moving this method here adheres to the Single Responsibility Principle, as it centralizes aggregation logic. This can improve cohesion and reusability. However, care must be taken to ensure that the method\u0027s dependencies are appropriately managed in the new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":115,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method forecastIndexWriteLoad to class AggregationTestUtils","description":"move method forecastIndexWriteLoad to PsiClass:AggregationTestUtils\nRationale: While primarily a utility class for testing, AggregationTestUtils may provide a suitable home for forecastIndexWriteLoad() because it deals with aggregation-related calculations. This move can enhance testing capabilities for aggregation logic, improving code clarity. However, it may dilute the purpose of a testing utility class if it becomes too focused on business logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":115,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method forecastIndexWriteLoad to class RuntimeUtils","description":"move method forecastIndexWriteLoad to PsiClass:RuntimeUtils\nRationale: The forecastIndexWriteLoad() method involves data processing logic that could be considered a utility operation. Placing it in RuntimeUtils could provide a centralized location for various runtime-related computations. This supports the Open/Closed Principle by allowing for future extensions of runtime-related functionalities. However, it might not be the most semantically appropriate fit for runtime-focused utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":99,"lineEnd":113,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method clearPreviousForecast to class ModelLoaderUtils","description":"move method clearPreviousForecast to PsiClass:ModelLoaderUtils\nRationale: The clearPreviousForecast() method deals with managing metadata and indices, which are likely part of a model loading or processing workflow. Moving it to ModelLoaderUtils adheres to the Single Responsibility Principle by consolidating metadata management functions. This enhances cohesion within the class, making it more intuitive for developers working on model-related tasks. However, care must be taken to ensure that the method\u0027s dependencies on DataStream and Metadata are properly managed in this new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":99,"lineEnd":113,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method clearPreviousForecast to class LifecyclePolicyUtils","description":"move method clearPreviousForecast to PsiClass:LifecyclePolicyUtils\nRationale: The method\u0027s responsibility for clearing previous forecasts aligns with lifecycle management of data models. By relocating it here, we maintain a clear separation of concerns, as LifecyclePolicyUtils handles policies related to data management. This move supports the Open/Closed Principle, allowing future extensions related to lifecycle management without modifying existing classes. However, it may require additional integration work if LifecyclePolicyUtils is not currently handling similar data structures.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":99,"lineEnd":113,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method clearPreviousForecast to class RuntimeUtils","description":"move method clearPreviousForecast to PsiClass:RuntimeUtils\nRationale: Given that RuntimeUtils deals with various utilities and helpers, it could serve as a suitable location for clearPreviousForecast(). This move aligns with the Utility Class design pattern, promoting code reuse and reducing redundancy. It also adheres to the Single Responsibility Principle by keeping utility functions centralized. However, this could lead to a bloated utility class if not managed carefully, and the method\u0027s specificity to forecast management might not fit well in a generalized utility context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"clearPreviousForecast","method_signature":"private static clearPreviousForecast(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""},{"method_name":"forecastIndexWriteLoad","method_signature":"static forecastIndexWriteLoad(List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange)","target_class":"","rationale":""},{"method_name":"getIndicesWithinMaxAgeRange","method_signature":" getIndicesWithinMaxAgeRange(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"getIndicesWithinMaxAgeRange","method_signature":" getIndicesWithinMaxAgeRange(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""},{"method_name":"forecastIndexWriteLoad","method_signature":"static forecastIndexWriteLoad(List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange)","target_class":"","rationale":""},{"method_name":"clearPreviousForecast","method_signature":"private static clearPreviousForecast(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{" getIndicesWithinMaxAgeRange(DataStream dataStream, Metadata.Builder metadata)":{"first":{"method_name":"getIndicesWithinMaxAgeRange","method_signature":" getIndicesWithinMaxAgeRange(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""},"second":0.6001811903688604},"static forecastIndexWriteLoad(List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange)":{"first":{"method_name":"forecastIndexWriteLoad","method_signature":"static forecastIndexWriteLoad(List\u003cIndexWriteLoad\u003e indicesWriteLoadWithinMaxAgeRange)","target_class":"","rationale":""},"second":0.6545989807985364},"private static clearPreviousForecast(DataStream dataStream, Metadata.Builder metadata)":{"first":{"method_name":"clearPreviousForecast","method_signature":"private static clearPreviousForecast(DataStream dataStream, Metadata.Builder metadata)","target_class":"","rationale":""},"second":0.6790666602944886}},"llmMethodPriority":{"priority_method_names":["getIndicesWithinMaxAgeRange","forecastIndexWriteLoad","clearPreviousForecast"],"llm_response_time":1586},"targetClassMap":{"getIndicesWithinMaxAgeRange":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":569,"similarity_computation_time":0,"similarity_metric":"voyage"},"forecastIndexWriteLoad":{"target_classes":[{"class_name":"AuditUtil","similarity_score":0.4362298268761155},{"class_name":"JwkValidateUtil","similarity_score":0.49318140849635667},{"class_name":"JwkValidateUtilTests","similarity_score":0.5233930238470845},{"class_name":"AggregationResultUtils","similarity_score":0.530310566145378},{"class_name":"AggregationResultUtilsTests","similarity_score":0.5595108555523062},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.46960149933940604},{"class_name":"AggregationTestUtils","similarity_score":0.6060777847276878},{"class_name":"AuthorizationUtils","similarity_score":0.22336311706799042},{"class_name":"JwtUtil","similarity_score":0.5144497074862802},{"class_name":"AnalysisUtils","similarity_score":0.330277920295676},{"class_name":"AnalyticsEventTestUtils","similarity_score":0.4221250925113625},{"class_name":"AnalyticsTestsUtils","similarity_score":0.5013339738378882},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.1974598381338712},{"class_name":"AnalyzerTestUtils","similarity_score":0.24423360338468855},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.48575633794101813},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.45801741749338093},{"class_name":"DocumentConversionUtils","similarity_score":0.21519388234756953},{"class_name":"DocumentConversionUtilsTests","similarity_score":0.4059166487692259},{"class_name":"LdapTestUtils","similarity_score":0.4368128700625746},{"class_name":"LdapUtils","similarity_score":0.4705267685858512},{"class_name":"ClusterAlertsUtil","similarity_score":0.3227740785991237},{"class_name":"ActionUtils","similarity_score":0.3564972664738742},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.35851258619603465},{"class_name":"BitTableUtil","similarity_score":0.30396843915268884},{"class_name":"RuntimeUtils","similarity_score":0.6018271549875002},{"class_name":"CohereUtils","similarity_score":0.3646440228497459},{"class_name":"LicenseUtils","similarity_score":0.41928806281548875},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.25150953162510303},{"class_name":"LifecyclePolicyTestsUtils","similarity_score":0.24986994744997237},{"class_name":"LifecyclePolicyUtils","similarity_score":0.4979631853311694}],"target_classes_sorted_by_llm":["AggregationResultUtils","AggregationTestUtils","RuntimeUtils","RollupJobIdentifierUtils","LifecyclePolicyUtils","JwtUtil","AnalyticsTestsUtils","JwkValidateUtil","JwkValidateUtilTests","AggregationResultUtilsTests"],"llm_response_time":12569,"similarity_computation_time":24,"similarity_metric":"voyage"},"clearPreviousForecast":{"target_classes":[{"class_name":"JwkValidateUtil","similarity_score":0.5817362743032991},{"class_name":"JwkValidateUtilTests","similarity_score":0.5792337887523488},{"class_name":"LicenseUtils","similarity_score":0.47516444521870527},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.2845611943216836},{"class_name":"LifecyclePolicyTestsUtils","similarity_score":0.20880727590028925},{"class_name":"LifecyclePolicyUtils","similarity_score":0.5541951424693972},{"class_name":"JwtUtil","similarity_score":0.5937752616678549},{"class_name":"MathUtils","similarity_score":0.20950047598562216},{"class_name":"LoggingUtils","similarity_score":0.35856858280031806},{"class_name":"NumericUtilsTests","similarity_score":0.16818737587123037},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.46774631849876314},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.43571236628558885},{"class_name":"MetadataUtils","similarity_score":0.49765322279548246},{"class_name":"OpenAiUtils","similarity_score":0.43939241394300027},{"class_name":"LdapTestUtils","similarity_score":0.4439161713253743},{"class_name":"LdapUtils","similarity_score":0.5081199189945367},{"class_name":"RuntimeUtils","similarity_score":0.6057850028917862},{"class_name":"MlConfigVersionUtils","similarity_score":0.47196152421063836},{"class_name":"MlIndicesUtils","similarity_score":0.31052950170405935},{"class_name":"MlParserUtils","similarity_score":0.35959211294986637},{"class_name":"MlPlatformArchitecturesUtil","similarity_score":0.47749602195242646},{"class_name":"SamlServiceProviderTestUtils","similarity_score":0.5212628507468503},{"class_name":"SamlUtils","similarity_score":0.5764476784420649},{"class_name":"CredentialsRedaction","similarity_score":0.5785788307820874},{"class_name":"ActionUtils","similarity_score":0.40549115517243645},{"class_name":"ModelLoaderUtils","similarity_score":0.60246114063534},{"class_name":"DocumentConversionUtils","similarity_score":0.17934971671346614},{"class_name":"DocumentConversionUtilsTests","similarity_score":0.49994431761216657},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.30383864375727765},{"class_name":"CsvTestUtils","similarity_score":0.48713146081328507}],"target_classes_sorted_by_llm":["ModelLoaderUtils","LifecyclePolicyUtils","RuntimeUtils","SamlUtils","JwtUtil","LdapUtils","CredentialsRedaction","SamlServiceProviderTestUtils","JwkValidateUtil","JwkValidateUtilTests"],"llm_response_time":12647,"similarity_computation_time":14,"similarity_metric":"voyage"}}}
{"id":"f0ef7ceb-080f-480c-bec9-d7033a9a74e2","methodCount":3,"hostFunctionTelemetryData":{"hostFunctionSize":15,"lineStart":166,"lineEnd":180,"bodyLineStart":166,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/test/java/org/elasticsearch/search/aggregations/bucket/sampler/random/RandomSamplerAggregatorTests.java","sourceCode":"private static class IsFinite extends TypeSafeMatcher\u003cDouble\u003e {\n        public static Matcher\u003cDouble\u003e isFinite() {\n            return new IsFinite();\n        }\n\n        @Override\n        protected boolean matchesSafely(Double item) {\n            return Double.isFinite(item);\n        }\n\n        @Override\n        public void describeTo(Description description) {\n            description.appendText(\"a finite double value\");\n        }\n    }","methodCount":3},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":166,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isFinite to class GeoTileGridValuesSourceBuilder","description":"move method isFinite to PsiClass:GeoTileGridValuesSourceBuilder\nRationale: This class primarily deals with geo-related data operations, making it a prime candidate for the isFinite() method. This move would enhance the class\u0027s focus on geographic data handling, adhering to the Single Responsibility Principle. However, the methods relevance to the specific operations of this class should be evaluated to prevent potential misuse.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":166,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isFinite to class GeoDistanceAggregationBuilder","description":"move method isFinite to PsiClass:GeoDistanceAggregationBuilder\nRationale: The isFinite() method could be relevant in the context of distance calculations, as finite values are crucial in geographic computations. This move would support the cohesion of distance-related logic in one place. It adheres to the Open/Closed Principle by allowing for future extensions related to geographic computations. However, care must be taken to ensure that the method\u0027s context fits well within distance aggregation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":166,"lineEnd":168,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isFinite to class GeoTileGridAggregationBuilder","description":"move method isFinite to PsiClass:GeoTileGridAggregationBuilder\nRationale: Similar to GeoTileGridValuesSourceBuilder, this class deals with geographic data, making it a suitable candidate for the isFinite() method. It enhances the clarity of geographic data handling. This move would also improve the Single Responsibility Principle by consolidating geographic-related checks within a dedicated class. However, it might not be directly related to grid aggregation, which could lead to confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"isFinite","method_signature":"public static isFinite()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"isFinite","method_signature":"public static isFinite()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static isFinite()":{"first":{"method_name":"isFinite","method_signature":"public static isFinite()","target_class":"","rationale":""},"second":0.4830458915396479}},"llmMethodPriority":{"priority_method_names":["isFinite"],"llm_response_time":678},"targetClassMap":{"isFinite":{"target_classes":[{"class_name":"RandomSamplerAggregatorTests","similarity_score":0.47980181163727803},{"class_name":"GeoTileUtils","similarity_score":0.32703732342544284},{"class_name":"BucketUtils","similarity_score":0.2164364899036836},{"class_name":"FastGeometric","similarity_score":0.24162688190295734},{"class_name":"RandomSamplerAggregationBuilder","similarity_score":0.5610403832375214},{"class_name":"DiversifiedAggregationBuilder","similarity_score":0.5614591947065168},{"class_name":"DiversifiedAggregatorFactory","similarity_score":0.3135635166677756},{"class_name":"SamplerAggregationBuilder","similarity_score":0.5664474168502651},{"class_name":"SearchUtils","similarity_score":0.32608002466744707},{"class_name":"HighlightUtils","similarity_score":0.5415749296399488},{"class_name":"NestedUtils","similarity_score":0.25324468927010285},{"class_name":"GeoDistanceAggregationBuilder","similarity_score":0.5436849772282482},{"class_name":"GeoDistanceRangeAggregatorFactory","similarity_score":0.3539352191498416},{"class_name":"TermsAggregationBuilder","similarity_score":0.5442449188054672},{"class_name":"TermsAggregatorFactory","similarity_score":0.3732338175823095},{"class_name":"TermsAggregatorTests","similarity_score":0.42584855904132823},{"class_name":"TermsDocCountErrorIT","similarity_score":0.201516331022755},{"class_name":"GeoHashGridAggregationBuilder","similarity_score":0.5543778366476769},{"class_name":"GeoHashGridAggregatorFactory","similarity_score":0.3025791978861457},{"class_name":"GeoHashGridIT","similarity_score":0.31152764700421426},{"class_name":"TermsShardMinDocCountIT","similarity_score":0.3114205494515249},{"class_name":"TermsValuesSourceBuilder","similarity_score":0.5280044826693304},{"class_name":"ReverseNestedAggregationBuilder","similarity_score":0.5450105579841249},{"class_name":"GeoTileGridAggregationBuilder","similarity_score":0.556319206164213},{"class_name":"GeoTileGridAggregatorFactory","similarity_score":0.3150980590019348},{"class_name":"GeoTileGridValuesSourceBuilder","similarity_score":0.5716619504750293},{"class_name":"TestScriptPlugin","similarity_score":0.39277665953249347},{"class_name":"DoubleBounds","similarity_score":0.5142243562105085},{"class_name":"DoubleBoundsTests","similarity_score":0.43835853771804917}],"target_classes_sorted_by_llm":["GeoTileGridValuesSourceBuilder","GeoDistanceAggregationBuilder","GeoTileGridAggregationBuilder","GeoHashGridAggregationBuilder","SamplerAggregationBuilder","DiversifiedAggregationBuilder","RandomSamplerAggregationBuilder","HighlightUtils","TermsAggregationBuilder","ReverseNestedAggregationBuilder"],"llm_response_time":13230,"similarity_computation_time":40,"similarity_metric":"voyage"}}}
{"id":"b9891f49-03be-4afe-8f84-8d2ea426f855","methodCount":16,"hostFunctionTelemetryData":{"hostFunctionSize":460,"lineStart":131,"lineEnd":590,"bodyLineStart":131,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/TransportGetSnapshotsAction.java","sourceCode":"/**\n     * A single invocation of the get-snapshots API.\n     * \u003cp\u003e\n     * Decides which repositories to query, picks a collection of candidate {@link SnapshotId} values from each {@link RepositoryData},\n     * chosen according to the request parameters, loads the relevant {@link SnapshotInfo} blobs, and finally sorts and filters the\n     * results.\n     */\n    private class GetSnapshotsOperation {\n        private final CancellableTask cancellableTask;\n\n        // repositories\n        private final List\u003cRepositoryMetadata\u003e repositories;\n        private final boolean isMultiRepoRequest;\n\n        // snapshots selection\n        private final String[] snapshots;\n        private final boolean ignoreUnavailable;\n        private final SnapshotPredicates predicates;\n\n        // snapshot ordering/pagination\n        private final SnapshotSortKey sortBy;\n        private final SortOrder order;\n        @Nullable\n        private final String fromSortValue;\n        private final int offset;\n        @Nullable\n        private final GetSnapshotsRequest.After after;\n        private final int size;\n\n        // current state\n        private final SnapshotsInProgress snapshotsInProgress;\n\n        // output detail\n        private final boolean verbose;\n        private final boolean indices;\n\n        // results\n        private final Map\u003cString, ElasticsearchException\u003e failuresByRepository \u003d ConcurrentCollections.newConcurrentMap();\n        private final Queue\u003cList\u003cSnapshotInfo\u003e\u003e allSnapshotInfos \u003d ConcurrentCollections.newQueue();\n        private final AtomicInteger remaining \u003d new AtomicInteger();\n        private final AtomicInteger totalCount \u003d new AtomicInteger();\n\n        GetSnapshotsOperation(\n            CancellableTask cancellableTask,\n            ResolvedRepositories resolvedRepositories,\n            boolean isMultiRepoRequest,\n            String[] snapshots,\n            boolean ignoreUnavailable,\n            SnapshotPredicates predicates,\n            SnapshotSortKey sortBy,\n            SortOrder order,\n            String fromSortValue,\n            int offset,\n            GetSnapshotsRequest.After after,\n            int size,\n            SnapshotsInProgress snapshotsInProgress,\n            boolean verbose,\n            boolean indices\n        ) {\n            this.cancellableTask \u003d cancellableTask;\n            this.repositories \u003d resolvedRepositories.repositoryMetadata();\n            this.isMultiRepoRequest \u003d isMultiRepoRequest;\n            this.snapshots \u003d snapshots;\n            this.ignoreUnavailable \u003d ignoreUnavailable;\n            this.predicates \u003d predicates;\n            this.sortBy \u003d sortBy;\n            this.order \u003d order;\n            this.fromSortValue \u003d fromSortValue;\n            this.offset \u003d offset;\n            this.after \u003d after;\n            this.size \u003d size;\n            this.snapshotsInProgress \u003d snapshotsInProgress;\n            this.verbose \u003d verbose;\n            this.indices \u003d indices;\n\n            for (final var missingRepo : resolvedRepositories.missing()) {\n                failuresByRepository.put(missingRepo, new RepositoryMissingException(missingRepo));\n            }\n        }\n\n        void getMultipleReposSnapshotInfo(ActionListener\u003cGetSnapshotsResponse\u003e listener) {\n            try (var listeners \u003d new RefCountingListener(listener.map(ignored -\u003e {\n                cancellableTask.ensureNotCancelled();\n                final var sortedSnapshotsInRepos \u003d sortSnapshots(\n                    allSnapshotInfos.stream().flatMap(Collection::stream),\n                    totalCount.get(),\n                    offset,\n                    size\n                );\n                final var snapshotInfos \u003d sortedSnapshotsInRepos.snapshotInfos();\n                assert indices || snapshotInfos.stream().allMatch(snapshotInfo -\u003e snapshotInfo.indices().isEmpty());\n                final int finalRemaining \u003d sortedSnapshotsInRepos.remaining() + remaining.get();\n                return new GetSnapshotsResponse(\n                    snapshotInfos,\n                    failuresByRepository,\n                    finalRemaining \u003e 0\n                        ? GetSnapshotsRequest.After.from(snapshotInfos.get(snapshotInfos.size() - 1), sortBy).asQueryParam()\n                        : null,\n                    totalCount.get(),\n                    finalRemaining\n                );\n            }))) {\n                for (final RepositoryMetadata repository : repositories) {\n                    final String repoName \u003d repository.name();\n                    if (skipRepository(repoName)) {\n                        // TODO we should still count the matching snapshots in totalCount\n                        continue;\n                    }\n\n                    getSingleRepoSnapshotInfo(repoName, listeners.acquire((SnapshotsInRepo snapshotsInRepo) -\u003e {\n                        allSnapshotInfos.add(snapshotsInRepo.snapshotInfos());\n                        remaining.addAndGet(snapshotsInRepo.remaining());\n                        totalCount.addAndGet(snapshotsInRepo.totalCount());\n                    }).delegateResponse((l, e) -\u003e {\n                        if (isMultiRepoRequest \u0026\u0026 e instanceof ElasticsearchException elasticsearchException) {\n                            failuresByRepository.put(repoName, elasticsearchException);\n                            l.onResponse(SnapshotsInRepo.EMPTY);\n                        } else {\n                            l.onFailure(e);\n                        }\n                    }));\n                }\n            }\n        }\n\n        private boolean skipRepository(String repositoryName) {\n            if (sortBy \u003d\u003d SnapshotSortKey.REPOSITORY \u0026\u0026 fromSortValue !\u003d null) {\n                // If we are sorting by repository name with an offset given by fromSortValue, skip earlier repositories\n                return order \u003d\u003d SortOrder.ASC ? fromSortValue.compareTo(repositoryName) \u003e 0 : fromSortValue.compareTo(repositoryName) \u003c 0;\n            } else {\n                return false;\n            }\n        }\n\n        private void getSingleRepoSnapshotInfo(String repo, ActionListener\u003cSnapshotsInRepo\u003e listener) {\n            final Map\u003cString, Snapshot\u003e allSnapshotIds \u003d new HashMap\u003c\u003e();\n            final List\u003cSnapshotInfo\u003e currentSnapshots \u003d new ArrayList\u003c\u003e();\n            for (final SnapshotInfo snapshotInfo : currentSnapshots(repo)) {\n                Snapshot snapshot \u003d snapshotInfo.snapshot();\n                allSnapshotIds.put(snapshot.getSnapshotId().getName(), snapshot);\n                currentSnapshots.add(snapshotInfo.maybeWithoutIndices(indices));\n            }\n\n            final ListenableFuture\u003cRepositoryData\u003e repositoryDataListener \u003d new ListenableFuture\u003c\u003e();\n            if (isCurrentSnapshotsOnly()) {\n                repositoryDataListener.onResponse(null);\n            } else {\n                repositoriesService.getRepositoryData(repo, repositoryDataListener);\n            }\n\n            repositoryDataListener.addListener(\n                listener.delegateFailureAndWrap(\n                    (l, repositoryData) -\u003e loadSnapshotInfos(repo, allSnapshotIds, currentSnapshots, repositoryData, l)\n                )\n            );\n        }\n\n        /**\n         * Returns a list of currently running snapshots from repository sorted by snapshot creation date\n         *\n         * @param repositoryName      repository name\n         * @return list of snapshots\n         */\n        private List\u003cSnapshotInfo\u003e currentSnapshots(String repositoryName) {\n            List\u003cSnapshotInfo\u003e snapshotList \u003d new ArrayList\u003c\u003e();\n            List\u003cSnapshotsInProgress.Entry\u003e entries \u003d SnapshotsService.currentSnapshots(\n                snapshotsInProgress,\n                repositoryName,\n                Collections.emptyList()\n            );\n            for (SnapshotsInProgress.Entry entry : entries) {\n                snapshotList.add(SnapshotInfo.inProgress(entry));\n            }\n            return snapshotList;\n        }\n\n        private void loadSnapshotInfos(\n            String repo,\n            Map\u003cString, Snapshot\u003e allSnapshotIds,\n            List\u003cSnapshotInfo\u003e currentSnapshots,\n            @Nullable RepositoryData repositoryData,\n            ActionListener\u003cSnapshotsInRepo\u003e listener\n        ) {\n            if (cancellableTask.notifyIfCancelled(listener)) {\n                return;\n            }\n\n            if (repositoryData !\u003d null) {\n                for (SnapshotId snapshotId : repositoryData.getSnapshotIds()) {\n                    if (predicates.test(snapshotId, repositoryData)) {\n                        allSnapshotIds.put(snapshotId.getName(), new Snapshot(repo, snapshotId));\n                    }\n                }\n            }\n\n            final Set\u003cSnapshot\u003e toResolve \u003d new HashSet\u003c\u003e();\n            if (ResolvedRepositories.isMatchAll(snapshots)) {\n                toResolve.addAll(allSnapshotIds.values());\n            } else {\n                final List\u003cString\u003e includePatterns \u003d new ArrayList\u003c\u003e();\n                final List\u003cString\u003e excludePatterns \u003d new ArrayList\u003c\u003e();\n                boolean hasCurrent \u003d false;\n                boolean seenWildcard \u003d false;\n                for (String snapshotOrPattern : snapshots) {\n                    if (seenWildcard \u0026\u0026 snapshotOrPattern.length() \u003e 1 \u0026\u0026 snapshotOrPattern.startsWith(\"-\")) {\n                        excludePatterns.add(snapshotOrPattern.substring(1));\n                    } else {\n                        if (Regex.isSimpleMatchPattern(snapshotOrPattern)) {\n                            seenWildcard \u003d true;\n                            includePatterns.add(snapshotOrPattern);\n                        } else if (GetSnapshotsRequest.CURRENT_SNAPSHOT.equalsIgnoreCase(snapshotOrPattern)) {\n                            hasCurrent \u003d true;\n                            seenWildcard \u003d true;\n                        } else {\n                            if (ignoreUnavailable \u003d\u003d false \u0026\u0026 allSnapshotIds.containsKey(snapshotOrPattern) \u003d\u003d false) {\n                                throw new SnapshotMissingException(repo, snapshotOrPattern);\n                            }\n                            includePatterns.add(snapshotOrPattern);\n                        }\n                    }\n                }\n                final String[] includes \u003d includePatterns.toArray(Strings.EMPTY_ARRAY);\n                final String[] excludes \u003d excludePatterns.toArray(Strings.EMPTY_ARRAY);\n                for (Map.Entry\u003cString, Snapshot\u003e entry : allSnapshotIds.entrySet()) {\n                    final Snapshot snapshot \u003d entry.getValue();\n                    if (toResolve.contains(snapshot) \u003d\u003d false\n                        \u0026\u0026 Regex.simpleMatch(includes, entry.getKey())\n                        \u0026\u0026 Regex.simpleMatch(excludes, entry.getKey()) \u003d\u003d false) {\n                        toResolve.add(snapshot);\n                    }\n                }\n                if (hasCurrent) {\n                    for (SnapshotInfo snapshotInfo : currentSnapshots) {\n                        final Snapshot snapshot \u003d snapshotInfo.snapshot();\n                        if (Regex.simpleMatch(excludes, snapshot.getSnapshotId().getName()) \u003d\u003d false) {\n                            toResolve.add(snapshot);\n                        }\n                    }\n                }\n                if (toResolve.isEmpty() \u0026\u0026 ignoreUnavailable \u003d\u003d false \u0026\u0026 isCurrentSnapshotsOnly() \u003d\u003d false) {\n                    throw new SnapshotMissingException(repo, snapshots[0]);\n                }\n            }\n\n            if (verbose) {\n                snapshots(repo, toResolve.stream().map(Snapshot::getSnapshotId).toList(), listener);\n            } else {\n                assert predicates.isMatchAll() : \"filtering is not supported in non-verbose mode\";\n                final SnapshotsInRepo snapshotInfos;\n                if (repositoryData !\u003d null) {\n                    // want non-current snapshots as well, which are found in the repository data\n                    snapshotInfos \u003d buildSimpleSnapshotInfos(toResolve, repo, repositoryData, currentSnapshots);\n                } else {\n                    // only want current snapshots\n                    snapshotInfos \u003d sortSnapshotsWithNoOffsetOrLimit(currentSnapshots.stream().map(SnapshotInfo::basic).toList());\n                }\n                listener.onResponse(snapshotInfos);\n            }\n        }\n\n        /**\n         * Returns a list of snapshots from repository sorted by snapshot creation date\n         *\n         * @param repositoryName repository name\n         * @param snapshotIds    snapshots for which to fetch snapshot information\n         */\n        private void snapshots(String repositoryName, Collection\u003cSnapshotId\u003e snapshotIds, ActionListener\u003cSnapshotsInRepo\u003e listener) {\n            if (cancellableTask.notifyIfCancelled(listener)) {\n                return;\n            }\n            final List\u003cSnapshotInfo\u003e snapshots \u003d new ArrayList\u003c\u003e(snapshotIds.size());\n            final Set\u003cSnapshotId\u003e snapshotIdsToIterate \u003d new HashSet\u003c\u003e(snapshotIds);\n            // first, look at the snapshots in progress\n            final List\u003cSnapshotsInProgress.Entry\u003e entries \u003d SnapshotsService.currentSnapshots(\n                snapshotsInProgress,\n                repositoryName,\n                snapshotIdsToIterate.stream().map(SnapshotId::getName).toList()\n            );\n            for (SnapshotsInProgress.Entry entry : entries) {\n                if (snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId())) {\n                    final SnapshotInfo snapshotInfo \u003d SnapshotInfo.inProgress(entry);\n                    if (predicates.test(snapshotInfo)) {\n                        snapshots.add(snapshotInfo.maybeWithoutIndices(indices));\n                    }\n                }\n            }\n            // then, look in the repository if there\u0027s any matching snapshots left\n            try (\n                var listeners \u003d new RefCountingListener(\n                    // no need to synchronize access to snapshots: Repository#getSnapshotInfo fails fast but we\u0027re on the success path here\n                    listener.safeMap(v -\u003e sortSnapshotsWithNoOffsetOrLimit(snapshots))\n                )\n            ) {\n                if (snapshotIdsToIterate.isEmpty()) {\n                    return;\n                }\n\n                final Repository repository;\n                try {\n                    repository \u003d repositoriesService.repository(repositoryName);\n                } catch (RepositoryMissingException e) {\n                    listeners.acquire().onFailure(e);\n                    return;\n                }\n\n                // only need to synchronize accesses related to reading SnapshotInfo from the repo\n                final List\u003cSnapshotInfo\u003e syncSnapshots \u003d Collections.synchronizedList(snapshots);\n\n                repository.getSnapshotInfo(snapshotIdsToIterate, ignoreUnavailable \u003d\u003d false, cancellableTask::isCancelled, snapshotInfo -\u003e {\n                    if (predicates.test(snapshotInfo)) {\n                        syncSnapshots.add(snapshotInfo.maybeWithoutIndices(indices));\n                    }\n                }, listeners.acquire());\n            }\n        }\n\n        private boolean isCurrentSnapshotsOnly() {\n            return snapshots.length \u003d\u003d 1 \u0026\u0026 GetSnapshotsRequest.CURRENT_SNAPSHOT.equalsIgnoreCase(snapshots[0]);\n        }\n\n        private SnapshotsInRepo buildSimpleSnapshotInfos(\n            final Set\u003cSnapshot\u003e toResolve,\n            final String repoName,\n            final RepositoryData repositoryData,\n            final List\u003cSnapshotInfo\u003e currentSnapshots\n        ) {\n            List\u003cSnapshotInfo\u003e snapshotInfos \u003d new ArrayList\u003c\u003e();\n            for (SnapshotInfo snapshotInfo : currentSnapshots) {\n                if (toResolve.remove(snapshotInfo.snapshot())) {\n                    snapshotInfos.add(snapshotInfo.basic());\n                }\n            }\n            Map\u003cSnapshotId, List\u003cString\u003e\u003e snapshotsToIndices \u003d new HashMap\u003c\u003e();\n            if (indices) {\n                for (IndexId indexId : repositoryData.getIndices().values()) {\n                    for (SnapshotId snapshotId : repositoryData.getSnapshots(indexId)) {\n                        if (toResolve.contains(new Snapshot(repoName, snapshotId))) {\n                            snapshotsToIndices.computeIfAbsent(snapshotId, (k) -\u003e new ArrayList\u003c\u003e()).add(indexId.getName());\n                        }\n                    }\n                }\n            }\n            for (Snapshot snapshot : toResolve) {\n                snapshotInfos.add(\n                    new SnapshotInfo(\n                        snapshot,\n                        snapshotsToIndices.getOrDefault(snapshot.getSnapshotId(), Collections.emptyList()),\n                        Collections.emptyList(),\n                        Collections.emptyList(),\n                        repositoryData.getSnapshotState(snapshot.getSnapshotId())\n                    )\n                );\n            }\n            return sortSnapshotsWithNoOffsetOrLimit(snapshotInfos);\n        }\n\n        private SnapshotsInRepo sortSnapshotsWithNoOffsetOrLimit(List\u003cSnapshotInfo\u003e snapshotInfos) {\n            return sortSnapshots(snapshotInfos.stream(), snapshotInfos.size(), 0, GetSnapshotsRequest.NO_LIMIT);\n        }\n\n        private SnapshotsInRepo sortSnapshots(Stream\u003cSnapshotInfo\u003e snapshotInfoStream, int totalCount, int offset, int size) {\n            final var resultsStream \u003d snapshotInfoStream.filter(buildAfterPredicate()).sorted(buildComparator()).skip(offset);\n            if (size \u003d\u003d GetSnapshotsRequest.NO_LIMIT) {\n                return new SnapshotsInRepo(resultsStream.toList(), totalCount, 0);\n            } else {\n                final var allocateSize \u003d Math.min(size, 1000); // ignore excessively-large sizes in request params\n                final var results \u003d new ArrayList\u003cSnapshotInfo\u003e(allocateSize);\n                var remaining \u003d 0;\n                for (var iterator \u003d resultsStream.iterator(); iterator.hasNext();) {\n                    final var snapshotInfo \u003d iterator.next();\n                    if (results.size() \u003c size) {\n                        results.add(snapshotInfo);\n                    } else {\n                        remaining +\u003d 1;\n                    }\n                }\n                return new SnapshotsInRepo(results, totalCount, remaining);\n            }\n        }\n\n        private Comparator\u003cSnapshotInfo\u003e buildComparator() {\n            final var comparator \u003d sortBy.getSnapshotInfoComparator();\n            return order \u003d\u003d SortOrder.DESC ? comparator.reversed() : comparator;\n        }\n\n        private Predicate\u003cSnapshotInfo\u003e buildAfterPredicate() {\n            if (after \u003d\u003d null) {\n                return Predicates.always();\n            }\n            assert offset \u003d\u003d 0 : \"can\u0027t combine after and offset but saw [\" + after + \"] and offset [\" + offset + \"]\";\n\n            final String snapshotName \u003d after.snapshotName();\n            final String repoName \u003d after.repoName();\n            final String value \u003d after.value();\n            return switch (sortBy) {\n                case START_TIME -\u003e filterByLongOffset(SnapshotInfo::startTime, Long.parseLong(value), snapshotName, repoName, order);\n                case NAME -\u003e\n                    // TODO: cover via pre-flight predicate\n                    order \u003d\u003d SortOrder.ASC\n                        ? (info -\u003e compareName(snapshotName, repoName, info) \u003c 0)\n                        : (info -\u003e compareName(snapshotName, repoName, info) \u003e 0);\n                case DURATION -\u003e filterByLongOffset(\n                    info -\u003e info.endTime() - info.startTime(),\n                    Long.parseLong(value),\n                    snapshotName,\n                    repoName,\n                    order\n                );\n                case INDICES -\u003e\n                    // TODO: cover via pre-flight predicate\n                    filterByLongOffset(info -\u003e info.indices().size(), Integer.parseInt(value), snapshotName, repoName, order);\n                case SHARDS -\u003e filterByLongOffset(SnapshotInfo::totalShards, Integer.parseInt(value), snapshotName, repoName, order);\n                case FAILED_SHARDS -\u003e filterByLongOffset(\n                    SnapshotInfo::failedShards,\n                    Integer.parseInt(value),\n                    snapshotName,\n                    repoName,\n                    order\n                );\n                case REPOSITORY -\u003e\n                    // TODO: cover via pre-flight predicate\n                    order \u003d\u003d SortOrder.ASC\n                        ? (info -\u003e compareRepositoryName(snapshotName, repoName, info) \u003c 0)\n                        : (info -\u003e compareRepositoryName(snapshotName, repoName, info) \u003e 0);\n            };\n        }\n\n        private static Predicate\u003cSnapshotInfo\u003e filterByLongOffset(\n            ToLongFunction\u003cSnapshotInfo\u003e extractor,\n            long after,\n            String snapshotName,\n            String repoName,\n            SortOrder order\n        ) {\n            return order \u003d\u003d SortOrder.ASC ? info -\u003e {\n                final long val \u003d extractor.applyAsLong(info);\n                return after \u003c val || (after \u003d\u003d val \u0026\u0026 compareName(snapshotName, repoName, info) \u003c 0);\n            } : info -\u003e {\n                final long val \u003d extractor.applyAsLong(info);\n                return after \u003e val || (after \u003d\u003d val \u0026\u0026 compareName(snapshotName, repoName, info) \u003e 0);\n            };\n        }\n\n        private static int compareRepositoryName(String name, String repoName, SnapshotInfo info) {\n            final int res \u003d repoName.compareTo(info.repository());\n            if (res !\u003d 0) {\n                return res;\n            }\n            return name.compareTo(info.snapshotId().getName());\n        }\n\n        private static int compareName(String name, String repoName, SnapshotInfo info) {\n            final int res \u003d name.compareTo(info.snapshotId().getName());\n            if (res !\u003d 0) {\n                return res;\n            }\n            return repoName.compareTo(info.repository());\n        }\n\n    }","methodCount":16},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":515,"lineEnd":555,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method buildAfterPredicate to class SnapshotPredicates","description":"Move method buildAfterPredicate to org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.SnapshotPredicates\nRationale: The buildAfterPredicate() method is primarily concerned with constructing predicates based on snapshot information, which closely aligns with the responsibilities of the SnapshotPredicates class. Moving this method out of its current class adheres to the Single Responsibility Principle, as it separates the logic for building predicates from other unrelated functionalities. The SnapshotPredicates class already contains methods like filterByLongOffset and getSortValuePredicate, which indicate that it is well-suited for handling predicate-related concerns. This relocation would enhance cohesion within the SnapshotPredicates class and improve the overall design by centralizing predicate logic in one place. However, care should be taken to ensure that the method\u0027s dependencies, such as \u0027after\u0027, \u0027offset\u0027, and \u0027sortBy\u0027, are appropriately managed in the new context to avoid introducing tight coupling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":486,"lineEnd":488,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method sortSnapshotsWithNoOffsetOrLimit to class SnapshotPredicates","description":"Move method sortSnapshotsWithNoOffsetOrLimit to org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.SnapshotPredicates\nRationale: The sortSnapshotsWithNoOffsetOrLimit() method is focused on sorting SnapshotInfo objects, which aligns closely with the responsibilities of the SnapshotPredicates class, particularly since this class deals with predicates and filtering related to snapshots. Moving this method out of its current class enhances the Single Responsibility Principle (SRP) as it separates sorting logic from potentially unrelated functionalities of the current class. Additionally, this move promotes better cohesion within the SnapshotPredicates class, as it now encapsulates both filtering and sorting operations related to snapshots. However, a potential drawback is that the method\u0027s dependency on the specific sorting criteria may require additional context or parameters, which could complicate its integration within SnapshotPredicates if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":446,"lineEnd":448,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method isCurrentSnapshotsOnly to class SnapshotPredicates","description":"Move method isCurrentSnapshotsOnly to org.elasticsearch.action.admin.cluster.snapshots.get.TransportGetSnapshotsAction.SnapshotPredicates\nRationale: The isCurrentSnapshotsOnly() method evaluates the state of snapshots and determines if they meet specific criteria that align with snapshot predicates. Moving this method to SnapshotPredicates adheres to the Single Responsibility Principle, as it centralizes logic related to snapshot evaluations in one class. This enhances cohesion within SnapshotPredicates, which already deals with predicates and matching logic for snapshots. Additionally, this relocation aligns with the Open/Closed Principle, allowing SnapshotPredicates to be extended with more snapshot-related logic without modifying the original class. However, a potential drawback is ensuring that any dependencies on the current class\u0027s state are adequately managed, as the method was previously private and may require adjustments in visibility or parameters to maintain encapsulation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"getMultipleReposSnapshotInfo","method_signature":" getMultipleReposSnapshotInfo(ActionListener\u003cGetSnapshotsResponse\u003e listener)","target_class":"","rationale":""},{"method_name":"skipRepository","method_signature":"private skipRepository(String repositoryName)","target_class":"","rationale":""},{"method_name":"getSingleRepoSnapshotInfo","method_signature":"private getSingleRepoSnapshotInfo(String repo, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},{"method_name":"currentSnapshots","method_signature":"private currentSnapshots(String repositoryName)","target_class":"","rationale":""},{"method_name":"loadSnapshotInfos","method_signature":"private loadSnapshotInfos(\n            String repo,\n            Map\u003cString, Snapshot\u003e allSnapshotIds,\n            List\u003cSnapshotInfo\u003e currentSnapshots,\n            @Nullable RepositoryData repositoryData,\n            ActionListener\u003cSnapshotsInRepo\u003e listener\n        )","target_class":"","rationale":""},{"method_name":"snapshots","method_signature":"private snapshots(String repositoryName, Collection\u003cSnapshotId\u003e snapshotIds, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},{"method_name":"isCurrentSnapshotsOnly","method_signature":"private isCurrentSnapshotsOnly()","target_class":"","rationale":""},{"method_name":"buildSimpleSnapshotInfos","method_signature":"private buildSimpleSnapshotInfos(\n            final Set\u003cSnapshot\u003e toResolve,\n            final String repoName,\n            final RepositoryData repositoryData,\n            final List\u003cSnapshotInfo\u003e currentSnapshots\n        )","target_class":"","rationale":""},{"method_name":"sortSnapshotsWithNoOffsetOrLimit","method_signature":"private sortSnapshotsWithNoOffsetOrLimit(List\u003cSnapshotInfo\u003e snapshotInfos)","target_class":"","rationale":""},{"method_name":"sortSnapshots","method_signature":"private sortSnapshots(Stream\u003cSnapshotInfo\u003e snapshotInfoStream, int totalCount, int offset, int size)","target_class":"","rationale":""},{"method_name":"buildComparator","method_signature":"private buildComparator()","target_class":"","rationale":""},{"method_name":"buildAfterPredicate","method_signature":"private buildAfterPredicate()","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n            ToLongFunction\u003cSnapshotInfo\u003e extractor,\n            long after,\n            String snapshotName,\n            String repoName,\n            SortOrder order\n        )","target_class":"","rationale":""},{"method_name":"compareRepositoryName","method_signature":"private static compareRepositoryName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},{"method_name":"compareName","method_signature":"private static compareName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"buildAfterPredicate","method_signature":"private buildAfterPredicate()","target_class":"","rationale":""},{"method_name":"sortSnapshotsWithNoOffsetOrLimit","method_signature":"private sortSnapshotsWithNoOffsetOrLimit(List\u003cSnapshotInfo\u003e snapshotInfos)","target_class":"","rationale":""},{"method_name":"isCurrentSnapshotsOnly","method_signature":"private isCurrentSnapshotsOnly()","target_class":"","rationale":""},{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n            ToLongFunction\u003cSnapshotInfo\u003e extractor,\n            long after,\n            String snapshotName,\n            String repoName,\n            SortOrder order\n        )","target_class":"","rationale":""},{"method_name":"skipRepository","method_signature":"private skipRepository(String repositoryName)","target_class":"","rationale":""},{"method_name":"buildComparator","method_signature":"private buildComparator()","target_class":"","rationale":""},{"method_name":"currentSnapshots","method_signature":"private currentSnapshots(String repositoryName)","target_class":"","rationale":""},{"method_name":"compareRepositoryName","method_signature":"private static compareRepositoryName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},{"method_name":"compareName","method_signature":"private static compareName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},{"method_name":"buildSimpleSnapshotInfos","method_signature":"private buildSimpleSnapshotInfos(\n            final Set\u003cSnapshot\u003e toResolve,\n            final String repoName,\n            final RepositoryData repositoryData,\n            final List\u003cSnapshotInfo\u003e currentSnapshots\n        )","target_class":"","rationale":""},{"method_name":"getSingleRepoSnapshotInfo","method_signature":"private getSingleRepoSnapshotInfo(String repo, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},{"method_name":"sortSnapshots","method_signature":"private sortSnapshots(Stream\u003cSnapshotInfo\u003e snapshotInfoStream, int totalCount, int offset, int size)","target_class":"","rationale":""},{"method_name":"getMultipleReposSnapshotInfo","method_signature":" getMultipleReposSnapshotInfo(ActionListener\u003cGetSnapshotsResponse\u003e listener)","target_class":"","rationale":""},{"method_name":"snapshots","method_signature":"private snapshots(String repositoryName, Collection\u003cSnapshotId\u003e snapshotIds, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},{"method_name":"loadSnapshotInfos","method_signature":"private loadSnapshotInfos(\n            String repo,\n            Map\u003cString, Snapshot\u003e allSnapshotIds,\n            List\u003cSnapshotInfo\u003e currentSnapshots,\n            @Nullable RepositoryData repositoryData,\n            ActionListener\u003cSnapshotsInRepo\u003e listener\n        )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private buildAfterPredicate()":{"first":{"method_name":"buildAfterPredicate","method_signature":"private buildAfterPredicate()","target_class":"","rationale":""},"second":0.32318789607274484},"private sortSnapshotsWithNoOffsetOrLimit(List\u003cSnapshotInfo\u003e snapshotInfos)":{"first":{"method_name":"sortSnapshotsWithNoOffsetOrLimit","method_signature":"private sortSnapshotsWithNoOffsetOrLimit(List\u003cSnapshotInfo\u003e snapshotInfos)","target_class":"","rationale":""},"second":0.38966290926334557},"private isCurrentSnapshotsOnly()":{"first":{"method_name":"isCurrentSnapshotsOnly","method_signature":"private isCurrentSnapshotsOnly()","target_class":"","rationale":""},"second":0.42928692338912255},"private static filterByLongOffset(\n            ToLongFunction\u003cSnapshotInfo\u003e extractor,\n            long after,\n            String snapshotName,\n            String repoName,\n            SortOrder order\n        )":{"first":{"method_name":"filterByLongOffset","method_signature":"private static filterByLongOffset(\n            ToLongFunction\u003cSnapshotInfo\u003e extractor,\n            long after,\n            String snapshotName,\n            String repoName,\n            SortOrder order\n        )","target_class":"","rationale":""},"second":0.46486907554431545},"private skipRepository(String repositoryName)":{"first":{"method_name":"skipRepository","method_signature":"private skipRepository(String repositoryName)","target_class":"","rationale":""},"second":0.519034122530724},"private buildComparator()":{"first":{"method_name":"buildComparator","method_signature":"private buildComparator()","target_class":"","rationale":""},"second":0.5433374583265831},"private currentSnapshots(String repositoryName)":{"first":{"method_name":"currentSnapshots","method_signature":"private currentSnapshots(String repositoryName)","target_class":"","rationale":""},"second":0.5850453726250471},"private static compareRepositoryName(String name, String repoName, SnapshotInfo info)":{"first":{"method_name":"compareRepositoryName","method_signature":"private static compareRepositoryName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},"second":0.6454662130137606},"private static compareName(String name, String repoName, SnapshotInfo info)":{"first":{"method_name":"compareName","method_signature":"private static compareName(String name, String repoName, SnapshotInfo info)","target_class":"","rationale":""},"second":0.6454662130137606},"private buildSimpleSnapshotInfos(\n            final Set\u003cSnapshot\u003e toResolve,\n            final String repoName,\n            final RepositoryData repositoryData,\n            final List\u003cSnapshotInfo\u003e currentSnapshots\n        )":{"first":{"method_name":"buildSimpleSnapshotInfos","method_signature":"private buildSimpleSnapshotInfos(\n            final Set\u003cSnapshot\u003e toResolve,\n            final String repoName,\n            final RepositoryData repositoryData,\n            final List\u003cSnapshotInfo\u003e currentSnapshots\n        )","target_class":"","rationale":""},"second":0.6831074076155318},"private getSingleRepoSnapshotInfo(String repo, ActionListener\u003cSnapshotsInRepo\u003e listener)":{"first":{"method_name":"getSingleRepoSnapshotInfo","method_signature":"private getSingleRepoSnapshotInfo(String repo, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},"second":0.7318246647966098},"private sortSnapshots(Stream\u003cSnapshotInfo\u003e snapshotInfoStream, int totalCount, int offset, int size)":{"first":{"method_name":"sortSnapshots","method_signature":"private sortSnapshots(Stream\u003cSnapshotInfo\u003e snapshotInfoStream, int totalCount, int offset, int size)","target_class":"","rationale":""},"second":0.7463931089330483}," getMultipleReposSnapshotInfo(ActionListener\u003cGetSnapshotsResponse\u003e listener)":{"first":{"method_name":"getMultipleReposSnapshotInfo","method_signature":" getMultipleReposSnapshotInfo(ActionListener\u003cGetSnapshotsResponse\u003e listener)","target_class":"","rationale":""},"second":0.7595197105601161},"private snapshots(String repositoryName, Collection\u003cSnapshotId\u003e snapshotIds, ActionListener\u003cSnapshotsInRepo\u003e listener)":{"first":{"method_name":"snapshots","method_signature":"private snapshots(String repositoryName, Collection\u003cSnapshotId\u003e snapshotIds, ActionListener\u003cSnapshotsInRepo\u003e listener)","target_class":"","rationale":""},"second":0.7665947229163923},"private loadSnapshotInfos(\n            String repo,\n            Map\u003cString, Snapshot\u003e allSnapshotIds,\n            List\u003cSnapshotInfo\u003e currentSnapshots,\n            @Nullable RepositoryData repositoryData,\n            ActionListener\u003cSnapshotsInRepo\u003e listener\n        )":{"first":{"method_name":"loadSnapshotInfos","method_signature":"private loadSnapshotInfos(\n            String repo,\n            Map\u003cString, Snapshot\u003e allSnapshotIds,\n            List\u003cSnapshotInfo\u003e currentSnapshots,\n            @Nullable RepositoryData repositoryData,\n            ActionListener\u003cSnapshotsInRepo\u003e listener\n        )","target_class":"","rationale":""},"second":0.7702122192262428}},"llmMethodPriority":{"priority_method_names":["buildAfterPredicate","sortSnapshotsWithNoOffsetOrLimit","isCurrentSnapshotsOnly","skipRepository","buildComparator","currentSnapshots","compareRepositoryName","compareName","getSingleRepoSnapshotInfo","sortSnapshots","snapshots","filterByLongOffset","buildSimpleSnapshotInfos","getMultipleReposSnapshotInfo","loadSnapshotInfos"],"llm_response_time":4602},"targetClassMap":{"buildAfterPredicate":{"target_classes":[{"class_name":"SnapshotPredicates","similarity_score":0.40164667107784785}],"target_classes_sorted_by_llm":["SnapshotPredicates"],"llm_response_time":2526,"similarity_computation_time":0,"similarity_metric":"voyage"},"sortSnapshotsWithNoOffsetOrLimit":{"target_classes":[{"class_name":"SnapshotPredicates","similarity_score":0.3657295985775044}],"target_classes_sorted_by_llm":["SnapshotPredicates"],"llm_response_time":1967,"similarity_computation_time":0,"similarity_metric":"voyage"},"isCurrentSnapshotsOnly":{"target_classes":[{"class_name":"SnapshotPredicates","similarity_score":0.4906872114248184}],"target_classes_sorted_by_llm":["SnapshotPredicates"],"llm_response_time":2380,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"44c05070-3d94-4453-8112-11e4ff54d3f8","methodCount":181,"hostFunctionTelemetryData":{"hostFunctionSize":3608,"lineStart":160,"lineEnd":3767,"bodyLineStart":160,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizerTests.java","sourceCode":"//@TestLogging(value \u003d \"org.elasticsearch.xpack.esql:TRACE\", reason \u003d \"debug\")\npublic class LogicalPlanOptimizerTests extends ESTestCase {\n\n    private static final Literal ONE \u003d L(1);\n    private static final Literal TWO \u003d L(2);\n    private static final Literal THREE \u003d L(3);\n\n    private static EsqlParser parser;\n    private static Analyzer analyzer;\n    private static LogicalPlanOptimizer logicalOptimizer;\n    private static Map\u003cString, EsField\u003e mapping;\n    private static Map\u003cString, EsField\u003e mappingAirports;\n    private static Analyzer analyzerAirports;\n    private static EnrichResolution enrichResolution;\n\n    @BeforeClass\n    public static void init() {\n        parser \u003d new EsqlParser();\n        logicalOptimizer \u003d new LogicalPlanOptimizer(new LogicalOptimizerContext(EsqlTestUtils.TEST_CFG));\n        enrichResolution \u003d new EnrichResolution();\n        AnalyzerTestUtils.loadEnrichPolicyResolution(enrichResolution, \"languages_idx\", \"id\", \"languages_idx\", \"mapping-languages.json\");\n\n        // Most tests used data from the test index, so we load it here, and use it in the plan() function.\n        mapping \u003d loadMapping(\"mapping-basic.json\");\n        EsIndex test \u003d new EsIndex(\"test\", mapping, Set.of(\"test\"));\n        IndexResolution getIndexResult \u003d IndexResolution.valid(test);\n        analyzer \u003d new Analyzer(\n            new AnalyzerContext(EsqlTestUtils.TEST_CFG, new EsqlFunctionRegistry(), getIndexResult, enrichResolution),\n            TEST_VERIFIER\n        );\n\n        // Some tests use data from the airports index, so we load it here, and use it in the plan_airports() function.\n        mappingAirports \u003d loadMapping(\"mapping-airports.json\");\n        EsIndex airports \u003d new EsIndex(\"airports\", mappingAirports, Set.of(\"airports\"));\n        IndexResolution getIndexResultAirports \u003d IndexResolution.valid(airports);\n        analyzerAirports \u003d new Analyzer(\n            new AnalyzerContext(EsqlTestUtils.TEST_CFG, new EsqlFunctionRegistry(), getIndexResultAirports, enrichResolution),\n            TEST_VERIFIER\n        );\n    }\n\n    public void testEmptyProjections() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | keep salary\n            | drop salary\n            \"\"\");\n\n        var relation \u003d as(plan, LocalRelation.class);\n        assertThat(relation.output(), is(empty()));\n        assertThat(relation.supplier().get(), emptyArray());\n    }\n\n    public void testEmptyProjectionInStat() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | stats c \u003d count(salary)\n            | drop c\n            \"\"\");\n\n        var relation \u003d as(plan, LocalRelation.class);\n        assertThat(relation.output(), is(empty()));\n        assertThat(relation.supplier().get(), emptyArray());\n    }\n\n    public void testCombineProjections() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | keep emp_no, *name, salary\n            | keep last_name\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        assertThat(Expressions.names(keep.projections()), contains(\"last_name\"));\n        var limit \u003d as(keep.child(), Limit.class);\n        var relation \u003d as(limit.child(), EsRelation.class);\n    }\n\n    public void testCombineProjectionWithFilterInBetween() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | keep *name, salary\n            | where salary \u003e 10\n            | keep last_name\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        assertThat(Expressions.names(keep.projections()), contains(\"last_name\"));\n    }\n\n    public void testCombineProjectionWhilePreservingAlias() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | rename first_name as x\n            | keep x, salary\n            | where salary \u003e 10\n            | rename x as y\n            | keep y\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        assertThat(Expressions.names(keep.projections()), contains(\"y\"));\n        var p \u003d keep.projections().get(0);\n        var alias \u003d as(p, Alias.class);\n        assertThat(Expressions.name(alias.child()), containsString(\"first_name\"));\n    }\n\n    public void testCombineProjectionWithAggregation() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | stats s \u003d sum(salary) by last_name, first_name\n            | keep s, last_name, first_name\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"s\", \"last_name\", \"first_name\"));\n        assertThat(Expressions.names(agg.groupings()), contains(\"last_name\", \"first_name\"));\n    }\n\n    /**\n     * Project[[s{r}#4 AS d, s{r}#4, last_name{f}#21, first_name{f}#18]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Aggregate[[last_name{f}#21, first_name{f}#18],[SUM(salary{f}#22) AS s, last_name{f}#21, first_name{f}#18]]\n     *     \\_EsRelation[test][_meta_field{f}#23, emp_no{f}#17, first_name{f}#18, ..]\n     */\n    public void testCombineProjectionWithDuplicateAggregation() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | stats s \u003d sum(salary), d \u003d sum(salary), c \u003d sum(salary) by last_name, first_name\n            | keep d, s, last_name, first_name\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"d\", \"s\", \"last_name\", \"first_name\"));\n        var limit \u003d as(project.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"s\", \"last_name\", \"first_name\"));\n        assertThat(Alias.unwrap(agg.aggregates().get(0)), instanceOf(Sum.class));\n        assertThat(Expressions.names(agg.groupings()), contains(\"last_name\", \"first_name\"));\n    }\n\n    public void testQlComparisonOptimizationsApply() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | where (1 + 4) \u003c salary\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        // The core QL optimizations rotate constants to the right.\n        var condition \u003d as(filter.condition(), GreaterThan.class);\n        assertThat(Expressions.name(condition.left()), equalTo(\"salary\"));\n        assertThat(Expressions.name(condition.right()), equalTo(\"1 + 4\"));\n        var con \u003d as(condition.right(), Literal.class);\n        assertThat(con.value(), equalTo(5));\n    }\n\n    public void testCombineProjectionWithPruning() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | rename first_name as x\n            | keep x, salary, last_name\n            | stats count(salary) by x\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"count(salary)\", \"x\"));\n        assertThat(Expressions.names(agg.groupings()), contains(\"x\"));\n        var alias \u003d as(agg.aggregates().get(1), Alias.class);\n        var field \u003d as(alias.child(), FieldAttribute.class);\n        assertThat(field.name(), is(\"first_name\"));\n        var group \u003d as(agg.groupings().get(0), Attribute.class);\n        assertThat(group, is(alias.toAttribute()));\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[f{r}#7],[SUM(emp_no{f}#15) AS s, COUNT(first_name{f}#16) AS c, first_name{f}#16 AS f]]\n     *   \\_EsRelation[test][_meta_field{f}#21, emp_no{f}#15, first_name{f}#16, ..]\n     */\n    public void testCombineProjectionWithAggregationFirstAndAliasedGroupingUsedInAgg() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | rename emp_no as e, first_name as f\n            | stats s \u003d sum(e), c \u003d count(f) by f\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"s\", \"c\", \"f\"));\n        Alias as \u003d as(aggs.get(0), Alias.class);\n        var sum \u003d as(as.child(), Sum.class);\n        assertThat(Expressions.name(sum.field()), is(\"emp_no\"));\n        as \u003d as(aggs.get(1), Alias.class);\n        var count \u003d as(as.child(), Count.class);\n        assertThat(Expressions.name(count.field()), is(\"first_name\"));\n\n        as \u003d as(aggs.get(2), Alias.class);\n        assertThat(Expressions.name(as.child()), is(\"first_name\"));\n\n        assertThat(Expressions.names(agg.groupings()), contains(\"f\"));\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[f{r}#7],[SUM(emp_no{f}#15) AS s, first_name{f}#16 AS f]]\n     *   \\_EsRelation[test][_meta_field{f}#21, emp_no{f}#15, first_name{f}#16, ..]\n     */\n    public void testCombineProjectionWithAggregationFirstAndAliasedGroupingUnused() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | rename emp_no as e, first_name as f, last_name as l\n            | stats s \u003d sum(e) by f\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"s\", \"f\"));\n        Alias as \u003d as(aggs.get(0), Alias.class);\n        var aggFunc \u003d as(as.child(), AggregateFunction.class);\n        assertThat(Expressions.name(aggFunc.field()), is(\"emp_no\"));\n        as \u003d as(aggs.get(1), Alias.class);\n        assertThat(Expressions.name(as.child()), is(\"first_name\"));\n\n        assertThat(Expressions.names(agg.groupings()), contains(\"f\"));\n    }\n\n    /**\n     * Expects\n     * EsqlProject[[x{r}#3, y{r}#6]]\n     * \\_Eval[[emp_no{f}#9 + 2[INTEGER] AS x, salary{f}#14 + 3[INTEGER] AS y]]\n     *   \\_Limit[10000[INTEGER]]\n     *     \\_EsRelation[test][_meta_field{f}#15, emp_no{f}#9, first_name{f}#10, g..]\n     */\n    public void testCombineEvals() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | eval x \u003d emp_no + 2\n            | eval y \u003d salary + 3\n            | keep x, y\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var eval \u003d as(project.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"x\", \"y\"));\n        var limit \u003d as(eval.child(), Limit.class);\n        var source \u003d as(limit.child(), EsRelation.class);\n    }\n\n    public void testCombineLimits() {\n        var limitValues \u003d new int[] { randomIntBetween(10, 99), randomIntBetween(100, 1000) };\n        var firstLimit \u003d randomBoolean() ? 0 : 1;\n        var secondLimit \u003d firstLimit \u003d\u003d 0 ? 1 : 0;\n        var oneLimit \u003d new Limit(EMPTY, L(limitValues[firstLimit]), emptySource());\n        var anotherLimit \u003d new Limit(EMPTY, L(limitValues[secondLimit]), oneLimit);\n        assertEquals(\n            new Limit(EMPTY, L(Math.min(limitValues[0], limitValues[1])), emptySource()),\n            new LogicalPlanOptimizer.PushDownAndCombineLimits().rule(anotherLimit)\n        );\n    }\n\n    public void testMultipleCombineLimits() {\n        var numberOfLimits \u003d randomIntBetween(3, 10);\n        var minimum \u003d randomIntBetween(10, 99);\n        var limitWithMinimum \u003d randomIntBetween(0, numberOfLimits - 1);\n\n        var fa \u003d getFieldAttribute(\"a\", INTEGER);\n        var relation \u003d localSource(TestBlockFactory.getNonBreakingInstance(), singletonList(fa), singletonList(1));\n        LogicalPlan plan \u003d relation;\n\n        for (int i \u003d 0; i \u003c numberOfLimits; i++) {\n            var value \u003d i \u003d\u003d limitWithMinimum ? minimum : randomIntBetween(100, 1000);\n            plan \u003d new Limit(EMPTY, L(value), plan);\n        }\n        assertEquals(\n            new Limit(EMPTY, L(minimum), relation),\n            new LogicalPlanOptimizer(new LogicalOptimizerContext(EsqlTestUtils.TEST_CFG)).optimize(plan)\n        );\n    }\n\n    public static GreaterThan greaterThanOf(Expression left, Expression right) {\n        return new GreaterThan(EMPTY, left, right, randomZone());\n    }\n\n    public static LessThan lessThanOf(Expression left, Expression right) {\n        return new LessThan(EMPTY, left, right, randomZone());\n    }\n\n    public static GreaterThanOrEqual greaterThanOrEqualOf(Expression left, Expression right) {\n        return new GreaterThanOrEqual(EMPTY, left, right, randomZone());\n    }\n\n    public void testCombineFilters() {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        Filter fb \u003d new Filter(EMPTY, fa, conditionB);\n\n        assertEquals(\n            new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB)),\n            new LogicalPlanOptimizer.PushDownAndCombineFilters().apply(fb)\n        );\n    }\n\n    public void testCombineFiltersLikeRLike() {\n        EsRelation relation \u003d relation();\n        RLike conditionA \u003d rlike(getFieldAttribute(\"a\"), \"foo\");\n        WildcardLike conditionB \u003d wildcardLike(getFieldAttribute(\"b\"), \"bar\");\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        Filter fb \u003d new Filter(EMPTY, fa, conditionB);\n\n        assertEquals(\n            new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB)),\n            new LogicalPlanOptimizer.PushDownAndCombineFilters().apply(fb)\n        );\n    }\n\n    public void testPushDownFilter() {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        List\u003cFieldAttribute\u003e projections \u003d singletonList(getFieldAttribute(\"b\"));\n        EsqlProject keep \u003d new EsqlProject(EMPTY, fa, projections);\n        Filter fb \u003d new Filter(EMPTY, keep, conditionB);\n\n        Filter combinedFilter \u003d new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB));\n        assertEquals(new EsqlProject(EMPTY, combinedFilter, projections), new LogicalPlanOptimizer.PushDownAndCombineFilters().apply(fb));\n    }\n\n    public void testPushDownLikeRlikeFilter() {\n        EsRelation relation \u003d relation();\n        org.elasticsearch.xpack.ql.expression.predicate.regex.RLike conditionA \u003d rlike(getFieldAttribute(\"a\"), \"foo\");\n        WildcardLike conditionB \u003d wildcardLike(getFieldAttribute(\"b\"), \"bar\");\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        List\u003cFieldAttribute\u003e projections \u003d singletonList(getFieldAttribute(\"b\"));\n        EsqlProject keep \u003d new EsqlProject(EMPTY, fa, projections);\n        Filter fb \u003d new Filter(EMPTY, keep, conditionB);\n\n        Filter combinedFilter \u003d new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB));\n        assertEquals(new EsqlProject(EMPTY, combinedFilter, projections), new LogicalPlanOptimizer.PushDownAndCombineFilters().apply(fb));\n    }\n\n    // from ... | where a \u003e 1 | stats count(1) by b | where count(1) \u003e\u003d 3 and b \u003c 2\n    // \u003d\u003e ... | where a \u003e 1 and b \u003c 2 | stats count(1) by b | where count(1) \u003e\u003d 3\n    public void testSelectivelyPushDownFilterPastFunctionAgg() {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n        GreaterThanOrEqual aggregateCondition \u003d greaterThanOrEqualOf(new Count(EMPTY, ONE), THREE);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        // invalid aggregate but that\u0027s fine cause its properties are not used by this rule\n        Aggregate aggregate \u003d new Aggregate(EMPTY, fa, singletonList(getFieldAttribute(\"b\")), emptyList());\n        Filter fb \u003d new Filter(EMPTY, aggregate, new And(EMPTY, aggregateCondition, conditionB));\n\n        // expected\n        Filter expected \u003d new Filter(\n            EMPTY,\n            new Aggregate(\n                EMPTY,\n                new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB)),\n                singletonList(getFieldAttribute(\"b\")),\n                emptyList()\n            ),\n            aggregateCondition\n        );\n        assertEquals(expected, new LogicalPlanOptimizer.PushDownAndCombineFilters().apply(fb));\n    }\n\n    public void testSelectivelyPushDownFilterPastRefAgg() {\n        // expected plan: \"from test | where emp_no \u003e 1 and emp_no \u003c 3 | stats x \u003d count(1) by emp_no | where x \u003e 7\"\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where emp_no \u003e 1\n            | stats x \u003d count(1) by emp_no\n            | where x + 2 \u003e 9\n            | where emp_no \u003c 3\"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof GreaterThan);\n        var gt \u003d (GreaterThan) filter.condition();\n        assertTrue(gt.left() instanceof ReferenceAttribute);\n        var refAttr \u003d (ReferenceAttribute) gt.left();\n        assertEquals(\"x\", refAttr.name());\n        assertEquals(L(7), gt.right());\n\n        var agg \u003d as(filter.child(), Aggregate.class);\n\n        filter \u003d as(agg.child(), Filter.class);\n        assertTrue(filter.condition() instanceof And);\n        var and \u003d (And) filter.condition();\n        assertTrue(and.left() instanceof GreaterThan);\n        gt \u003d (GreaterThan) and.left();\n        assertTrue(gt.left() instanceof FieldAttribute);\n        assertEquals(\"emp_no\", ((FieldAttribute) gt.left()).name());\n        assertTrue(and.right() instanceof LessThan);\n        var lt \u003d (LessThan) and.right();\n        assertTrue(lt.left() instanceof FieldAttribute);\n        assertEquals(\"emp_no\", ((FieldAttribute) lt.left()).name());\n\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testNoPushDownOrFilterPastAgg() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats x \u003d count(1) by emp_no\n            | where emp_no \u003c 3 or x \u003e 9\"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof Or);\n        var or \u003d (Or) filter.condition();\n        assertTrue(or.left() instanceof LessThan);\n        assertTrue(or.right() instanceof GreaterThan);\n\n        var stats \u003d as(filter.child(), Aggregate.class);\n        assertTrue(stats.child() instanceof EsRelation);\n    }\n\n    public void testSelectivePushDownComplexFilterPastAgg() {\n        // expected plan: from test | emp_no \u003e 0 | stats x \u003d count(1) by emp_no | where emp_no \u003c 3 or x \u003e 9\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats x \u003d count(1) by emp_no\n            | where (emp_no \u003c 3 or x \u003e 9) and emp_no \u003e 0\"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof Or);\n        var or \u003d (Or) filter.condition();\n        assertTrue(or.left() instanceof LessThan);\n        assertTrue(or.right() instanceof GreaterThan);\n\n        var stats \u003d as(filter.child(), Aggregate.class);\n        filter \u003d as(stats.child(), Filter.class);\n        assertTrue(filter.condition() instanceof GreaterThan);\n        var gt \u003d (GreaterThan) filter.condition();\n        assertTrue(gt.left() instanceof FieldAttribute);\n        assertEquals(\"emp_no\", ((FieldAttribute) gt.left()).name());\n        assertEquals(L(0), gt.right());\n\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testSelectivelyPushDownFilterPastEval() {\n        // expected plan: \"from test | where emp_no \u003e 1 and emp_no \u003c 3 | eval x \u003d emp_no + 1 | where x \u003c 7\"\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where emp_no \u003e 1\n            | eval x \u003d emp_no + 1\n            | where x + 2 \u003c 9\n            | where emp_no \u003c 3\"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof LessThan);\n        var lt \u003d (LessThan) filter.condition();\n        assertTrue(lt.left() instanceof ReferenceAttribute);\n        var refAttr \u003d (ReferenceAttribute) lt.left();\n        assertEquals(\"x\", refAttr.name());\n        assertEquals(L(7), lt.right());\n\n        var eval \u003d as(filter.child(), Eval.class);\n        assertEquals(1, eval.fields().size());\n        assertTrue(eval.fields().get(0) instanceof Alias);\n        assertEquals(\"x\", (eval.fields().get(0)).name());\n\n        filter \u003d as(eval.child(), Filter.class);\n        assertTrue(filter.condition() instanceof And);\n        var and \u003d (And) filter.condition();\n        assertTrue(and.left() instanceof GreaterThan);\n        var gt \u003d (GreaterThan) and.left();\n        assertTrue(gt.left() instanceof FieldAttribute);\n        assertEquals(\"emp_no\", ((FieldAttribute) gt.left()).name());\n        assertTrue(and.right() instanceof LessThan);\n        lt \u003d (LessThan) and.right();\n        assertTrue(lt.left() instanceof FieldAttribute);\n        assertEquals(\"emp_no\", ((FieldAttribute) lt.left()).name());\n\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testNoPushDownOrFilterPastLimit() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | limit 3\n            | where emp_no \u003c 3 or salary \u003e 9\"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof Or);\n        var or \u003d (Or) filter.condition();\n        assertTrue(or.left() instanceof LessThan);\n        assertTrue(or.right() instanceof GreaterThan);\n\n        var limit2 \u003d as(filter.child(), Limit.class);\n        assertTrue(limit2.child() instanceof EsRelation);\n    }\n\n    public void testPushDownFilterPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename emp_no as x\n            | keep x\n            | where x \u003e 10\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var attr \u003d filter.condition().collect(Attribute.class::isInstance).stream().findFirst().get();\n        assertThat(as(attr, FieldAttribute.class).name(), is(\"emp_no\"));\n    }\n\n    public void testPushDownEvalPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename emp_no as x\n            | keep x\n            | eval y \u003d x * 2\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var eval \u003d as(keep.child(), Eval.class);\n        assertThat(\n            eval.fields(),\n            contains(\n                new Alias(\n                    EMPTY,\n                    \"y\",\n                    new Mul(EMPTY, new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")), new Literal(EMPTY, 2, INTEGER))\n                )\n            )\n        );\n    }\n\n    public void testPushDownDissectPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename first_name as x\n            | keep x\n            | dissect x \"%{y}\"\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var dissect \u003d as(keep.child(), Dissect.class);\n        assertThat(dissect.extractedFields(), contains(new ReferenceAttribute(Source.EMPTY, \"y\", DataTypes.KEYWORD)));\n    }\n\n    public void testPushDownGrokPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename first_name as x\n            | keep x\n            | grok x \"%{WORD:y}\"\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var grok \u003d as(keep.child(), Grok.class);\n        assertThat(grok.extractedFields(), contains(new ReferenceAttribute(Source.EMPTY, \"y\", DataTypes.KEYWORD)));\n    }\n\n    public void testPushDownFilterPastProjectUsingEval() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval y \u003d emp_no + 1\n            | rename y as x\n            | where x \u003e 10\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var attr \u003d filter.condition().collect(Attribute.class::isInstance).stream().findFirst().get();\n        assertThat(as(attr, ReferenceAttribute.class).name(), is(\"y\"));\n        var eval \u003d as(filter.child(), Eval.class);\n        as(eval.child(), EsRelation.class);\n    }\n\n    public void testPushDownFilterPastProjectUsingDissect() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | dissect first_name \"%{y}\"\n            | rename y as x\n            | keep x\n            | where x \u003d\u003d \"foo\"\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var attr \u003d filter.condition().collect(Attribute.class::isInstance).stream().findFirst().get();\n        assertThat(as(attr, ReferenceAttribute.class).name(), is(\"y\"));\n        var dissect \u003d as(filter.child(), Dissect.class);\n        as(dissect.child(), EsRelation.class);\n    }\n\n    public void testPushDownFilterPastProjectUsingGrok() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | grok first_name \"%{WORD:y}\"\n            | rename y as x\n            | keep x\n            | where x \u003d\u003d \"foo\"\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var attr \u003d filter.condition().collect(Attribute.class::isInstance).stream().findFirst().get();\n        assertThat(as(attr, ReferenceAttribute.class).name(), is(\"y\"));\n        var grok \u003d as(filter.child(), Grok.class);\n        as(grok.child(), EsRelation.class);\n    }\n\n    public void testPushDownLimitPastEval() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d emp_no + 100\n            | limit 10\"\"\");\n\n        var eval \u003d as(plan, Eval.class);\n        as(eval.child(), Limit.class);\n    }\n\n    public void testPushDownLimitPastDissect() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | dissect first_name \"%{y}\"\n            | limit 10\"\"\");\n\n        var dissect \u003d as(plan, Dissect.class);\n        as(dissect.child(), Limit.class);\n    }\n\n    public void testPushDownLimitPastGrok() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | grok first_name \"%{WORD:y}\"\n            | limit 10\"\"\");\n\n        var grok \u003d as(plan, Grok.class);\n        as(grok.child(), Limit.class);\n    }\n\n    public void testPushDownLimitPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename emp_no as a\n            | keep a\n            | limit 10\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        as(keep.child(), Limit.class);\n    }\n\n    public void testDontPushDownLimitPastFilter() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | limit 100\n            | where emp_no \u003e 10\n            | limit 10\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        as(filter.child(), Limit.class);\n    }\n\n    public void testEliminateHigherLimitDueToDescendantLimit() throws Exception {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | limit 10\n            | sort emp_no\n            | where emp_no \u003e 10\n            | eval c \u003d emp_no + 2\n            | limit 100\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        var eval \u003d as(topN.child(), Eval.class);\n        var filter \u003d as(eval.child(), Filter.class);\n        as(filter.child(), Limit.class);\n    }\n\n    public void testDoNotEliminateHigherLimitDueToDescendantLimit() throws Exception {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | limit 10\n            | where emp_no \u003e 10\n            | stats c \u003d count(emp_no) by emp_no\n            | limit 100\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var filter \u003d as(agg.child(), Filter.class);\n        as(filter.child(), Limit.class);\n    }\n\n    public void testPruneSortBeforeStats() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | where emp_no \u003e 10\n            | stats x \u003d sum(salary) by first_name\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var stats \u003d as(limit.child(), Aggregate.class);\n        var filter \u003d as(stats.child(), Filter.class);\n        as(filter.child(), EsRelation.class);\n    }\n\n    public void testDontPruneSortWithLimitBeforeStats() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | limit 100\n            | stats x \u003d sum(salary) by first_name\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var stats \u003d as(limit.child(), Aggregate.class);\n        var topN \u003d as(stats.child(), TopN.class);\n        as(topN.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderBy() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | sort salary\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"salary\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughEval() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | eval x \u003d salary + 1\n            | sort x\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"x\"));\n        var eval \u003d as(topN.child(), Eval.class);\n        as(eval.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughEvalWithTwoDefs() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | eval x \u003d salary + 1, y \u003d salary + 2\n            | eval z \u003d x * y\n            | sort z\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"z\"));\n        var eval \u003d as(topN.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"x\", \"y\", \"z\"));\n        as(eval.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughDissect() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | dissect first_name \"%{x}\"\n            | sort x\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"x\"));\n        var dissect \u003d as(topN.child(), Dissect.class);\n        as(dissect.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughGrok() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | grok first_name \"%{WORD:x}\"\n            | sort x\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"x\"));\n        var grok \u003d as(topN.child(), Grok.class);\n        as(grok.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | keep salary, emp_no\n            | sort salary\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(orderNames(topN), contains(\"salary\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughProjectAndEval() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | rename emp_no as en\n            | keep salary, en\n            | eval e \u003d en * 2\n            | sort salary\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(orderNames(topN), contains(\"salary\"));\n        var eval \u003d as(topN.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"e\"));\n        as(eval.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughProjectWithAlias() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | rename salary as l\n            | keep l, emp_no\n            | sort l\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(orderNames(topN), contains(\"salary\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    public void testCombineOrderByThroughFilter() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | where emp_no \u003e 10\n            | sort salary\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"salary\"));\n        var filter \u003d as(topN.child(), Filter.class);\n        as(filter.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * TopN[[Order[first_name{f}#170,ASC,LAST]],1000[INTEGER]]\n     *  \\_MvExpand[first_name{f}#170]\n     *    \\_TopN[[Order[emp_no{f}#169,ASC,LAST]],1000[INTEGER]]\n     *      \\_EsRelation[test][avg_worked_seconds{f}#167, birth_date{f}#168, emp_n..]\n     */\n    public void testDontCombineOrderByThroughMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | mv_expand first_name\n            | sort first_name\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(orderNames(topN), contains(\"first_name\"));\n        var mvExpand \u003d as(topN.child(), MvExpand.class);\n        topN \u003d as(mvExpand.child(), TopN.class);\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[1000[INTEGER]]\n     *  \\_MvExpand[x{r}#159]\n     *    \\_EsqlProject[[first_name{f}#162 AS x]]\n     *      \\_Limit[1000[INTEGER]]\n     *        \\_EsRelation[test][first_name{f}#162]\n     */\n    public void testCopyDefaultLimitPastMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename first_name as x\n            | keep x\n            | mv_expand x\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var mvExpand \u003d as(limit.child(), MvExpand.class);\n        var keep \u003d as(mvExpand.child(), EsqlProject.class);\n        var limitPastMvExpand \u003d as(keep.child(), Limit.class);\n        assertThat(limitPastMvExpand.limit(), equalTo(limit.limit()));\n        as(limitPastMvExpand.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[10[INTEGER]]\n     *  \\_MvExpand[first_name{f}#155]\n     *    \\_EsqlProject[[first_name{f}#155, last_name{f}#156]]\n     *      \\_Limit[1[INTEGER]]\n     *        \\_EsRelation[test][first_name{f}#155, last_name{f}#156]\n     */\n    public void testDontPushDownLimitPastMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | limit 1\n            | keep first_name, last_name\n            | mv_expand first_name\n            | limit 10\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        assertThat(limit.limit().fold(), equalTo(10));\n        var mvExpand \u003d as(limit.child(), MvExpand.class);\n        var project \u003d as(mvExpand.child(), EsqlProject.class);\n        limit \u003d as(project.child(), Limit.class);\n        assertThat(limit.limit().fold(), equalTo(1));\n        as(limit.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#141, first_name{f}#142, languages{f}#143, lll{r}#132, salary{f}#147]]\n     *  \\_TopN[[Order[salary{f}#147,DESC,FIRST], Order[first_name{f}#142,ASC,LAST]],5[INTEGER]]\n     *    \\_Limit[5[INTEGER]]\n     *      \\_MvExpand[salary{f}#147]\n     *        \\_Eval[[languages{f}#143 + 5[INTEGER] AS lll]]\n     *          \\_Filter[languages{f}#143 \u003e 1[INTEGER]]\n     *            \\_Limit[10[INTEGER]]\n     *              \\_MvExpand[first_name{f}#142]\n     *                \\_TopN[[Order[emp_no{f}#141,DESC,FIRST]],10[INTEGER]]\n     *                  \\_Filter[emp_no{f}#141 \u0026lt; 10006[INTEGER]]\n     *                    \\_EsRelation[test][emp_no{f}#141, first_name{f}#142, languages{f}#1..]\n     */\n    public void testMultipleMvExpandWithSortAndLimit() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where emp_no \u003c\u003d 10006\n            | sort emp_no desc\n            | mv_expand first_name\n            | limit 10\n            | where languages \u003e 1\n            | eval lll \u003d languages + 5\n            | mv_expand salary\n            | limit 5\n            | sort first_name\n            | keep emp_no, first_name, languages, lll, salary\n            | sort salary desc\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(5));\n        assertThat(orderNames(topN), contains(\"salary\"));\n        var limit \u003d as(topN.child(), Limit.class);\n        assertThat(limit.limit().fold(), equalTo(5));\n        var mvExp \u003d as(limit.child(), MvExpand.class);\n        var eval \u003d as(mvExp.child(), Eval.class);\n        var filter \u003d as(eval.child(), Filter.class);\n        limit \u003d as(filter.child(), Limit.class);\n        assertThat(limit.limit().fold(), equalTo(10));\n        mvExp \u003d as(limit.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(10));\n        filter \u003d as(topN.child(), Filter.class);\n        as(filter.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#350, first_name{f}#351, salary{f}#352]]\n     *  \\_TopN[[Order[salary{f}#352,ASC,LAST], Order[first_name{f}#351,ASC,LAST]],5[INTEGER]]\n     *    \\_MvExpand[first_name{f}#351]\n     *      \\_TopN[[Order[emp_no{f}#350,ASC,LAST]],10000[INTEGER]]\n     *        \\_EsRelation[employees][emp_no{f}#350, first_name{f}#351, salary{f}#352]\n     */\n    public void testPushDownLimitThroughMultipleSort_AfterMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | mv_expand first_name\n            | keep emp_no, first_name, salary\n            | sort salary, first_name\n            | limit 5\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(5));\n        assertThat(orderNames(topN), contains(\"salary\", \"first_name\"));\n        var mvExp \u003d as(topN.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#361, first_name{f}#362, salary{f}#363]]\n     *  \\_TopN[[Order[first_name{f}#362,ASC,LAST]],5[INTEGER]]\n     *    \\_TopN[[Order[salary{f}#363,ASC,LAST]],5[INTEGER]]\n     *      \\_MvExpand[first_name{f}#362]\n     *        \\_TopN[[Order[emp_no{f}#361,ASC,LAST]],10000[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#361, first_name{f}#362, salary{f}#363]\n     */\n    public void testPushDownLimitThroughMultipleSort_AfterMvExpand2() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | mv_expand first_name\n            | keep emp_no, first_name, salary\n            | sort salary\n            | limit 5\n            | sort first_name\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(5));\n        assertThat(orderNames(topN), contains(\"first_name\"));\n        topN \u003d as(topN.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(5));\n        assertThat(orderNames(topN), contains(\"salary\"));\n        var mvExp \u003d as(topN.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[5[INTEGER]]\n     *  \\_Aggregate[[first_name{f}#232],[MAX(salary{f}#233) AS max_s, first_name{f}#232]]\n     *    \\_Filter[ISNOTNULL(first_name{f}#232)]\n     *      \\_MvExpand[first_name{f}#232]\n     *        \\_TopN[[Order[emp_no{f}#231,ASC,LAST]],50[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#231, first_name{f}#232, salary{f}#233]\n     */\n    public void testDontPushDownLimitPastAggregate_AndMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | limit 50\n            | mv_expand first_name\n            | keep emp_no, first_name, salary\n            | stats max_s \u003d max(salary) by first_name\n            | where first_name is not null\n            | limit 5\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        assertThat(limit.limit().fold(), equalTo(5));\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var filter \u003d as(agg.child(), Filter.class);\n        var mvExp \u003d as(filter.child(), MvExpand.class);\n        var topN \u003d as(mvExp.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(50));\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[5[INTEGER]]\n     *  \\_Aggregate[[first_name{f}#262],[MAX(salary{f}#263) AS max_s, first_name{f}#262]]\n     *    \\_Filter[ISNOTNULL(first_name{f}#262)]\n     *      \\_Limit[50[INTEGER]]\n     *        \\_MvExpand[first_name{f}#262]\n     *          \\_Limit[50[INTEGER]]\n     *            \\_EsRelation[employees][emp_no{f}#261, first_name{f}#262, salary{f}#263]\n     */\n    public void testPushDown_TheRightLimit_PastMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | mv_expand first_name\n            | limit 50\n            | keep emp_no, first_name, salary\n            | stats max_s \u003d max(salary) by first_name\n            | where first_name is not null\n            | limit 5\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        assertThat(limit.limit().fold(), equalTo(5));\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var filter \u003d as(agg.child(), Filter.class);\n        limit \u003d as(filter.child(), Limit.class);\n        assertThat(limit.limit().fold(), equalTo(50));\n        var mvExp \u003d as(limit.child(), MvExpand.class);\n        limit \u003d as(mvExp.child(), Limit.class);\n        assertThat(limit.limit().fold(), equalTo(50));\n        as(limit.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[first_name{f}#11, emp_no{f}#10, salary{f}#12, b{r}#4]]\n     *  \\_TopN[[Order[salary{f}#12,ASC,LAST]],5[INTEGER]]\n     *    \\_Eval[[100[INTEGER] AS b]]\n     *      \\_MvExpand[first_name{f}#11]\n     *        \\_TopN[[Order[first_name{f}#11,ASC,LAST]],10000[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#10, first_name{f}#11, salary{f}#12]\n     */\n    public void testPushDownLimit_PastEvalAndMvExpand() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort first_name\n            | mv_expand first_name\n            | eval b \u003d 100\n            | sort salary\n            | limit 5\n            | keep first_name, emp_no, salary, b\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(5));\n        assertThat(orderNames(topN), contains(\"salary\"));\n        var eval \u003d as(topN.child(), Eval.class);\n        var mvExp \u003d as(eval.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"first_name\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#104, first_name{f}#105, salary{f}#106]]\n     *  \\_TopN[[Order[salary{f}#106,ASC,LAST], Order[first_name{f}#105,ASC,LAST]],15[INTEGER]]\n     *    \\_Filter[gender{f}#215 \u003d\u003d [46][KEYWORD] AND WILDCARDLIKE(first_name{f}#105)]\n     *      \\_MvExpand[first_name{f}#105]\n     *        \\_TopN[[Order[emp_no{f}#104,ASC,LAST]],10000[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#104, first_name{f}#105, salary{f}#106]\n     */\n    public void testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedField() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | mv_expand first_name\n            | where gender \u003d\u003d \"F\"\n            | where first_name LIKE \"R*\"\n            | keep emp_no, first_name, salary\n            | sort salary, first_name\n            | limit 15\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(15));\n        assertThat(orderNames(topN), contains(\"salary\", \"first_name\"));\n        var filter \u003d as(topN.child(), Filter.class);\n        assertThat(filter.condition(), instanceOf(And.class));\n        var mvExp \u003d as(filter.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        // the filter acts on first_name (the one used in mv_expand), so the limit 15 is not pushed down past mv_expand\n        // instead the default limit is added\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#104, first_name{f}#105, salary{f}#106]]\n     *  \\_TopN[[Order[salary{f}#106,ASC,LAST], Order[first_name{f}#105,ASC,LAST]],15[INTEGER]]\n     *    \\_Filter[gender{f}#215 \u003d\u003d [46][KEYWORD] AND salary{f}#106 \u003e 60000[INTEGER]]\n     *      \\_MvExpand[first_name{f}#105]\n     *        \\_TopN[[Order[emp_no{f}#104,ASC,LAST]],10000[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#104, first_name{f}#105, salary{f}#106]\n     */\n    public void testAddDefaultLimit_BeforeMvExpand_WithFilter_NOT_OnExpandedField() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | mv_expand first_name\n            | where gender \u003d\u003d \"F\"\n            | where salary \u003e 60000\n            | keep emp_no, first_name, salary\n            | sort salary, first_name\n            | limit 15\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(15));\n        assertThat(orderNames(topN), contains(\"salary\", \"first_name\"));\n        var filter \u003d as(topN.child(), Filter.class);\n        assertThat(filter.condition(), instanceOf(And.class));\n        var mvExp \u003d as(filter.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        // the filters after mv_expand do not act on the expanded field values, as such the limit 15 is the one being pushed down\n        // otherwise that limit wouldn\u0027t have pushed down and the default limit was instead being added by default before mv_expanded\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * EsqlProject[[emp_no{f}#116, first_name{f}#117 AS x, salary{f}#119]]\n     *  \\_TopN[[Order[salary{f}#119,ASC,LAST], Order[first_name{f}#117,ASC,LAST]],15[INTEGER]]\n     *    \\_Filter[gender{f}#118 \u003d\u003d [46][KEYWORD] AND WILDCARDLIKE(first_name{f}#117)]\n     *      \\_MvExpand[first_name{f}#117]\n     *        \\_TopN[[Order[gender{f}#118,ASC,LAST]],10000[INTEGER]]\n     *          \\_EsRelation[employees][emp_no{f}#116, first_name{f}#117, gender{f}#118, sa..]\n     */\n    public void testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedFieldAlias() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort gender\n            | mv_expand first_name\n            | rename first_name AS x\n            | where gender \u003d\u003d \"F\"\n            | where x LIKE \"A*\"\n            | keep emp_no, x, salary\n            | sort salary, x\n            | limit 15\"\"\");\n\n        var keep \u003d as(plan, EsqlProject.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(topN.limit().fold(), equalTo(15));\n        assertThat(orderNames(topN), contains(\"salary\", \"first_name\"));\n        var filter \u003d as(topN.child(), Filter.class);\n        assertThat(filter.condition(), instanceOf(And.class));\n        var mvExp \u003d as(filter.child(), MvExpand.class);\n        topN \u003d as(mvExp.child(), TopN.class);\n        // the filter uses an alias (\"x\") to the expanded field (\"first_name\"), so the default limit is used and not the one provided\n        assertThat(topN.limit().fold(), equalTo(10000));\n        assertThat(orderNames(topN), contains(\"gender\"));\n        as(topN.child(), EsRelation.class);\n    }\n\n    private static List\u003cString\u003e orderNames(TopN topN) {\n        return topN.order().stream().map(o -\u003e as(o.child(), NamedExpression.class).name()).toList();\n    }\n\n    public void testCombineLimitWithOrderByThroughFilterAndEval() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort salary\n            | eval x \u003d emp_no / 2\n            | where x \u003e 20\n            | sort x\n            | limit 10\"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        var filter \u003d as(topN.child(), Filter.class);\n        var eval \u003d as(filter.child(), Eval.class);\n        as(eval.child(), EsRelation.class);\n    }\n\n    public void testCombineMultipleOrderByAndLimits() {\n        // expected plan:\n        // from test\n        // | sort salary, emp_no\n        // | limit 100\n        // | where salary \u003e 1\n        // | sort emp_no, first_name\n        // | keep l \u003d salary, emp_no, first_name\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no\n            | rename salary as l\n            | keep l, emp_no, first_name\n            | sort l\n            | limit 100\n            | sort first_name\n            | where l \u003e 1\n            | sort emp_no\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(orderNames(topN), contains(\"emp_no\"));\n        var filter \u003d as(topN.child(), Filter.class);\n        var topN2 \u003d as(filter.child(), TopN.class);\n        assertThat(orderNames(topN2), contains(\"salary\"));\n        as(topN2.child(), EsRelation.class);\n    }\n\n    public void testDontPruneSameFieldDifferentDirectionSortClauses() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort salary nulls last, emp_no desc nulls first\n            | where salary \u003e 2\n            | eval e \u003d emp_no * 2\n            | keep salary, emp_no, e\n            | sort e, emp_no, salary desc, emp_no desc\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(\n            topN.order(),\n            contains(\n                new Order(\n                    EMPTY,\n                    new ReferenceAttribute(EMPTY, \"e\", INTEGER, null, Nullability.TRUE, null, false),\n                    Order.OrderDirection.ASC,\n                    Order.NullsPosition.LAST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.ASC,\n                    Order.NullsPosition.LAST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"salary\", mapping.get(\"salary\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.FIRST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.FIRST\n                )\n            )\n        );\n        assertThat(topN.child().collect(OrderBy.class::isInstance), is(emptyList()));\n    }\n\n    public void testPruneRedundantSortClauses() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort salary desc nulls last, emp_no desc nulls first\n            | where salary \u003e 2\n            | eval e \u003d emp_no * 2\n            | keep salary, emp_no, e\n            | sort e, emp_no desc, salary desc, emp_no desc nulls last\"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var topN \u003d as(project.child(), TopN.class);\n        assertThat(\n            topN.order(),\n            contains(\n                new Order(\n                    EMPTY,\n                    new ReferenceAttribute(EMPTY, \"e\", INTEGER, null, Nullability.TRUE, null, false),\n                    Order.OrderDirection.ASC,\n                    Order.NullsPosition.LAST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.FIRST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"salary\", mapping.get(\"salary\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.FIRST\n                ),\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.LAST\n                )\n            )\n        );\n        assertThat(topN.child().collect(OrderBy.class::isInstance), is(emptyList()));\n    }\n\n    public void testDontPruneSameFieldDifferentDirectionSortClauses_UsingAlias() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no desc\n            | rename emp_no as e\n            | keep e\n            | sort e\"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        assertThat(\n            topN.order(),\n            contains(\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.ASC,\n                    Order.NullsPosition.LAST\n                )\n            )\n        );\n    }\n\n    public void testPruneRedundantSortClausesUsingAlias() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | sort emp_no desc\n            | rename emp_no as e\n            | keep e\n            | sort e desc\"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var topN \u003d as(project.child(), TopN.class);\n        assertThat(\n            topN.order(),\n            contains(\n                new Order(\n                    EMPTY,\n                    new FieldAttribute(EMPTY, \"emp_no\", mapping.get(\"emp_no\")),\n                    Order.OrderDirection.DESC,\n                    Order.NullsPosition.FIRST\n                )\n            )\n        );\n    }\n\n    public void testSimplifyLikeNoWildcard() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where first_name like \"foo\"\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof Equals);\n        Equals equals \u003d as(filter.condition(), Equals.class);\n        assertEquals(BytesRefs.toBytesRef(\"foo\"), equals.right().fold());\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testSimplifyLikeMatchAll() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where first_name like \"*\"\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        as(filter.condition(), IsNotNull.class);\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testSimplifyRLikeNoWildcard() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where first_name rlike \"foo\"\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        assertTrue(filter.condition() instanceof Equals);\n        Equals equals \u003d as(filter.condition(), Equals.class);\n        assertEquals(BytesRefs.toBytesRef(\"foo\"), equals.right().fold());\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testSimplifyRLikeMatchAll() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where first_name rlike \".*\"\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n\n        var isNotNull \u003d as(filter.condition(), IsNotNull.class);\n        assertTrue(filter.child() instanceof EsRelation);\n    }\n\n    public void testFoldNullInToLocalRelation() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where null in (first_name, \".*\")\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n    }\n\n    public void testFoldNullListInToLocalRelation() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where first_name in (null, null)\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n    }\n\n    public void testFoldInKeyword() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where \"foo\" in (\"bar\", \"baz\")\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n\n        plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where \"foo\" in (\"bar\", \"foo\", \"baz\")\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        as(limit.child(), EsRelation.class);\n    }\n\n    public void testFoldInIP() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where to_ip(\"1.1.1.1\") in (to_ip(\"1.1.1.2\"), to_ip(\"1.1.1.2\"))\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n\n        plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where to_ip(\"1.1.1.1\") in (to_ip(\"1.1.1.1\"), to_ip(\"1.1.1.2\"))\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        as(limit.child(), EsRelation.class);\n    }\n\n    public void testFoldInVersion() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where to_version(\"1.2.3\") in (to_version(\"1\"), to_version(\"1.2.4\"))\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n\n        plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where to_version(\"1.2.3\") in (to_version(\"1\"), to_version(\"1.2.3\"))\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        as(limit.child(), EsRelation.class);\n    }\n\n    public void testFoldInNumerics() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where 3 in (4.0, 5, 2147483648)\n            \"\"\");\n        assertThat(plan, instanceOf(LocalRelation.class));\n\n        plan \u003d optimizedPlan(\"\"\"\n            from test\n            | where 3 in (4.0, 3.0, to_long(3))\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        as(limit.child(), EsRelation.class);\n    }\n\n    public void testFoldInEval() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval a \u003d 1, b \u003d a + 1, c \u003d b + a\n            | where c \u003e 10\n            \"\"\");\n\n        var local \u003d as(plan, LocalRelation.class);\n        assertThat(local.supplier(), is(LocalSupplier.EMPTY));\n    }\n\n    public void testFoldFromRow() {\n        var plan \u003d optimizedPlan(\"\"\"\n              row a \u003d 1, b \u003d 2, c \u003d 3\n            | where c \u003e 10\n            \"\"\");\n\n        as(plan, LocalRelation.class);\n    }\n\n    public void testFoldFromRowInEval() {\n        var plan \u003d optimizedPlan(\"\"\"\n              row a \u003d 1, b \u003d 2, c \u003d 3\n            | eval x \u003d c\n            | where x \u003e 10\n            \"\"\");\n\n        as(plan, LocalRelation.class);\n    }\n\n    public void testInvalidFoldDueToReplacement() {\n        var plan \u003d optimizedPlan(\"\"\"\n              from test\n            | eval x \u003d 1\n            | eval x \u003d emp_no\n            | where x \u003e 10\n            | keep x\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"x\"));\n        var child \u003d aliased(project.projections().get(0), FieldAttribute.class);\n        assertThat(Expressions.name(child), is(\"emp_no\"));\n        var limit \u003d as(project.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var source \u003d as(filter.child(), EsRelation.class);\n    }\n\n    public void testEnrich() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d to_string(languages)\n            | enrich languages_idx on x\n            \"\"\");\n        var enrich \u003d as(plan, Enrich.class);\n        assertTrue(enrich.policyName().resolved());\n        assertThat(enrich.policyName().fold(), is(BytesRefs.toBytesRef(\"languages_idx\")));\n        var eval \u003d as(enrich.child(), Eval.class);\n        var limit \u003d as(eval.child(), Limit.class);\n        as(limit.child(), EsRelation.class);\n    }\n\n    public void testPushDownEnrichPastProject() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval a \u003d to_string(languages)\n            | rename a as x\n            | keep x\n            | enrich languages_idx on x\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        as(keep.child(), Enrich.class);\n    }\n\n    public void testTopNEnrich() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename languages as x\n            | eval x \u003d to_string(x)\n            | keep x\n            | enrich languages_idx on x\n            | sort language_name\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var topN \u003d as(keep.child(), TopN.class);\n        as(topN.child(), Enrich.class);\n    }\n\n    public void testEnrichNotNullFilter() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d to_string(languages)\n            | enrich languages_idx on x\n            | where language_name is not null\n            | limit 10\n            \"\"\");\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var enrich \u003d as(filter.child(), Enrich.class);\n        assertTrue(enrich.policyName().resolved());\n        assertThat(enrich.policyName().fold(), is(BytesRefs.toBytesRef(\"languages_idx\")));\n        var eval \u003d as(enrich.child(), Eval.class);\n        as(eval.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * EsqlProject[[a{r}#3, last_name{f}#9]]\n     * \\_Eval[[__a_SUM_123{r}#12 / __a_COUNT_150{r}#13 AS a]]\n     *   \\_Limit[10000[INTEGER]]\n     *     \\_Aggregate[[last_name{f}#9],[SUM(salary{f}#10) AS __a_SUM_123, COUNT(salary{f}#10) AS __a_COUNT_150, last_nam\n     * e{f}#9]]\n     *       \\_EsRelation[test][_meta_field{f}#11, emp_no{f}#5, first_name{f}#6, !g..]\n     */\n    public void testSimpleAvgReplacement() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats a \u003d avg(salary) by last_name\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"a\", \"last_name\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var f \u003d eval.fields();\n        assertThat(f, hasSize(1));\n        assertThat(f.get(0).name(), is(\"a\"));\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var a \u003d as(aggs.get(0), Alias.class);\n        assertThat(a.name(), startsWith(\"$$SUM$a$\"));\n        var sum \u003d as(a.child(), Sum.class);\n\n        a \u003d as(aggs.get(1), Alias.class);\n        assertThat(a.name(), startsWith(\"$$COUNT$a$\"));\n        var count \u003d as(a.child(), Count.class);\n\n        assertThat(Expressions.names(agg.groupings()), contains(\"last_name\"));\n    }\n\n    /**\n     * Expects\n     * EsqlProject[[a{r}#3, c{r}#6, s{r}#9, last_name{f}#15]]\n     * \\_Eval[[s{r}#9 / c{r}#6 AS a]]\n     *   \\_Limit[10000[INTEGER]]\n     *     \\_Aggregate[[last_name{f}#15],[COUNT(salary{f}#16) AS c, SUM(salary{f}#16) AS s, last_name{f}#15]]\n     *       \\_EsRelation[test][_meta_field{f}#17, emp_no{f}#11, first_name{f}#12, ..]\n     */\n    public void testClashingAggAvgReplacement() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | stats a \u003d avg(salary), c \u003d count(salary), s \u003d sum(salary) by last_name\n            \"\"\");\n\n        assertThat(Expressions.names(plan.output()), contains(\"a\", \"c\", \"s\", \"last_name\"));\n        var project \u003d as(plan, Project.class);\n        var eval \u003d as(project.child(), Eval.class);\n        var f \u003d eval.fields();\n        assertThat(f, hasSize(1));\n        assertThat(f.get(0).name(), is(\"a\"));\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"c\", \"s\", \"last_name\"));\n    }\n\n    /**\n     * Expects\n     * EsqlProject[[a{r}#3, c{r}#6, s{r}#9, last_name{f}#15]]\n     * \\_Eval[[s{r}#9 / __a_COUNT@xxx{r}#18 AS a]]\n     *   \\_Limit[10000[INTEGER]]\n     *     \\_Aggregate[[last_name{f}#15],[COUNT(salary{f}#16) AS __a_COUNT@xxx, COUNT(languages{f}#14) AS c, SUM(salary{f}#16) AS\n     *  s, last_name{f}#15]]\n     *       \\_EsRelation[test][_meta_field{f}#17, emp_no{f}#11, first_name{f}#12, ..]\n     */\n    public void testSemiClashingAvgReplacement() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | stats a \u003d avg(salary), c \u003d count(languages), s \u003d sum(salary) by last_name\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"a\", \"c\", \"s\", \"last_name\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var f \u003d eval.fields();\n        assertThat(f, hasSize(1));\n        assertThat(f.get(0).name(), is(\"a\"));\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var a \u003d as(aggs.get(0), Alias.class);\n        assertThat(a.name(), startsWith(\"$$COUNT$a$0\"));\n        var sum \u003d as(a.child(), Count.class);\n\n        a \u003d as(aggs.get(1), Alias.class);\n        assertThat(a.name(), is(\"c\"));\n        var count \u003d as(a.child(), Count.class);\n\n        a \u003d as(aggs.get(2), Alias.class);\n        assertThat(a.name(), is(\"s\"));\n    }\n\n    /**\n     * Expected\n     * Limit[10000[INTEGER]]\n     * \\_Aggregate[[last_name{f}#9],[PERCENTILE(salary{f}#10,50[INTEGER]) AS m, last_name{f}#9]]\n     *   \\_EsRelation[test][_meta_field{f}#11, emp_no{f}#5, first_name{f}#6, !g..]\n     */\n    public void testMedianReplacement() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats m \u003d median(salary) by last_name\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"m\", \"last_name\"));\n        var aggs \u003d agg.aggregates();\n        var a \u003d as(aggs.get(0), Alias.class);\n        var per \u003d as(a.child(), Percentile.class);\n        var literal \u003d as(per.percentile(), Literal.class);\n        assertThat((int) QuantileStates.MEDIAN, is(literal.fold()));\n\n        assertThat(Expressions.names(agg.groupings()), contains(\"last_name\"));\n    }\n\n    public void testSplittingInWithFoldableValue() {\n        FieldAttribute fa \u003d getFieldAttribute(\"foo\");\n        In in \u003d new In(EMPTY, ONE, List.of(TWO, THREE, fa, L(null)));\n        Or expected \u003d new Or(EMPTY, new In(EMPTY, ONE, List.of(TWO, THREE)), new In(EMPTY, ONE, List.of(fa, L(null))));\n        assertThat(new LogicalPlanOptimizer.SplitInWithFoldableValue().rule(in), equalTo(expected));\n    }\n\n    public void testReplaceFilterWithExact() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | where job \u003d\u003d \"foo\"\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        Equals equals \u003d as(filter.condition(), Equals.class);\n        FieldAttribute left \u003d as(equals.left(), FieldAttribute.class);\n        assertThat(left.name(), equalTo(\"job\"));\n    }\n\n    public void testReplaceExpressionWithExact() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d job\n            \"\"\");\n\n        var eval \u003d as(plan, Eval.class);\n        var alias \u003d as(eval.fields().get(0), Alias.class);\n        var field \u003d as(alias.child(), FieldAttribute.class);\n        assertThat(field.name(), equalTo(\"job\"));\n    }\n\n    public void testReplaceSortWithExact() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | sort job\n            \"\"\");\n\n        var topN \u003d as(plan, TopN.class);\n        assertThat(topN.order().size(), equalTo(1));\n        var sortField \u003d as(topN.order().get(0).child(), FieldAttribute.class);\n        assertThat(sortField.name(), equalTo(\"job\"));\n    }\n\n    public void testPruneUnusedEval() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval garbage \u003d salary + 3\n            | keep salary\n            \"\"\");\n\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var source \u003d as(limit.child(), EsRelation.class);\n    }\n\n    public void testPruneChainedEval() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval garbage_a \u003d salary + 3\n            | eval garbage_b \u003d emp_no / garbage_a, garbage_c \u003d garbage_a\n            | eval garbage_x \u003d 1 - garbage_b/garbage_c\n            | keep salary\n            \"\"\");\n        var keep \u003d as(plan, Project.class);\n        var limit \u003d as(keep.child(), Limit.class);\n        var source \u003d as(limit.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[COUNT(salary{f}#1345) AS c]]\n     *   \\_EsRelation[test][_meta_field{f}#1346, emp_no{f}#1340, first_name{f}#..]\n     */\n    public void testPruneEvalDueToStats() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval garbage_a \u003d salary + 3, x \u003d salary\n            | eval garbage_b \u003d x + 3\n            | stats c \u003d count(x)\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var aggregate \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d aggregate.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"c\"));\n        aggFieldName(aggs.get(0), Count.class, \"salary\");\n        var source \u003d as(aggregate.child(), EsRelation.class);\n    }\n\n    public void testPruneUnusedAggSimple() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c \u003d count(salary), max \u003d max(salary), min \u003d min(salary)\n            | keep c\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(agg.groupings(), hasSize(0));\n        assertThat(agg.aggregates(), hasSize(1));\n        var aggOne \u003d as(agg.aggregates().get(0), Alias.class);\n        assertThat(aggOne.name(), is(\"c\"));\n        var count \u003d as(aggOne.child(), Count.class);\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[COUNT(salary{f}#19) AS x]]\n     *   \\_EsRelation[test][_meta_field{f}#20, emp_no{f}#14, first_name{f}#15, ..]\n     */\n    public void testPruneUnusedAggMixedWithEval() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c \u003d count(salary), max \u003d max(salary), min \u003d min(salary)\n            | eval x \u003d c\n            | keep x\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(agg.groupings(), hasSize(0));\n        var aggs \u003d agg.aggregates();\n        assertThat(aggs, hasSize(1));\n        assertThat(Expressions.names(aggs), contains(\"x\"));\n        aggFieldName(agg.aggregates().get(0), Count.class, \"salary\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    public void testPruneUnusedAggsChainedAgg() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c \u003d count(salary), max \u003d max(salary), min \u003d min(salary)\n            | eval x \u003d max + min + c\n            | eval y \u003d min\n            | eval z \u003d c\n            | keep c\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var limit \u003d as(project.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(agg.groupings(), hasSize(0));\n        var aggs \u003d agg.aggregates();\n        assertThat(aggs, hasSize(1));\n        assertThat(Expressions.names(aggs), contains(\"c\"));\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Project[[c{r}#342]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Filter[min{r}#348 \u003e 10[INTEGER]]\n     *     \\_Aggregate[[],[COUNT(salary{f}#367) AS c, MIN(salary{f}#367) AS min]]\n     *       \\_EsRelation[test][_meta_field{f}#368, emp_no{f}#362, first_name{f}#36..]\n     */\n    public void testPruneMixedAggInsideUnusedEval() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c \u003d count(salary), max \u003d max(salary), min \u003d min(salary)\n            | eval x \u003d max + min + c\n            | eval y \u003d min\n            | where y \u003e 10\n            | eval z \u003d c\n            | keep c\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var limit \u003d as(project.child(), Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var agg \u003d as(filter.child(), Aggregate.class);\n        assertThat(agg.groupings(), hasSize(0));\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"c\", \"min\"));\n        aggFieldName(aggs.get(0), Count.class, \"salary\");\n        aggFieldName(aggs.get(1), Min.class, \"salary\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Eval[[max{r}#6 + min{r}#9 + c{r}#3 AS x, min{r}#9 AS y, c{r}#3 AS z]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Aggregate[[],[COUNT(salary{f}#26) AS c, MAX(salary{f}#26) AS max, MIN(salary{f}#26) AS min]]\n     *     \\_EsRelation[test][_meta_field{f}#27, emp_no{f}#21, first_name{f}#22, ..]\n     */\n    public void testNoPruningWhenDealingJustWithEvals() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c \u003d count(salary), max \u003d max(salary), min \u003d min(salary)\n            | eval x \u003d max + min + c\n            | eval y \u003d min\n            | eval z \u003d c\n            \"\"\");\n\n        var eval \u003d as(plan, Eval.class);\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n    }\n\n    /**\n     * Expects\n     * Project[[y{r}#6 AS z]]\n     * \\_Eval[[emp_no{f}#11 + 1[INTEGER] AS y]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_EsRelation[test][_meta_field{f}#17, emp_no{f}#11, first_name{f}#12, ..]\n     */\n    public void testNoPruningWhenChainedEvals() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, y \u003d x + 1, z \u003d y\n            | keep z\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"z\"));\n        var eval \u003d as(project.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"y\"));\n        var limit \u003d as(eval.child(), Limit.class);\n        var source \u003d as(limit.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Project[[salary{f}#20 AS x, emp_no{f}#15 AS y]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_EsRelation[test][_meta_field{f}#21, emp_no{f}#15, first_name{f}#16, ..]\n     */\n    public void testPruningDuplicateEvals() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, x \u003d salary\n            | eval y \u003d salary\n            | eval y \u003d emp_no\n            | keep x, y\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var projections \u003d project.projections();\n        assertThat(Expressions.names(projections), contains(\"x\", \"y\"));\n        var child \u003d aliased(projections.get(0), FieldAttribute.class);\n        assertThat(child.name(), is(\"salary\"));\n        child \u003d aliased(projections.get(1), FieldAttribute.class);\n        assertThat(child.name(), is(\"emp_no\"));\n\n        var limit \u003d as(project.child(), Limit.class);\n        var source \u003d as(limit.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[COUNT(salary{f}#24) AS cx, COUNT(emp_no{f}#19) AS cy]]\n     *   \\_EsRelation[test][_meta_field{f}#25, emp_no{f}#19, first_name{f}#20, ..]\n     */\n    public void testPruneEvalAliasOnAggUngrouped() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, x \u003d salary\n            | eval y \u003d salary\n            | eval y \u003d emp_no\n            | stats cx \u003d count(x), cy \u003d count(y)\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cx\", \"cy\"));\n        aggFieldName(aggs.get(0), Count.class, \"salary\");\n        aggFieldName(aggs.get(1), Count.class, \"emp_no\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[x{r}#6],[COUNT(emp_no{f}#17) AS cy, salary{f}#22 AS x]]\n     *   \\_EsRelation[test][_meta_field{f}#23, emp_no{f}#17, first_name{f}#18, ..]\n     */\n    public void testPruneEvalAliasOnAggGroupedByAlias() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, x \u003d salary\n            | eval y \u003d salary\n            | eval y \u003d emp_no\n            | stats cy \u003d count(y) by x\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"x\"));\n        aggFieldName(aggs.get(0), Count.class, \"emp_no\");\n        var x \u003d aliased(aggs.get(1), FieldAttribute.class);\n        assertThat(x.name(), is(\"salary\"));\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#22],[COUNT(emp_no{f}#20) AS cy, MIN(salary{f}#25) AS cx, gender{f}#22]]\n     *   \\_EsRelation[test][_meta_field{f}#26, emp_no{f}#20, first_name{f}#21, ..]\n     */\n    public void testPruneEvalAliasOnAggGrouped() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, x \u003d salary\n            | eval y \u003d salary\n            | eval y \u003d emp_no\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"emp_no\");\n        aggFieldName(aggs.get(1), Min.class, \"salary\");\n        var by \u003d as(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(by), is(\"gender\"));\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#21],[COUNT(emp_no{f}#19) AS cy, MIN(salary{f}#24) AS cx, gender{f}#21]]\n     *   \\_EsRelation[test][_meta_field{f}#25, emp_no{f}#19, first_name{f}#20, ..]\n     */\n    public void testPruneEvalAliasMixedWithRenameOnAggGrouped() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no, x \u003d salary\n            | rename salary as x\n            | eval y \u003d emp_no\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"emp_no\");\n        aggFieldName(aggs.get(1), Min.class, \"salary\");\n        var by \u003d as(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(by), is(\"gender\"));\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#19],[COUNT(x{r}#3) AS cy, MIN(x{r}#3) AS cx, gender{f}#19]]\n     *   \\_Eval[[emp_no{f}#17 + 1[INTEGER] AS x]]\n     *     \\_EsRelation[test][_meta_field{f}#23, emp_no{f}#17, first_name{f}#18, ..]\n     */\n    public void testEvalAliasingAcrossCommands() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no + 1\n            | eval y \u003d x\n            | eval z \u003d y + 1\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"x\");\n        aggFieldName(aggs.get(1), Min.class, \"x\");\n        var by \u003d as(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(by), is(\"gender\"));\n        var eval \u003d as(agg.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"x\"));\n        var source \u003d as(eval.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#19],[COUNT(x{r}#3) AS cy, MIN(x{r}#3) AS cx, gender{f}#19]]\n     *   \\_Eval[[emp_no{f}#17 + 1[INTEGER] AS x]]\n     *     \\_EsRelation[test][_meta_field{f}#23, emp_no{f}#17, first_name{f}#18, ..]\n     */\n    public void testEvalAliasingInsideSameCommand() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no + 1, y \u003d x, z \u003d y + 1\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"x\");\n        aggFieldName(aggs.get(1), Min.class, \"x\");\n        var by \u003d as(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(by), is(\"gender\"));\n        var eval \u003d as(agg.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"x\"));\n        var source \u003d as(eval.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#22],[COUNT(z{r}#9) AS cy, MIN(x{r}#3) AS cx, gender{f}#22]]\n     *   \\_Eval[[emp_no{f}#20 + 1[INTEGER] AS x, x{r}#3 + 1[INTEGER] AS z]]\n     *     \\_EsRelation[test][_meta_field{f}#26, emp_no{f}#20, first_name{f}#21, ..]\n     */\n    public void testEvalAliasingInsideSameCommandWithShadowing() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d emp_no + 1, y \u003d x, z \u003d y + 1, y \u003d z\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"z\");\n        aggFieldName(aggs.get(1), Min.class, \"x\");\n        var by \u003d as(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(by), is(\"gender\"));\n        var eval \u003d as(agg.child(), Eval.class);\n        assertThat(Expressions.names(eval.fields()), contains(\"x\", \"z\"));\n        var source \u003d as(eval.child(), EsRelation.class);\n    }\n\n    public void testPruneRenameOnAgg() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | rename emp_no as x\n            | rename salary as y\n            | stats cy \u003d count(y), cx \u003d min(x) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"gender\"));\n        aggFieldName(aggs.get(0), Count.class, \"salary\");\n        aggFieldName(aggs.get(1), Min.class, \"emp_no\");\n\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#14],[COUNT(salary{f}#17) AS cy, MIN(emp_no{f}#12) AS cx, gender{f}#14]]\n     *   \\_EsRelation[test][_meta_field{f}#18, emp_no{f}#12, first_name{f}#13, ..]\n     */\n    public void testPruneRenameOnAggBy() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | rename emp_no as x\n            | rename salary as y, gender as g\n            | stats cy \u003d count(y), cx \u003d min(x) by g\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"cy\", \"cx\", \"g\"));\n        aggFieldName(aggs.get(0), Count.class, \"salary\");\n        aggFieldName(aggs.get(1), Min.class, \"emp_no\");\n        var groupby \u003d aliased(aggs.get(2), FieldAttribute.class);\n        assertThat(Expressions.name(groupby), is(\"gender\"));\n\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Project[[c1{r}#2, c2{r}#4, cs{r}#6, cm{r}#8, cexp{r}#10]]\n     * \\_Eval[[c1{r}#2 AS c2, c1{r}#2 AS cs, c1{r}#2 AS cm, c1{r}#2 AS cexp]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[],[COUNT([2a][KEYWORD]) AS c1]]\n     *       \\_EsRelation[test][_meta_field{f}#17, emp_no{f}#11, first_name{f}#12, ..]\n     */\n    @AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public void testEliminateDuplicateAggsCountAll() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats c1 \u003d count(1), c2 \u003d count(2), cs \u003d count(*), cm \u003d count(), cexp \u003d count(\"123\")\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"c1\", \"c2\", \"cs\", \"cm\", \"cexp\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(Expressions.names(fields), contains(\"c2\", \"cs\", \"cm\", \"cexp\"));\n        for (Alias field : fields) {\n            assertThat(Expressions.name(field.child()), is(\"c1\"));\n        }\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"c1\"));\n        aggFieldName(aggs.get(0), Count.class, \"*\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Project[[c1{r}#7, cx{r}#10, cs{r}#12, cy{r}#15]]\n     * \\_Eval[[c1{r}#7 AS cx, c1{r}#7 AS cs, c1{r}#7 AS cy]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[],[COUNT([2a][KEYWORD]) AS c1]]\n     *       \\_EsRelation[test][_meta_field{f}#22, emp_no{f}#16, first_name{f}#17, ..]\n     */\n    @AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public void testEliminateDuplicateAggsWithAliasedFields() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d 1\n            | eval y \u003d x\n            | stats c1 \u003d count(1), cx \u003d count(x), cs \u003d count(*), cy \u003d count(y)\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"c1\", \"cx\", \"cs\", \"cy\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(Expressions.names(fields), contains(\"cx\", \"cs\", \"cy\"));\n        for (Alias field : fields) {\n            assertThat(Expressions.name(field.child()), is(\"c1\"));\n        }\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"c1\"));\n        aggFieldName(aggs.get(0), Count.class, \"*\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Project[[min{r}#1385, max{r}#1388, min{r}#1385 AS min2, max{r}#1388 AS max2, gender{f}#1398]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Aggregate[[gender{f}#1398],[MIN(salary{f}#1401) AS min, MAX(salary{f}#1401) AS max, gender{f}#1398]]\n     *     \\_EsRelation[test][_meta_field{f}#1402, emp_no{f}#1396, first_name{f}#..]\n     */\n    public void testEliminateDuplicateAggsMixed() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | stats min \u003d min(salary), max \u003d max(salary), min2 \u003d min(salary), max2 \u003d max(salary) by gender\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var projections \u003d project.projections();\n        assertThat(Expressions.names(projections), contains(\"min\", \"max\", \"min2\", \"max2\", \"gender\"));\n        as(projections.get(0), ReferenceAttribute.class);\n        as(projections.get(1), ReferenceAttribute.class);\n        assertThat(Expressions.name(aliased(projections.get(2), ReferenceAttribute.class)), is(\"min\"));\n        assertThat(Expressions.name(aliased(projections.get(3), ReferenceAttribute.class)), is(\"max\"));\n\n        var limit \u003d as(project.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"min\", \"max\", \"gender\"));\n        aggFieldName(aggs.get(0), Min.class, \"salary\");\n        aggFieldName(aggs.get(1), Max.class, \"salary\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * EsqlProject[[a{r}#5, c{r}#8]]\n     * \\_Eval[[null[INTEGER] AS x]]\n     *   \\_EsRelation[test][_meta_field{f}#15, emp_no{f}#9, first_name{f}#10, g..]\n     */\n    @AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public void testEliminateDuplicateAggWithNull() {\n        var plan \u003d plan(\"\"\"\n              from test\n            | eval x \u003d null + 1\n            | stats a \u003d avg(x), c \u003d count(x)\n            \"\"\");\n        fail(\"Awaits fix\");\n    }\n\n    /**\n     * Expects\n     * Project[[max(x){r}#11, max(x){r}#11 AS max(y), max(x){r}#11 AS max(z)]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Aggregate[[],[MAX(salary{f}#21) AS max(x)]]\n     *     \\_EsRelation[test][_meta_field{f}#22, emp_no{f}#16, first_name{f}#17, ..]\n     */\n    public void testEliminateDuplicateAggsNonCount() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | eval x \u003d salary\n            | eval y \u003d x\n            | eval z \u003d y\n            | stats max(x), max(y), max(z)\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var projections \u003d project.projections();\n        assertThat(Expressions.names(projections), contains(\"max(x)\", \"max(y)\", \"max(z)\"));\n        as(projections.get(0), ReferenceAttribute.class);\n        assertThat(Expressions.name(aliased(projections.get(1), ReferenceAttribute.class)), is(\"max(x)\"));\n        assertThat(Expressions.name(aliased(projections.get(2), ReferenceAttribute.class)), is(\"max(x)\"));\n\n        var limit \u003d as(project.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(Expressions.names(aggs), contains(\"max(x)\"));\n        aggFieldName(aggs.get(0), Max.class, \"salary\");\n        var source \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[2[INTEGER]]\n     * \\_Filter[a{r}#6 \u003e 2[INTEGER]]\n     *   \\_MvExpand[a{r}#2,a{r}#6]\n     *     \\_Row[[[1, 2, 3][INTEGER] AS a]]\n     */\n    public void testMvExpandFoldable() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            row a \u003d [1, 2, 3]\n            | mv_expand a\n            | where a \u003e 2\n            | limit 2\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var filter \u003d as(limit.child(), Filter.class);\n        var expand \u003d as(filter.child(), MvExpand.class);\n        assertThat(filter.condition(), instanceOf(GreaterThan.class));\n        var filterProp \u003d ((GreaterThan) filter.condition()).left();\n        assertTrue(expand.expanded().semanticEquals(filterProp));\n        assertFalse(expand.target().semanticEquals(filterProp));\n        var row \u003d as(expand.child(), Row.class);\n    }\n\n    /**\n     * Expected\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[a{r}#2],[COUNT([2a][KEYWORD]) AS bar]]\n     *   \\_Row[[1[INTEGER] AS a]]\n     */\n    public void testRenameStatsDropGroup() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            row a \u003d 1\n            | rename a AS foo\n            | stats bar \u003d count(*) by foo\n            | drop foo\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"a\"));\n        var row \u003d as(agg.child(), Row.class);\n    }\n\n    /**\n     * Expected\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[a{r}#2, bar{r}#8],[COUNT([2a][KEYWORD]) AS baz, b{r}#4 AS bar]]\n     *   \\_Row[[1[INTEGER] AS a, 2[INTEGER] AS b]]\n     */\n    public void testMultipleRenameStatsDropGroup() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            row a \u003d 1, b \u003d 2\n            | rename a AS foo, b as bar\n            | stats baz \u003d count(*) by foo, bar\n            | drop foo\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"a\", \"bar\"));\n        var row \u003d as(agg.child(), Row.class);\n    }\n\n    /**\n     * Expected\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[emp_no{f}#11, bar{r}#4],[MAX(salary{f}#16) AS baz, gender{f}#13 AS bar]]\n     *   \\_EsRelation[test][_meta_field{f}#17, emp_no{f}#11, first_name{f}#12, ..]\n     */\n    public void testMultipleRenameStatsDropGroupMultirow() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | rename emp_no AS foo, gender as bar\n            | stats baz \u003d max(salary) by foo, bar\n            | drop foo\"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"emp_no\", \"bar\"));\n        var row \u003d as(agg.child(), EsRelation.class);\n    }\n\n    public void testLimitZeroUsesLocalRelation() {\n        LogicalPlan plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats count\u003dcount(*)\n            | sort count desc\n            | limit 0\"\"\");\n\n        assertThat(plan, instanceOf(LocalRelation.class));\n    }\n\n    private \u003cT\u003e T aliased(Expression exp, Class\u003cT\u003e clazz) {\n        var alias \u003d as(exp, Alias.class);\n        return as(alias.child(), clazz);\n    }\n\n    private \u003cT extends AggregateFunction\u003e void aggFieldName(Expression exp, Class\u003cT\u003e aggType, String fieldName) {\n        var alias \u003d as(exp, Alias.class);\n        var af \u003d as(alias.child(), aggType);\n        var field \u003d af.field();\n        var name \u003d field.foldable() ? BytesRefs.toString(field.fold()) : Expressions.name(field);\n        assertThat(name, is(fieldName));\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[SUM(emp_no{f}#4) AS sum(emp_no)]]\n     *   \\_EsRelation[test][_meta_field{f}#10, emp_no{f}#4, first_name{f}#5, ge..]\n     */\n    public void testIsNotNullConstraintForStatsWithoutGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats sum(emp_no)\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), is(empty()));\n        assertThat(Expressions.names(agg.aggregates()), contains(\"sum(emp_no)\"));\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    public void testIsNotNullConstraintForStatsWithGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats sum(emp_no) by salary\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"salary\"));\n        assertThat(Expressions.names(agg.aggregates()), contains(\"sum(emp_no)\", \"salary\"));\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expected\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[salary{f}#1185],[SUM(salary{f}#1185) AS sum(salary), salary{f}#1185]]\n     *   \\_EsRelation[test][_meta_field{f}#1186, emp_no{f}#1180, first_name{f}#..]\n     */\n    public void testIsNotNullConstraintForStatsWithAndOnGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats sum(salary) by salary\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"salary\"));\n        assertThat(Expressions.names(agg.aggregates()), contains(\"sum(salary)\", \"salary\"));\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[x{r}#4],[SUM(salary{f}#13) AS sum(salary), salary{f}#13 AS x]]\n     *   \\_EsRelation[test][_meta_field{f}#14, emp_no{f}#8, first_name{f}#9, ge..]\n     */\n    public void testIsNotNullConstraintForStatsWithAndOnGroupingAlias() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d salary\n            | stats sum(salary) by x\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"x\"));\n        assertThat(Expressions.names(agg.aggregates()), contains(\"sum(salary)\", \"x\"));\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[salary{f}#13],[SUM(emp_no{f}#8) AS sum(x), salary{f}#13]]\n     *   \\_EsRelation[test][_meta_field{f}#14, emp_no{f}#8, first_name{f}#9, ge..]\n     */\n    public void testIsNotNullConstraintSkippedForStatsWithAlias() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d emp_no\n            | stats sum(x) by salary\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.groupings()), contains(\"salary\"));\n        assertThat(Expressions.names(agg.aggregates()), contains(\"sum(x)\", \"salary\"));\n\n        // non null filter for stats\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[SUM(emp_no{f}#8) AS a, MIN(salary{f}#13) AS b]]\n     *   \\_EsRelation[test][_meta_field{f}#14, emp_no{f}#8, first_name{f}#9, ge..]\n     */\n    public void testIsNotNullConstraintForStatsWithMultiAggWithoutGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d sum(emp_no), b \u003d min(salary)\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"a\", \"b\"));\n\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[gender{f}#11],[SUM(emp_no{f}#9) AS a, MIN(salary{f}#14) AS b, gender{f}#11]]\n     *   \\_EsRelation[test][_meta_field{f}#15, emp_no{f}#9, first_name{f}#10, g..]\n     */\n    public void testIsNotNullConstraintForStatsWithMultiAggWithGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d sum(emp_no), b \u003d min(salary) by gender\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"a\", \"b\", \"gender\"));\n\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[emp_no{f}#9],[SUM(emp_no{f}#9) AS a, MIN(salary{f}#14) AS b, emp_no{f}#9]]\n     *   \\_EsRelation[test][_meta_field{f}#15, emp_no{f}#9, first_name{f}#10, g..]\n     */\n    public void testIsNotNullConstraintForStatsWithMultiAggWithAndOnGrouping() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d sum(emp_no), b \u003d min(salary) by emp_no\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"a\", \"b\", \"emp_no\"));\n\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[w{r}#14, g{r}#16],[COUNT(b{r}#24) AS c, w{r}#14, gender{f}#32 AS g]]\n     *   \\_Eval[[emp_no{f}#30 / 10[INTEGER] AS x, x{r}#4 + salary{f}#35 AS y, y{r}#8 / 4[INTEGER] AS z, z{r}#11 * 2[INTEGER] +\n     *  3[INTEGER] AS w, salary{f}#35 + 4[INTEGER] / 2[INTEGER] AS a, a{r}#21 + 3[INTEGER] AS b]]\n     *     \\_EsRelation[test][_meta_field{f}#36, emp_no{f}#30, first_name{f}#31, ..]\n     */\n    public void testIsNotNullConstraintForAliasedExpressions() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | eval x \u003d emp_no / 10\n            | eval y \u003d x + salary\n            | eval z \u003d y / 4\n            | eval w \u003d z * 2 + 3\n            | rename gender as g, salary as s\n            | eval a \u003d (s + 4) / 2\n            | eval b \u003d a + 3\n            | stats c \u003d count(b) by w, g\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"c\", \"w\", \"g\"));\n        var eval \u003d as(agg.child(), Eval.class);\n        var from \u003d as(eval.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[],[SPATIALCENTROID(location{f}#9) AS centroid]]\n     *   \\_EsRelation[airports][abbrev{f}#5, location{f}#9, name{f}#6, scalerank{f}..]\n     */\n    public void testSpatialTypesAndStatsUseDocValues() {\n        var plan \u003d planAirports(\"\"\"\n            from test\n            | stats centroid \u003d st_centroid(location)\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.aggregates()), contains(\"centroid\"));\n        assertTrue(\"Expected GEO_POINT aggregation for STATS\", agg.aggregates().stream().allMatch(aggExp -\u003e {\n            var alias \u003d as(aggExp, Alias.class);\n            var aggFunc \u003d as(alias.child(), AggregateFunction.class);\n            var aggField \u003d as(aggFunc.field(), FieldAttribute.class);\n            return aggField.dataType() \u003d\u003d GEO_POINT;\n        }));\n\n        var from \u003d as(agg.child(), EsRelation.class);\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[emp_no%2{r}#6],[COUNT(salary{f}#12) AS c, emp_no%2{r}#6]]\n     *   \\_Eval[[emp_no{f}#7 % 2[INTEGER] AS emp_no%2]]\n     *     \\_EsRelation[test][_meta_field{f}#13, emp_no{f}#7, first_name{f}#8, ge..]\n     */\n    public void testNestedExpressionsInGroups() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats c \u003d count(salary) by emp_no % 2\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var groupings \u003d agg.groupings();\n        var aggs \u003d agg.aggregates();\n        var ref \u003d as(groupings.get(0), ReferenceAttribute.class);\n        assertThat(aggs.get(1), is(ref));\n        var eval \u003d as(agg.child(), Eval.class);\n        assertThat(eval.fields(), hasSize(1));\n        assertThat(eval.fields().get(0).toAttribute(), is(ref));\n        assertThat(eval.fields().get(0).name(), is(\"emp_no % 2\"));\n    }\n\n    /**\n     * Expects\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[emp_no{f}#6],[COUNT(__c_COUNT@1bd45f36{r}#16) AS c, emp_no{f}#6]]\n     *   \\_Eval[[salary{f}#11 + 1[INTEGER] AS __c_COUNT@1bd45f36]]\n     *     \\_EsRelation[test][_meta_field{f}#12, emp_no{f}#6, first_name{f}#7, ge..]\n     */\n    public void testNestedExpressionsInAggs() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats c \u003d count(salary + 1) by emp_no\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var count \u003d aliased(aggs.get(0), Count.class);\n        var ref \u003d as(count.field(), ReferenceAttribute.class);\n        var eval \u003d as(agg.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(fields, hasSize(1));\n        assertThat(fields.get(0).toAttribute(), is(ref));\n        var add \u003d aliased(fields.get(0), Add.class);\n        assertThat(Expressions.name(add.left()), is(\"salary\"));\n    }\n\n    /**\n     * Limit[1000[INTEGER]]\n     * \\_Aggregate[[emp_no%2{r}#7],[COUNT(__c_COUNT@fb7855b0{r}#18) AS c, emp_no%2{r}#7]]\n     *   \\_Eval[[emp_no{f}#8 % 2[INTEGER] AS emp_no%2, 100[INTEGER] / languages{f}#11 + salary{f}#13 + 1[INTEGER] AS __c_COUNT\n     * @fb7855b0]]\n     *     \\_EsRelation[test][_meta_field{f}#14, emp_no{f}#8, first_name{f}#9, ge..]\n     */\n    public void testNestedExpressionsInBothAggsAndGroups() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats c \u003d count(salary + 1 + 100 / languages) by emp_no % 2\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var groupings \u003d agg.groupings();\n        var aggs \u003d agg.aggregates();\n        var gRef \u003d as(groupings.get(0), ReferenceAttribute.class);\n        assertThat(aggs.get(1), is(gRef));\n\n        var count \u003d aliased(aggs.get(0), Count.class);\n        var aggRef \u003d as(count.field(), ReferenceAttribute.class);\n        var eval \u003d as(agg.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(fields, hasSize(2));\n        assertThat(fields.get(0).toAttribute(), is(gRef));\n        assertThat(fields.get(1).toAttribute(), is(aggRef));\n\n        var mod \u003d aliased(fields.get(0), Mod.class);\n        assertThat(Expressions.name(mod.left()), is(\"emp_no\"));\n        var refs \u003d Expressions.references(singletonList(fields.get(1)));\n        assertThat(Expressions.names(refs), containsInAnyOrder(\"languages\", \"salary\"));\n    }\n\n    public void testNestedMultiExpressionsInGroupingAndAggs() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats count(salary + 1), max(salary   +  23) by languages   + 1, emp_no %  3\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        assertThat(Expressions.names(agg.output()), contains(\"count(salary + 1)\", \"max(salary   +  23)\", \"languages   + 1\", \"emp_no %  3\"));\n    }\n\n    public void testLogicalPlanOptimizerVerifier() {\n        var plan \u003d plan(\"\"\"\n            from test\n            | eval bucket_start \u003d 1, bucket_end \u003d 100000\n            | eval auto_bucket(salary, 10, bucket_start, bucket_end)\n            \"\"\");\n        var ab \u003d as(plan, Eval.class);\n        assertTrue(ab.optimized());\n    }\n\n    public void testLogicalPlanOptimizerVerificationException() {\n        VerificationException e \u003d expectThrows(VerificationException.class, () -\u003e plan(\"\"\"\n            from test\n            | eval bucket_end \u003d 100000\n            | eval auto_bucket(salary, 10, emp_no, bucket_end)\n            \"\"\"));\n        assertTrue(e.getMessage().startsWith(\"Found \"));\n        final String header \u003d \"Found 1 problem\\nline \";\n        assertEquals(\n            \"3:32: third argument of [auto_bucket(salary, 10, emp_no, bucket_end)] must be a constant, received [emp_no]\",\n            e.getMessage().substring(header.length())\n        );\n    }\n\n    /**\n     * Expects\n     * Project[[x{r}#5]]\n     * \\_Eval[[____x_AVG@9efc3cf3_SUM@daf9f221{r}#18 / ____x_AVG@9efc3cf3_COUNT@53cd08ed{r}#19 AS __x_AVG@9efc3cf3, __x_AVG@\n     * 9efc3cf3{r}#16 / 2[INTEGER] + __x_MAX@475d0e4d{r}#17 AS x]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[],[SUM(salary{f}#11) AS ____x_AVG@9efc3cf3_SUM@daf9f221, COUNT(salary{f}#11) AS ____x_AVG@9efc3cf3_COUNT@53cd0\n     * 8ed, MAX(salary{f}#11) AS __x_MAX@475d0e4d]]\n     *       \\_EsRelation[test][_meta_field{f}#12, emp_no{f}#6, first_name{f}#7, ge..]\n     */\n    public void testStatsExpOverAggs() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats x \u003d avg(salary) /2 + max(salary)\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"x\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(Expressions.name(fields.get(1)), is(\"x\"));\n        // sum/count to compute avg\n        var div \u003d as(fields.get(0).child(), Div.class);\n        // avg + max\n        var add \u003d as(fields.get(1).child(), Add.class);\n        var limit \u003d as(eval.child(), Limit.class);\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        assertThat(aggs, hasSize(3));\n        var sum \u003d as(Alias.unwrap(aggs.get(0)), Sum.class);\n        assertThat(Expressions.name(sum.field()), is(\"salary\"));\n        var count \u003d as(Alias.unwrap(aggs.get(1)), Count.class);\n        assertThat(Expressions.name(count.field()), is(\"salary\"));\n        var max \u003d as(Alias.unwrap(aggs.get(2)), Max.class);\n        assertThat(Expressions.name(max.field()), is(\"salary\"));\n    }\n\n    /**\n     * Expects\n     * Project[[x{r}#5, y{r}#9, z{r}#12]]\n     * \\_Eval[[$$SUM$$$AVG$avg(salary_%_3)\u003e$0$0{r}#29 / $$COUNT$$$AVG$avg(salary_%_3)\u003e$0$1{r}#30 AS $$AVG$avg(salary_%_3)\u003e$0,\n     *   $$AVG$avg(salary_%_3)\u003e$0{r}#23 + $$MAX$avg(salary_%_3)\u003e$1{r}#24 AS x,\n     *   $$MIN$min(emp_no_/_3)\u003e$2{r}#25 + 10[INTEGER] - $$MEDIAN$min(emp_no_/_3)\u003e$3{r}#26 AS y]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[z{r}#12],[SUM($$salary_%_3$AVG$0{r}#27) AS $$SUM$$$AVG$avg(salary_%_3)\u003e$0$0,\n     *     COUNT($$salary_%_3$AVG$0{r}#27) AS $$COUNT$$$AVG$avg(salary_%_3)\u003e$0$1,\n     *     MAX(emp_no{f}#13) AS $$MAX$avg(salary_%_3)\u003e$1,\n     *     MIN($$emp_no_/_3$MIN$1{r}#28) AS $$MIN$min(emp_no_/_3)\u003e$2,\n     *     PERCENTILE(salary{f}#18,50[INTEGER]) AS $$MEDIAN$min(emp_no_/_3)\u003e$3, z{r}#12]]\n     *       \\_Eval[[languages{f}#16 % 2[INTEGER] AS z,\n     *       salary{f}#18 % 3[INTEGER] AS $$salary_%_3$AVG$0,\n     *       emp_no{f}#13 / 3[INTEGER] AS $$emp_no_/_3$MIN$1]]\n     *         \\_EsRelation[test][_meta_field{f}#19, emp_no{f}#13, first_name{f}#14, ..]\n     */\n    public void testStatsExpOverAggsMulti() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats x \u003d avg(salary % 3) + max(emp_no), y \u003d min(emp_no / 3) + 10 - median(salary) by z \u003d languages % 2\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"x\", \"y\", \"z\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        // avg \u003d Sum/Count\n        assertThat(Expressions.name(fields.get(0)), containsString(\"AVG\"));\n        assertThat(Alias.unwrap(fields.get(0)), instanceOf(Div.class));\n        // avg + max\n        assertThat(Expressions.name(fields.get(1)), containsString(\"x\"));\n        assertThat(Alias.unwrap(fields.get(1)), instanceOf(Add.class));\n        // min + 10 - median\n        assertThat(Expressions.name(fields.get(2)), containsString(\"y\"));\n        assertThat(Alias.unwrap(fields.get(2)), instanceOf(Sub.class));\n\n        var limit \u003d as(eval.child(), Limit.class);\n\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var sum \u003d as(Alias.unwrap(aggs.get(0)), Sum.class);\n        var count \u003d as(Alias.unwrap(aggs.get(1)), Count.class);\n        var max \u003d as(Alias.unwrap(aggs.get(2)), Max.class);\n        var min \u003d as(Alias.unwrap(aggs.get(3)), Min.class);\n        var percentile \u003d as(Alias.unwrap(aggs.get(4)), Percentile.class);\n\n        eval \u003d as(agg.child(), Eval.class);\n        fields \u003d eval.fields();\n        assertThat(Expressions.name(fields.get(0)), is(\"z\"));\n        assertThat(Expressions.name(fields.get(1)), containsString(\"AVG\"));\n        assertThat(Expressions.name(Alias.unwrap(fields.get(1))), containsString(\"salary\"));\n        assertThat(Expressions.name(fields.get(2)), containsString(\"MIN\"));\n        assertThat(Expressions.name(Alias.unwrap(fields.get(2))), containsString(\"emp_no\"));\n    }\n\n    /**\n     * Expects\n     * Project[[x{r}#5, y{r}#9, z{r}#12]]\n     * \\_Eval[[$$SUM$$$AVG$CONCAT(TO_STRIN\u003e$0$0{r}#29 / $$COUNT$$$AVG$CONCAT(TO_STRIN\u003e$0$1{r}#30 AS $$AVG$CONCAT(TO_STRIN\u003e$0,\n     *        CONCAT(TOSTRING($$AVG$CONCAT(TO_STRIN\u003e$0{r}#23),TOSTRING($$MAX$CONCAT(TO_STRIN\u003e$1{r}#24)) AS x,\n     *        $$MIN$(MIN(emp_no_/_3\u003e$2{r}#25 + 3.141592653589793[DOUBLE] - $$MEDIAN$(MIN(emp_no_/_3\u003e$3{r}#26 / 2.718281828459045[DOUBLE]\n     *         AS y]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[z{r}#12],[SUM($$salary_%_3$AVG$0{r}#27) AS $$SUM$$$AVG$CONCAT(TO_STRIN\u003e$0$0,\n     *      COUNT($$salary_%_3$AVG$0{r}#27) AS $$COUNT$$$AVG$CONCAT(TO_STRIN\u003e$0$1,\n     *      MAX(emp_no{f}#13) AS $$MAX$CONCAT(TO_STRIN\u003e$1,\n     *      MIN($$emp_no_/_3$MIN$1{r}#28) AS $$MIN$(MIN(emp_no_/_3\u003e$2,\n     *      PERCENTILE(salary{f}#18,50[INTEGER]) AS $$MEDIAN$(MIN(emp_no_/_3\u003e$3, z{r}#12]]\n     *       \\_Eval[[languages{f}#16 % 2[INTEGER] AS z,\n     *       salary{f}#18 % 3[INTEGER] AS $$salary_%_3$AVG$0,\n     *       emp_no{f}#13 / 3[INTEGER] AS $$emp_no_/_3$MIN$1]]\n     *         \\_EsRelation[test][_meta_field{f}#19, emp_no{f}#13, first_name{f}#14, ..]\n     */\n    public void testStatsExpOverAggsWithScalars() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats x \u003d CONCAT(TO_STRING(AVG(salary % 3)), TO_STRING(MAX(emp_no))),\n                    y \u003d (MIN(emp_no / 3) + PI() - MEDIAN(salary))/E()\n                    by z \u003d languages % 2\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"x\", \"y\", \"z\"));\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        // avg \u003d Sum/Count\n        assertThat(Expressions.name(fields.get(0)), containsString(\"AVG\"));\n        assertThat(Alias.unwrap(fields.get(0)), instanceOf(Div.class));\n        // concat(to_string(avg)\n        assertThat(Expressions.name(fields.get(1)), containsString(\"x\"));\n        var concat \u003d as(Alias.unwrap(fields.get(1)), Concat.class);\n        var toString \u003d as(concat.children().get(0), ToString.class);\n        toString \u003d as(concat.children().get(1), ToString.class);\n        // min + 10 - median/e\n        assertThat(Expressions.name(fields.get(2)), containsString(\"y\"));\n        assertThat(Alias.unwrap(fields.get(2)), instanceOf(Div.class));\n\n        var limit \u003d as(eval.child(), Limit.class);\n\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var sum \u003d as(Alias.unwrap(aggs.get(0)), Sum.class);\n        var count \u003d as(Alias.unwrap(aggs.get(1)), Count.class);\n        var max \u003d as(Alias.unwrap(aggs.get(2)), Max.class);\n        var min \u003d as(Alias.unwrap(aggs.get(3)), Min.class);\n        var percentile \u003d as(Alias.unwrap(aggs.get(4)), Percentile.class);\n        assertThat(Expressions.name(aggs.get(5)), is(\"z\"));\n\n        eval \u003d as(agg.child(), Eval.class);\n        fields \u003d eval.fields();\n        assertThat(Expressions.name(fields.get(0)), is(\"z\"));\n        assertThat(Expressions.name(fields.get(1)), containsString(\"AVG\"));\n        assertThat(Expressions.name(Alias.unwrap(fields.get(1))), containsString(\"salary\"));\n        assertThat(Expressions.name(fields.get(2)), containsString(\"MIN\"));\n        assertThat(Expressions.name(Alias.unwrap(fields.get(2))), containsString(\"emp_no\"));\n    }\n\n    /**\n     * Expects\n     * Project[[a{r}#5, b{r}#9, $$max(salary)_+_3\u003e$COUNT$2{r}#46 AS d, $$count(salary)_-\u003e$MIN$3{r}#47 AS e, $$avg(salary)_+_m\n     * \u003e$MAX$1{r}#45 AS g]]\n     * \\_Eval[[$$$$avg(salary)_+_m\u003e$AVG$0$SUM$0{r}#48 / $$max(salary)_+_3\u003e$COUNT$2{r}#46 AS $$avg(salary)_+_m\u003e$AVG$0, $$avg(\n     * salary)_+_m\u003e$AVG$0{r}#44 + $$avg(salary)_+_m\u003e$MAX$1{r}#45 AS a, $$avg(salary)_+_m\u003e$MAX$1{r}#45 + 3[INTEGER] +\n     * 3.141592653589793[DOUBLE] + $$max(salary)_+_3\u003e$COUNT$2{r}#46 AS b]]\n     *   \\_Limit[1000[INTEGER]]\n     *     \\_Aggregate[[w{r}#28],[SUM(salary{f}#39) AS $$$$avg(salary)_+_m\u003e$AVG$0$SUM$0, MAX(salary{f}#39) AS $$avg(salary)_+_m\u003e$MAX$1\n     * , COUNT(salary{f}#39) AS $$max(salary)_+_3\u003e$COUNT$2, MIN(salary{f}#39) AS $$count(salary)_-\u003e$MIN$3]]\n     *       \\_Eval[[languages{f}#37 % 2[INTEGER] AS w]]\n     *         \\_EsRelation[test][_meta_field{f}#40, emp_no{f}#34, first_name{f}#35, ..]\n     */\n    public void testStatsExpOverAggsWithScalarAndDuplicateAggs() {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d avg(salary) + max(salary),\n                    b \u003d max(salary) + 3 + PI() + count(salary),\n                    c \u003d count(salary) - min(salary),\n                    d \u003d count(salary),\n                    e \u003d min(salary),\n                    f \u003d max(salary),\n                    g \u003d max(salary)\n                    by w \u003d languages % 2\n            | keep a, b, d, e, g\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        var projections \u003d project.projections();\n        assertThat(Expressions.names(projections), contains(\"a\", \"b\", \"d\", \"e\", \"g\"));\n        var refA \u003d Alias.unwrap(projections.get(0));\n        var refB \u003d Alias.unwrap(projections.get(1));\n        var refD \u003d Alias.unwrap(projections.get(2));\n        var refE \u003d Alias.unwrap(projections.get(3));\n        var refG \u003d Alias.unwrap(projections.get(4));\n\n        var eval \u003d as(project.child(), Eval.class);\n        var fields \u003d eval.fields();\n        // avg \u003d Sum/Count\n        assertThat(Expressions.name(fields.get(0)), containsString(\"AVG\"));\n        assertThat(Alias.unwrap(fields.get(0)), instanceOf(Div.class));\n        // avg + max\n        assertThat(Expressions.name(fields.get(1)), is(\"a\"));\n        var add \u003d as(Alias.unwrap(fields.get(1)), Add.class);\n        var max_salary \u003d add.right();\n        assertThat(Expressions.attribute(fields.get(1)), is(Expressions.attribute(refA)));\n\n        assertThat(Expressions.name(fields.get(2)), is(\"b\"));\n        assertThat(Expressions.attribute(fields.get(2)), is(Expressions.attribute(refB)));\n\n        add \u003d as(Alias.unwrap(fields.get(2)), Add.class);\n        add \u003d as(add.left(), Add.class);\n        add \u003d as(add.left(), Add.class);\n        assertThat(Expressions.attribute(max_salary), is(Expressions.attribute(add.left())));\n\n        var limit \u003d as(eval.child(), Limit.class);\n\n        var agg \u003d as(limit.child(), Aggregate.class);\n        var aggs \u003d agg.aggregates();\n        var sum \u003d as(Alias.unwrap(aggs.get(0)), Sum.class);\n\n        assertThat(Expressions.attribute(aggs.get(1)), is(Expressions.attribute(max_salary)));\n        var max \u003d as(Alias.unwrap(aggs.get(1)), Max.class);\n        var count \u003d as(Alias.unwrap(aggs.get(2)), Count.class);\n        var min \u003d as(Alias.unwrap(aggs.get(3)), Min.class);\n\n        eval \u003d as(agg.child(), Eval.class);\n        fields \u003d eval.fields();\n        assertThat(Expressions.name(fields.get(0)), is(\"w\"));\n    }\n\n    /**\n     * Expects\n     * Project[[a{r}#5, a{r}#5 AS b, w{r}#12]]\n     * \\_Limit[1000[INTEGER]]\n     *   \\_Aggregate[[w{r}#12],[SUM($$salary_/_2_+_la\u003e$SUM$0{r}#26) AS a, w{r}#12]]\n     *     \\_Eval[[emp_no{f}#16 % 2[INTEGER] AS w, salary{f}#21 / 2[INTEGER] + languages{f}#19 AS $$salary_/_2_+_la\u003e$SUM$0]]\n     *       \\_EsRelation[test][_meta_field{f}#22, emp_no{f}#16, first_name{f}#17, ..]\n     */\n    public void testStatsWithCanonicalAggregate() throws Exception {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d sum(salary / 2 + languages),\n                    b \u003d sum(languages + salary / 2)\n                    by w \u003d emp_no % 2\n            | keep a, b, w\n            \"\"\");\n\n        var project \u003d as(plan, Project.class);\n        assertThat(Expressions.names(project.projections()), contains(\"a\", \"b\", \"w\"));\n        assertThat(Expressions.name(Alias.unwrap(project.projections().get(1))), is(\"a\"));\n        var limit \u003d as(project.child(), Limit.class);\n        var aggregate \u003d as(limit.child(), Aggregate.class);\n        var aggregates \u003d aggregate.aggregates();\n        assertThat(Expressions.names(aggregates), contains(\"a\", \"w\"));\n        var unwrapped \u003d Alias.unwrap(aggregates.get(0));\n        var sum \u003d as(unwrapped, Sum.class);\n        var sum_argument \u003d sum.field();\n        var grouping \u003d aggregates.get(1);\n\n        var eval \u003d as(aggregate.child(), Eval.class);\n        var fields \u003d eval.fields();\n        assertThat(Expressions.attribute(fields.get(0)), is(Expressions.attribute(grouping)));\n        assertThat(Expressions.attribute(fields.get(1)), is(Expressions.attribute(sum_argument)));\n    }\n\n    public void testEmptyMappingIndex() {\n        EsIndex empty \u003d new EsIndex(\"empty_test\", emptyMap(), emptySet());\n        IndexResolution getIndexResultAirports \u003d IndexResolution.valid(empty);\n        var analyzer \u003d new Analyzer(\n            new AnalyzerContext(EsqlTestUtils.TEST_CFG, new EsqlFunctionRegistry(), getIndexResultAirports, enrichResolution),\n            TEST_VERIFIER\n        );\n\n        var plan \u003d logicalOptimizer.optimize(analyzer.analyze(parser.createStatement(\"from empty_test\")));\n        as(plan, LocalRelation.class);\n        assertThat(plan.output(), equalTo(NO_FIELDS));\n\n        plan \u003d logicalOptimizer.optimize(analyzer.analyze(parser.createStatement(\"from empty_test metadata _id | eval x \u003d 1\")));\n        as(plan, LocalRelation.class);\n        assertThat(Expressions.names(plan.output()), contains(\"_id\", \"x\"));\n\n        plan \u003d logicalOptimizer.optimize(analyzer.analyze(parser.createStatement(\"from empty_test metadata _id, _version | limit 5\")));\n        as(plan, LocalRelation.class);\n        assertThat(Expressions.names(plan.output()), contains(\"_id\", \"_version\"));\n\n        plan \u003d logicalOptimizer.optimize(\n            analyzer.analyze(parser.createStatement(\"from empty_test | eval x \u003d \\\"abc\\\" | enrich languages_idx on x\"))\n        );\n        LocalRelation local \u003d as(plan, LocalRelation.class);\n        assertThat(Expressions.names(local.output()), contains(NO_FIELDS.get(0).name(), \"x\", \"language_code\", \"language_name\"));\n    }\n\n    @AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/105436\")\n    public void testPlanSanityCheck() throws Exception {\n        var plan \u003d optimizedPlan(\"\"\"\n            from test\n            | stats a \u003d min(salary) by emp_no\n            \"\"\");\n\n        var limit \u003d as(plan, Limit.class);\n        var aggregate \u003d as(limit.child(), Aggregate.class);\n        var min \u003d as(Alias.unwrap(aggregate.aggregates().get(0)), Min.class);\n        var salary \u003d as(min.field(), NamedExpression.class);\n        assertThat(salary.name(), is(\"salary\"));\n        // emulate a rule that adds an invalid field\n        var invalidPlan \u003d new OrderBy(\n            limit.source(),\n            limit,\n            asList(\n                new Order(\n                    limit.source(),\n                    salary,\n                    org.elasticsearch.xpack.ql.expression.Order.OrderDirection.ASC,\n                    org.elasticsearch.xpack.ql.expression.Order.NullsPosition.FIRST\n                )\n            )\n        );\n\n        VerificationException e \u003d expectThrows(VerificationException.class, () -\u003e logicalOptimizer.optimize(invalidPlan));\n        assertThat(e.getMessage(), containsString(\"Plan [OrderBy[[Order[salary\"));\n        assertThat(e.getMessage(), containsString(\" optimized incorrectly due to missing references [salary\"));\n    }\n\n    // https://github.com/elastic/elasticsearch/issues/104995\n    public void testNoWrongIsNotNullPruning() {\n        var plan \u003d optimizedPlan(\"\"\"\n              ROW a \u003d 5, b \u003d [ 1, 2 ]\n              | EVAL sum \u003d a + b\n              | LIMIT 1\n              | WHERE sum IS NOT NULL\n            \"\"\");\n\n        var local \u003d as(plan, LocalRelation.class);\n        assertThat(local.supplier(), equalTo(LocalSupplier.EMPTY));\n        assertWarnings(\n            \"Line 2:16: evaluation of [a + b] failed, treating result as null. Only first 20 failures recorded.\",\n            \"Line 2:16: java.lang.IllegalArgumentException: single-value function encountered multi-value\"\n        );\n    }\n\n    /**\n     * Pushing down EVAL/GROK/DISSECT/ENRICH must not accidentally shadow attributes required by SORT.\n     *\n     * For DISSECT expects the following; the others are similar.\n     *\n     * EsqlProject[[first_name{f}#37, emp_no{r}#33, salary{r}#34]]\n     * \\_TopN[[Order[$$emp_no$temp_name$36{r}#46 + $$salary$temp_name$41{r}#47 * 13[INTEGER],ASC,LAST], Order[NEG($$salary$t\n     * emp_name$41{r}#47),DESC,FIRST]],3[INTEGER]]\n     *   \\_Dissect[first_name{f}#37,Parser[pattern\u003d%{emp_no} %{salary}, appendSeparator\u003d, parser\u003dorg.elasticsearch.dissect.Dissect\n     * Parser@b6858b],[emp_no{r}#33, salary{r}#34]]\n     *     \\_Eval[[emp_no{f}#36 AS $$emp_no$temp_name$36, salary{f}#41 AS $$salary$temp_name$41]]\n     *       \\_EsRelation[test][_meta_field{f}#42, emp_no{f}#36, first_name{f}#37, ..]\n     */\n    public void testPushdownWithOverwrittenName() {\n        List\u003cString\u003e overwritingCommands \u003d List.of(\n            \"EVAL emp_no \u003d 3*emp_no, salary \u003d -2*emp_no-salary\",\n            \"DISSECT first_name \\\"%{emp_no} %{salary}\\\"\",\n            \"GROK first_name \\\"%{WORD:emp_no} %{WORD:salary}\\\"\",\n            \"ENRICH languages_idx ON first_name WITH emp_no \u003d language_code, salary \u003d language_code\"\n        );\n\n        String queryTemplateKeepAfter \u003d \"\"\"\n            FROM test\n            | SORT 13*(emp_no+salary) ASC, -salary DESC\n            | {}\n            | KEEP first_name, emp_no, salary\n            | LIMIT 3\n            \"\"\";\n        // Equivalent but with KEEP first - ensures that attributes in the final projection are correct after pushdown rules were applied.\n        String queryTemplateKeepFirst \u003d \"\"\"\n            FROM test\n            | KEEP emp_no, salary, first_name\n            | SORT 13*(emp_no+salary) ASC, -salary DESC\n            | {}\n            | LIMIT 3\n            \"\"\";\n\n        for (String overwritingCommand : overwritingCommands) {\n            String queryTemplate \u003d randomBoolean() ? queryTemplateKeepFirst : queryTemplateKeepAfter;\n            var plan \u003d optimizedPlan(LoggerMessageFormat.format(null, queryTemplate, overwritingCommand));\n\n            var project \u003d as(plan, Project.class);\n            var projections \u003d project.projections();\n            assertThat(projections.size(), equalTo(3));\n            assertThat(projections.get(0).name(), equalTo(\"first_name\"));\n            assertThat(projections.get(1).name(), equalTo(\"emp_no\"));\n            assertThat(projections.get(2).name(), equalTo(\"salary\"));\n\n            var topN \u003d as(project.child(), TopN.class);\n            assertThat(topN.order().size(), is(2));\n\n            var firstOrderExpr \u003d as(topN.order().get(0), Order.class);\n            var mul \u003d as(firstOrderExpr.child(), Mul.class);\n            var add \u003d as(mul.left(), Add.class);\n            var renamed_emp_no \u003d as(add.left(), ReferenceAttribute.class);\n            var renamed_salary \u003d as(add.right(), ReferenceAttribute.class);\n            assertThat(renamed_emp_no.toString(), startsWith(\"$$emp_no$temp_name\"));\n            assertThat(renamed_salary.toString(), startsWith(\"$$salary$temp_name\"));\n\n            var secondOrderExpr \u003d as(topN.order().get(1), Order.class);\n            var neg \u003d as(secondOrderExpr.child(), Neg.class);\n            var renamed_salary2 \u003d as(neg.field(), ReferenceAttribute.class);\n            assert (renamed_salary2.semanticEquals(renamed_salary) \u0026\u0026 renamed_salary2.equals(renamed_salary));\n\n            Eval renamingEval \u003d null;\n            if (overwritingCommand.startsWith(\"EVAL\")) {\n                // Multiple EVALs should be merged, so there\u0027s only one.\n                renamingEval \u003d as(topN.child(), Eval.class);\n            }\n            if (overwritingCommand.startsWith(\"DISSECT\")) {\n                var dissect \u003d as(topN.child(), Dissect.class);\n                renamingEval \u003d as(dissect.child(), Eval.class);\n            }\n            if (overwritingCommand.startsWith(\"GROK\")) {\n                var grok \u003d as(topN.child(), Grok.class);\n                renamingEval \u003d as(grok.child(), Eval.class);\n            }\n            if (overwritingCommand.startsWith(\"ENRICH\")) {\n                var enrich \u003d as(topN.child(), Enrich.class);\n                renamingEval \u003d as(enrich.child(), Eval.class);\n            }\n\n            AttributeSet attributesCreatedInEval \u003d new AttributeSet();\n            for (Alias field : renamingEval.fields()) {\n                attributesCreatedInEval.add(field.toAttribute());\n            }\n            assert (attributesCreatedInEval.contains(renamed_emp_no));\n            assert (attributesCreatedInEval.contains(renamed_salary));\n\n            assertThat(renamingEval.child(), instanceOf(EsRelation.class));\n        }\n    }\n\n    public void testPartiallyFoldCase() {\n        var plan \u003d optimizedPlan(\"\"\"\n              FROM test\n            | EVAL c \u003d CASE(true, emp_no, salary)\n            \"\"\");\n\n        var eval \u003d as(plan, Eval.class);\n        var languages \u003d as(Alias.unwrap(eval.expressions().get(0)), FieldAttribute.class);\n        assertThat(languages.name(), is(\"emp_no\"));\n    }\n\n    private LogicalPlan optimizedPlan(String query) {\n        return plan(query);\n    }\n\n    private LogicalPlan plan(String query) {\n        var analyzed \u003d analyzer.analyze(parser.createStatement(query));\n        // System.out.println(analyzed);\n        var optimized \u003d logicalOptimizer.optimize(analyzed);\n        // System.out.println(optimized);\n        return optimized;\n    }\n\n    private LogicalPlan planAirports(String query) {\n        var analyzed \u003d analyzerAirports.analyze(parser.createStatement(query));\n        // System.out.println(analyzed);\n        var optimized \u003d logicalOptimizer.optimize(analyzed);\n        // System.out.println(optimized);\n        return optimized;\n    }\n\n    private void assertNullLiteral(Expression expression) {\n        assertEquals(Literal.class, expression.getClass());\n        assertNull(expression.fold());\n    }\n\n    // TODO: move these from org.elasticsearch.xpack.ql.optimizer.OptimizerRulesTests to org.elasticsearch.xpack.ql.TestUtils\n    public static FieldAttribute getFieldAttribute(String name) {\n        return getFieldAttribute(name, INTEGER);\n    }\n\n    private static FieldAttribute getFieldAttribute(String name, DataType dataType) {\n        return new FieldAttribute(EMPTY, name, new EsField(name + \"f\", dataType, emptyMap(), true));\n    }\n\n    public static WildcardLike wildcardLike(Expression left, String exp) {\n        return new WildcardLike(EMPTY, left, new WildcardPattern(exp));\n    }\n\n    public static RLike rlike(Expression left, String exp) {\n        return new RLike(EMPTY, left, new RLikePattern(exp));\n    }\n\n    @Override\n    protected List\u003cString\u003e filteredWarnings() {\n        return withDefaultLimitWarning(super.filteredWarnings());\n    }\n\n    // Null folding\n\n    public void testBasicNullFolding() {\n        FoldNull rule \u003d new FoldNull();\n        assertNullLiteral(rule.rule(new Add(EMPTY, L(randomInt()), Literal.NULL)));\n        assertNullLiteral(rule.rule(new Round(EMPTY, Literal.NULL, null)));\n        assertNullLiteral(rule.rule(new Pow(EMPTY, Literal.NULL, Literal.NULL)));\n        assertNullLiteral(rule.rule(new DateFormat(EMPTY, Literal.NULL, Literal.NULL, null)));\n        assertNullLiteral(rule.rule(new DateParse(EMPTY, Literal.NULL, Literal.NULL)));\n        assertNullLiteral(rule.rule(new DateTrunc(EMPTY, Literal.NULL, Literal.NULL)));\n        assertNullLiteral(rule.rule(new Substring(EMPTY, Literal.NULL, Literal.NULL, Literal.NULL)));\n    }\n\n    public void testNullFoldingIsNull() {\n        FoldNull foldNull \u003d new FoldNull();\n        assertEquals(true, foldNull.rule(new IsNull(EMPTY, NULL)).fold());\n        assertEquals(false, foldNull.rule(new IsNull(EMPTY, TRUE)).fold());\n    }\n\n    public void testNullFoldingIsNotNull() {\n        FoldNull foldNull \u003d new FoldNull();\n        assertEquals(true, foldNull.rule(new IsNotNull(EMPTY, TRUE)).fold());\n        assertEquals(false, foldNull.rule(new IsNotNull(EMPTY, NULL)).fold());\n    }\n\n    public void testGenericNullableExpression() {\n        FoldNull rule \u003d new FoldNull();\n        // arithmetic\n        assertNullLiteral(rule.rule(new Add(EMPTY, getFieldAttribute(\"a\"), NULL)));\n        // comparison\n        assertNullLiteral(rule.rule(greaterThanOf(getFieldAttribute(\"a\"), NULL)));\n        // regex\n        assertNullLiteral(rule.rule(new RLike(EMPTY, NULL, new RLikePattern(\"123\"))));\n        // date functions\n        assertNullLiteral(rule.rule(new DateExtract(EMPTY, NULL, NULL, configuration(\"\"))));\n        // math functions\n        assertNullLiteral(rule.rule(new Cos(EMPTY, NULL)));\n        // string functions\n        assertNullLiteral(rule.rule(new LTrim(EMPTY, NULL)));\n        // spatial\n        assertNullLiteral(rule.rule(new SpatialCentroid(EMPTY, NULL)));\n        // ip\n        assertNullLiteral(rule.rule(new CIDRMatch(EMPTY, NULL, List.of(NULL))));\n        // conversion\n        assertNullLiteral(rule.rule(new ToString(EMPTY, NULL)));\n    }\n\n    public void testNullFoldingDoesNotApplyOnLogicalExpressions() {\n        FoldNull rule \u003d new FoldNull();\n\n        Or or \u003d new Or(EMPTY, NULL, TRUE);\n        assertEquals(or, rule.rule(or));\n        or \u003d new Or(EMPTY, NULL, NULL);\n        assertEquals(or, rule.rule(or));\n\n        And and \u003d new And(EMPTY, NULL, TRUE);\n        assertEquals(and, rule.rule(and));\n        and \u003d new And(EMPTY, NULL, NULL);\n        assertEquals(and, rule.rule(and));\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    public void testNullFoldingDoesNotApplyOnAbstractMultivalueFunction() throws Exception {\n        FoldNull rule \u003d new FoldNull();\n\n        List\u003cClass\u003c? extends AbstractMultivalueFunction\u003e\u003e items \u003d List.of(\n            MvDedupe.class,\n            MvFirst.class,\n            MvLast.class,\n            MvMax.class,\n            MvMedian.class,\n            MvMin.class,\n            MvSum.class\n        );\n        for (Class\u003c? extends AbstractMultivalueFunction\u003e clazz : items) {\n            Constructor\u003c? extends AbstractMultivalueFunction\u003e ctor \u003d clazz.getConstructor(Source.class, Expression.class);\n            AbstractMultivalueFunction conditionalFunction \u003d ctor.newInstance(EMPTY, getFieldAttribute(\"a\"));\n            assertEquals(conditionalFunction, rule.rule(conditionalFunction));\n\n            conditionalFunction \u003d ctor.newInstance(EMPTY, NULL);\n            assertEquals(NULL, rule.rule(conditionalFunction));\n        }\n\n        // avg and count ar different just because they know the return type in advance (all the others infer the type from the input)\n        MvAvg avg \u003d new MvAvg(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(avg, rule.rule(avg));\n        avg \u003d new MvAvg(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(avg));\n\n        MvCount count \u003d new MvCount(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(count, rule.rule(count));\n        count \u003d new MvCount(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, INTEGER), rule.rule(count));\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    public void testNullFoldingDoesNotApplyOnAggregate() throws Exception {\n        FoldNull rule \u003d new FoldNull();\n\n        List\u003cClass\u003c? extends AggregateFunction\u003e\u003e items \u003d List.of(Max.class, Min.class);\n        for (Class\u003c? extends AggregateFunction\u003e clazz : items) {\n            Constructor\u003c? extends AggregateFunction\u003e ctor \u003d clazz.getConstructor(Source.class, Expression.class);\n            AggregateFunction conditionalFunction \u003d ctor.newInstance(EMPTY, getFieldAttribute(\"a\"));\n            assertEquals(conditionalFunction, rule.rule(conditionalFunction));\n\n            conditionalFunction \u003d ctor.newInstance(EMPTY, NULL);\n            assertEquals(NULL, rule.rule(conditionalFunction));\n        }\n\n        Avg avg \u003d new Avg(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(avg, rule.rule(avg));\n        avg \u003d new Avg(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(avg));\n\n        Count count \u003d new Count(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(count, rule.rule(count));\n        count \u003d new Count(EMPTY, NULL);\n        assertEquals(count, rule.rule(count));\n\n        CountDistinct countd \u003d new CountDistinct(EMPTY, getFieldAttribute(\"a\"), getFieldAttribute(\"a\"));\n        assertEquals(countd, rule.rule(countd));\n        countd \u003d new CountDistinct(EMPTY, NULL, NULL);\n        assertEquals(new Literal(EMPTY, null, LONG), rule.rule(countd));\n\n        Median median \u003d new Median(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(median, rule.rule(median));\n        median \u003d new Median(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(median));\n\n        MedianAbsoluteDeviation medianad \u003d new MedianAbsoluteDeviation(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(medianad, rule.rule(medianad));\n        medianad \u003d new MedianAbsoluteDeviation(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(medianad));\n\n        Percentile percentile \u003d new Percentile(EMPTY, getFieldAttribute(\"a\"), getFieldAttribute(\"a\"));\n        assertEquals(percentile, rule.rule(percentile));\n        percentile \u003d new Percentile(EMPTY, NULL, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(percentile));\n\n        Sum sum \u003d new Sum(EMPTY, getFieldAttribute(\"a\"));\n        assertEquals(sum, rule.rule(sum));\n        sum \u003d new Sum(EMPTY, NULL);\n        assertEquals(new Literal(EMPTY, null, DOUBLE), rule.rule(sum));\n\n    }\n\n    public void testNullFoldableDoesNotApplyToIsNullAndNotNull() {\n        FoldNull rule \u003d new FoldNull();\n\n        DataType numericType \u003d randomFrom(INTEGER, LONG, DOUBLE);\n        DataType genericType \u003d randomFrom(INTEGER, LONG, DOUBLE, UNSIGNED_LONG, KEYWORD, TEXT, GEO_POINT, GEO_SHAPE, VERSION, IP);\n        List\u003cExpression\u003e items \u003d List.of(\n            new Add(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType)),\n            new Add(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER)),\n            new Sub(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType)),\n            new Sub(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER)),\n            new Mul(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType)),\n            new Mul(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER)),\n            new Div(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType)),\n            new Div(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER)),\n\n            new GreaterThan(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType), randomZone()),\n            new GreaterThan(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER), randomZone()),\n            new GreaterThanOrEqual(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType), randomZone()),\n            new GreaterThanOrEqual(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER), randomZone()),\n            new LessThan(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType), randomZone()),\n            new LessThan(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER), randomZone()),\n            new LessThanOrEqual(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType), randomZone()),\n            new LessThanOrEqual(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER), randomZone()),\n            new NotEquals(EMPTY, getFieldAttribute(\"a\", numericType), getFieldAttribute(\"b\", numericType), randomZone()),\n            new NotEquals(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER), randomZone()),\n\n            new Equals(EMPTY, getFieldAttribute(\"a\", genericType), getFieldAttribute(\"b\", genericType)),\n            new Equals(EMPTY, new Literal(EMPTY, 1, INTEGER), new Literal(EMPTY, List.of(1, 2, 3), INTEGER))\n        );\n        for (Expression item : items) {\n            Expression isNull \u003d new IsNull(EMPTY, item);\n            Expression transformed \u003d rule.rule(isNull);\n            assertEquals(isNull, transformed);\n\n            IsNotNull isNotNull \u003d new IsNotNull(EMPTY, item);\n            transformed \u003d rule.rule(isNotNull);\n            assertEquals(isNotNull, transformed);\n        }\n\n    }\n\n    //\n    // Propagate nullability (IS NULL / IS NOT NULL)\n    //\n\n    // a IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNull() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n\n        And and \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        assertEquals(FALSE, new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b IS NOT NULL AND c IS NULL AND d IS NOT NULL AND e IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNullMultiField() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n\n        And andOne \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, getFieldAttribute(\"b\")));\n        And andTwo \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute(\"c\")), new IsNotNull(EMPTY, getFieldAttribute(\"d\")));\n        And andThree \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute(\"e\")), new IsNotNull(EMPTY, fa));\n\n        And and \u003d new And(EMPTY, andOne, new And(EMPTY, andTwo, andThree));\n\n        assertEquals(FALSE, new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND a \u003e 1 \u003d\u003e a IS NULL AND NULL\n    public void testIsNullAndComparison() {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        And and \u003d new And(EMPTY, isNull, greaterThanOf(fa, ONE));\n        assertEquals(new And(EMPTY, isNull, nullOf(BOOLEAN)), new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b \u003c 1 AND c \u003c 1 AND a \u003c 1 \u003d\u003e a IS NULL AND b \u003c 1 AND c \u003c 1 AND NULL\n    public void testIsNullAndMultipleComparison() {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        IsNull aIsNull \u003d new IsNull(EMPTY, fa);\n\n        And bLT1_AND_cLT1 \u003d new And(EMPTY, lessThanOf(getFieldAttribute(\"b\"), ONE), lessThanOf(getFieldAttribute(\"c\"), ONE));\n        And aIsNull_AND_bLT1_AND_cLT1 \u003d new And(EMPTY, aIsNull, bLT1_AND_cLT1);\n        And aIsNull_AND_bLT1_AND_cLT1_AND_aLT1 \u003d new And(EMPTY, aIsNull_AND_bLT1_AND_cLT1, lessThanOf(fa, ONE));\n\n        Expression optimized \u003d new PropagateNullable().rule(aIsNull_AND_bLT1_AND_cLT1_AND_aLT1);\n        Expression aIsNull_AND_bLT1_AND_cLT1_AND_NULL \u003d new And(EMPTY, aIsNull_AND_bLT1_AND_cLT1, nullOf(BOOLEAN));\n        assertEquals(Predicates.splitAnd(aIsNull_AND_bLT1_AND_cLT1_AND_NULL), Predicates.splitAnd(optimized));\n    }\n\n    public void testDoNotOptimizeIsNullAndMultipleComparisonWithConstants() {\n        Literal a \u003d ONE;\n        Literal b \u003d ONE;\n        IsNull aIsNull \u003d new IsNull(EMPTY, a);\n\n        And bLT1_AND_cLT1 \u003d new And(EMPTY, lessThanOf(b, ONE), lessThanOf(getFieldAttribute(\"c\"), ONE));\n        And aIsNull_AND_bLT1_AND_cLT1 \u003d new And(EMPTY, aIsNull, bLT1_AND_cLT1);\n        And aIsNull_AND_bLT1_AND_cLT1_AND_aLT1 \u003d new And(EMPTY, aIsNull_AND_bLT1_AND_cLT1, lessThanOf(a, ONE));\n\n        Expression optimized \u003d new PropagateNullable().rule(aIsNull_AND_bLT1_AND_cLT1_AND_aLT1);\n        Literal nullLiteral \u003d new Literal(EMPTY, null, BOOLEAN);\n        assertEquals(asList(aIsNull, nullLiteral, nullLiteral, nullLiteral), Predicates.splitAnd(optimized));\n    }\n\n    // ((a+1)/2) \u003e 1 AND a + 2 AND a IS NULL AND b \u003c 3 \u003d\u003e NULL AND NULL AND a IS NULL AND b \u003c 3\n    public void testIsNullAndDeeplyNestedExpression() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Expression nullified \u003d new And(\n            EMPTY,\n            greaterThanOf(new Div(EMPTY, new Add(EMPTY, fa, ONE), TWO), ONE),\n            greaterThanOf(new Add(EMPTY, fa, TWO), ONE)\n        );\n        Expression kept \u003d new And(EMPTY, isNull, lessThanOf(getFieldAttribute(\"b\"), THREE));\n        And and \u003d new And(EMPTY, nullified, kept);\n\n        Expression optimized \u003d new PropagateNullable().rule(and);\n        Expression expected \u003d new And(EMPTY, new And(EMPTY, nullOf(BOOLEAN), nullOf(BOOLEAN)), kept);\n\n        assertEquals(Predicates.splitAnd(expected), Predicates.splitAnd(optimized));\n    }\n\n    // a IS NULL OR a IS NOT NULL \u003d\u003e no change\n    // a IS NULL OR a \u003e 1 \u003d\u003e no change\n    public void testIsNullInDisjunction() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n\n        Or or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        Filter dummy \u003d new Filter(EMPTY, relation(), or);\n        LogicalPlan transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n\n        or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), greaterThanOf(fa, ONE));\n        dummy \u003d new Filter(EMPTY, relation(), or);\n        transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n    }\n\n    // a + 1 AND (a IS NULL OR a \u003e 3) \u003d\u003e no change\n    public void testIsNullDisjunction() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Or or \u003d new Or(EMPTY, isNull, greaterThanOf(fa, THREE));\n        And and \u003d new And(EMPTY, new Add(EMPTY, fa, ONE), or);\n\n        assertEquals(and, new PropagateNullable().rule(and));\n    }\n\n    private Literal nullOf(DataType dataType) {\n        return new Literal(Source.EMPTY, null, dataType);\n    }\n}","methodCount":181},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":1395,"lineEnd":1397,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method orderNames to class AnalyzerTestUtils","description":"move method orderNames to PsiClass:AnalyzerTestUtils\nRationale: The orderNames() method processes a collection of expressions related to a \u0027TopN\u0027 object, which likely involves analysis of data. By moving this method to AnalyzerTestUtils, we align it with classes that are more focused on analyzing and manipulating expressions. This adheres to the Single Responsibility Principle by keeping analysis-related methods together. However, care should be taken to ensure that the dependencies on \u0027TopN\u0027 and the expressions are managed correctly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1395,"lineEnd":1397,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method orderNames to class LogicalPlanOptimizer","description":"move method orderNames to PsiClass:LogicalPlanOptimizer\nRationale: The orderNames() method is related to ordering expressions, which is a key aspect of logical planning in query optimization. LogicalPlanOptimizer is responsible for optimizing logical plans, making it a suitable home for this method. This move enhances cohesion and keeps related functionalities together, adhering to the Open/Closed Principle by allowing future enhancements to be made in one place. However, it may introduce dependencies on \u0027TopN\u0027 that need to be managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1395,"lineEnd":1397,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method orderNames to class PlannerUtils","description":"move method orderNames to PsiClass:PlannerUtils\nRationale: The method orderNames() is concerned with ordering elements, which is closely related to planning functionalities. By relocating it to PlannerUtils, we consolidate planning-related methods, improving maintainability and readability. This aligns with the Single Responsibility Principle. However, we should consider how this move interacts with other planning methods and ensure that dependencies are appropriately handled.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"init","method_signature":"@BeforeClass\n    public static init()","target_class":"","rationale":""},{"method_name":"testEmptyProjections","method_signature":"public testEmptyProjections()","target_class":"","rationale":""},{"method_name":"testEmptyProjectionInStat","method_signature":"public testEmptyProjectionInStat()","target_class":"","rationale":""},{"method_name":"testCombineProjections","method_signature":"public testCombineProjections()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithFilterInBetween","method_signature":"public testCombineProjectionWithFilterInBetween()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWhilePreservingAlias","method_signature":"public testCombineProjectionWhilePreservingAlias()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithAggregation","method_signature":"public testCombineProjectionWithAggregation()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithDuplicateAggregation","method_signature":"public testCombineProjectionWithDuplicateAggregation()","target_class":"","rationale":""},{"method_name":"testQlComparisonOptimizationsApply","method_signature":"public testQlComparisonOptimizationsApply()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithPruning","method_signature":"public testCombineProjectionWithPruning()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithAggregationFirstAndAliasedGroupingUsedInAgg","method_signature":"public testCombineProjectionWithAggregationFirstAndAliasedGroupingUsedInAgg()","target_class":"","rationale":""},{"method_name":"testCombineProjectionWithAggregationFirstAndAliasedGroupingUnused","method_signature":"public testCombineProjectionWithAggregationFirstAndAliasedGroupingUnused()","target_class":"","rationale":""},{"method_name":"testCombineEvals","method_signature":"public testCombineEvals()","target_class":"","rationale":""},{"method_name":"testCombineLimits","method_signature":"public testCombineLimits()","target_class":"","rationale":""},{"method_name":"testMultipleCombineLimits","method_signature":"public testMultipleCombineLimits()","target_class":"","rationale":""},{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOf","method_signature":"public static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"testCombineFilters","method_signature":"public testCombineFilters()","target_class":"","rationale":""},{"method_name":"testCombineFiltersLikeRLike","method_signature":"public testCombineFiltersLikeRLike()","target_class":"","rationale":""},{"method_name":"testPushDownFilter","method_signature":"public testPushDownFilter()","target_class":"","rationale":""},{"method_name":"testPushDownLikeRlikeFilter","method_signature":"public testPushDownLikeRlikeFilter()","target_class":"","rationale":""},{"method_name":"testSelectivelyPushDownFilterPastFunctionAgg","method_signature":"public testSelectivelyPushDownFilterPastFunctionAgg()","target_class":"","rationale":""},{"method_name":"testSelectivelyPushDownFilterPastRefAgg","method_signature":"public testSelectivelyPushDownFilterPastRefAgg()","target_class":"","rationale":""},{"method_name":"testNoPushDownOrFilterPastAgg","method_signature":"public testNoPushDownOrFilterPastAgg()","target_class":"","rationale":""},{"method_name":"testSelectivePushDownComplexFilterPastAgg","method_signature":"public testSelectivePushDownComplexFilterPastAgg()","target_class":"","rationale":""},{"method_name":"testSelectivelyPushDownFilterPastEval","method_signature":"public testSelectivelyPushDownFilterPastEval()","target_class":"","rationale":""},{"method_name":"testNoPushDownOrFilterPastLimit","method_signature":"public testNoPushDownOrFilterPastLimit()","target_class":"","rationale":""},{"method_name":"testPushDownFilterPastProject","method_signature":"public testPushDownFilterPastProject()","target_class":"","rationale":""},{"method_name":"testPushDownEvalPastProject","method_signature":"public testPushDownEvalPastProject()","target_class":"","rationale":""},{"method_name":"testPushDownDissectPastProject","method_signature":"public testPushDownDissectPastProject()","target_class":"","rationale":""},{"method_name":"testPushDownGrokPastProject","method_signature":"public testPushDownGrokPastProject()","target_class":"","rationale":""},{"method_name":"testPushDownFilterPastProjectUsingEval","method_signature":"public testPushDownFilterPastProjectUsingEval()","target_class":"","rationale":""},{"method_name":"testPushDownFilterPastProjectUsingDissect","method_signature":"public testPushDownFilterPastProjectUsingDissect()","target_class":"","rationale":""},{"method_name":"testPushDownFilterPastProjectUsingGrok","method_signature":"public testPushDownFilterPastProjectUsingGrok()","target_class":"","rationale":""},{"method_name":"testPushDownLimitPastEval","method_signature":"public testPushDownLimitPastEval()","target_class":"","rationale":""},{"method_name":"testPushDownLimitPastDissect","method_signature":"public testPushDownLimitPastDissect()","target_class":"","rationale":""},{"method_name":"testPushDownLimitPastGrok","method_signature":"public testPushDownLimitPastGrok()","target_class":"","rationale":""},{"method_name":"testPushDownLimitPastProject","method_signature":"public testPushDownLimitPastProject()","target_class":"","rationale":""},{"method_name":"testDontPushDownLimitPastFilter","method_signature":"public testDontPushDownLimitPastFilter()","target_class":"","rationale":""},{"method_name":"testEliminateHigherLimitDueToDescendantLimit","method_signature":"public testEliminateHigherLimitDueToDescendantLimit()","target_class":"","rationale":""},{"method_name":"testDoNotEliminateHigherLimitDueToDescendantLimit","method_signature":"public testDoNotEliminateHigherLimitDueToDescendantLimit()","target_class":"","rationale":""},{"method_name":"testPruneSortBeforeStats","method_signature":"public testPruneSortBeforeStats()","target_class":"","rationale":""},{"method_name":"testDontPruneSortWithLimitBeforeStats","method_signature":"public testDontPruneSortWithLimitBeforeStats()","target_class":"","rationale":""},{"method_name":"testCombineOrderBy","method_signature":"public testCombineOrderBy()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughEval","method_signature":"public testCombineOrderByThroughEval()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughEvalWithTwoDefs","method_signature":"public testCombineOrderByThroughEvalWithTwoDefs()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughDissect","method_signature":"public testCombineOrderByThroughDissect()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughGrok","method_signature":"public testCombineOrderByThroughGrok()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughProject","method_signature":"public testCombineOrderByThroughProject()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughProjectAndEval","method_signature":"public testCombineOrderByThroughProjectAndEval()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughProjectWithAlias","method_signature":"public testCombineOrderByThroughProjectWithAlias()","target_class":"","rationale":""},{"method_name":"testCombineOrderByThroughFilter","method_signature":"public testCombineOrderByThroughFilter()","target_class":"","rationale":""},{"method_name":"testDontCombineOrderByThroughMvExpand","method_signature":"public testDontCombineOrderByThroughMvExpand()","target_class":"","rationale":""},{"method_name":"testCopyDefaultLimitPastMvExpand","method_signature":"public testCopyDefaultLimitPastMvExpand()","target_class":"","rationale":""},{"method_name":"testDontPushDownLimitPastMvExpand","method_signature":"public testDontPushDownLimitPastMvExpand()","target_class":"","rationale":""},{"method_name":"testMultipleMvExpandWithSortAndLimit","method_signature":"public testMultipleMvExpandWithSortAndLimit()","target_class":"","rationale":""},{"method_name":"testPushDownLimitThroughMultipleSort_AfterMvExpand","method_signature":"public testPushDownLimitThroughMultipleSort_AfterMvExpand()","target_class":"","rationale":""},{"method_name":"testPushDownLimitThroughMultipleSort_AfterMvExpand2","method_signature":"public testPushDownLimitThroughMultipleSort_AfterMvExpand2()","target_class":"","rationale":""},{"method_name":"testDontPushDownLimitPastAggregate_AndMvExpand","method_signature":"public testDontPushDownLimitPastAggregate_AndMvExpand()","target_class":"","rationale":""},{"method_name":"testPushDown_TheRightLimit_PastMvExpand","method_signature":"public testPushDown_TheRightLimit_PastMvExpand()","target_class":"","rationale":""},{"method_name":"testPushDownLimit_PastEvalAndMvExpand","method_signature":"public testPushDownLimit_PastEvalAndMvExpand()","target_class":"","rationale":""},{"method_name":"testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedField","method_signature":"public testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedField()","target_class":"","rationale":""},{"method_name":"testAddDefaultLimit_BeforeMvExpand_WithFilter_NOT_OnExpandedField","method_signature":"public testAddDefaultLimit_BeforeMvExpand_WithFilter_NOT_OnExpandedField()","target_class":"","rationale":""},{"method_name":"testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedFieldAlias","method_signature":"public testAddDefaultLimit_BeforeMvExpand_WithFilterOnExpandedFieldAlias()","target_class":"","rationale":""},{"method_name":"orderNames","method_signature":"private static orderNames(TopN topN)","target_class":"","rationale":""},{"method_name":"testCombineLimitWithOrderByThroughFilterAndEval","method_signature":"public testCombineLimitWithOrderByThroughFilterAndEval()","target_class":"","rationale":""},{"method_name":"testCombineMultipleOrderByAndLimits","method_signature":"public testCombineMultipleOrderByAndLimits()","target_class":"","rationale":""},{"method_name":"testDontPruneSameFieldDifferentDirectionSortClauses","method_signature":"public testDontPruneSameFieldDifferentDirectionSortClauses()","target_class":"","rationale":""},{"method_name":"testPruneRedundantSortClauses","method_signature":"public testPruneRedundantSortClauses()","target_class":"","rationale":""},{"method_name":"testDontPruneSameFieldDifferentDirectionSortClauses_UsingAlias","method_signature":"public testDontPruneSameFieldDifferentDirectionSortClauses_UsingAlias()","target_class":"","rationale":""},{"method_name":"testPruneRedundantSortClausesUsingAlias","method_signature":"public testPruneRedundantSortClausesUsingAlias()","target_class":"","rationale":""},{"method_name":"testSimplifyLikeNoWildcard","method_signature":"public testSimplifyLikeNoWildcard()","target_class":"","rationale":""},{"method_name":"testSimplifyLikeMatchAll","method_signature":"public testSimplifyLikeMatchAll()","target_class":"","rationale":""},{"method_name":"testSimplifyRLikeNoWildcard","method_signature":"public testSimplifyRLikeNoWildcard()","target_class":"","rationale":""},{"method_name":"testSimplifyRLikeMatchAll","method_signature":"public testSimplifyRLikeMatchAll()","target_class":"","rationale":""},{"method_name":"testFoldNullInToLocalRelation","method_signature":"public testFoldNullInToLocalRelation()","target_class":"","rationale":""},{"method_name":"testFoldNullListInToLocalRelation","method_signature":"public testFoldNullListInToLocalRelation()","target_class":"","rationale":""},{"method_name":"testFoldInKeyword","method_signature":"public testFoldInKeyword()","target_class":"","rationale":""},{"method_name":"testFoldInIP","method_signature":"public testFoldInIP()","target_class":"","rationale":""},{"method_name":"testFoldInVersion","method_signature":"public testFoldInVersion()","target_class":"","rationale":""},{"method_name":"testFoldInNumerics","method_signature":"public testFoldInNumerics()","target_class":"","rationale":""},{"method_name":"testFoldInEval","method_signature":"public testFoldInEval()","target_class":"","rationale":""},{"method_name":"testFoldFromRow","method_signature":"public testFoldFromRow()","target_class":"","rationale":""},{"method_name":"testFoldFromRowInEval","method_signature":"public testFoldFromRowInEval()","target_class":"","rationale":""},{"method_name":"testInvalidFoldDueToReplacement","method_signature":"public testInvalidFoldDueToReplacement()","target_class":"","rationale":""},{"method_name":"testEnrich","method_signature":"public testEnrich()","target_class":"","rationale":""},{"method_name":"testPushDownEnrichPastProject","method_signature":"public testPushDownEnrichPastProject()","target_class":"","rationale":""},{"method_name":"testTopNEnrich","method_signature":"public testTopNEnrich()","target_class":"","rationale":""},{"method_name":"testEnrichNotNullFilter","method_signature":"public testEnrichNotNullFilter()","target_class":"","rationale":""},{"method_name":"testSimpleAvgReplacement","method_signature":"public testSimpleAvgReplacement()","target_class":"","rationale":""},{"method_name":"testClashingAggAvgReplacement","method_signature":"public testClashingAggAvgReplacement()","target_class":"","rationale":""},{"method_name":"testSemiClashingAvgReplacement","method_signature":"public testSemiClashingAvgReplacement()","target_class":"","rationale":""},{"method_name":"testMedianReplacement","method_signature":"public testMedianReplacement()","target_class":"","rationale":""},{"method_name":"testSplittingInWithFoldableValue","method_signature":"public testSplittingInWithFoldableValue()","target_class":"","rationale":""},{"method_name":"testReplaceFilterWithExact","method_signature":"public testReplaceFilterWithExact()","target_class":"","rationale":""},{"method_name":"testReplaceExpressionWithExact","method_signature":"public testReplaceExpressionWithExact()","target_class":"","rationale":""},{"method_name":"testReplaceSortWithExact","method_signature":"public testReplaceSortWithExact()","target_class":"","rationale":""},{"method_name":"testPruneUnusedEval","method_signature":"public testPruneUnusedEval()","target_class":"","rationale":""},{"method_name":"testPruneChainedEval","method_signature":"public testPruneChainedEval()","target_class":"","rationale":""},{"method_name":"testPruneEvalDueToStats","method_signature":"public testPruneEvalDueToStats()","target_class":"","rationale":""},{"method_name":"testPruneUnusedAggSimple","method_signature":"public testPruneUnusedAggSimple()","target_class":"","rationale":""},{"method_name":"testPruneUnusedAggMixedWithEval","method_signature":"public testPruneUnusedAggMixedWithEval()","target_class":"","rationale":""},{"method_name":"testPruneUnusedAggsChainedAgg","method_signature":"public testPruneUnusedAggsChainedAgg()","target_class":"","rationale":""},{"method_name":"testPruneMixedAggInsideUnusedEval","method_signature":"public testPruneMixedAggInsideUnusedEval()","target_class":"","rationale":""},{"method_name":"testNoPruningWhenDealingJustWithEvals","method_signature":"public testNoPruningWhenDealingJustWithEvals()","target_class":"","rationale":""},{"method_name":"testNoPruningWhenChainedEvals","method_signature":"public testNoPruningWhenChainedEvals()","target_class":"","rationale":""},{"method_name":"testPruningDuplicateEvals","method_signature":"public testPruningDuplicateEvals()","target_class":"","rationale":""},{"method_name":"testPruneEvalAliasOnAggUngrouped","method_signature":"public testPruneEvalAliasOnAggUngrouped()","target_class":"","rationale":""},{"method_name":"testPruneEvalAliasOnAggGroupedByAlias","method_signature":"public testPruneEvalAliasOnAggGroupedByAlias()","target_class":"","rationale":""},{"method_name":"testPruneEvalAliasOnAggGrouped","method_signature":"public testPruneEvalAliasOnAggGrouped()","target_class":"","rationale":""},{"method_name":"testPruneEvalAliasMixedWithRenameOnAggGrouped","method_signature":"public testPruneEvalAliasMixedWithRenameOnAggGrouped()","target_class":"","rationale":""},{"method_name":"testEvalAliasingAcrossCommands","method_signature":"public testEvalAliasingAcrossCommands()","target_class":"","rationale":""},{"method_name":"testEvalAliasingInsideSameCommand","method_signature":"public testEvalAliasingInsideSameCommand()","target_class":"","rationale":""},{"method_name":"testEvalAliasingInsideSameCommandWithShadowing","method_signature":"public testEvalAliasingInsideSameCommandWithShadowing()","target_class":"","rationale":""},{"method_name":"testPruneRenameOnAgg","method_signature":"public testPruneRenameOnAgg()","target_class":"","rationale":""},{"method_name":"testPruneRenameOnAggBy","method_signature":"public testPruneRenameOnAggBy()","target_class":"","rationale":""},{"method_name":"testEliminateDuplicateAggsCountAll","method_signature":"@AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public testEliminateDuplicateAggsCountAll()","target_class":"","rationale":""},{"method_name":"testEliminateDuplicateAggsWithAliasedFields","method_signature":"@AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public testEliminateDuplicateAggsWithAliasedFields()","target_class":"","rationale":""},{"method_name":"testEliminateDuplicateAggsMixed","method_signature":"public testEliminateDuplicateAggsMixed()","target_class":"","rationale":""},{"method_name":"testEliminateDuplicateAggWithNull","method_signature":"@AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/100634\")\n    public testEliminateDuplicateAggWithNull()","target_class":"","rationale":""},{"method_name":"testEliminateDuplicateAggsNonCount","method_signature":"public testEliminateDuplicateAggsNonCount()","target_class":"","rationale":""},{"method_name":"testMvExpandFoldable","method_signature":"public testMvExpandFoldable()","target_class":"","rationale":""},{"method_name":"testRenameStatsDropGroup","method_signature":"public testRenameStatsDropGroup()","target_class":"","rationale":""},{"method_name":"testMultipleRenameStatsDropGroup","method_signature":"public testMultipleRenameStatsDropGroup()","target_class":"","rationale":""},{"method_name":"testMultipleRenameStatsDropGroupMultirow","method_signature":"public testMultipleRenameStatsDropGroupMultirow()","target_class":"","rationale":""},{"method_name":"testLimitZeroUsesLocalRelation","method_signature":"public testLimitZeroUsesLocalRelation()","target_class":"","rationale":""},{"method_name":"aliased","method_signature":"private aliased(Expression exp, Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"aggFieldName","method_signature":"private aggFieldName(Expression exp, Class\u003cT\u003e aggType, String fieldName)","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithoutGrouping","method_signature":"public testIsNotNullConstraintForStatsWithoutGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithGrouping","method_signature":"public testIsNotNullConstraintForStatsWithGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithAndOnGrouping","method_signature":"public testIsNotNullConstraintForStatsWithAndOnGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithAndOnGroupingAlias","method_signature":"public testIsNotNullConstraintForStatsWithAndOnGroupingAlias()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintSkippedForStatsWithAlias","method_signature":"public testIsNotNullConstraintSkippedForStatsWithAlias()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithMultiAggWithoutGrouping","method_signature":"public testIsNotNullConstraintForStatsWithMultiAggWithoutGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithMultiAggWithGrouping","method_signature":"public testIsNotNullConstraintForStatsWithMultiAggWithGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForStatsWithMultiAggWithAndOnGrouping","method_signature":"public testIsNotNullConstraintForStatsWithMultiAggWithAndOnGrouping()","target_class":"","rationale":""},{"method_name":"testIsNotNullConstraintForAliasedExpressions","method_signature":"public testIsNotNullConstraintForAliasedExpressions()","target_class":"","rationale":""},{"method_name":"testSpatialTypesAndStatsUseDocValues","method_signature":"public testSpatialTypesAndStatsUseDocValues()","target_class":"","rationale":""},{"method_name":"testNestedExpressionsInGroups","method_signature":"public testNestedExpressionsInGroups()","target_class":"","rationale":""},{"method_name":"testNestedExpressionsInAggs","method_signature":"public testNestedExpressionsInAggs()","target_class":"","rationale":""},{"method_name":"testNestedExpressionsInBothAggsAndGroups","method_signature":"public testNestedExpressionsInBothAggsAndGroups()","target_class":"","rationale":""},{"method_name":"testNestedMultiExpressionsInGroupingAndAggs","method_signature":"public testNestedMultiExpressionsInGroupingAndAggs()","target_class":"","rationale":""},{"method_name":"testLogicalPlanOptimizerVerifier","method_signature":"public testLogicalPlanOptimizerVerifier()","target_class":"","rationale":""},{"method_name":"testLogicalPlanOptimizerVerificationException","method_signature":"public testLogicalPlanOptimizerVerificationException()","target_class":"","rationale":""},{"method_name":"testStatsExpOverAggs","method_signature":"public testStatsExpOverAggs()","target_class":"","rationale":""},{"method_name":"testStatsExpOverAggsMulti","method_signature":"public testStatsExpOverAggsMulti()","target_class":"","rationale":""},{"method_name":"testStatsExpOverAggsWithScalars","method_signature":"public testStatsExpOverAggsWithScalars()","target_class":"","rationale":""},{"method_name":"testStatsExpOverAggsWithScalarAndDuplicateAggs","method_signature":"public testStatsExpOverAggsWithScalarAndDuplicateAggs()","target_class":"","rationale":""},{"method_name":"testStatsWithCanonicalAggregate","method_signature":"public testStatsWithCanonicalAggregate()","target_class":"","rationale":""},{"method_name":"testEmptyMappingIndex","method_signature":"public testEmptyMappingIndex()","target_class":"","rationale":""},{"method_name":"testPlanSanityCheck","method_signature":"@AwaitsFix(bugUrl \u003d \"https://github.com/elastic/elasticsearch/issues/105436\")\n    public testPlanSanityCheck()","target_class":"","rationale":""},{"method_name":"testNoWrongIsNotNullPruning","method_signature":"public testNoWrongIsNotNullPruning()","target_class":"","rationale":""},{"method_name":"testPushdownWithOverwrittenName","method_signature":"public testPushdownWithOverwrittenName()","target_class":"","rationale":""},{"method_name":"testPartiallyFoldCase","method_signature":"public testPartiallyFoldCase()","target_class":"","rationale":""},{"method_name":"optimizedPlan","method_signature":"private optimizedPlan(String query)","target_class":"","rationale":""},{"method_name":"plan","method_signature":"private plan(String query)","target_class":"","rationale":""},{"method_name":"planAirports","method_signature":"private planAirports(String query)","target_class":"","rationale":""},{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"public static getFieldAttribute(String name)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},{"method_name":"wildcardLike","method_signature":"public static wildcardLike(Expression left, String exp)","target_class":"","rationale":""},{"method_name":"rlike","method_signature":"public static rlike(Expression left, String exp)","target_class":"","rationale":""},{"method_name":"testBasicNullFolding","method_signature":"public testBasicNullFolding()","target_class":"","rationale":""},{"method_name":"testNullFoldingIsNull","method_signature":"public testNullFoldingIsNull()","target_class":"","rationale":""},{"method_name":"testNullFoldingIsNotNull","method_signature":"public testNullFoldingIsNotNull()","target_class":"","rationale":""},{"method_name":"testGenericNullableExpression","method_signature":"public testGenericNullableExpression()","target_class":"","rationale":""},{"method_name":"testNullFoldingDoesNotApplyOnLogicalExpressions","method_signature":"public testNullFoldingDoesNotApplyOnLogicalExpressions()","target_class":"","rationale":""},{"method_name":"testNullFoldingDoesNotApplyOnAbstractMultivalueFunction","method_signature":"@SuppressWarnings(\"unchecked\")\n    public testNullFoldingDoesNotApplyOnAbstractMultivalueFunction()","target_class":"","rationale":""},{"method_name":"testNullFoldingDoesNotApplyOnAggregate","method_signature":"@SuppressWarnings(\"unchecked\")\n    public testNullFoldingDoesNotApplyOnAggregate()","target_class":"","rationale":""},{"method_name":"testNullFoldableDoesNotApplyToIsNullAndNotNull","method_signature":"public testNullFoldableDoesNotApplyToIsNullAndNotNull()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNull","method_signature":"public testIsNullAndNotNull()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNullMultiField","method_signature":"public testIsNullAndNotNullMultiField()","target_class":"","rationale":""},{"method_name":"testIsNullAndComparison","method_signature":"public testIsNullAndComparison()","target_class":"","rationale":""},{"method_name":"testIsNullAndMultipleComparison","method_signature":"public testIsNullAndMultipleComparison()","target_class":"","rationale":""},{"method_name":"testDoNotOptimizeIsNullAndMultipleComparisonWithConstants","method_signature":"public testDoNotOptimizeIsNullAndMultipleComparisonWithConstants()","target_class":"","rationale":""},{"method_name":"testIsNullAndDeeplyNestedExpression","method_signature":"public testIsNullAndDeeplyNestedExpression()","target_class":"","rationale":""},{"method_name":"testIsNullInDisjunction","method_signature":"public testIsNullInDisjunction()","target_class":"","rationale":""},{"method_name":"testIsNullDisjunction","method_signature":"public testIsNullDisjunction()","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"testBasicNullFolding","method_signature":"public testBasicNullFolding()","target_class":"","rationale":""},{"method_name":"orderNames","method_signature":"private static orderNames(TopN topN)","target_class":"","rationale":""},{"method_name":"testGenericNullableExpression","method_signature":"public testGenericNullableExpression()","target_class":"","rationale":""},{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"public static getFieldAttribute(String name)","target_class":"","rationale":""},{"method_name":"optimizedPlan","method_signature":"private optimizedPlan(String query)","target_class":"","rationale":""},{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOf","method_signature":"public static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},{"method_name":"wildcardLike","method_signature":"public static wildcardLike(Expression left, String exp)","target_class":"","rationale":""},{"method_name":"rlike","method_signature":"public static rlike(Expression left, String exp)","target_class":"","rationale":""},{"method_name":"testNullFoldableDoesNotApplyToIsNullAndNotNull","method_signature":"public testNullFoldableDoesNotApplyToIsNullAndNotNull()","target_class":"","rationale":""},{"method_name":"testNullFoldingIsNotNull","method_signature":"public testNullFoldingIsNotNull()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public testBasicNullFolding()":{"first":{"method_name":"testBasicNullFolding","method_signature":"public testBasicNullFolding()","target_class":"","rationale":""},"second":0.09214699072895766},"private static orderNames(TopN topN)":{"first":{"method_name":"orderNames","method_signature":"private static orderNames(TopN topN)","target_class":"","rationale":""},"second":0.09664344818280833},"public testGenericNullableExpression()":{"first":{"method_name":"testGenericNullableExpression","method_signature":"public testGenericNullableExpression()","target_class":"","rationale":""},"second":0.10768202385630947},"private assertNullLiteral(Expression expression)":{"first":{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},"second":0.10928584593456336},"public static getFieldAttribute(String name)":{"first":{"method_name":"getFieldAttribute","method_signature":"public static getFieldAttribute(String name)","target_class":"","rationale":""},"second":0.11380414887603196},"private optimizedPlan(String query)":{"first":{"method_name":"optimizedPlan","method_signature":"private optimizedPlan(String query)","target_class":"","rationale":""},"second":0.12690499674454706},"public static greaterThanOrEqualOf(Expression left, Expression right)":{"first":{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.14185997392301333},"public static greaterThanOf(Expression left, Expression right)":{"first":{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.1418600864926494},"public static lessThanOf(Expression left, Expression right)":{"first":{"method_name":"lessThanOf","method_signature":"public static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.1418600864926494},"private static getFieldAttribute(String name, DataType dataType)":{"first":{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},"second":0.15370130337769544},"private nullOf(DataType dataType)":{"first":{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},"second":0.15378645757072637},"public static wildcardLike(Expression left, String exp)":{"first":{"method_name":"wildcardLike","method_signature":"public static wildcardLike(Expression left, String exp)","target_class":"","rationale":""},"second":0.16912551935516162},"public static rlike(Expression left, String exp)":{"first":{"method_name":"rlike","method_signature":"public static rlike(Expression left, String exp)","target_class":"","rationale":""},"second":0.1693248592998127},"public testNullFoldableDoesNotApplyToIsNullAndNotNull()":{"first":{"method_name":"testNullFoldableDoesNotApplyToIsNullAndNotNull","method_signature":"public testNullFoldableDoesNotApplyToIsNullAndNotNull()","target_class":"","rationale":""},"second":0.19036699380050595},"public testNullFoldingIsNotNull()":{"first":{"method_name":"testNullFoldingIsNotNull","method_signature":"public testNullFoldingIsNotNull()","target_class":"","rationale":""},"second":0.24479084383371508}},"llmMethodPriority":{"priority_method_names":["testBasicNullFolding","orderNames","testGenericNullableExpression","assertNullLiteral","getFieldAttribute","optimizedPlan","greaterThanOrEqualOf","greaterThanOf","lessThanOf","getFieldAttribute","nullOf","wildcardLike","rlike","testNullFoldableDoesNotApplyToIsNullAndNotNull","testNullFoldingIsNotNull"],"llm_response_time":7630},"targetClassMap":{"testBasicNullFolding":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":447,"similarity_computation_time":0,"similarity_metric":"voyage"},"orderNames":{"target_classes":[{"class_name":"ResponseValueUtils","similarity_score":0.42371284840524104},{"class_name":"ResponseXContentUtils","similarity_score":0.41101308382846174},{"class_name":"AnalyzerTestUtils","similarity_score":0.41118502561633236},{"class_name":"PlannerUtils","similarity_score":0.3766415580663877},{"class_name":"SerializationTestUtils","similarity_score":0.33611115913797196},{"class_name":"EsqlTestUtils","similarity_score":0.4548971239209154},{"class_name":"ExceptionUtils","similarity_score":0.14334554477024897},{"class_name":"CsvTestUtils","similarity_score":0.3951246971609447},{"class_name":"SpatialRelatesUtils","similarity_score":0.2758686295341227},{"class_name":"NormalizeAggregate","similarity_score":0.30217360062311216},{"class_name":"PruneColumns","similarity_score":0.2996533869192075},{"class_name":"PruneOrderByBeforeStats","similarity_score":0.3139110478868201},{"class_name":"PushDownAndCombineFilters","similarity_score":0.24772589501387773},{"class_name":"PushDownAndCombineLimits","similarity_score":0.31393167816118617},{"class_name":"PushFiltersToSource","similarity_score":0.36794947952706863},{"class_name":"ReplaceStatsAggExpressionWithEval","similarity_score":0.19634089141736435},{"class_name":"ReplaceStatsNestedExpressionWithEval","similarity_score":0.21996575868827617},{"class_name":"CombineProjections","similarity_score":0.30652463980084843},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.3305926222113418},{"class_name":"PhysicalPlanOptimizer","similarity_score":0.3220226432815482},{"class_name":"PhysicalPlanOptimizerTests","similarity_score":0.07234927438059859},{"class_name":"LocalLogicalPlanOptimizerTests","similarity_score":0.12701913302041037},{"class_name":"LocalPhysicalPlanOptimizer","similarity_score":0.4036117334277583},{"class_name":"LocalPhysicalPlanOptimizerTests","similarity_score":0.1293789256469225},{"class_name":"LogicalPlanOptimizer","similarity_score":0.35123099216790876},{"class_name":"InsertFieldExtraction","similarity_score":0.3120188603766914},{"class_name":"SubstituteSurrogates","similarity_score":0.2739978727937291},{"class_name":"JwkValidateUtil","similarity_score":0.3279379103022023},{"class_name":"JwkValidateUtilTests","similarity_score":0.3655850517241954}],"target_classes_sorted_by_llm":["AnalyzerTestUtils","LogicalPlanOptimizer","PlannerUtils","ResponseValueUtils","LocalPhysicalPlanOptimizer","EsqlTestUtils","ResponseXContentUtils","CsvTestUtils","PushFiltersToSource","JwkValidateUtilTests"],"llm_response_time":14782,"similarity_computation_time":31,"similarity_metric":"voyage"},"testGenericNullableExpression":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":453,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"ef27d505-82ed-4fb7-8cbc-67b5e666057e","methodCount":141,"hostFunctionTelemetryData":{"hostFunctionSize":1768,"lineStart":99,"lineEnd":1866,"bodyLineStart":99,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/ql/src/test/java/org/elasticsearch/xpack/ql/optimizer/OptimizerRulesTests.java","sourceCode":"public class OptimizerRulesTests extends ESTestCase {\n\n    private static final Expression DUMMY_EXPRESSION \u003d new DummyBooleanExpression(EMPTY, 0);\n\n    private static final Literal ONE \u003d L(1);\n    private static final Literal TWO \u003d L(2);\n    private static final Literal THREE \u003d L(3);\n    private static final Literal FOUR \u003d L(4);\n    private static final Literal FIVE \u003d L(5);\n    private static final Literal SIX \u003d L(6);\n\n    public static class DummyBooleanExpression extends Expression {\n\n        private final int id;\n\n        public DummyBooleanExpression(Source source, int id) {\n            super(source, Collections.emptyList());\n            this.id \u003d id;\n        }\n\n        @Override\n        protected NodeInfo\u003c? extends Expression\u003e info() {\n            return NodeInfo.create(this, DummyBooleanExpression::new, id);\n        }\n\n        @Override\n        public Expression replaceChildren(List\u003cExpression\u003e newChildren) {\n            throw new UnsupportedOperationException(\"this type of node doesn\u0027t have any children\");\n        }\n\n        @Override\n        public Nullability nullable() {\n            return Nullability.FALSE;\n        }\n\n        @Override\n        public DataType dataType() {\n            return BOOLEAN;\n        }\n\n        @Override\n        public int hashCode() {\n            int h \u003d getClass().hashCode();\n            h \u003d 31 * h + id;\n            return h;\n        }\n\n        @Override\n        public boolean equals(Object obj) {\n            if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n                return false;\n            }\n            return id \u003d\u003d ((DummyBooleanExpression) obj).id;\n        }\n    }\n\n    private static Literal L(Object value) {\n        return of(value);\n    }\n\n    private static FieldAttribute getFieldAttribute() {\n        return getFieldAttribute(\"a\");\n    }\n\n    private static FieldAttribute getFieldAttribute(String name) {\n        return getFieldAttribute(name, INTEGER);\n    }\n\n    private static FieldAttribute getFieldAttribute(String name, DataType dataType) {\n        return new FieldAttribute(EMPTY, name, new EsField(name + \"f\", dataType, emptyMap(), true));\n    }\n\n    //\n    // Constant folding\n    //\n\n    public void testConstantFolding() {\n        Expression exp \u003d new Add(EMPTY, TWO, THREE);\n\n        assertTrue(exp.foldable());\n        Expression result \u003d new ConstantFolding().rule(exp);\n        assertTrue(result instanceof Literal);\n        assertEquals(5, ((Literal) result).value());\n\n        // check now with an alias\n        result \u003d new ConstantFolding().rule(new Alias(EMPTY, \"a\", exp));\n        assertEquals(\"a\", Expressions.name(result));\n        assertEquals(Alias.class, result.getClass());\n    }\n\n    public void testConstantFoldingBinaryComparison() {\n        assertEquals(FALSE, new ConstantFolding().rule(greaterThanOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(greaterThanOrEqualOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(equalsOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(nullEqualsOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(nullEqualsOf(TWO, NULL)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(notEqualsOf(TWO, THREE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(lessThanOrEqualOf(TWO, THREE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(lessThanOf(TWO, THREE)).canonical());\n    }\n\n    public void testConstantFoldingBinaryLogic() {\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, greaterThanOf(TWO, THREE), TRUE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, greaterThanOrEqualOf(TWO, THREE), TRUE)).canonical());\n    }\n\n    public void testConstantFoldingBinaryLogic_WithNullHandling() {\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, NULL, TRUE)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, TRUE, NULL)).canonical().nullable());\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, NULL, FALSE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, FALSE, NULL)).canonical());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, NULL, NULL)).canonical().nullable());\n\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, TRUE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, TRUE, NULL)).canonical());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, FALSE)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, FALSE, NULL)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, NULL)).canonical().nullable());\n    }\n\n    public void testConstantFoldingRange() {\n        assertEquals(true, new ConstantFolding().rule(rangeOf(FIVE, FIVE, true, L(10), false)).fold());\n        assertEquals(false, new ConstantFolding().rule(rangeOf(FIVE, FIVE, false, L(10), false)).fold());\n    }\n\n    public void testConstantNot() {\n        assertEquals(FALSE, new ConstantFolding().rule(new Not(EMPTY, TRUE)));\n        assertEquals(TRUE, new ConstantFolding().rule(new Not(EMPTY, FALSE)));\n    }\n\n    public void testConstantFoldingLikes() {\n        assertEquals(TRUE, new ConstantFolding().rule(new Like(EMPTY, of(\"test_emp\"), new LikePattern(\"test%\", (char) 0))).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new WildcardLike(EMPTY, of(\"test_emp\"), new WildcardPattern(\"test*\"))).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new RLike(EMPTY, of(\"test_emp\"), new RLikePattern(\"test.emp\"))).canonical());\n    }\n\n    public void testArithmeticFolding() {\n        assertEquals(10, foldOperator(new Add(EMPTY, L(7), THREE)));\n        assertEquals(4, foldOperator(new Sub(EMPTY, L(7), THREE)));\n        assertEquals(21, foldOperator(new Mul(EMPTY, L(7), THREE)));\n        assertEquals(2, foldOperator(new Div(EMPTY, L(7), THREE)));\n        assertEquals(1, foldOperator(new Mod(EMPTY, L(7), THREE)));\n    }\n\n    private static Object foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b) {\n        return ((Literal) new ConstantFolding().rule(b)).value();\n    }\n\n    //\n    // Logical simplifications\n    //\n\n    public void testLiteralsOnTheRight() {\n        Alias a \u003d new Alias(EMPTY, \"a\", L(10));\n        Expression result \u003d new LiteralsOnTheRight().rule(equalsOf(FIVE, a));\n        assertTrue(result instanceof Equals);\n        Equals eq \u003d (Equals) result;\n        assertEquals(a, eq.left());\n        assertEquals(FIVE, eq.right());\n\n        a \u003d new Alias(EMPTY, \"a\", L(10));\n        result \u003d new LiteralsOnTheRight().rule(nullEqualsOf(FIVE, a));\n        assertTrue(result instanceof NullEquals);\n        NullEquals nullEquals \u003d (NullEquals) result;\n        assertEquals(a, nullEquals.left());\n        assertEquals(FIVE, nullEquals.right());\n    }\n\n    public void testBoolSimplifyOr() {\n        BooleanSimplification simplification \u003d new BooleanSimplification();\n\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, TRUE, TRUE)));\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, TRUE, DUMMY_EXPRESSION)));\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, DUMMY_EXPRESSION, TRUE)));\n\n        assertEquals(FALSE, simplification.rule(new Or(EMPTY, FALSE, FALSE)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new Or(EMPTY, FALSE, DUMMY_EXPRESSION)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new Or(EMPTY, DUMMY_EXPRESSION, FALSE)));\n    }\n\n    public void testBoolSimplifyAnd() {\n        BooleanSimplification simplification \u003d new BooleanSimplification();\n\n        assertEquals(TRUE, simplification.rule(new And(EMPTY, TRUE, TRUE)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new And(EMPTY, TRUE, DUMMY_EXPRESSION)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new And(EMPTY, DUMMY_EXPRESSION, TRUE)));\n\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, FALSE, FALSE)));\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, FALSE, DUMMY_EXPRESSION)));\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, DUMMY_EXPRESSION, FALSE)));\n    }\n\n    public void testBoolCommonFactorExtraction() {\n        BooleanSimplification simplification \u003d new BooleanSimplification();\n\n        Expression a1 \u003d new DummyBooleanExpression(EMPTY, 1);\n        Expression a2 \u003d new DummyBooleanExpression(EMPTY, 1);\n        Expression b \u003d new DummyBooleanExpression(EMPTY, 2);\n        Expression c \u003d new DummyBooleanExpression(EMPTY, 3);\n\n        Or actual \u003d new Or(EMPTY, new And(EMPTY, a1, b), new And(EMPTY, a2, c));\n        And expected \u003d new And(EMPTY, a1, new Or(EMPTY, b, c));\n\n        assertEquals(expected, simplification.rule(actual));\n    }\n\n    public void testBinaryComparisonSimplification() {\n        assertEquals(TRUE, new BinaryComparisonSimplification().rule(equalsOf(FIVE, FIVE)));\n        assertEquals(TRUE, new BinaryComparisonSimplification().rule(nullEqualsOf(FIVE, FIVE)));\n        assertEquals(TRUE, new BinaryComparisonSimplification().rule(nullEqualsOf(NULL, NULL)));\n        assertEquals(FALSE, new BinaryComparisonSimplification().rule(notEqualsOf(FIVE, FIVE)));\n        assertEquals(TRUE, new BinaryComparisonSimplification().rule(greaterThanOrEqualOf(FIVE, FIVE)));\n        assertEquals(TRUE, new BinaryComparisonSimplification().rule(lessThanOrEqualOf(FIVE, FIVE)));\n\n        assertEquals(FALSE, new BinaryComparisonSimplification().rule(greaterThanOf(FIVE, FIVE)));\n        assertEquals(FALSE, new BinaryComparisonSimplification().rule(lessThanOf(FIVE, FIVE)));\n    }\n\n    public void testNullEqualsWithNullLiteralBecomesIsNull() {\n        LiteralsOnTheRight swapLiteralsToRight \u003d new LiteralsOnTheRight();\n        BinaryComparisonSimplification bcSimpl \u003d new BinaryComparisonSimplification();\n        FieldAttribute fa \u003d getFieldAttribute();\n        Source source \u003d new Source(1, 10, \"IS_NULL(a)\");\n\n        Expression e \u003d bcSimpl.rule((BinaryComparison) swapLiteralsToRight.rule(new NullEquals(source, fa, NULL, randomZone())));\n        assertEquals(IsNull.class, e.getClass());\n        IsNull isNull \u003d (IsNull) e;\n        assertEquals(source, isNull.source());\n\n        e \u003d bcSimpl.rule((BinaryComparison) swapLiteralsToRight.rule(new NullEquals(source, NULL, fa, randomZone())));\n        assertEquals(IsNull.class, e.getClass());\n        isNull \u003d (IsNull) e;\n        assertEquals(source, isNull.source());\n    }\n\n    public void testBoolEqualsSimplificationOnExpressions() {\n        BooleanFunctionEqualsElimination s \u003d new BooleanFunctionEqualsElimination();\n        Expression exp \u003d new GreaterThan(EMPTY, getFieldAttribute(), L(0), null);\n\n        assertEquals(exp, s.rule(new Equals(EMPTY, exp, TRUE)));\n        assertEquals(new Not(EMPTY, exp), s.rule(new Equals(EMPTY, exp, FALSE)));\n    }\n\n    public void testBoolEqualsSimplificationOnFields() {\n        BooleanFunctionEqualsElimination s \u003d new BooleanFunctionEqualsElimination();\n\n        FieldAttribute field \u003d getFieldAttribute();\n\n        List\u003c? extends BinaryComparison\u003e comparisons \u003d asList(\n            new Equals(EMPTY, field, TRUE),\n            new Equals(EMPTY, field, FALSE),\n            notEqualsOf(field, TRUE),\n            notEqualsOf(field, FALSE),\n            new Equals(EMPTY, NULL, TRUE),\n            new Equals(EMPTY, NULL, FALSE),\n            notEqualsOf(NULL, TRUE),\n            notEqualsOf(NULL, FALSE)\n        );\n\n        for (BinaryComparison comparison : comparisons) {\n            assertEquals(comparison, s.rule(comparison));\n        }\n    }\n\n    //\n    // Range optimization\n    //\n\n    // 6 \u003c a \u003c\u003d 5 -\u003e FALSE\n    public void testFoldExcludingRangeToFalse() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r \u003d rangeOf(fa, SIX, false, FIVE, true);\n        assertTrue(r.foldable());\n        assertEquals(Boolean.FALSE, r.fold());\n    }\n\n    // 6 \u003c a \u003c\u003d 5.5 -\u003e FALSE\n    public void testFoldExcludingRangeWithDifferentTypesToFalse() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r \u003d rangeOf(fa, SIX, false, L(5.5d), true);\n        assertTrue(r.foldable());\n        assertEquals(Boolean.FALSE, r.fold());\n    }\n\n    // Conjunction\n\n    public void testCombineBinaryComparisonsNotComparable() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, SIX);\n        LessThan lt \u003d lessThanOf(fa, FALSE);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        And and \u003d new And(EMPTY, lte, lt);\n        Expression exp \u003d rule.rule(and);\n        assertEquals(exp, and);\n    }\n\n    // a \u003c\u003d 6 AND a \u003c 5 -\u003e a \u003c 5\n    public void testCombineBinaryComparisonsUpper() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, SIX);\n        LessThan lt \u003d lessThanOf(fa, FIVE);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n\n        Expression exp \u003d rule.rule(new And(EMPTY, lte, lt));\n        assertEquals(LessThan.class, exp.getClass());\n        LessThan r \u003d (LessThan) exp;\n        assertEquals(FIVE, r.right());\n    }\n\n    // 6 \u003c\u003d a AND 5 \u003c a -\u003e 6 \u003c\u003d a\n    public void testCombineBinaryComparisonsLower() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, SIX);\n        GreaterThan gt \u003d greaterThanOf(fa, FIVE);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n\n        Expression exp \u003d rule.rule(new And(EMPTY, gte, gt));\n        assertEquals(GreaterThanOrEqual.class, exp.getClass());\n        GreaterThanOrEqual r \u003d (GreaterThanOrEqual) exp;\n        assertEquals(SIX, r.right());\n    }\n\n    // 5 \u003c\u003d a AND 5 \u003c a -\u003e 5 \u003c a\n    public void testCombineBinaryComparisonsInclude() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, FIVE);\n        GreaterThan gt \u003d greaterThanOf(fa, FIVE);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n\n        Expression exp \u003d rule.rule(new And(EMPTY, gte, gt));\n        assertEquals(GreaterThan.class, exp.getClass());\n        GreaterThan r \u003d (GreaterThan) exp;\n        assertEquals(FIVE, r.right());\n    }\n\n    // 2 \u003c a AND (2 \u003c\u003d a \u003c 3) -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsAndRangeLower() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n        Range range \u003d rangeOf(fa, TWO, true, THREE, false);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(new And(EMPTY, gt, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a \u003c 4 AND (1 \u003c a \u003c 3) -\u003e 1 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsAndRangeUpper() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        LessThan lt \u003d lessThanOf(fa, FOUR);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(new And(EMPTY, range, lt));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(ONE, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a \u003c\u003d 2 AND (1 \u003c a \u003c 3) -\u003e 1 \u003c a \u003c\u003d 2\n    public void testCombineBinaryComparisonsAndRangeUpperEqual() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(new And(EMPTY, lte, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(ONE, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(TWO, r.upper());\n        assertTrue(r.includeUpper());\n    }\n\n    // 3 \u003c\u003d a AND 4 \u003c a AND a \u003c\u003d 7 AND a \u003c 6 -\u003e 4 \u003c a \u003c 6\n    public void testCombineMultipleBinaryComparisons() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, THREE);\n        GreaterThan gt \u003d greaterThanOf(fa, FOUR);\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, L(7));\n        LessThan lt \u003d lessThanOf(fa, SIX);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n\n        Expression exp \u003d rule.rule(new And(EMPTY, gte, new And(EMPTY, gt, new And(EMPTY, lt, lte))));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(FOUR, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(SIX, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // 3 \u003c\u003d a AND TRUE AND 4 \u003c a AND a !\u003d 5 AND a \u003c\u003d 7 -\u003e 4 \u003c a \u003c\u003d 7 AND a !\u003d 5 AND TRUE\n    public void testCombineMixedMultipleBinaryComparisons() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, THREE);\n        GreaterThan gt \u003d greaterThanOf(fa, FOUR);\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, L(7));\n        Expression ne \u003d new Not(EMPTY, equalsOf(fa, FIVE));\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n\n        // TRUE AND a !\u003d 5 AND 4 \u003c a \u003c\u003d 7\n        Expression exp \u003d rule.rule(new And(EMPTY, gte, new And(EMPTY, TRUE, new And(EMPTY, gt, new And(EMPTY, ne, lte)))));\n        assertEquals(And.class, exp.getClass());\n        And and \u003d ((And) exp);\n        assertEquals(Range.class, and.right().getClass());\n        Range r \u003d (Range) and.right();\n        assertEquals(FOUR, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(L(7), r.upper());\n        assertTrue(r.includeUpper());\n    }\n\n    // 1 \u003c\u003d a AND a \u003c 5 -\u003e 1 \u003c\u003d a \u003c 5\n    public void testCombineComparisonsIntoRange() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, ONE);\n        LessThan lt \u003d lessThanOf(fa, FIVE);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(new And(EMPTY, gte, lt));\n        assertEquals(Range.class, exp.getClass());\n\n        Range r \u003d (Range) exp;\n        assertEquals(ONE, r.lower());\n        assertTrue(r.includeLower());\n        assertEquals(FIVE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // 1 \u003c a AND a \u003c 3 AND 2 \u003c b AND b \u003c 4 AND c \u003c 4 -\u003e (1 \u003c a \u003c 3) AND (2 \u003c b \u003c 4) AND c \u003c 4\n    public void testCombineMultipleComparisonsIntoRange() {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        FieldAttribute fb \u003d getFieldAttribute(\"b\");\n        FieldAttribute fc \u003d getFieldAttribute(\"c\");\n\n        ZoneId zoneId \u003d randomZone();\n        GreaterThan agt1 \u003d new GreaterThan(EMPTY, fa, ONE, zoneId);\n        LessThan alt3 \u003d new LessThan(EMPTY, fa, THREE, zoneId);\n        GreaterThan bgt2 \u003d new GreaterThan(EMPTY, fb, TWO, zoneId);\n        LessThan blt4 \u003d new LessThan(EMPTY, fb, FOUR, zoneId);\n        LessThan clt4 \u003d new LessThan(EMPTY, fc, FOUR, zoneId);\n\n        Expression inputAnd \u003d Predicates.combineAnd(asList(agt1, alt3, bgt2, blt4, clt4));\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression outputAnd \u003d rule.rule((And) inputAnd);\n\n        Range agt1lt3 \u003d new Range(EMPTY, fa, ONE, false, THREE, false, zoneId);\n        Range bgt2lt4 \u003d new Range(EMPTY, fb, TWO, false, FOUR, false, zoneId);\n\n        // The actual outcome is (c \u003c 4) AND (1 \u003c a \u003c 3) AND (2 \u003c b \u003c 4), due to the way the Expression types are combined in the Optimizer\n        Expression expectedAnd \u003d Predicates.combineAnd(asList(clt4, agt1lt3, bgt2lt4));\n\n        assertTrue(outputAnd.semanticEquals(expectedAnd));\n    }\n\n    // (2 \u003c a \u003c 3) AND (1 \u003c a \u003c 4) -\u003e (2 \u003c a \u003c 3)\n    public void testCombineBinaryComparisonsConjunctionOfIncludedRange() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, ONE, false, FOUR, false);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(r1, exp);\n    }\n\n    // (2 \u003c a \u003c 3) AND a \u003c 2 -\u003e 2 \u003c a \u003c 2\n    public void testCombineBinaryComparisonsConjunctionOfNonOverlappingBoundaries() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, ONE, false, TWO, false);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(TWO, r.upper());\n        assertFalse(r.includeUpper());\n        assertEquals(Boolean.FALSE, r.fold());\n    }\n\n    // (2 \u003c a \u003c 3) AND (2 \u003c a \u003c\u003d 3) -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunctionOfUpperEqualsOverlappingBoundaries() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, true);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(r1, exp);\n    }\n\n    // (2 \u003c a \u003c 3) AND (1 \u003c a \u003c 3) -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunctionOverlappingUpperBoundary() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r1 \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(r2, exp);\n    }\n\n    // (2 \u003c a \u003c\u003d 3) AND (1 \u003c a \u003c 3) -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunctionWithDifferentUpperLimitInclusion() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, ONE, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, true);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // (0 \u003c a \u003c\u003d 1) AND (0 \u003c\u003d a \u003c 2) -\u003e 0 \u003c a \u003c\u003d 1\n    public void testRangesOverlappingConjunctionNoLowerBoundary() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, L(0), false, ONE, true);\n        Range r2 \u003d rangeOf(fa, L(0), true, TWO, false);\n\n        And and \u003d new And(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(r1, exp);\n    }\n\n    // a !\u003d 2 AND 3 \u003c a \u003c 5 -\u003e 3 \u003c a \u003c 5\n    public void testCombineBinaryComparisonsConjunction_Neq2AndRangeGt3Lt5() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, THREE, false, FIVE, false);\n        And and \u003d new And(EMPTY, range, neq);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(THREE, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(FIVE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a !\u003d 2 AND 0 \u003c a \u003c 1 -\u003e 0 \u003c a \u003c 1\n    public void testCombineBinaryComparisonsConjunction_Neq2AndRangeGt0Lt1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, L(0), false, ONE, false);\n        And and \u003d new And(EMPTY, neq, range);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(L(0), r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(ONE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a !\u003d 2 AND 2 \u003c\u003d a \u003c 3 -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunction_Neq2AndRangeGte2Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, TWO, true, THREE, false);\n        And and \u003d new And(EMPTY, neq, range);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a !\u003d 3 AND 2 \u003c a \u003c\u003d 3 -\u003e 2 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunction_Neq3AndRangeGt2Lte3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, THREE);\n        Range range \u003d rangeOf(fa, TWO, false, THREE, true);\n        And and \u003d new And(EMPTY, neq, range);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a !\u003d 2 AND 1 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsConjunction_Neq2AndRangeGt1Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n        And and \u003d new And(EMPTY, neq, range);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(And.class, exp.getClass()); // can\u0027t optimize\n    }\n\n    // a !\u003d 2 AND a \u003e 3 -\u003e a \u003e 3\n    public void testCombineBinaryComparisonsConjunction_Neq2AndGt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, THREE);\n        And and \u003d new And(EMPTY, neq, gt);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(gt, exp);\n    }\n\n    // a !\u003d 2 AND a \u003e\u003d 2 -\u003e a \u003e 2\n    public void testCombineBinaryComparisonsConjunction_Neq2AndGte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, TWO);\n        And and \u003d new And(EMPTY, neq, gte);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(GreaterThan.class, exp.getClass());\n        GreaterThan gt \u003d (GreaterThan) exp;\n        assertEquals(TWO, gt.right());\n    }\n\n    // a !\u003d 2 AND a \u003e\u003d 1 -\u003e nop\n    public void testCombineBinaryComparisonsConjunction_Neq2AndGte1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, ONE);\n        And and \u003d new And(EMPTY, neq, gte);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(And.class, exp.getClass()); // can\u0027t optimize\n    }\n\n    // a !\u003d 2 AND a \u003c\u003d 3 -\u003e nop\n    public void testCombineBinaryComparisonsConjunction_Neq2AndLte3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, THREE);\n        And and \u003d new And(EMPTY, neq, lte);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(and, exp); // can\u0027t optimize\n    }\n\n    // a !\u003d 2 AND a \u003c\u003d 2 -\u003e a \u003c 2\n    public void testCombineBinaryComparisonsConjunction_Neq2AndLte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, TWO);\n        And and \u003d new And(EMPTY, neq, lte);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(LessThan.class, exp.getClass());\n        LessThan lt \u003d (LessThan) exp;\n        assertEquals(TWO, lt.right());\n    }\n\n    // a !\u003d 2 AND a \u003c\u003d 1 -\u003e a \u003c\u003d 1\n    public void testCombineBinaryComparisonsConjunction_Neq2AndLte1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n        LessThanOrEqual lte \u003d lessThanOrEqualOf(fa, ONE);\n        And and \u003d new And(EMPTY, neq, lte);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(lte, exp);\n    }\n\n    // Disjunction\n\n    public void testCombineBinaryComparisonsDisjunctionNotComparable() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        GreaterThan gt1 \u003d greaterThanOf(fa, ONE);\n        GreaterThan gt2 \u003d greaterThanOf(fa, FALSE);\n\n        Or or \u003d new Or(EMPTY, gt1, gt2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(exp, or);\n    }\n\n    // 2 \u003c a OR 1 \u003c a OR 3 \u003c a -\u003e 1 \u003c a\n    public void testCombineBinaryComparisonsDisjunctionLowerBound() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        GreaterThan gt1 \u003d greaterThanOf(fa, ONE);\n        GreaterThan gt2 \u003d greaterThanOf(fa, TWO);\n        GreaterThan gt3 \u003d greaterThanOf(fa, THREE);\n\n        Or or \u003d new Or(EMPTY, gt1, new Or(EMPTY, gt2, gt3));\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(GreaterThan.class, exp.getClass());\n\n        GreaterThan gt \u003d (GreaterThan) exp;\n        assertEquals(ONE, gt.right());\n    }\n\n    // 2 \u003c a OR 1 \u003c a OR 3 \u003c\u003d a -\u003e 1 \u003c a\n    public void testCombineBinaryComparisonsDisjunctionIncludeLowerBounds() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        GreaterThan gt1 \u003d greaterThanOf(fa, ONE);\n        GreaterThan gt2 \u003d greaterThanOf(fa, TWO);\n        GreaterThanOrEqual gte3 \u003d greaterThanOrEqualOf(fa, THREE);\n\n        Or or \u003d new Or(EMPTY, new Or(EMPTY, gt1, gt2), gte3);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(GreaterThan.class, exp.getClass());\n\n        GreaterThan gt \u003d (GreaterThan) exp;\n        assertEquals(ONE, gt.right());\n    }\n\n    // a \u003c 1 OR a \u003c 2 OR a \u003c 3 -\u003e a \u003c 3\n    public void testCombineBinaryComparisonsDisjunctionUpperBound() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        LessThan lt1 \u003d lessThanOf(fa, ONE);\n        LessThan lt2 \u003d lessThanOf(fa, TWO);\n        LessThan lt3 \u003d lessThanOf(fa, THREE);\n\n        Or or \u003d new Or(EMPTY, new Or(EMPTY, lt1, lt2), lt3);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(LessThan.class, exp.getClass());\n\n        LessThan lt \u003d (LessThan) exp;\n        assertEquals(THREE, lt.right());\n    }\n\n    // a \u003c 2 OR a \u003c\u003d 2 OR a \u003c 1 -\u003e a \u003c\u003d 2\n    public void testCombineBinaryComparisonsDisjunctionIncludeUpperBounds() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        LessThan lt1 \u003d lessThanOf(fa, ONE);\n        LessThan lt2 \u003d lessThanOf(fa, TWO);\n        LessThanOrEqual lte2 \u003d lessThanOrEqualOf(fa, TWO);\n\n        Or or \u003d new Or(EMPTY, lt2, new Or(EMPTY, lte2, lt1));\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(LessThanOrEqual.class, exp.getClass());\n\n        LessThanOrEqual lte \u003d (LessThanOrEqual) exp;\n        assertEquals(TWO, lte.right());\n    }\n\n    // a \u003c 2 OR 3 \u003c a OR a \u003c 1 OR 4 \u003c a -\u003e a \u003c 2 OR 3 \u003c a\n    public void testCombineBinaryComparisonsDisjunctionOfLowerAndUpperBounds() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        LessThan lt1 \u003d lessThanOf(fa, ONE);\n        LessThan lt2 \u003d lessThanOf(fa, TWO);\n\n        GreaterThan gt3 \u003d greaterThanOf(fa, THREE);\n        GreaterThan gt4 \u003d greaterThanOf(fa, FOUR);\n\n        Or or \u003d new Or(EMPTY, new Or(EMPTY, lt2, gt3), new Or(EMPTY, lt1, gt4));\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(Or.class, exp.getClass());\n\n        Or ro \u003d (Or) exp;\n\n        assertEquals(LessThan.class, ro.left().getClass());\n        LessThan lt \u003d (LessThan) ro.left();\n        assertEquals(TWO, lt.right());\n        assertEquals(GreaterThan.class, ro.right().getClass());\n        GreaterThan gt \u003d (GreaterThan) ro.right();\n        assertEquals(THREE, gt.right());\n    }\n\n    // (2 \u003c a \u003c 3) OR (1 \u003c a \u003c 4) -\u003e (1 \u003c a \u003c 4)\n    public void testCombineBinaryComparisonsDisjunctionOfIncludedRangeNotComparable() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, ONE, false, FALSE, false);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(or, exp);\n    }\n\n    // (2 \u003c a \u003c 3) OR (1 \u003c a \u003c 4) -\u003e (1 \u003c a \u003c 4)\n    public void testCombineBinaryComparisonsDisjunctionOfIncludedRange() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, ONE, false, FOUR, false);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(Range.class, exp.getClass());\n\n        Range r \u003d (Range) exp;\n        assertEquals(ONE, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(FOUR, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // (2 \u003c a \u003c 3) OR (1 \u003c a \u003c 2) -\u003e same\n    public void testCombineBinaryComparisonsDisjunctionOfNonOverlappingBoundaries() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, ONE, false, TWO, false);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(or, exp);\n    }\n\n    // (2 \u003c a \u003c 3) OR (2 \u003c a \u003c\u003d 3) -\u003e 2 \u003c a \u003c\u003d 3\n    public void testCombineBinaryComparisonsDisjunctionOfUpperEqualsOverlappingBoundaries() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, true);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(r2, exp);\n    }\n\n    // (2 \u003c a \u003c 3) OR (1 \u003c a \u003c 3) -\u003e 1 \u003c a \u003c 3\n    public void testCombineBinaryComparisonsOverlappingUpperBoundary() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, false);\n        Range r1 \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(r1, exp);\n    }\n\n    // (2 \u003c a \u003c\u003d 3) OR (1 \u003c a \u003c 3) -\u003e same (the \u003c\u003d prevents the ranges from being combined)\n    public void testCombineBinaryComparisonsWithDifferentUpperLimitInclusion() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r1 \u003d rangeOf(fa, ONE, false, THREE, false);\n        Range r2 \u003d rangeOf(fa, TWO, false, THREE, true);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(or, exp);\n    }\n\n    // (a \u003d 1 AND b \u003d 3 AND c \u003d 4) OR (a \u003d 2 AND b \u003d 3 AND c \u003d 4) -\u003e (b \u003d 3 AND c \u003d 4) AND (a \u003d 1 OR a \u003d 2)\n    public void testBooleanSimplificationCommonExpressionSubstraction() {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\");\n        FieldAttribute fb \u003d getFieldAttribute(\"b\");\n        FieldAttribute fc \u003d getFieldAttribute(\"c\");\n\n        Expression a1 \u003d equalsOf(fa, ONE);\n        Expression a2 \u003d equalsOf(fa, TWO);\n        And common \u003d new And(EMPTY, equalsOf(fb, THREE), equalsOf(fc, FOUR));\n        And left \u003d new And(EMPTY, a1, common);\n        And right \u003d new And(EMPTY, a2, common);\n        Or or \u003d new Or(EMPTY, left, right);\n\n        Expression exp \u003d new BooleanSimplification().rule(or);\n        assertEquals(new And(EMPTY, common, new Or(EMPTY, a1, a2)), exp);\n    }\n\n    // (0 \u003c a \u003c\u003d 1) OR (0 \u003c a \u003c 2) -\u003e 0 \u003c a \u003c 2\n    public void testRangesOverlappingNoLowerBoundary() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Range r2 \u003d rangeOf(fa, L(0), false, TWO, false);\n        Range r1 \u003d rangeOf(fa, L(0), false, ONE, true);\n\n        Or or \u003d new Or(EMPTY, r1, r2);\n\n        CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n        Expression exp \u003d rule.rule(or);\n        assertEquals(r2, exp);\n    }\n\n    public void testBinaryComparisonAndOutOfRangeNotEqualsDifferentFields() {\n        FieldAttribute doubleOne \u003d fieldAttribute(\"double\", DOUBLE);\n        FieldAttribute doubleTwo \u003d fieldAttribute(\"double2\", DOUBLE);\n        FieldAttribute intOne \u003d fieldAttribute(\"int\", INTEGER);\n        FieldAttribute datetimeOne \u003d fieldAttribute(\"datetime\", INTEGER);\n        FieldAttribute keywordOne \u003d fieldAttribute(\"keyword\", KEYWORD);\n        FieldAttribute keywordTwo \u003d fieldAttribute(\"keyword2\", KEYWORD);\n\n        List\u003cAnd\u003e testCases \u003d asList(\n            // double \u003e 10 AND integer !\u003d -10\n            new And(EMPTY, greaterThanOf(doubleOne, L(10)), notEqualsOf(intOne, L(-10))),\n            // keyword \u003e \u00275\u0027 AND keyword2 !\u003d \u002748\u0027\n            new And(EMPTY, greaterThanOf(keywordOne, L(\"5\")), notEqualsOf(keywordTwo, L(\"48\"))),\n            // keyword !\u003d \u00272021\u0027 AND datetime \u003c\u003d \u00272020-12-04T17:48:22.954240Z\u0027\n            new And(EMPTY, notEqualsOf(keywordOne, L(\"2021\")), lessThanOrEqualOf(datetimeOne, L(\"2020-12-04T17:48:22.954240Z\"))),\n            // double \u003e 10.1 AND double2 !\u003d -10.1\n            new And(EMPTY, greaterThanOf(doubleOne, L(10.1d)), notEqualsOf(doubleTwo, L(-10.1d)))\n        );\n\n        for (And and : testCases) {\n            CombineBinaryComparisons rule \u003d new CombineBinaryComparisons();\n            Expression exp \u003d rule.rule(and);\n            assertEquals(\"Rule should not have transformed [\" + and.nodeString() + \"]\", and, exp);\n        }\n    }\n\n    // Equals \u0026 NullEquals\n\n    // 1 \u003c\u003d a \u003c 10 AND a \u003d\u003d 1 -\u003e a \u003d\u003d 1\n    public void testEliminateRangeByEqualsInInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Range r \u003d rangeOf(fa, ONE, true, L(10), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(eq1, exp);\n    }\n\n    // 1 \u003c\u003d a \u003c 10 AND a \u003c\u003d\u003e 1 -\u003e a \u003c\u003d\u003e 1\n    public void testEliminateRangeByNullEqualsInInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NullEquals eq1 \u003d nullEqualsOf(fa, ONE);\n        Range r \u003d rangeOf(fa, ONE, true, L(10), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(eq1, exp);\n    }\n\n    // The following tests should work only to simplify filters and\n    // not if the expressions are part of a projection\n    // See: https://github.com/elastic/elasticsearch/issues/35859\n\n    // a \u003d\u003d 1 AND a \u003d\u003d 2 -\u003e FALSE\n    public void testDualEqualsConjunction() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Equals eq2 \u003d equalsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, eq2));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003c\u003d\u003e 1 AND a \u003c\u003d\u003e 2 -\u003e FALSE\n    public void testDualNullEqualsConjunction() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NullEquals eq1 \u003d nullEqualsOf(fa, ONE);\n        NullEquals eq2 \u003d nullEqualsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, eq2));\n        assertEquals(FALSE, exp);\n    }\n\n    // 1 \u003c a \u003c 10 AND a \u003d\u003d 10 -\u003e FALSE\n    public void testEliminateRangeByEqualsOutsideInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, L(10));\n        Range r \u003d rangeOf(fa, ONE, false, L(10), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(FALSE, exp);\n    }\n\n    // 1 \u003c a \u003c 10 AND a \u003c\u003d\u003e 10 -\u003e FALSE\n    public void testEliminateRangeByNullEqualsOutsideInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NullEquals eq1 \u003d nullEqualsOf(fa, L(10));\n        Range r \u003d rangeOf(fa, ONE, false, L(10), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(FALSE, exp);\n    }\n\n    // a !\u003d 3 AND a \u003d 3 -\u003e FALSE\n    public void testPropagateEquals_VarNeq3AndVarEq3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NotEquals neq \u003d notEqualsOf(fa, THREE);\n        Equals eq \u003d equalsOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, neq, eq));\n        assertEquals(FALSE, exp);\n    }\n\n    // a !\u003d 4 AND a \u003d 3 -\u003e a \u003d 3\n    public void testPropagateEquals_VarNeq4AndVarEq3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n        Equals eq \u003d equalsOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, neq, eq));\n        assertEquals(Equals.class, exp.getClass());\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003c 2 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLt2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003c\u003d 2 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarLte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThanOrEqual lt \u003d lessThanOrEqualOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003c\u003d 1 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLte1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThanOrEqual lt \u003d lessThanOrEqualOf(fa, ONE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003e 2 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarGt2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003e\u003d 2 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarGte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gte));\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003e 3 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003c 3 AND a \u003e 1 AND a !\u003d 4 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n        GreaterThan gt \u003d greaterThanOf(fa, ONE);\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression and \u003d Predicates.combineAnd(asList(eq, lt, gt, neq));\n        Expression exp \u003d rule.rule((And) and);\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND 1 \u003c a \u003c 3 AND a \u003e 0 AND a !\u003d 4 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n        GreaterThan gt \u003d greaterThanOf(fa, L(0));\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression and \u003d Predicates.combineAnd(asList(eq, range, gt, neq));\n        Expression exp \u003d rule.rule((And) and);\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 OR a \u003e 1 -\u003e a \u003e 1\n    public void testPropagateEquals_VarEq2OrVarGt1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, ONE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, gt));\n        assertEquals(gt, exp);\n    }\n\n    // a \u003d 2 OR a \u003e 2 -\u003e a \u003e\u003d 2\n    public void testPropagateEquals_VarEq2OrVarGte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, gt));\n        assertEquals(GreaterThanOrEqual.class, exp.getClass());\n        GreaterThanOrEqual gte \u003d (GreaterThanOrEqual) exp;\n        assertEquals(TWO, gte.right());\n    }\n\n    // a \u003d 2 OR a \u003c 3 -\u003e a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, lt));\n        assertEquals(lt, exp);\n    }\n\n    // a \u003d 3 OR a \u003c 3 -\u003e a \u003c\u003d 3\n    public void testPropagateEquals_VarEq3OrVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, THREE);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, lt));\n        assertEquals(LessThanOrEqual.class, exp.getClass());\n        LessThanOrEqual lte \u003d (LessThanOrEqual) exp;\n        assertEquals(THREE, lte.right());\n    }\n\n    // a \u003d 2 OR 1 \u003c a \u003c 3 -\u003e 1 \u003c a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarRangeGt1Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(range, exp);\n    }\n\n    // a \u003d 2 OR 2 \u003c a \u003c 3 -\u003e 2 \u003c\u003d a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarRangeGt2Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, TWO, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertTrue(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a \u003d 3 OR 2 \u003c a \u003c 3 -\u003e 2 \u003c a \u003c\u003d 3\n    public void testPropagateEquals_VarEq3OrVarRangeGt2Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, THREE);\n        Range range \u003d rangeOf(fa, TWO, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertTrue(r.includeUpper());\n    }\n\n    // a \u003d 2 OR a !\u003d 2 -\u003e TRUE\n    public void testPropagateEquals_VarEq2OrVarNeq2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, neq));\n        assertEquals(TRUE, exp);\n    }\n\n    // a \u003d 2 OR a !\u003d 5 -\u003e a !\u003d 5\n    public void testPropagateEquals_VarEq2OrVarNeq5() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, FIVE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, neq));\n        assertEquals(NotEquals.class, exp.getClass());\n        NotEquals ne \u003d (NotEquals) exp;\n        assertEquals(FIVE, ne.right());\n    }\n\n    // a \u003d 2 OR 3 \u003c a \u003c 4 OR a \u003e 2 OR a!\u003d 2 -\u003e TRUE\n    public void testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, THREE, false, FOUR, false);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule((Or) Predicates.combineOr(asList(eq, range, neq, gt)));\n        assertEquals(TRUE, exp);\n    }\n\n    // a \u003d\u003d 1 AND a \u003d\u003d 2 -\u003e nop for date/time fields\n    public void testPropagateEquals_ignoreDateTimeFields() {\n        FieldAttribute fa \u003d getFieldAttribute(\"a\", DataTypes.DATETIME);\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Equals eq2 \u003d equalsOf(fa, TWO);\n        And and \u003d new And(EMPTY, eq1, eq2);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(and, exp);\n    }\n\n    //\n    // Like / Regex\n    //\n    public void testMatchAllLikeToExist() throws Exception {\n        for (String s : asList(\"%\", \"%%\", \"%%%\")) {\n            LikePattern pattern \u003d new LikePattern(s, (char) 0);\n            FieldAttribute fa \u003d getFieldAttribute();\n            Like l \u003d new Like(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(IsNotNull.class, e.getClass());\n            IsNotNull inn \u003d (IsNotNull) e;\n            assertEquals(fa, inn.field());\n        }\n    }\n\n    public void testMatchAllWildcardLikeToExist() throws Exception {\n        for (String s : asList(\"*\", \"**\", \"***\")) {\n            WildcardPattern pattern \u003d new WildcardPattern(s);\n            FieldAttribute fa \u003d getFieldAttribute();\n            WildcardLike l \u003d new WildcardLike(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(IsNotNull.class, e.getClass());\n            IsNotNull inn \u003d (IsNotNull) e;\n            assertEquals(fa, inn.field());\n        }\n    }\n\n    public void testMatchAllRLikeToExist() throws Exception {\n        RLikePattern pattern \u003d new RLikePattern(\".*\");\n        FieldAttribute fa \u003d getFieldAttribute();\n        RLike l \u003d new RLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(IsNotNull.class, e.getClass());\n        IsNotNull inn \u003d (IsNotNull) e;\n        assertEquals(fa, inn.field());\n    }\n\n    public void testExactMatchLike() throws Exception {\n        for (String s : asList(\"ab\", \"ab0%\", \"ab0_c\")) {\n            LikePattern pattern \u003d new LikePattern(s, \u00270\u0027);\n            FieldAttribute fa \u003d getFieldAttribute();\n            Like l \u003d new Like(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(Equals.class, e.getClass());\n            Equals eq \u003d (Equals) e;\n            assertEquals(fa, eq.left());\n            assertEquals(s.replace(\"0\", StringUtils.EMPTY), eq.right().fold());\n        }\n    }\n\n    public void testExactMatchWildcardLike() throws Exception {\n        String s \u003d \"ab\";\n        WildcardPattern pattern \u003d new WildcardPattern(s);\n        FieldAttribute fa \u003d getFieldAttribute();\n        WildcardLike l \u003d new WildcardLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(s, eq.right().fold());\n    }\n\n    public void testExactMatchRLike() throws Exception {\n        RLikePattern pattern \u003d new RLikePattern(\"abc\");\n        FieldAttribute fa \u003d getFieldAttribute();\n        RLike l \u003d new RLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(\"abc\", eq.right().fold());\n    }\n\n    //\n    // CombineDisjunction in Equals\n    //\n    public void testTwoEqualsWithOr() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), equalsOf(fa, TWO));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testTwoEqualsWithSameValue() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), equalsOf(fa, ONE));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(ONE, eq.right());\n    }\n\n    public void testOneEqualsOneIn() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), new In(EMPTY, fa, singletonList(TWO)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testOneEqualsOneInWithSameValue() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), new In(EMPTY, fa, asList(ONE, TWO)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testSingleValueInToEquals() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Equals equals \u003d equalsOf(fa, ONE);\n        Or or \u003d new Or(EMPTY, equals, new In(EMPTY, fa, singletonList(ONE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(equals, e);\n    }\n\n    public void testEqualsBehindAnd() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And and \u003d new And(EMPTY, equalsOf(fa, ONE), equalsOf(fa, TWO));\n        Filter dummy \u003d new Filter(EMPTY, relation(), and);\n        LogicalPlan transformed \u003d new CombineDisjunctionsToIn().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(and, ((Filter) transformed).condition());\n    }\n\n    public void testTwoEqualsDifferentFields() throws Exception {\n        FieldAttribute fieldOne \u003d getFieldAttribute(\"ONE\");\n        FieldAttribute fieldTwo \u003d getFieldAttribute(\"TWO\");\n\n        Or or \u003d new Or(EMPTY, equalsOf(fieldOne, ONE), equalsOf(fieldTwo, TWO));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(or, e);\n    }\n\n    public void testMultipleIn() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or firstOr \u003d new Or(EMPTY, new In(EMPTY, fa, singletonList(ONE)), new In(EMPTY, fa, singletonList(TWO)));\n        Or secondOr \u003d new Or(EMPTY, firstOr, new In(EMPTY, fa, singletonList(THREE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(secondOr);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO, THREE));\n    }\n\n    public void testOrWithNonCombinableExpressions() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or firstOr \u003d new Or(EMPTY, new In(EMPTY, fa, singletonList(ONE)), lessThanOf(fa, TWO));\n        Or secondOr \u003d new Or(EMPTY, firstOr, new In(EMPTY, fa, singletonList(THREE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(secondOr);\n        assertEquals(Or.class, e.getClass());\n        Or or \u003d (Or) e;\n        assertEquals(or.left(), firstOr.right());\n        assertEquals(In.class, or.right().getClass());\n        In in \u003d (In) or.right();\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, THREE));\n    }\n\n    // Null folding\n\n    public void testNullFoldingIsNull() {\n        FoldNull foldNull \u003d new FoldNull();\n        assertEquals(true, foldNull.rule(new IsNull(EMPTY, NULL)).fold());\n        assertEquals(false, foldNull.rule(new IsNull(EMPTY, TRUE)).fold());\n    }\n\n    public void testGenericNullableExpression() {\n        FoldNull rule \u003d new FoldNull();\n        // arithmetic\n        assertNullLiteral(rule.rule(new Add(EMPTY, getFieldAttribute(), NULL)));\n        // comparison\n        assertNullLiteral(rule.rule(greaterThanOf(getFieldAttribute(), NULL)));\n        // regex\n        assertNullLiteral(rule.rule(new RLike(EMPTY, NULL, new RLikePattern(\"123\"))));\n    }\n\n    public void testNullFoldingDoesNotApplyOnLogicalExpressions() {\n        FoldNull rule \u003d new FoldNull();\n\n        Or or \u003d new Or(EMPTY, NULL, TRUE);\n        assertEquals(or, rule.rule(or));\n        or \u003d new Or(EMPTY, NULL, NULL);\n        assertEquals(or, rule.rule(or));\n\n        And and \u003d new And(EMPTY, NULL, TRUE);\n        assertEquals(and, rule.rule(and));\n        and \u003d new And(EMPTY, NULL, NULL);\n        assertEquals(and, rule.rule(and));\n    }\n\n    //\n    // Propagate nullability (IS NULL / IS NOT NULL)\n    //\n\n    // a IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNull() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And and \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        assertEquals(FALSE, new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b IS NOT NULL AND c IS NULL AND d IS NOT NULL AND e IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNullMultiField() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And andOne \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, getFieldAttribute()));\n        And andTwo \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute()), new IsNotNull(EMPTY, getFieldAttribute()));\n        And andThree \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute()), new IsNotNull(EMPTY, fa));\n\n        And and \u003d new And(EMPTY, andOne, new And(EMPTY, andThree, andTwo));\n\n        assertEquals(FALSE, new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND a \u003e 1 \u003d\u003e a IS NULL AND false\n    public void testIsNullAndComparison() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        And and \u003d new And(EMPTY, isNull, greaterThanOf(fa, ONE));\n        assertEquals(new And(EMPTY, isNull, nullOf(BOOLEAN)), new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b \u003c 1 AND c \u003c 1 AND a \u003c 1 \u003d\u003e a IS NULL AND b \u003c 1 AND c \u003c 1 \u003d\u003e a IS NULL AND b \u003c 1 AND c \u003c 1\n    public void testIsNullAndMultipleComparison() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        And nestedAnd \u003d new And(EMPTY, lessThanOf(getFieldAttribute(\"b\"), ONE), lessThanOf(getFieldAttribute(\"c\"), ONE));\n        And and \u003d new And(EMPTY, isNull, nestedAnd);\n        And top \u003d new And(EMPTY, and, lessThanOf(fa, ONE));\n\n        Expression optimized \u003d new PropagateNullable().rule(top);\n        Expression expected \u003d new And(EMPTY, and, nullOf(BOOLEAN));\n        assertEquals(Predicates.splitAnd(expected), Predicates.splitAnd(optimized));\n    }\n\n    // ((a+1)/2) \u003e 1 AND a + 2 AND a IS NULL AND b \u003c 3 \u003d\u003e NULL AND NULL AND a IS NULL AND b \u003c 3\n    public void testIsNullAndDeeplyNestedExpression() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Expression nullified \u003d new And(\n            EMPTY,\n            greaterThanOf(new Div(EMPTY, new Add(EMPTY, fa, ONE), TWO), ONE),\n            greaterThanOf(new Add(EMPTY, fa, TWO), ONE)\n        );\n        Expression kept \u003d new And(EMPTY, isNull, lessThanOf(getFieldAttribute(\"b\"), THREE));\n        And and \u003d new And(EMPTY, nullified, kept);\n\n        Expression optimized \u003d new PropagateNullable().rule(and);\n        Expression expected \u003d new And(EMPTY, new And(EMPTY, nullOf(BOOLEAN), nullOf(BOOLEAN)), kept);\n\n        assertEquals(Predicates.splitAnd(expected), Predicates.splitAnd(optimized));\n    }\n\n    // a IS NULL OR a IS NOT NULL \u003d\u003e no change\n    // a IS NULL OR a \u003e 1 \u003d\u003e no change\n    public void testIsNullInDisjunction() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        Filter dummy \u003d new Filter(EMPTY, relation(), or);\n        LogicalPlan transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n\n        or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), greaterThanOf(fa, ONE));\n        dummy \u003d new Filter(EMPTY, relation(), or);\n        transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n    }\n\n    // a + 1 AND (a IS NULL OR a \u003e 3) \u003d\u003e no change\n    public void testIsNullDisjunction() throws Exception {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Or or \u003d new Or(EMPTY, isNull, greaterThanOf(fa, THREE));\n        And and \u003d new And(EMPTY, new Add(EMPTY, fa, ONE), or);\n\n        assertEquals(and, new PropagateNullable().rule(and));\n    }\n\n    public void testCombineFilters() throws Exception {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        Filter fb \u003d new Filter(EMPTY, fa, conditionB);\n\n        assertEquals(new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB)), new PushDownAndCombineFilters().apply(fb));\n    }\n\n    public void testPushDownFilter() throws Exception {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        List\u003cFieldAttribute\u003e projections \u003d singletonList(getFieldAttribute(\"b\"));\n        Project project \u003d new Project(EMPTY, fa, projections);\n        Filter fb \u003d new Filter(EMPTY, project, conditionB);\n\n        Filter combinedFilter \u003d new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB));\n        assertEquals(new Project(EMPTY, combinedFilter, projections), new PushDownAndCombineFilters().apply(fb));\n    }\n\n    public void testPushDownFilterThroughAgg() throws Exception {\n        EsRelation relation \u003d relation();\n        GreaterThan conditionA \u003d greaterThanOf(getFieldAttribute(\"a\"), ONE);\n        LessThan conditionB \u003d lessThanOf(getFieldAttribute(\"b\"), TWO);\n        GreaterThanOrEqual aggregateCondition \u003d greaterThanOrEqualOf(new Count(EMPTY, ONE, false), THREE);\n\n        Filter fa \u003d new Filter(EMPTY, relation, conditionA);\n        List\u003cFieldAttribute\u003e projections \u003d singletonList(getFieldAttribute(\"b\"));\n        // invalid aggregate but that\u0027s fine cause its properties are not used by this rule\n        Aggregate aggregate \u003d new Aggregate(EMPTY, fa, emptyList(), emptyList());\n        Filter fb \u003d new Filter(EMPTY, aggregate, new And(EMPTY, aggregateCondition, conditionB));\n\n        Filter combinedFilter \u003d new Filter(EMPTY, relation, new And(EMPTY, conditionA, conditionB));\n\n        // expected\n        Filter expected \u003d new Filter(EMPTY, new Aggregate(EMPTY, combinedFilter, emptyList(), emptyList()), aggregateCondition);\n        assertEquals(expected, new PushDownAndCombineFilters().apply(fb));\n    }\n\n    public void testIsNotNullOnIsNullField() {\n        EsRelation relation \u003d relation();\n        var fieldA \u003d getFieldAttribute(\"a\");\n        Expression inn \u003d isNotNull(fieldA);\n        Filter f \u003d new Filter(EMPTY, relation, inn);\n\n        assertEquals(f, new OptimizerRules.InferIsNotNull().apply(f));\n    }\n\n    public void testIsNotNullOnOperatorWithOneField() {\n        EsRelation relation \u003d relation();\n        var fieldA \u003d getFieldAttribute(\"a\");\n        Expression inn \u003d isNotNull(new Add(EMPTY, fieldA, ONE));\n        Filter f \u003d new Filter(EMPTY, relation, inn);\n        Filter expected \u003d new Filter(EMPTY, relation, new And(EMPTY, isNotNull(fieldA), inn));\n\n        assertEquals(expected, new OptimizerRules.InferIsNotNull().apply(f));\n    }\n\n    public void testIsNotNullOnOperatorWithTwoFields() {\n        EsRelation relation \u003d relation();\n        var fieldA \u003d getFieldAttribute(\"a\");\n        var fieldB \u003d getFieldAttribute(\"b\");\n        Expression inn \u003d isNotNull(new Add(EMPTY, fieldA, fieldB));\n        Filter f \u003d new Filter(EMPTY, relation, inn);\n        Filter expected \u003d new Filter(EMPTY, relation, new And(EMPTY, new And(EMPTY, isNotNull(fieldA), isNotNull(fieldB)), inn));\n\n        assertEquals(expected, new OptimizerRules.InferIsNotNull().apply(f));\n    }\n\n    public void testIsNotNullOnFunctionWithOneField() {\n        EsRelation relation \u003d relation();\n        var fieldA \u003d getFieldAttribute(\"a\");\n        var pattern \u003d L(\"abc\");\n        Expression inn \u003d isNotNull(\n            new And(EMPTY, new TestStartsWith(EMPTY, fieldA, pattern, false), greaterThanOf(new Add(EMPTY, ONE, TWO), THREE))\n        );\n\n        Filter f \u003d new Filter(EMPTY, relation, inn);\n        Filter expected \u003d new Filter(EMPTY, relation, new And(EMPTY, isNotNull(fieldA), inn));\n\n        assertEquals(expected, new OptimizerRules.InferIsNotNull().apply(f));\n    }\n\n    public void testIsNotNullOnFunctionWithTwoFields() {\n        EsRelation relation \u003d relation();\n        var fieldA \u003d getFieldAttribute(\"a\");\n        var fieldB \u003d getFieldAttribute(\"b\");\n        var pattern \u003d L(\"abc\");\n        Expression inn \u003d isNotNull(new TestStartsWith(EMPTY, fieldA, fieldB, false));\n\n        Filter f \u003d new Filter(EMPTY, relation, inn);\n        Filter expected \u003d new Filter(EMPTY, relation, new And(EMPTY, new And(EMPTY, isNotNull(fieldA), isNotNull(fieldB)), inn));\n\n        assertEquals(expected, new OptimizerRules.InferIsNotNull().apply(f));\n    }\n\n    public static class TestStartsWith extends StartsWith {\n\n        public TestStartsWith(Source source, Expression input, Expression pattern, boolean caseInsensitive) {\n            super(source, input, pattern, caseInsensitive);\n        }\n\n        @Override\n        public Expression replaceChildren(List\u003cExpression\u003e newChildren) {\n            return new TestStartsWith(source(), newChildren.get(0), newChildren.get(1), isCaseInsensitive());\n        }\n\n        @Override\n        protected NodeInfo\u003cTestStartsWith\u003e info() {\n            return NodeInfo.create(this, TestStartsWith::new, input(), pattern(), isCaseInsensitive());\n        }\n    }\n\n    public void testIsNotNullOnFunctionWithTwoField() {}\n\n    private IsNotNull isNotNull(Expression field) {\n        return new IsNotNull(EMPTY, field);\n    }\n\n    private IsNull isNull(Expression field) {\n        return new IsNull(EMPTY, field);\n    }\n\n    private Literal nullOf(DataType dataType) {\n        return new Literal(Source.EMPTY, null, dataType);\n    }\n\n    private void assertNullLiteral(Expression expression) {\n        assertEquals(Literal.class, expression.getClass());\n        assertNull(expression.fold());\n    }\n}","methodCount":141},"candidatesTelemetryData":{"numberOfSuggestions":5,"candidates":[{"lineStart":1861,"lineEnd":1864,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertNullLiteral to class Expression","description":"Move method assertNullLiteral to org.elasticsearch.xpack.ql.expression.Expression\nRationale: The assertNullLiteral() method evaluates properties of an Expression object, specifically checking if it is an instance of Literal and if its fold() method returns null. This method should be moved to the Expression class because it directly relates to the behavior of expressions and their evaluation. This move aligns with the Single Responsibility Principle by encapsulating related functionality within the class that owns the data, thus improving cohesion. However, it is important to ensure that moving this method does not lead to a tight coupling between the Expression class and the testing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1861,"lineEnd":1864,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertNullLiteral to class Expression","description":"Move method assertNullLiteral to org.elasticsearch.xpack.ql.expression.Expression\nRationale: The assertNullLiteral() method evaluates properties of an Expression object, specifically checking if it is an instance of Literal and if its fold() method returns null. This method should be moved to the Expression class because it directly relates to the behavior of expressions and their evaluation. This move aligns with the Single Responsibility Principle by encapsulating related functionality within the class that owns the data, thus improving cohesion. However, it is important to ensure that moving this method does not lead to a tight coupling between the Expression class and the testing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getFieldAttribute to class TestUtils","description":"move method getFieldAttribute to PsiClass:TestUtils\nRationale: The getFieldAttribute() method is a utility function that seems to be related to testing or generating attributes for fields. Moving it to TestUtils aligns with the Single Responsibility Principle, as TestUtils already contains multiple utility methods for testing purposes. This enhances cohesion by grouping related functionality together. However, care must be taken to ensure that the method does not inadvertently introduce dependencies that could complicate testing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getFieldAttribute to class InternalQlScriptUtils","description":"move method getFieldAttribute to PsiClass:InternalQlScriptUtils\nRationale: Given that the method deals with field attributes, which may be relevant in query language contexts, moving it to InternalQlScriptUtils would be appropriate. This class already handles various operations related to query language, and the method could enhance its utility. This move would also follow the Open/Closed Principle, as it allows for extension of the query language functionalities. However, it may require careful consideration of dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getFieldAttribute to class FunctionTestUtils","description":"move method getFieldAttribute to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils appears to be focused on generating various test inputs, which may include field attributes. Relocating getFieldAttribute() here would encapsulate the method within a class dedicated to testing functions, thus improving cohesion. This adheres to the Single Responsibility Principle. However, ensure that the method\u0027s use cases align with the existing methods in this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},{"method_name":"testConstantFolding","method_signature":"public testConstantFolding()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},{"method_name":"testConstantFoldingRange","method_signature":"public testConstantFoldingRange()","target_class":"","rationale":""},{"method_name":"testConstantNot","method_signature":"public testConstantNot()","target_class":"","rationale":""},{"method_name":"testConstantFoldingLikes","method_signature":"public testConstantFoldingLikes()","target_class":"","rationale":""},{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""},{"method_name":"testLiteralsOnTheRight","method_signature":"public testLiteralsOnTheRight()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},{"method_name":"testBoolCommonFactorExtraction","method_signature":"public testBoolCommonFactorExtraction()","target_class":"","rationale":""},{"method_name":"testBinaryComparisonSimplification","method_signature":"public testBinaryComparisonSimplification()","target_class":"","rationale":""},{"method_name":"testNullEqualsWithNullLiteralBecomesIsNull","method_signature":"public testNullEqualsWithNullLiteralBecomesIsNull()","target_class":"","rationale":""},{"method_name":"testBoolEqualsSimplificationOnExpressions","method_signature":"public testBoolEqualsSimplificationOnExpressions()","target_class":"","rationale":""},{"method_name":"testBoolEqualsSimplificationOnFields","method_signature":"public testBoolEqualsSimplificationOnFields()","target_class":"","rationale":""},{"method_name":"testFoldExcludingRangeToFalse","method_signature":"public testFoldExcludingRangeToFalse()","target_class":"","rationale":""},{"method_name":"testFoldExcludingRangeWithDifferentTypesToFalse","method_signature":"public testFoldExcludingRangeWithDifferentTypesToFalse()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsNotComparable","method_signature":"public testCombineBinaryComparisonsNotComparable()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsUpper","method_signature":"public testCombineBinaryComparisonsUpper()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsLower","method_signature":"public testCombineBinaryComparisonsLower()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsInclude","method_signature":"public testCombineBinaryComparisonsInclude()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsAndRangeLower","method_signature":"public testCombineBinaryComparisonsAndRangeLower()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsAndRangeUpper","method_signature":"public testCombineBinaryComparisonsAndRangeUpper()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsAndRangeUpperEqual","method_signature":"public testCombineBinaryComparisonsAndRangeUpperEqual()","target_class":"","rationale":""},{"method_name":"testCombineMultipleBinaryComparisons","method_signature":"public testCombineMultipleBinaryComparisons()","target_class":"","rationale":""},{"method_name":"testCombineMixedMultipleBinaryComparisons","method_signature":"public testCombineMixedMultipleBinaryComparisons()","target_class":"","rationale":""},{"method_name":"testCombineComparisonsIntoRange","method_signature":"public testCombineComparisonsIntoRange()","target_class":"","rationale":""},{"method_name":"testCombineMultipleComparisonsIntoRange","method_signature":"public testCombineMultipleComparisonsIntoRange()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunctionOfIncludedRange","method_signature":"public testCombineBinaryComparisonsConjunctionOfIncludedRange()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunctionOfNonOverlappingBoundaries","method_signature":"public testCombineBinaryComparisonsConjunctionOfNonOverlappingBoundaries()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunctionOfUpperEqualsOverlappingBoundaries","method_signature":"public testCombineBinaryComparisonsConjunctionOfUpperEqualsOverlappingBoundaries()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunctionOverlappingUpperBoundary","method_signature":"public testCombineBinaryComparisonsConjunctionOverlappingUpperBoundary()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunctionWithDifferentUpperLimitInclusion","method_signature":"public testCombineBinaryComparisonsConjunctionWithDifferentUpperLimitInclusion()","target_class":"","rationale":""},{"method_name":"testRangesOverlappingConjunctionNoLowerBoundary","method_signature":"public testRangesOverlappingConjunctionNoLowerBoundary()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndRangeGt3Lt5","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndRangeGt3Lt5()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndRangeGt0Lt1","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndRangeGt0Lt1()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndRangeGte2Lt3","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndRangeGte2Lt3()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq3AndRangeGt2Lte3","method_signature":"public testCombineBinaryComparisonsConjunction_Neq3AndRangeGt2Lte3()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndRangeGt1Lt3","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndRangeGt1Lt3()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndGt3","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndGt3()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndGte2","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndGte2()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndGte1","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndGte1()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndLte3","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndLte3()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndLte2","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndLte2()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsConjunction_Neq2AndLte1","method_signature":"public testCombineBinaryComparisonsConjunction_Neq2AndLte1()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionNotComparable","method_signature":"public testCombineBinaryComparisonsDisjunctionNotComparable()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionLowerBound","method_signature":"public testCombineBinaryComparisonsDisjunctionLowerBound()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionIncludeLowerBounds","method_signature":"public testCombineBinaryComparisonsDisjunctionIncludeLowerBounds()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionUpperBound","method_signature":"public testCombineBinaryComparisonsDisjunctionUpperBound()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionIncludeUpperBounds","method_signature":"public testCombineBinaryComparisonsDisjunctionIncludeUpperBounds()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionOfLowerAndUpperBounds","method_signature":"public testCombineBinaryComparisonsDisjunctionOfLowerAndUpperBounds()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionOfIncludedRangeNotComparable","method_signature":"public testCombineBinaryComparisonsDisjunctionOfIncludedRangeNotComparable()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionOfIncludedRange","method_signature":"public testCombineBinaryComparisonsDisjunctionOfIncludedRange()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionOfNonOverlappingBoundaries","method_signature":"public testCombineBinaryComparisonsDisjunctionOfNonOverlappingBoundaries()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsDisjunctionOfUpperEqualsOverlappingBoundaries","method_signature":"public testCombineBinaryComparisonsDisjunctionOfUpperEqualsOverlappingBoundaries()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsOverlappingUpperBoundary","method_signature":"public testCombineBinaryComparisonsOverlappingUpperBoundary()","target_class":"","rationale":""},{"method_name":"testCombineBinaryComparisonsWithDifferentUpperLimitInclusion","method_signature":"public testCombineBinaryComparisonsWithDifferentUpperLimitInclusion()","target_class":"","rationale":""},{"method_name":"testBooleanSimplificationCommonExpressionSubstraction","method_signature":"public testBooleanSimplificationCommonExpressionSubstraction()","target_class":"","rationale":""},{"method_name":"testRangesOverlappingNoLowerBoundary","method_signature":"public testRangesOverlappingNoLowerBoundary()","target_class":"","rationale":""},{"method_name":"testBinaryComparisonAndOutOfRangeNotEqualsDifferentFields","method_signature":"public testBinaryComparisonAndOutOfRangeNotEqualsDifferentFields()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByEqualsInInterval","method_signature":"public testEliminateRangeByEqualsInInterval()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByNullEqualsInInterval","method_signature":"public testEliminateRangeByNullEqualsInInterval()","target_class":"","rationale":""},{"method_name":"testDualEqualsConjunction","method_signature":"public testDualEqualsConjunction()","target_class":"","rationale":""},{"method_name":"testDualNullEqualsConjunction","method_signature":"public testDualNullEqualsConjunction()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByEqualsOutsideInterval","method_signature":"public testEliminateRangeByEqualsOutsideInterval()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByNullEqualsOutsideInterval","method_signature":"public testEliminateRangeByNullEqualsOutsideInterval()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarNeq3AndVarEq3","method_signature":"public testPropagateEquals_VarNeq3AndVarEq3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarNeq4AndVarEq3","method_signature":"public testPropagateEquals_VarNeq4AndVarEq3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt2","method_signature":"public testPropagateEquals_VarEq2AndVarLt2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLte2","method_signature":"public testPropagateEquals_VarEq2AndVarLte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLte1","method_signature":"public testPropagateEquals_VarEq2AndVarLte1()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarGt2","method_signature":"public testPropagateEquals_VarEq2AndVarGt2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarGte2","method_signature":"public testPropagateEquals_VarEq2AndVarGte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt3","method_signature":"public testPropagateEquals_VarEq2AndVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4","method_signature":"public testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4","method_signature":"public testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarGt1","method_signature":"public testPropagateEquals_VarEq2OrVarGt1()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarGte2","method_signature":"public testPropagateEquals_VarEq2OrVarGte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarLt3","method_signature":"public testPropagateEquals_VarEq2OrVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq3OrVarLt3","method_signature":"public testPropagateEquals_VarEq3OrVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt1Lt3","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt1Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt2Lt3","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt2Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq3OrVarRangeGt2Lt3","method_signature":"public testPropagateEquals_VarEq3OrVarRangeGt2Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarNeq2","method_signature":"public testPropagateEquals_VarEq2OrVarNeq2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarNeq5","method_signature":"public testPropagateEquals_VarEq2OrVarNeq5()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_ignoreDateTimeFields","method_signature":"public testPropagateEquals_ignoreDateTimeFields()","target_class":"","rationale":""},{"method_name":"testMatchAllLikeToExist","method_signature":"public testMatchAllLikeToExist()","target_class":"","rationale":""},{"method_name":"testMatchAllWildcardLikeToExist","method_signature":"public testMatchAllWildcardLikeToExist()","target_class":"","rationale":""},{"method_name":"testMatchAllRLikeToExist","method_signature":"public testMatchAllRLikeToExist()","target_class":"","rationale":""},{"method_name":"testExactMatchLike","method_signature":"public testExactMatchLike()","target_class":"","rationale":""},{"method_name":"testExactMatchWildcardLike","method_signature":"public testExactMatchWildcardLike()","target_class":"","rationale":""},{"method_name":"testExactMatchRLike","method_signature":"public testExactMatchRLike()","target_class":"","rationale":""},{"method_name":"testTwoEqualsWithOr","method_signature":"public testTwoEqualsWithOr()","target_class":"","rationale":""},{"method_name":"testTwoEqualsWithSameValue","method_signature":"public testTwoEqualsWithSameValue()","target_class":"","rationale":""},{"method_name":"testOneEqualsOneIn","method_signature":"public testOneEqualsOneIn()","target_class":"","rationale":""},{"method_name":"testOneEqualsOneInWithSameValue","method_signature":"public testOneEqualsOneInWithSameValue()","target_class":"","rationale":""},{"method_name":"testSingleValueInToEquals","method_signature":"public testSingleValueInToEquals()","target_class":"","rationale":""},{"method_name":"testEqualsBehindAnd","method_signature":"public testEqualsBehindAnd()","target_class":"","rationale":""},{"method_name":"testTwoEqualsDifferentFields","method_signature":"public testTwoEqualsDifferentFields()","target_class":"","rationale":""},{"method_name":"testMultipleIn","method_signature":"public testMultipleIn()","target_class":"","rationale":""},{"method_name":"testOrWithNonCombinableExpressions","method_signature":"public testOrWithNonCombinableExpressions()","target_class":"","rationale":""},{"method_name":"testNullFoldingIsNull","method_signature":"public testNullFoldingIsNull()","target_class":"","rationale":""},{"method_name":"testGenericNullableExpression","method_signature":"public testGenericNullableExpression()","target_class":"","rationale":""},{"method_name":"testNullFoldingDoesNotApplyOnLogicalExpressions","method_signature":"public testNullFoldingDoesNotApplyOnLogicalExpressions()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNull","method_signature":"public testIsNullAndNotNull()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNullMultiField","method_signature":"public testIsNullAndNotNullMultiField()","target_class":"","rationale":""},{"method_name":"testIsNullAndComparison","method_signature":"public testIsNullAndComparison()","target_class":"","rationale":""},{"method_name":"testIsNullAndMultipleComparison","method_signature":"public testIsNullAndMultipleComparison()","target_class":"","rationale":""},{"method_name":"testIsNullAndDeeplyNestedExpression","method_signature":"public testIsNullAndDeeplyNestedExpression()","target_class":"","rationale":""},{"method_name":"testIsNullInDisjunction","method_signature":"public testIsNullInDisjunction()","target_class":"","rationale":""},{"method_name":"testIsNullDisjunction","method_signature":"public testIsNullDisjunction()","target_class":"","rationale":""},{"method_name":"testCombineFilters","method_signature":"public testCombineFilters()","target_class":"","rationale":""},{"method_name":"testPushDownFilter","method_signature":"public testPushDownFilter()","target_class":"","rationale":""},{"method_name":"testPushDownFilterThroughAgg","method_signature":"public testPushDownFilterThroughAgg()","target_class":"","rationale":""},{"method_name":"testIsNotNullOnIsNullField","method_signature":"public testIsNotNullOnIsNullField()","target_class":"","rationale":""},{"method_name":"testIsNotNullOnOperatorWithOneField","method_signature":"public testIsNotNullOnOperatorWithOneField()","target_class":"","rationale":""},{"method_name":"testIsNotNullOnOperatorWithTwoFields","method_signature":"public testIsNotNullOnOperatorWithTwoFields()","target_class":"","rationale":""},{"method_name":"testIsNotNullOnFunctionWithOneField","method_signature":"public testIsNotNullOnFunctionWithOneField()","target_class":"","rationale":""},{"method_name":"testIsNotNullOnFunctionWithTwoFields","method_signature":"public testIsNotNullOnFunctionWithTwoFields()","target_class":"","rationale":""},{"method_name":"isNotNull","method_signature":"private isNotNull(Expression field)","target_class":"","rationale":""},{"method_name":"isNull","method_signature":"private isNull(Expression field)","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name)","target_class":"","rationale":""},{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},{"method_name":"testConstantFoldingRange","method_signature":"public testConstantFoldingRange()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},{"method_name":"testBinaryComparisonSimplification","method_signature":"public testBinaryComparisonSimplification()","target_class":"","rationale":""},{"method_name":"testConstantNot","method_signature":"public testConstantNot()","target_class":"","rationale":""},{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""},{"method_name":"isNotNull","method_signature":"private isNotNull(Expression field)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public testArithmeticFolding()":{"first":{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},"second":0.03351752374559523},"private assertNullLiteral(Expression expression)":{"first":{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},"second":0.1356634688384737},"private static getFieldAttribute(String name)":{"first":{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name)","target_class":"","rationale":""},"second":0.14345758865090838},"public testBoolSimplifyOr()":{"first":{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},"second":0.183589019659298},"public testBoolSimplifyAnd()":{"first":{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},"second":0.20870787430508667},"public testConstantFoldingRange()":{"first":{"method_name":"testConstantFoldingRange","method_signature":"public testConstantFoldingRange()","target_class":"","rationale":""},"second":0.22432407278389813},"public testConstantFoldingBinaryLogic()":{"first":{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},"second":0.2584349016995696},"public testConstantFoldingBinaryLogic_WithNullHandling()":{"first":{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},"second":0.2590388812075226},"public testConstantFoldingBinaryComparison()":{"first":{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},"second":0.26060321315651946},"private nullOf(DataType dataType)":{"first":{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},"second":0.2611487765320614},"public testBinaryComparisonSimplification()":{"first":{"method_name":"testBinaryComparisonSimplification","method_signature":"public testBinaryComparisonSimplification()","target_class":"","rationale":""},"second":0.26126223583159597},"public testConstantNot()":{"first":{"method_name":"testConstantNot","method_signature":"public testConstantNot()","target_class":"","rationale":""},"second":0.2625827417208894},"private static getFieldAttribute(String name, DataType dataType)":{"first":{"method_name":"getFieldAttribute","method_signature":"private static getFieldAttribute(String name, DataType dataType)","target_class":"","rationale":""},"second":0.2674620814952469},"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)":{"first":{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""},"second":0.2762119493065579},"private isNotNull(Expression field)":{"first":{"method_name":"isNotNull","method_signature":"private isNotNull(Expression field)","target_class":"","rationale":""},"second":0.2783024168671843}},"llmMethodPriority":{"priority_method_names":["testArithmeticFolding","assertNullLiteral","getFieldAttribute","testBoolSimplifyOr","testBoolSimplifyAnd","testConstantFoldingRange","testConstantFoldingBinaryLogic","testConstantFoldingBinaryLogic_WithNullHandling","testConstantFoldingBinaryComparison","nullOf","testBinaryComparisonSimplification","testConstantNot","getFieldAttribute","foldOperator","isNotNull"],"llm_response_time":4275},"targetClassMap":{"testArithmeticFolding":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":553,"similarity_computation_time":0,"similarity_metric":"voyage"},"assertNullLiteral":{"target_classes":[{"class_name":"Expression","similarity_score":0.2729394093831036},{"class_name":"Expression","similarity_score":0.2729394093831036}],"target_classes_sorted_by_llm":["Expression","Expression"],"llm_response_time":2623,"similarity_computation_time":0,"similarity_metric":"voyage"},"getFieldAttribute":{"target_classes":[{"class_name":"StringContainsRegex","similarity_score":0.41403933560541245},{"class_name":"StringUtils","similarity_score":0.4136516269447651},{"class_name":"SourceUtils","similarity_score":0.3979660329108319},{"class_name":"TestUtils","similarity_score":0.43526361834943345},{"class_name":"ParserUtils","similarity_score":0.4194125367882554},{"class_name":"NumericUtilsTests","similarity_score":0.16989490569788243},{"class_name":"LoggingUtils","similarity_score":0.253546276418555},{"class_name":"TransportActionUtils","similarity_score":0.25832630100078136},{"class_name":"ReflectionUtils","similarity_score":0.34310015697711027},{"class_name":"DateUtils","similarity_score":0.3535074118700683},{"class_name":"FunctionTestUtils","similarity_score":0.4870232549415787},{"class_name":"InternalQlScriptUtils","similarity_score":0.46632614521391963},{"class_name":"SetAsOptimized","similarity_score":0.4743416490252569},{"class_name":"SimplifyComparisonsArithmetics","similarity_score":0.4265245155160724},{"class_name":"PropagateEquals","similarity_score":0.2558268296559505},{"class_name":"PropagateNullable","similarity_score":0.3237290514506185},{"class_name":"MulDivSimplifier","similarity_score":0.3858052442784548},{"class_name":"BooleanSimplification","similarity_score":0.3416187511937878},{"class_name":"CombineBinaryComparisons","similarity_score":0.21003575123803186},{"class_name":"JwkValidateUtil","similarity_score":0.3193226505486613},{"class_name":"JwkValidateUtilTests","similarity_score":0.37620694333315613},{"class_name":"JwtUtil","similarity_score":0.36952053150386116},{"class_name":"SecuritySettingsUtil","similarity_score":0.15752081325927425},{"class_name":"SecurityTestUtils","similarity_score":0.3703985987435961},{"class_name":"SecurityUtils","similarity_score":0.4216370213557839},{"class_name":"TemplateUtils","similarity_score":0.3287016158528148},{"class_name":"TemplateUtilsTests","similarity_score":0.3502184141554632},{"class_name":"Term","similarity_score":0.35082320772281167},{"class_name":"SerializationTestUtils","similarity_score":0.3375087167633058}],"target_classes_sorted_by_llm":["TestUtils","InternalQlScriptUtils","FunctionTestUtils","ParserUtils","StringUtils","SourceUtils","SetAsOptimized","SimplifyComparisonsArithmetics","SecurityUtils","StringContainsRegex"],"llm_response_time":14212,"similarity_computation_time":26,"similarity_metric":"voyage"}}}
{"id":"64af1837-a6b1-4af2-a935-996d1e71e4a1","methodCount":19,"hostFunctionTelemetryData":{"hostFunctionSize":204,"lineStart":33,"lineEnd":236,"bodyLineStart":33,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/explain/ExplainResponse.java","sourceCode":"/**\n * Response containing the score explanation.\n */\npublic class ExplainResponse extends ActionResponse implements ToXContentObject {\n\n    private static final ParseField _INDEX \u003d new ParseField(\"_index\");\n    private static final ParseField _ID \u003d new ParseField(\"_id\");\n    private static final ParseField MATCHED \u003d new ParseField(\"matched\");\n    private static final ParseField EXPLANATION \u003d new ParseField(\"explanation\");\n    private static final ParseField VALUE \u003d new ParseField(\"value\");\n    private static final ParseField DESCRIPTION \u003d new ParseField(\"description\");\n    private static final ParseField DETAILS \u003d new ParseField(\"details\");\n    private static final ParseField GET \u003d new ParseField(\"get\");\n\n    private final String index;\n    private final String id;\n    private final boolean exists;\n    private Explanation explanation;\n    private GetResult getResult;\n\n    public ExplainResponse(String index, String id, boolean exists) {\n        this.index \u003d index;\n        this.id \u003d id;\n        this.exists \u003d exists;\n    }\n\n    public ExplainResponse(String index, String id, boolean exists, Explanation explanation) {\n        this(index, id, exists);\n        this.explanation \u003d explanation;\n    }\n\n    public ExplainResponse(String index, String id, boolean exists, Explanation explanation, GetResult getResult) {\n        this(index, id, exists, explanation);\n        this.getResult \u003d getResult;\n    }\n\n    public ExplainResponse(StreamInput in) throws IOException {\n        super(in);\n        index \u003d in.readString();\n        if (in.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            in.readString();\n        }\n        id \u003d in.readString();\n        exists \u003d in.readBoolean();\n        if (in.readBoolean()) {\n            explanation \u003d readExplanation(in);\n        }\n        if (in.readBoolean()) {\n            getResult \u003d new GetResult(in);\n        }\n    }\n\n    public String getIndex() {\n        return index;\n    }\n\n    public String getId() {\n        return id;\n    }\n\n    public Explanation getExplanation() {\n        return explanation;\n    }\n\n    public boolean isMatch() {\n        return explanation !\u003d null \u0026\u0026 explanation.isMatch();\n    }\n\n    public boolean hasExplanation() {\n        return explanation !\u003d null;\n    }\n\n    public boolean isExists() {\n        return exists;\n    }\n\n    public GetResult getGetResult() {\n        return getResult;\n    }\n\n    public RestStatus status() {\n        return exists ? RestStatus.OK : RestStatus.NOT_FOUND;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeString(index);\n        if (out.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            out.writeString(MapperService.SINGLE_MAPPING_NAME);\n        }\n        out.writeString(id);\n        out.writeBoolean(exists);\n        if (explanation \u003d\u003d null) {\n            out.writeBoolean(false);\n        } else {\n            out.writeBoolean(true);\n            writeExplanation(out, explanation);\n        }\n        if (getResult \u003d\u003d null) {\n            out.writeBoolean(false);\n        } else {\n            out.writeBoolean(true);\n            getResult.writeTo(out);\n        }\n    }\n\n    private static final ConstructingObjectParser\u003cExplainResponse, Boolean\u003e PARSER \u003d new ConstructingObjectParser\u003c\u003e(\n        \"explain\",\n        true,\n        (arg, exists) -\u003e new ExplainResponse((String) arg[0], (String) arg[1], exists, (Explanation) arg[2], (GetResult) arg[3])\n    );\n\n    static {\n        PARSER.declareString(ConstructingObjectParser.constructorArg(), _INDEX);\n        PARSER.declareString(ConstructingObjectParser.constructorArg(), _ID);\n        final ConstructingObjectParser\u003cExplanation, Boolean\u003e explanationParser \u003d getExplanationsParser();\n        PARSER.declareObject(ConstructingObjectParser.optionalConstructorArg(), explanationParser, EXPLANATION);\n        PARSER.declareObject(ConstructingObjectParser.optionalConstructorArg(), (p, c) -\u003e GetResult.fromXContentEmbedded(p), GET);\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private static ConstructingObjectParser\u003cExplanation, Boolean\u003e getExplanationsParser() {\n        final ConstructingObjectParser\u003cExplanation, Boolean\u003e explanationParser \u003d new ConstructingObjectParser\u003c\u003e(\n            \"explanation\",\n            true,\n            arg -\u003e {\n                if ((float) arg[0] \u003e 0) {\n                    return Explanation.match((float) arg[0], (String) arg[1], (Collection\u003cExplanation\u003e) arg[2]);\n                } else {\n                    return Explanation.noMatch((String) arg[1], (Collection\u003cExplanation\u003e) arg[2]);\n                }\n            }\n        );\n        explanationParser.declareFloat(ConstructingObjectParser.constructorArg(), VALUE);\n        explanationParser.declareString(ConstructingObjectParser.constructorArg(), DESCRIPTION);\n        explanationParser.declareObjectArray(ConstructingObjectParser.constructorArg(), explanationParser, DETAILS);\n        return explanationParser;\n    }\n\n    public static ExplainResponse fromXContent(XContentParser parser, boolean exists) {\n        return PARSER.apply(parser, exists);\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject();\n        builder.field(_INDEX.getPreferredName(), index);\n        if (builder.getRestApiVersion() \u003d\u003d RestApiVersion.V_7) {\n            builder.field(MapperService.TYPE_FIELD_NAME, MapperService.SINGLE_MAPPING_NAME);\n        }\n\n        builder.field(_ID.getPreferredName(), id);\n        builder.field(MATCHED.getPreferredName(), isMatch());\n        if (hasExplanation()) {\n            builder.startObject(EXPLANATION.getPreferredName());\n            buildExplanation(builder, explanation);\n            builder.endObject();\n        }\n        if (getResult !\u003d null) {\n            builder.startObject(GET.getPreferredName());\n            getResult.toXContentEmbedded(builder, params);\n            builder.endObject();\n        }\n        builder.endObject();\n        return builder;\n    }\n\n    private static void buildExplanation(XContentBuilder builder, Explanation explanation) throws IOException {\n        builder.field(VALUE.getPreferredName(), explanation.getValue());\n        builder.field(DESCRIPTION.getPreferredName(), explanation.getDescription());\n        Explanation[] innerExps \u003d explanation.getDetails();\n        if (innerExps !\u003d null) {\n            builder.startArray(DETAILS.getPreferredName());\n            for (Explanation exp : innerExps) {\n                builder.startObject();\n                buildExplanation(builder, exp);\n                builder.endObject();\n            }\n            builder.endArray();\n        }\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (this \u003d\u003d obj) {\n            return true;\n        }\n        if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n            return false;\n        }\n        ExplainResponse other \u003d (ExplainResponse) obj;\n        return index.equals(other.index)\n            \u0026\u0026 id.equals(other.id)\n            \u0026\u0026 Objects.equals(explanation, other.explanation)\n            \u0026\u0026 getResult.isExists() \u003d\u003d other.getResult.isExists()\n            \u0026\u0026 Objects.equals(getResult.sourceAsMap(), other.getResult.sourceAsMap())\n            \u0026\u0026 Objects.equals(getResult.getFields(), other.getResult.getFields());\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(index, id, explanation, getResult.isExists(), getResult.sourceAsMap(), getResult.getFields());\n    }\n}","methodCount":19},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":171,"lineEnd":173,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestResponseUtils","description":"move method fromXContent to PsiClass:RestResponseUtils\nRationale: The fromXContent() method is likely related to parsing and generating responses, which aligns well with the responsibilities of RestResponseUtils. Moving it here adheres to the Single Responsibility Principle by placing the method in a class that deals with response handling. This enhances cohesion, making it easier to manage response-related functionalities. However, care must be taken to ensure that dependencies on the current class do not break existing functionality.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":171,"lineEnd":173,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class AuditUtil","description":"move method fromXContent to PsiClass:AuditUtil\nRationale: The method fromXContent() involves parsing data, which can be relevant for audit logging processes. Relocating it to AuditUtil can enhance the utility of the class by integrating response parsing with auditing functionalities. This move supports the Open/Closed Principle, allowing AuditUtil to be extended with response handling capabilities without modifying existing code. However, it may introduce complexity if AuditUtil becomes overloaded with responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":171,"lineEnd":173,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class ActionTestUtils","description":"move method fromXContent to PsiClass:ActionTestUtils\nRationale: ActionTestUtils is focused on executing actions and handling responses, making it a suitable candidate for fromXContent(). This relocation promotes the Interface Segregation Principle, ensuring that classes only handle what they are designed for. Additionally, it will improve the testability of response-related actions. A potential drawback could be increased coupling if ActionTestUtils becomes too intertwined with response parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"isMatch","method_signature":"public isMatch()","target_class":"","rationale":""},{"method_name":"hasExplanation","method_signature":"public hasExplanation()","target_class":"","rationale":""},{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, boolean exists)","target_class":"","rationale":""},{"method_name":"buildExplanation","method_signature":"private static buildExplanation(XContentBuilder builder, Explanation explanation)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},{"method_name":"isMatch","method_signature":"public isMatch()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, boolean exists)","target_class":"","rationale":""},{"method_name":"hasExplanation","method_signature":"public hasExplanation()","target_class":"","rationale":""},{"method_name":"buildExplanation","method_signature":"private static buildExplanation(XContentBuilder builder, Explanation explanation)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public status()":{"first":{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},"second":0.43492424925044043},"public isMatch()":{"first":{"method_name":"isMatch","method_signature":"public isMatch()","target_class":"","rationale":""},"second":0.5110588450982614},"public static fromXContent(XContentParser parser, boolean exists)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, boolean exists)","target_class":"","rationale":""},"second":0.5464918251146371},"public hasExplanation()":{"first":{"method_name":"hasExplanation","method_signature":"public hasExplanation()","target_class":"","rationale":""},"second":0.5572583722858095},"private static buildExplanation(XContentBuilder builder, Explanation explanation)":{"first":{"method_name":"buildExplanation","method_signature":"private static buildExplanation(XContentBuilder builder, Explanation explanation)","target_class":"","rationale":""},"second":0.5607560628381035}},"llmMethodPriority":{"priority_method_names":["fromXContent","status","isMatch","hasExplanation","buildExplanation"],"llm_response_time":1270},"targetClassMap":{"status":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":504,"similarity_computation_time":1,"similarity_metric":"voyage"},"isMatch":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":482,"similarity_computation_time":0,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"ClusterStateCreationUtils","similarity_score":0.22996463859060998},{"class_name":"ActionTestUtils","similarity_score":0.408248290463863},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.46984098573493954},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.5141812936185794},{"class_name":"DataStreamsActionUtil","similarity_score":0.3546496828075953},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.22047927592204922},{"class_name":"SynonymsTestUtils","similarity_score":0.4652421051992354},{"class_name":"ExplainResponseTests","similarity_score":0.34990925405431866},{"class_name":"AuditUtil","similarity_score":0.5124540148752712},{"class_name":"RestResponseUtils","similarity_score":0.44939589857361506},{"class_name":"JwkValidateUtil","similarity_score":0.31579206177249114},{"class_name":"JwkValidateUtilTests","similarity_score":0.4098983913271282},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.23096744271857797},{"class_name":"AuthorizationUtils","similarity_score":0.16535498388634656},{"class_name":"FunctionTestUtils","similarity_score":0.5335072455221841},{"class_name":"FutureUtils","similarity_score":0.3627561712789943},{"class_name":"JwtUtil","similarity_score":0.3809114311213352},{"class_name":"RestTestUtil","similarity_score":0.30589507818778766},{"class_name":"GceMockUtils","similarity_score":0.44420202187924673},{"class_name":"CheckedFunctionUtils","similarity_score":0.13463011596692667},{"class_name":"RestUtils","similarity_score":0.30026291733537724},{"class_name":"RestUtilsTests","similarity_score":0.16297741028476553},{"class_name":"NumberUtils","similarity_score":0.31980107453341566},{"class_name":"GeneratorUtils","similarity_score":0.38750300851030034},{"class_name":"NumericUtilsTests","similarity_score":0.155092120426572},{"class_name":"KeyStoreUtil","similarity_score":0.35427961379118467},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.2686460541066734},{"class_name":"AwsEc2Utils","similarity_score":0.3297475890922907},{"class_name":"DiffableTestUtils","similarity_score":0.28659510138303507}],"target_classes_sorted_by_llm":["RestResponseUtils","AuditUtil","ActionTestUtils","FunctionTestUtils","GeneratorUtils","ShardMultiGetFromTranslogUtil","SynonymsTestUtils","GceMockUtils","PrevalidateShardPathRequestSerializationTestUtils","JwkValidateUtilTests"],"llm_response_time":10787,"similarity_computation_time":23,"similarity_metric":"voyage"}}}
{"id":"f434429c-69e4-40f2-9444-550726a57c87","methodCount":16,"hostFunctionTelemetryData":{"hostFunctionSize":160,"lineStart":24,"lineEnd":183,"bodyLineStart":24,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/update/UpdateResponse.java","sourceCode":"public class UpdateResponse extends DocWriteResponse {\n\n    private static final String GET \u003d \"get\";\n\n    private GetResult getResult;\n\n    public UpdateResponse(ShardId shardId, StreamInput in) throws IOException {\n        super(shardId, in);\n        if (in.readBoolean()) {\n            getResult \u003d new GetResult(in);\n        }\n    }\n\n    public UpdateResponse(StreamInput in) throws IOException {\n        super(in);\n        if (in.readBoolean()) {\n            getResult \u003d new GetResult(in);\n        }\n    }\n\n    /**\n     * Constructor to be used when a update didn\u0027t translate in a write.\n     * For example: update script with operation set to none\n     */\n    public UpdateResponse(ShardId shardId, String id, long seqNo, long primaryTerm, long version, Result result) {\n        this(ShardInfo.EMPTY, shardId, id, seqNo, primaryTerm, version, result);\n    }\n\n    @SuppressWarnings(\"this-escape\")\n    public UpdateResponse(ShardInfo shardInfo, ShardId shardId, String id, long seqNo, long primaryTerm, long version, Result result) {\n        super(shardId, id, seqNo, primaryTerm, version, result);\n        setShardInfo(shardInfo);\n    }\n\n    public void setGetResult(GetResult getResult) {\n        this.getResult \u003d getResult;\n    }\n\n    public GetResult getGetResult() {\n        return this.getResult;\n    }\n\n    @Override\n    public RestStatus status() {\n        return this.result \u003d\u003d Result.CREATED ? RestStatus.CREATED : super.status();\n    }\n\n    @Override\n    public void writeThin(StreamOutput out) throws IOException {\n        super.writeThin(out);\n        writeGetResult(out);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        writeGetResult(out);\n    }\n\n    private void writeGetResult(StreamOutput out) throws IOException {\n        if (getResult \u003d\u003d null) {\n            out.writeBoolean(false);\n        } else {\n            out.writeBoolean(true);\n            getResult.writeTo(out);\n        }\n    }\n\n    @Override\n    public XContentBuilder innerToXContent(XContentBuilder builder, Params params) throws IOException {\n        super.innerToXContent(builder, params);\n        if (getGetResult() !\u003d null) {\n            builder.startObject(GET);\n            getGetResult().toXContentEmbedded(builder, params);\n            builder.endObject();\n        }\n        return builder;\n    }\n\n    @Override\n    public String toString() {\n        StringBuilder builder \u003d new StringBuilder();\n        builder.append(\"UpdateResponse[\");\n        builder.append(\"index\u003d\").append(getIndex());\n        builder.append(\",id\u003d\").append(getId());\n        builder.append(\",version\u003d\").append(getVersion());\n        builder.append(\",seqNo\u003d\").append(getSeqNo());\n        builder.append(\",primaryTerm\u003d\").append(getPrimaryTerm());\n        builder.append(\",result\u003d\").append(getResult().getLowercase());\n        builder.append(\",shards\u003d\").append(getShardInfo());\n        return builder.append(\"]\").toString();\n    }\n\n    public static UpdateResponse fromXContent(XContentParser parser) throws IOException {\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser);\n\n        Builder context \u003d new Builder();\n        while (parser.nextToken() !\u003d XContentParser.Token.END_OBJECT) {\n            parseXContentFields(parser, context);\n        }\n        return context.build();\n    }\n\n    /**\n     * Parse the current token and update the parsing context appropriately.\n     */\n    public static void parseXContentFields(XContentParser parser, Builder context) throws IOException {\n        XContentParser.Token token \u003d parser.currentToken();\n        String currentFieldName \u003d parser.currentName();\n\n        if (GET.equals(currentFieldName)) {\n            if (token \u003d\u003d XContentParser.Token.START_OBJECT) {\n                context.setGetResult(GetResult.fromXContentEmbedded(parser));\n            }\n        } else {\n            DocWriteResponse.parseInnerToXContent(parser, context);\n        }\n    }\n\n    /**\n     * Builder class for {@link UpdateResponse}. This builder is usually used during xcontent parsing to\n     * temporarily store the parsed values, then the {@link DocWriteResponse.Builder#build()} method is called to\n     * instantiate the {@link UpdateResponse}.\n     */\n    public static class Builder extends DocWriteResponse.Builder {\n\n        private GetResult getResult \u003d null;\n\n        public void setGetResult(GetResult getResult) {\n            this.getResult \u003d getResult;\n        }\n\n        @Override\n        public UpdateResponse build() {\n            UpdateResponse update;\n            if (shardInfo !\u003d null) {\n                update \u003d new UpdateResponse(shardInfo, shardId, id, seqNo, primaryTerm, version, result);\n            } else {\n                update \u003d new UpdateResponse(shardId, id, seqNo, primaryTerm, version, result);\n            }\n            if (getResult !\u003d null) {\n                update.setGetResult(\n                    new GetResult(\n                        update.getIndex(),\n                        update.getId(),\n                        getResult.getSeqNo(),\n                        getResult.getPrimaryTerm(),\n                        update.getVersion(),\n                        getResult.isExists(),\n                        getResult.internalSourceRef(),\n                        getResult.getDocumentFields(),\n                        getResult.getMetadataFields()\n                    )\n                );\n            }\n            update.setForcedRefresh(forcedRefresh);\n            return update;\n        }\n    }\n}","methodCount":16},"candidatesTelemetryData":{"numberOfSuggestions":7,"candidates":[{"lineStart":116,"lineEnd":124,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class UpdateHelper","description":"move method fromXContent to PsiClass:UpdateHelper\nRationale: The fromXContent() method is responsible for parsing and constructing an UpdateResponse from a given XContentParser. It aligns closely with the responsibilities of UpdateHelper, which deals with preparing and executing updates. Moving this method to UpdateHelper adheres to the Single Responsibility Principle, as it centralizes update-related logic. This move enhances cohesion and reusability, while also improving the organization of the codebase. A potential drawback is that it may increase the size of UpdateHelper, which could lead to a violation of the Interface Segregation Principle if it becomes too bulky.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":124,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestResponseUtils","description":"move method fromXContent to PsiClass:RestResponseUtils\nRationale: The fromXContent() method deals with parsing content, which can be considered a utility function for handling responses. RestResponseUtils already contains methods related to response handling, making it a logical fit. This relocation would promote utility and reusability of the parsing method. However, it may dilute the focus of RestResponseUtils if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":124,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class LicenseUtils","description":"move method fromXContent to PsiClass:LicenseUtils\nRationale: Although primarily focused on license management, LicenseUtils may benefit from utility methods that handle parsing and validation. The fromXContent() method could be seen as a utility for creating license-related responses. This move could enhance the utility of LicenseUtils, but it risks mixing concerns, which could lead to a violation of the Single Responsibility Principle.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":82,"lineEnd":89,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method writeGetResult to class GetResult","description":"Move method writeGetResult to org.elasticsearch.index.get.GetResult\nRationale: The writeGetResult() method is directly related to the GetResult object, as it checks if getResult is null and writes its state to the StreamOutput. Moving this method to the GetResult class adheres to the Single Responsibility Principle, as it centralizes the logic for handling the serialization of GetResult instances. This enhances cohesion within the GetResult class, making it the primary owner of its serialization logic, which is an essential part of its functionality. Additionally, this move aligns with the Open/Closed Principle, as the GetResult class can be extended in the future with additional serialization methods without modifying the original class that contained writeGetResult(). A potential drawback is that if the current class has significant dependencies on writeGetResult(), those dependencies will need to be managed, but overall, this move leads to a cleaner and more maintainable design.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":126,"lineEnd":140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseXContentFields to class UpdateHelper","description":"move method parseXContentFields to PsiClass:UpdateHelper\nRationale: The parseXContentFields() method is involved in parsing content and updating context, which aligns closely with the responsibilities of UpdateHelper that includes methods for preparing and executing updates. Moving it here adheres to the Single Responsibility Principle, as UpdateHelper is responsible for handling updates and related parsing. This enhances cohesion by grouping parsing logic with update operations. A potential drawback is that it may increase the complexity of UpdateHelper if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":126,"lineEnd":140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseXContentFields to class RestUtils","description":"move method parseXContentFields to PsiClass:RestUtils\nRationale: RestUtils deals with various utility functions related to REST operations, including decoding and extracting information from requests. Since parseXContentFields() involves parsing tokens and updating context based on REST-like content, it fits well here. This move aligns with the Interface Segregation Principle by keeping REST-related utilities together, improving organization. However, it may lead to a bloated utility class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":126,"lineEnd":140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseXContentFields to class JwtUtil","description":"move method parseXContentFields to PsiClass:JwtUtil\nRationale: JwtUtil is focused on parsing and validating tokens and URIs, which is conceptually similar to parsing content fields. Moving parseXContentFields() here would consolidate parsing logic related to tokens, adhering to the Single Responsibility Principle. This enhances cohesion in the class, but there\u0027s a risk of diluting the class\u0027s focus on JWT-specific logic if not carefully managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"writeGetResult","method_signature":"private writeGetResult(StreamOutput out)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseXContentFields","method_signature":"public static parseXContentFields(XContentParser parser, Builder context)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"writeGetResult","method_signature":"private writeGetResult(StreamOutput out)","target_class":"","rationale":""},{"method_name":"parseXContentFields","method_signature":"public static parseXContentFields(XContentParser parser, Builder context)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.537822862601302},"private writeGetResult(StreamOutput out)":{"first":{"method_name":"writeGetResult","method_signature":"private writeGetResult(StreamOutput out)","target_class":"","rationale":""},"second":0.6397608934876533},"public static parseXContentFields(XContentParser parser, Builder context)":{"first":{"method_name":"parseXContentFields","method_signature":"public static parseXContentFields(XContentParser parser, Builder context)","target_class":"","rationale":""},"second":0.6555174244918096}},"llmMethodPriority":{"priority_method_names":["fromXContent","writeGetResult","parseXContentFields"],"llm_response_time":1253},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"ActionTestUtils","similarity_score":0.39370039370059057},{"class_name":"ClusterStateCreationUtils","similarity_score":0.3388211690128957},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.526178598924592},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.5118539172638097},{"class_name":"DataStreamsActionUtil","similarity_score":0.4086162106921597},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.2351585405008862},{"class_name":"SynonymsTestUtils","similarity_score":0.5065552689186129},{"class_name":"UpdateHelper","similarity_score":0.4602822767521865},{"class_name":"UpdateResponseTests","similarity_score":0.4463713913695891},{"class_name":"RestResponseUtils","similarity_score":0.5592022063569749},{"class_name":"MapperTestUtils","similarity_score":0.42113487104341957},{"class_name":"JwkValidateUtil","similarity_score":0.397991199651609},{"class_name":"JwkValidateUtilTests","similarity_score":0.496268560084601},{"class_name":"LevelUtil","similarity_score":0.18953562637585883},{"class_name":"JwtUtil","similarity_score":0.46455158535260693},{"class_name":"CheckedFunctionUtils","similarity_score":0.12242278206274654},{"class_name":"RestTestUtil","similarity_score":0.31052055826838504},{"class_name":"LicenseUtils","similarity_score":0.478138081493187},{"class_name":"RestUtils","similarity_score":0.3636472944452673},{"class_name":"RestUtilsTests","similarity_score":0.25513503368148294},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.21397579292615485},{"class_name":"NumberUtils","similarity_score":0.3979419194568437},{"class_name":"LifecyclePolicyTestsUtils","similarity_score":0.3478596385570741},{"class_name":"LifecyclePolicyUtils","similarity_score":0.47051093826279783},{"class_name":"MathUtils","similarity_score":0.22885377114725872},{"class_name":"KeyStoreUtil","similarity_score":0.41985239534766794},{"class_name":"NumericUtilsTests","similarity_score":0.16817494738381392},{"class_name":"DiffableTestUtils","similarity_score":0.40263811598013555},{"class_name":"DiffableUtils","similarity_score":0.5176125754813462}],"target_classes_sorted_by_llm":["UpdateHelper","RestResponseUtils","LicenseUtils","LifecyclePolicyUtils","DiffableUtils","ShardMultiGetFromTranslogUtil","JwtUtil","PrevalidateShardPathRequestSerializationTestUtils","SynonymsTestUtils","JwkValidateUtilTests"],"llm_response_time":10056,"similarity_computation_time":60,"similarity_metric":"voyage"},"writeGetResult":{"target_classes":[{"class_name":"GetResult","similarity_score":0.663324999925332}],"target_classes_sorted_by_llm":["GetResult"],"llm_response_time":2170,"similarity_computation_time":1,"similarity_metric":"voyage"},"parseXContentFields":{"target_classes":[{"class_name":"ClusterStateCreationUtils","similarity_score":0.5179972124375347},{"class_name":"ActionTestUtils","similarity_score":0.4387660253483626},{"class_name":"DataStreamsActionUtil","similarity_score":0.4883741565338877},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.32936627462012996},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.4859054032563392},{"class_name":"SynonymsTestUtils","similarity_score":0.4684874806016906},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.5459058939351292},{"class_name":"UpdateHelper","similarity_score":0.5907533158858167},{"class_name":"UpdateResponseTests","similarity_score":0.5604642179312218},{"class_name":"RestResponseUtils","similarity_score":0.6091759908603348},{"class_name":"AuditUtil","similarity_score":0.5814898587835297},{"class_name":"RestTestUtil","similarity_score":0.51753843742723},{"class_name":"RestUtils","similarity_score":0.6116391211946106},{"class_name":"RestUtilsTests","similarity_score":0.3115320831085783},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.5160767649029815},{"class_name":"AuthorizationUtils","similarity_score":0.3791943348182858},{"class_name":"JwkValidateUtil","similarity_score":0.5049031814707879},{"class_name":"JwkValidateUtilTests","similarity_score":0.5835244094097736},{"class_name":"JwtUtil","similarity_score":0.620931855835606},{"class_name":"CredentialsRedaction","similarity_score":0.6345263120605439},{"class_name":"RetentionLeaseUtils","similarity_score":0.3302891295379081},{"class_name":"CryptUtils","similarity_score":0.5300999190441517},{"class_name":"CheckedFunctionUtils","similarity_score":0.2647210231115392},{"class_name":"AwsEc2Utils","similarity_score":0.5006259130345433},{"class_name":"CsvTestUtils","similarity_score":0.580810587892763},{"class_name":"TemplateUtils","similarity_score":0.6212956283914159},{"class_name":"TemplateUtilsTests","similarity_score":0.616352963136031},{"class_name":"Term","similarity_score":0.43412157106222954},{"class_name":"KeyStoreUtil","similarity_score":0.6169868626934623}],"target_classes_sorted_by_llm":["UpdateHelper","RestUtils","JwtUtil","TemplateUtils","RestResponseUtils","CredentialsRedaction","AuditUtil","KeyStoreUtil","TemplateUtilsTests","JwkValidateUtilTests"],"llm_response_time":12913,"similarity_computation_time":15,"similarity_metric":"voyage"}}}
{"id":"198d4943-9f13-46ba-b7a0-2b2fd2b63c1c","methodCount":13,"hostFunctionTelemetryData":{"hostFunctionSize":223,"lineStart":40,"lineEnd":262,"bodyLineStart":40,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/admin/cluster/node/tasks/list/ListTasksResponse.java","sourceCode":"/**\n * Returns the list of tasks currently running on the nodes\n */\npublic class ListTasksResponse extends BaseTasksResponse {\n    private static final String TASKS \u003d \"tasks\";\n\n    private final List\u003cTaskInfo\u003e tasks;\n\n    private Map\u003cString, List\u003cTaskInfo\u003e\u003e perNodeTasks;\n\n    private List\u003cTaskGroup\u003e groups;\n\n    public ListTasksResponse(\n        List\u003cTaskInfo\u003e tasks,\n        List\u003cTaskOperationFailure\u003e taskFailures,\n        List\u003c? extends ElasticsearchException\u003e nodeFailures\n    ) {\n        super(taskFailures, nodeFailures);\n        this.tasks \u003d tasks \u003d\u003d null ? List.of() : List.copyOf(tasks);\n    }\n\n    public ListTasksResponse(StreamInput in) throws IOException {\n        super(in);\n        tasks \u003d in.readCollectionAsImmutableList(TaskInfo::from);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        out.writeCollection(tasks);\n    }\n\n    protected static \u003cT\u003e ConstructingObjectParser\u003cT, Void\u003e setupParser(\n        String name,\n        TriFunction\u003cList\u003cTaskInfo\u003e, List\u003cTaskOperationFailure\u003e, List\u003cElasticsearchException\u003e, T\u003e ctor\n    ) {\n        ConstructingObjectParser\u003cT, Void\u003e parser \u003d new ConstructingObjectParser\u003c\u003e(name, true, constructingObjects -\u003e {\n            int i \u003d 0;\n            @SuppressWarnings(\"unchecked\")\n            List\u003cTaskInfo\u003e tasks \u003d (List\u003cTaskInfo\u003e) constructingObjects[i++];\n            @SuppressWarnings(\"unchecked\")\n            List\u003cTaskOperationFailure\u003e tasksFailures \u003d (List\u003cTaskOperationFailure\u003e) constructingObjects[i++];\n            @SuppressWarnings(\"unchecked\")\n            List\u003cElasticsearchException\u003e nodeFailures \u003d (List\u003cElasticsearchException\u003e) constructingObjects[i];\n            return ctor.apply(tasks, tasksFailures, nodeFailures);\n        });\n        parser.declareObjectArray(optionalConstructorArg(), TaskInfo.PARSER, new ParseField(TASKS));\n        parser.declareObjectArray(optionalConstructorArg(), (p, c) -\u003e TaskOperationFailure.fromXContent(p), new ParseField(TASK_FAILURES));\n        parser.declareObjectArray(\n            optionalConstructorArg(),\n            (p, c) -\u003e ElasticsearchException.fromXContent(p),\n            new ParseField(NODE_FAILURES)\n        );\n        return parser;\n    }\n\n    private static final ConstructingObjectParser\u003cListTasksResponse, Void\u003e PARSER \u003d setupParser(\n        \"list_tasks_response\",\n        ListTasksResponse::new\n    );\n\n    /**\n     * Returns the list of tasks by node\n     */\n    public Map\u003cString, List\u003cTaskInfo\u003e\u003e getPerNodeTasks() {\n        if (perNodeTasks \u003d\u003d null) {\n            perNodeTasks \u003d tasks.stream().collect(Collectors.groupingBy(t -\u003e t.taskId().getNodeId()));\n        }\n        return perNodeTasks;\n    }\n\n    /**\n     * Get the tasks found by this request grouped by parent tasks.\n     */\n    public List\u003cTaskGroup\u003e getTaskGroups() {\n        if (groups \u003d\u003d null) {\n            buildTaskGroups();\n        }\n        return groups;\n    }\n\n    private void buildTaskGroups() {\n        Map\u003cTaskId, TaskGroup.Builder\u003e taskGroups \u003d new HashMap\u003c\u003e();\n        List\u003cTaskGroup.Builder\u003e topLevelTasks \u003d new ArrayList\u003c\u003e();\n        // First populate all tasks\n        for (TaskInfo taskInfo : this.tasks) {\n            taskGroups.put(taskInfo.taskId(), TaskGroup.builder(taskInfo));\n        }\n\n        // Now go through all task group builders and add children to their parents\n        for (TaskGroup.Builder taskGroup : taskGroups.values()) {\n            TaskId parentTaskId \u003d taskGroup.getTaskInfo().parentTaskId();\n            if (parentTaskId.isSet()) {\n                TaskGroup.Builder parentTask \u003d taskGroups.get(parentTaskId);\n                if (parentTask !\u003d null) {\n                    // we found parent in the list of tasks - add it to the parent list\n                    parentTask.addGroup(taskGroup);\n                } else {\n                    // we got zombie or the parent was filtered out - add it to the top task list\n                    topLevelTasks.add(taskGroup);\n                }\n            } else {\n                // top level task - add it to the top task list\n                topLevelTasks.add(taskGroup);\n            }\n        }\n        this.groups \u003d topLevelTasks.stream().map(TaskGroup.Builder::build).toList();\n    }\n\n    /**\n     * Get the tasks found by this request.\n     */\n    public List\u003cTaskInfo\u003e getTasks() {\n        return tasks;\n    }\n\n    /**\n     * Convert this task response to XContent grouping by executing nodes.\n     */\n    public ChunkedToXContentObject groupedByNode(Supplier\u003cDiscoveryNodes\u003e nodesInCluster) {\n        return ignored -\u003e {\n            final var discoveryNodes \u003d nodesInCluster.get();\n            return Iterators.concat(Iterators.single((builder, params) -\u003e {\n                builder.startObject();\n                toXContentCommon(builder, params);\n                builder.startObject(\"nodes\");\n                return builder;\n            }), Iterators.flatMap(getPerNodeTasks().entrySet().iterator(), entry -\u003e {\n                DiscoveryNode node \u003d discoveryNodes.get(entry.getKey());\n                return Iterators.concat(Iterators.single((builder, params) -\u003e {\n                    builder.startObject(entry.getKey());\n                    if (node !\u003d null) {\n                        // If the node is no longer part of the cluster, oh well, we\u0027ll just skip its useful information.\n                        builder.field(\"name\", node.getName());\n                        builder.field(\"transport_address\", node.getAddress().toString());\n                        builder.field(\"host\", node.getHostName());\n                        builder.field(\"ip\", node.getAddress());\n\n                        builder.startArray(\"roles\");\n                        for (DiscoveryNodeRole role : node.getRoles()) {\n                            builder.value(role.roleName());\n                        }\n                        builder.endArray();\n\n                        if (node.getAttributes().isEmpty() \u003d\u003d false) {\n                            builder.startObject(\"attributes\");\n                            for (Map.Entry\u003cString, String\u003e attrEntry : node.getAttributes().entrySet()) {\n                                builder.field(attrEntry.getKey(), attrEntry.getValue());\n                            }\n                            builder.endObject();\n                        }\n                    }\n                    builder.startObject(TASKS);\n                    return builder;\n                }), Iterators.map(entry.getValue().iterator(), task -\u003e (builder, params) -\u003e {\n                    builder.startObject(task.taskId().toString());\n                    task.toXContent(builder, params);\n                    builder.endObject();\n                    return builder;\n                }), Iterators.single((builder, params) -\u003e {\n                    builder.endObject();\n                    builder.endObject();\n                    return builder;\n                }));\n            }), Iterators.single((builder, params) -\u003e {\n                builder.endObject();\n                builder.endObject();\n                return builder;\n            }));\n        };\n    }\n\n    /**\n     * Convert this response to XContent grouping by parent tasks.\n     */\n    public ChunkedToXContentObject groupedByParent() {\n        return ignored -\u003e Iterators.concat(Iterators.single((builder, params) -\u003e {\n            builder.startObject();\n            toXContentCommon(builder, params);\n            builder.startObject(TASKS);\n            return builder;\n        }), Iterators.map(getTaskGroups().iterator(), group -\u003e (builder, params) -\u003e {\n            builder.field(group.taskInfo().taskId().toString());\n            group.toXContent(builder, params);\n            return builder;\n        }), Iterators.single((builder, params) -\u003e {\n            builder.endObject();\n            builder.endObject();\n            return builder;\n        }));\n    }\n\n    /**\n     * Presents a flat list of tasks\n     */\n    public ChunkedToXContentObject groupedByNone() {\n        return ignored -\u003e Iterators.concat(Iterators.single((builder, params) -\u003e {\n            builder.startObject();\n            toXContentCommon(builder, params);\n            builder.startArray(TASKS);\n            return builder;\n        }), Iterators.map(getTasks().iterator(), taskInfo -\u003e (builder, params) -\u003e {\n            builder.startObject();\n            taskInfo.toXContent(builder, params);\n            builder.endObject();\n            return builder;\n        }), Iterators.single((builder, params) -\u003e {\n            builder.endArray();\n            builder.endObject();\n            return builder;\n        }));\n    }\n\n    public static ListTasksResponse fromXContent(XContentParser parser) {\n        return PARSER.apply(parser, null);\n    }\n\n    @Override\n    public String toString() {\n        return Strings.toString(ChunkedToXContent.wrapAsToXContent(groupedByNone()), true, true);\n    }\n\n}","methodCount":13},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":71,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method setupParser to class NodeResult","description":"move method setupParser to PsiClass:NodeResult\nRationale: The setupParser() method is responsible for creating a ConstructingObjectParser that deals with TaskInfo and related failure types, which are closely tied to node results. Moving it to NodeResult aligns with the Single Responsibility Principle, as NodeResult is responsible for parsing and managing node-related data. This enhances cohesion and reusability, as the parser setup is directly related to the node\u0027s data structure. However, care must be taken to ensure that the method\u0027s static nature and generic type parameters are compatible with NodeResult\u0027s existing structure.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":71,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method setupParser to class NodesRemovalPrevalidation","description":"move method setupParser to PsiClass:NodesRemovalPrevalidation\nRationale: Since the setupParser() method involves parsing tasks and failures which are relevant to node removal validation, relocating it to NodesRemovalPrevalidation would make sense. This adheres to the Open/Closed Principle, allowing for extension of parsing capabilities specific to node removal scenarios. It enhances clarity by keeping all related parsing logic within the same class. However, it may introduce dependencies that need to be managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":71,"lineEnd":93,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method setupParser to class TransportNodesStatsAction","description":"move method setupParser to PsiClass:TransportNodesStatsAction\nRationale: The TransportNodesStatsAction class is involved in node statistics, which could benefit from having a dedicated parser for task data. Moving setupParser() here would align with the Interface Segregation Principle, ensuring that classes remain focused on their primary responsibilities. This would improve the overall design by centralizing parsing logic related to node statistics. However, this could lead to a bloated class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":252,"lineEnd":254,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class NodesRemovalPrevalidation","description":"move method fromXContent to PsiClass:NodesRemovalPrevalidation\nRationale: The fromXContent() method is related to parsing and constructing an instance of NodesRemovalPrevalidation. Moving it to this class enhances cohesion as it directly involves creating an object of the same type. This aligns with the Single Responsibility Principle (SRP) by keeping parsing logic encapsulated within the relevant class. However, care must be taken to ensure that the current static context is appropriately handled.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":252,"lineEnd":254,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class PrevalidateNodeRemovalResponse","description":"move method fromXContent to PsiClass:PrevalidateNodeRemovalResponse\nRationale: The fromXContent() method could be placed in PrevalidateNodeRemovalResponse as it deals with the response type that includes NodesRemovalPrevalidation. This maintains a clear relationship between parsing and the response object. It supports the Open/Closed Principle (OCP) by allowing new response types to extend parsing capabilities easily. However, it may introduce dependencies that could complicate the response management.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":252,"lineEnd":254,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class Result","description":"move method fromXContent to PsiClass:Result\nRationale: Result is closely related to the outcomes of various operations, including prevalidation tasks. Moving fromXContent() here can help centralize parsing logic related to results, improving the organization of response handling. This aligns with the SRP and the Interface Segregation Principle (ISP) by ensuring that Result only handles its specific parsing needs. The drawback is the potential for bloating the Result class with unrelated parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"setupParser","method_signature":"protected static setupParser(\n        String name,\n        TriFunction\u003cList\u003cTaskInfo\u003e, List\u003cTaskOperationFailure\u003e, List\u003cElasticsearchException\u003e, T\u003e ctor\n    )","target_class":"","rationale":""},{"method_name":"buildTaskGroups","method_signature":"private buildTaskGroups()","target_class":"","rationale":""},{"method_name":"groupedByNode","method_signature":"public groupedByNode(Supplier\u003cDiscoveryNodes\u003e nodesInCluster)","target_class":"","rationale":""},{"method_name":"groupedByParent","method_signature":"public groupedByParent()","target_class":"","rationale":""},{"method_name":"groupedByNone","method_signature":"public groupedByNone()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"setupParser","method_signature":"protected static setupParser(\n        String name,\n        TriFunction\u003cList\u003cTaskInfo\u003e, List\u003cTaskOperationFailure\u003e, List\u003cElasticsearchException\u003e, T\u003e ctor\n    )","target_class":"","rationale":""},{"method_name":"buildTaskGroups","method_signature":"private buildTaskGroups()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"groupedByNone","method_signature":"public groupedByNone()","target_class":"","rationale":""},{"method_name":"groupedByParent","method_signature":"public groupedByParent()","target_class":"","rationale":""},{"method_name":"groupedByNode","method_signature":"public groupedByNode(Supplier\u003cDiscoveryNodes\u003e nodesInCluster)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"protected static setupParser(\n        String name,\n        TriFunction\u003cList\u003cTaskInfo\u003e, List\u003cTaskOperationFailure\u003e, List\u003cElasticsearchException\u003e, T\u003e ctor\n    )":{"first":{"method_name":"setupParser","method_signature":"protected static setupParser(\n        String name,\n        TriFunction\u003cList\u003cTaskInfo\u003e, List\u003cTaskOperationFailure\u003e, List\u003cElasticsearchException\u003e, T\u003e ctor\n    )","target_class":"","rationale":""},"second":0.3807935102761261},"private buildTaskGroups()":{"first":{"method_name":"buildTaskGroups","method_signature":"private buildTaskGroups()","target_class":"","rationale":""},"second":0.4571994305181298},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.5231855961546401},"public groupedByNone()":{"first":{"method_name":"groupedByNone","method_signature":"public groupedByNone()","target_class":"","rationale":""},"second":0.6368974121535446},"public groupedByParent()":{"first":{"method_name":"groupedByParent","method_signature":"public groupedByParent()","target_class":"","rationale":""},"second":0.6450367851246201},"public groupedByNode(Supplier\u003cDiscoveryNodes\u003e nodesInCluster)":{"first":{"method_name":"groupedByNode","method_signature":"public groupedByNode(Supplier\u003cDiscoveryNodes\u003e nodesInCluster)","target_class":"","rationale":""},"second":0.7097326983445141}},"llmMethodPriority":{"priority_method_names":["setupParser","buildTaskGroups","fromXContent","groupedByNone","groupedByParent","groupedByNode"],"llm_response_time":1943},"targetClassMap":{"setupParser":{"target_classes":[{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.30817493893085796},{"class_name":"ListTasksRequestTests","similarity_score":0.39240671925011966},{"class_name":"TaskGroup","similarity_score":0.29332380046472484},{"class_name":"TransportListTasksAction","similarity_score":0.39190510147982494},{"class_name":"CancellableTasksIT","similarity_score":0.4351926019935423},{"class_name":"CancellableTasksTests","similarity_score":0.4749480896408718},{"class_name":"Result","similarity_score":0.37110351520760065},{"class_name":"PrevalidateNodeRemovalRequest","similarity_score":0.3882485213467487},{"class_name":"PrevalidateNodeRemovalRequestSerializationTests","similarity_score":0.33423145614956246},{"class_name":"PrevalidateNodeRemovalResponse","similarity_score":0.2529558920296699},{"class_name":"NodePrevalidateShardPathResponseSerializationTests","similarity_score":0.30242271082990124},{"class_name":"NodeResult","similarity_score":0.41459554700043827},{"class_name":"NodesRemovalPrevalidation","similarity_score":0.40344778465438214},{"class_name":"NodesRemovalPrevalidationSerializationTests","similarity_score":0.5019960159204454},{"class_name":"NodesStatsRequestTests","similarity_score":0.3923838434930941},{"class_name":"NodeStats","similarity_score":0.3178759140732292},{"class_name":"NodeStatsTests","similarity_score":0.5212841255620294},{"class_name":"TransportNodesStatsAction","similarity_score":0.4116223006538567},{"class_name":"TransportPrevalidateNodeRemovalAction","similarity_score":0.49060238478229207},{"class_name":"ActionTestUtils","similarity_score":0.19170289512680813},{"class_name":"ClusterStateCreationUtils","similarity_score":0.36888991975433366},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.2882025775393406},{"class_name":"DataStreamsActionUtil","similarity_score":0.3015437112081588},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.08451542547285167},{"class_name":"SynonymsTestUtils","similarity_score":0.31902931178765026},{"class_name":"DesiredBalanceResponse","similarity_score":0.38446417482390344},{"class_name":"DesiredShards","similarity_score":0.232969602273015},{"class_name":"GetFeatureUpgradeStatusResponseTests","similarity_score":0.27373394341569607},{"class_name":"ClusterAllocationExplainActionTests","similarity_score":0.4752573304947366}],"target_classes_sorted_by_llm":["NodeResult","NodesRemovalPrevalidation","TransportNodesStatsAction","CancellableTasksIT","TransportPrevalidateNodeRemovalAction","CancellableTasksTests","ClusterAllocationExplainActionTests","NodesRemovalPrevalidationSerializationTests","ListTasksRequestTests","NodeStatsTests"],"llm_response_time":10752,"similarity_computation_time":115,"similarity_metric":"voyage"},"buildTaskGroups":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":703,"similarity_computation_time":1,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.5146850126549787},{"class_name":"TaskGroup","similarity_score":0.5388702304143923},{"class_name":"ListTasksRequestTests","similarity_score":0.3072676485105926},{"class_name":"TransportListTasksAction","similarity_score":0.39495806793019816},{"class_name":"CancellableTasksIT","similarity_score":0.42517719408733184},{"class_name":"CancellableTasksTests","similarity_score":0.3510492100633595},{"class_name":"Result","similarity_score":0.5324226344926251},{"class_name":"TransportNodesStatsAction","similarity_score":0.4609209615325419},{"class_name":"TransportPrevalidateNodeRemovalAction","similarity_score":0.28824203743573656},{"class_name":"PrevalidateNodeRemovalRequest","similarity_score":0.5133070686985689},{"class_name":"PrevalidateNodeRemovalRequestSerializationTests","similarity_score":0.3393281643677095},{"class_name":"PrevalidateNodeRemovalResponse","similarity_score":0.5546534498569374},{"class_name":"NodePrevalidateShardPathResponseSerializationTests","similarity_score":0.5342173039633603},{"class_name":"NodeResult","similarity_score":0.48913987007807896},{"class_name":"NodesRemovalPrevalidation","similarity_score":0.5688615369981187},{"class_name":"NodesRemovalPrevalidationSerializationTests","similarity_score":0.4196370313678693},{"class_name":"NodesStatsRequestTests","similarity_score":0.24028504996754343},{"class_name":"NodeStats","similarity_score":0.39690803273826436},{"class_name":"NodeStatsTests","similarity_score":0.23525369509124258},{"class_name":"ActionTestUtils","similarity_score":0.4472135954999579},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.24152294576982397},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.5632573863241661},{"class_name":"ClusterStateCreationUtils","similarity_score":0.2488226750616026},{"class_name":"DataStreamsActionUtil","similarity_score":0.38849926257154405},{"class_name":"SynonymsTestUtils","similarity_score":0.5096471914376255},{"class_name":"DesiredBalanceResponse","similarity_score":0.4901684987407428},{"class_name":"DesiredShards","similarity_score":0.4585633803868072},{"class_name":"GetFeatureUpgradeStatusResponseTests","similarity_score":0.3440767234116473},{"class_name":"GetScriptContextResponse","similarity_score":0.5329197843048206}],"target_classes_sorted_by_llm":["NodesRemovalPrevalidation","PrevalidateNodeRemovalResponse","Result","TaskGroup","PrevalidateNodeRemovalRequest","GetScriptContextResponse","ShardMultiGetFromTranslogUtil","NodePrevalidateShardPathResponseSerializationTests","PrevalidateShardPathRequestSerializationTestUtils","SynonymsTestUtils"],"llm_response_time":10101,"similarity_computation_time":10,"similarity_metric":"voyage"}}}
{"id":"c7db67c3-b0c3-4420-9b60-eab29d8c1b5c","methodCount":11,"hostFunctionTelemetryData":{"hostFunctionSize":203,"lineStart":36,"lineEnd":238,"bodyLineStart":36,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/search/profile/SearchProfileResults.java","sourceCode":"/**\n * Profile results for all shards.\n */\npublic final class SearchProfileResults implements Writeable, ToXContentFragment {\n\n    private static final Logger logger \u003d LogManager.getLogger(SearchProfileResults.class);\n    private static final String ID_FIELD \u003d \"id\";\n    private static final String NODE_ID_FIELD \u003d \"node_id\";\n    private static final String CLUSTER_FIELD \u003d \"cluster\";\n    private static final String INDEX_NAME_FIELD \u003d \"index\";\n    private static final String SHARD_ID_FIELD \u003d \"shard_id\";\n    private static final String SHARDS_FIELD \u003d \"shards\";\n    public static final String PROFILE_FIELD \u003d \"profile\";\n\n    // map key is the composite \"id\" of form [nodeId][(clusterName:)indexName][shardId] created from SearchShardTarget.toString\n    private final Map\u003cString, SearchProfileShardResult\u003e shardResults;\n\n    public SearchProfileResults(Map\u003cString, SearchProfileShardResult\u003e shardResults) {\n        this.shardResults \u003d Collections.unmodifiableMap(shardResults);\n    }\n\n    public SearchProfileResults(StreamInput in) throws IOException {\n        shardResults \u003d in.readMap(SearchProfileShardResult::new);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeMap(shardResults, StreamOutput::writeWriteable);\n    }\n\n    public Map\u003cString, SearchProfileShardResult\u003e getShardResults() {\n        return shardResults;\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject(PROFILE_FIELD).startArray(SHARDS_FIELD);\n        // shardResults is a map, but we print entries in a json array, which is ordered.\n        // we sort the keys of the map, so that toXContent always prints out the same array order\n        TreeSet\u003cString\u003e sortedKeys \u003d new TreeSet\u003c\u003e(shardResults.keySet());\n        for (String key : sortedKeys) {\n            builder.startObject();\n            builder.field(ID_FIELD, key);\n\n            ShardProfileId shardProfileId \u003d parseCompositeProfileShardId(key);\n            if (shardProfileId !\u003d null) {\n                builder.field(NODE_ID_FIELD, shardProfileId.nodeId());\n                builder.field(SHARD_ID_FIELD, shardProfileId.shardId());\n                builder.field(INDEX_NAME_FIELD, shardProfileId.indexName());\n                String cluster \u003d shardProfileId.clusterName();\n                if (cluster \u003d\u003d null) {\n                    cluster \u003d \"(local)\";\n                }\n                builder.field(CLUSTER_FIELD, cluster);\n            }\n\n            SearchProfileShardResult shardResult \u003d shardResults.get(key);\n            shardResult.toXContent(builder, params);\n            builder.endObject();\n        }\n\n        builder.endArray().endObject();\n        return builder;\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n            return false;\n        }\n        SearchProfileResults other \u003d (SearchProfileResults) obj;\n        return shardResults.equals(other.shardResults);\n    }\n\n    @Override\n    public int hashCode() {\n        return shardResults.hashCode();\n    }\n\n    @Override\n    public String toString() {\n        return Strings.toString(this);\n    }\n\n    public static SearchProfileResults fromXContent(XContentParser parser) throws IOException {\n        XContentParser.Token token \u003d parser.currentToken();\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser);\n        Map\u003cString, SearchProfileShardResult\u003e profileResults \u003d new HashMap\u003c\u003e();\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n                if (SHARDS_FIELD.equals(parser.currentName())) {\n                    while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                        parseProfileResultsEntry(parser, profileResults);\n                    }\n                } else {\n                    parser.skipChildren();\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_OBJECT) {\n                parser.skipChildren();\n            }\n        }\n        return new SearchProfileResults(profileResults);\n    }\n\n    private static void parseProfileResultsEntry(XContentParser parser, Map\u003cString, SearchProfileShardResult\u003e searchProfileResults)\n        throws IOException {\n        XContentParser.Token token \u003d parser.currentToken();\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser);\n        SearchProfileDfsPhaseResult searchProfileDfsPhaseResult \u003d null;\n        List\u003cQueryProfileShardResult\u003e queryProfileResults \u003d new ArrayList\u003c\u003e();\n        AggregationProfileShardResult aggProfileShardResult \u003d null;\n        ProfileResult fetchResult \u003d null;\n        String id \u003d null;\n        String currentFieldName \u003d null;\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            if (token \u003d\u003d XContentParser.Token.FIELD_NAME) {\n                currentFieldName \u003d parser.currentName();\n            } else if (token.isValue()) {\n                if (ID_FIELD.equals(currentFieldName)) {\n                    id \u003d parser.text();\n                } else {\n                    parser.skipChildren();\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n                if (\"searches\".equals(currentFieldName)) {\n                    while ((parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                        queryProfileResults.add(QueryProfileShardResult.fromXContent(parser));\n                    }\n                } else if (AggregationProfileShardResult.AGGREGATIONS.equals(currentFieldName)) {\n                    aggProfileShardResult \u003d AggregationProfileShardResult.fromXContent(parser);\n                } else {\n                    parser.skipChildren();\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_OBJECT) {\n                if (\"dfs\".equals(currentFieldName)) {\n                    searchProfileDfsPhaseResult \u003d SearchProfileDfsPhaseResult.fromXContent(parser);\n                } else if (\"fetch\".equals(currentFieldName)) {\n                    fetchResult \u003d ProfileResult.fromXContent(parser);\n                } else {\n                    parser.skipChildren();\n                }\n            } else {\n                parser.skipChildren();\n            }\n        }\n        SearchProfileShardResult result \u003d new SearchProfileShardResult(\n            new SearchProfileQueryPhaseResult(queryProfileResults, aggProfileShardResult),\n            fetchResult\n        );\n        result.getQueryPhase().setSearchProfileDfsPhaseResult(searchProfileDfsPhaseResult);\n        searchProfileResults.put(id, result);\n    }\n\n    /**\n     * Parsed representation of a composite id used for shards in a profile.\n     * The composite id format is specified/created via the {@code SearchShardTarget} method.\n     * @param nodeId nodeId that the shard is on\n     * @param indexName index being profiled\n     * @param shardId shard id being profiled\n     * @param clusterName if a CCS search, the remote clusters will have a name in the id. Local clusters will be null.\n     */\n    record ShardProfileId(String nodeId, String indexName, int shardId, @Nullable String clusterName) {}\n\n    private static final Pattern SHARD_ID_DECOMPOSITION \u003d Pattern.compile(\"\\\\[([^]]+)\\\\]\\\\[([^]]+)\\\\]\\\\[(\\\\d+)\\\\]\");\n\n    /**\n     * Parse the composite \"shard id\" from the profiles output, which comes from the\n     * {@code SearchShardTarget.toString()} method, into its separate components.\n     * \u003cp\u003e\n     * One of two expected patterns is accepted:\n     * \u003cp\u003e\n     * 1) [nodeId][indexName][shardId]\n     * example: [2m7SW9oIRrirdrwirM1mwQ][blogs][1]\n     * \u003cp\u003e\n     * 2) [nodeId][clusterName:indexName][shardId]\n     * example: [UngEVXTBQL-7w5j_tftGAQ][remote1:blogs][0]\n     *\n     * @param compositeId see above for accepted formats\n     * @return ShardProfileId with parsed components or null if the compositeId has an unsupported format\n     */\n    static ShardProfileId parseCompositeProfileShardId(String compositeId) {\n        assert Strings.isNullOrEmpty(compositeId) \u003d\u003d false : \"An empty id should not be passed to parseCompositeProfileShardId\";\n\n        Matcher m \u003d SHARD_ID_DECOMPOSITION.matcher(compositeId);\n        if (m.find()) {\n            String nodeId \u003d m.group(1);\n            String indexName \u003d m.group(2);\n            int shardId \u003d Integer.parseInt(m.group(3));\n            String cluster \u003d null;\n            if (indexName.contains(\":\")) {\n                // index names and cluster names cannot contain a \u0027:\u0027, so this split should be accurate\n                String[] tokens \u003d indexName.split(\":\", 2);\n                cluster \u003d tokens[0];\n                indexName \u003d tokens[1];\n            }\n            return new ShardProfileId(nodeId, indexName, shardId, cluster);\n        } else {\n            assert false : \"Unable to match input against expected pattern of [nodeId][indexName][shardId]. Input: \" + compositeId;\n            logger.warn(\"Unable to match input against expected pattern of [nodeId][indexName][shardId]. Input: {}\", compositeId);\n            return null;\n        }\n    }\n}","methodCount":11},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":200,"lineEnd":236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseCompositeProfileShardId to class QueryProfileShardResult","description":"move method parseCompositeProfileShardId to PsiClass:QueryProfileShardResult\nRationale: The parseCompositeProfileShardId() method is directly related to parsing shard identifiers, which are likely relevant to the QueryProfileShardResult\u0027s functionality. Moving it here enhances cohesion by ensuring that parsing logic for shard identifiers resides within a context that deals with query profiling. This aligns with the Single Responsibility Principle by grouping related functionalities. However, care must be taken to ensure that the QueryProfileShardResult class does not become overly complex.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":200,"lineEnd":236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseCompositeProfileShardId to class ProfileResult","description":"move method parseCompositeProfileShardId to PsiClass:ProfileResult\nRationale: The method\u0027s functionality is tied to profiling, which is a core aspect of the ProfileResult class. Relocating the method here would improve cohesion and encapsulate parsing logic related to profiling. This adheres to the Open/Closed Principle, allowing for extension without modifying existing code. One consideration is that ProfileResult might become overloaded with utility methods if too many are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":200,"lineEnd":236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseCompositeProfileShardId to class AggregationProfileShardResult","description":"move method parseCompositeProfileShardId to PsiClass:AggregationProfileShardResult\nRationale: Similar to ProfileResult, AggregationProfileShardResult deals with profiling and could benefit from having parsing logic for shard identifiers included. This move would maintain high cohesion and better organize the codebase. It follows the Interface Segregation Principle by keeping related functionalities together. However, it may increase the complexity of AggregationProfileShardResult if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":139,"lineEnd":186,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseProfileResultsEntry to class SearchProfileDfsPhaseResult","description":"move method parseProfileResultsEntry to PsiClass:SearchProfileDfsPhaseResult\nRationale: The parseProfileResultsEntry() method is responsible for parsing results that include the SearchProfileDfsPhaseResult. Moving it to this class aligns with the Single Responsibility Principle by keeping parsing logic within the class that represents the data being parsed. This enhances cohesion, as the method directly deals with the structure of SearchProfileDfsPhaseResult. However, it may increase dependencies on the parser within this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":139,"lineEnd":186,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseProfileResultsEntry to class AggregationProfileShardResult","description":"move method parseProfileResultsEntry to PsiClass:AggregationProfileShardResult\nRationale: This class deals with aggregations, and the parsing method handles aggregation results. Moving it here would enhance cohesion by tying parsing directly to the data structure it produces. However, this could increase the complexity of the class and make it less maintainable.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":139,"lineEnd":186,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method parseProfileResultsEntry to class QueryProfileShardResult","description":"move method parseProfileResultsEntry to PsiClass:QueryProfileShardResult\nRationale: The method creates and populates a QueryProfileShardResult instance. By moving the parsing logic here, we enhance the encapsulation of how query profiles are constructed from raw data. This aligns with the Single Responsibility Principle, as QueryProfileShardResult would handle its own parsing. However, it could lead to a bloated QueryProfileShardResult class if not carefully managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":119,"lineEnd":137,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class SearchProfileDfsPhaseResult","description":"move method fromXContent to PsiClass:SearchProfileDfsPhaseResult\nRationale: The fromXContent() method processes a search profile\u0027s results, which are closely related to the SearchProfileDfsPhaseResult class. Moving this method enhances cohesion since it directly deals with parsing and constructing objects that this class represents. This aligns with the Single Responsibility Principle by ensuring that parsing logic is encapsulated within relevant classes. A potential drawback is that it may increase the complexity of the SearchProfileDfsPhaseResult class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":119,"lineEnd":137,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class AggregationProfileShardResult","description":"move method fromXContent to PsiClass:AggregationProfileShardResult\nRationale: The method deals with parsing profile results that can be related to aggregation profiles. Moving it to AggregationProfileShardResult would enhance the encapsulation of parsing logic tied to aggregation-related functionality. This adheres to the Open/Closed Principle, allowing the class to be extended with parsing capabilities. However, care must be taken to ensure it doesn\u0027t bloat the AggregationProfileShardResult class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":119,"lineEnd":137,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class QueryProfileShardResult","description":"move method fromXContent to PsiClass:QueryProfileShardResult\nRationale: The fromXContent() method parses data that could be relevant to query profiles. Relocating it here would improve the cohesion of parsing logic associated with query results and align with the Single Responsibility Principle. This move would also facilitate better organization of query-related functionality. However, this may lead to a tight coupling between query results and parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseProfileResultsEntry","method_signature":"private static parseProfileResultsEntry(XContentParser parser, Map\u003cString, SearchProfileShardResult\u003e searchProfileResults)","target_class":"","rationale":""},{"method_name":"parseCompositeProfileShardId","method_signature":"static parseCompositeProfileShardId(String compositeId)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"parseCompositeProfileShardId","method_signature":"static parseCompositeProfileShardId(String compositeId)","target_class":"","rationale":""},{"method_name":"parseProfileResultsEntry","method_signature":"private static parseProfileResultsEntry(XContentParser parser, Map\u003cString, SearchProfileShardResult\u003e searchProfileResults)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static parseCompositeProfileShardId(String compositeId)":{"first":{"method_name":"parseCompositeProfileShardId","method_signature":"static parseCompositeProfileShardId(String compositeId)","target_class":"","rationale":""},"second":0.6116925649486338},"private static parseProfileResultsEntry(XContentParser parser, Map\u003cString, SearchProfileShardResult\u003e searchProfileResults)":{"first":{"method_name":"parseProfileResultsEntry","method_signature":"private static parseProfileResultsEntry(XContentParser parser, Map\u003cString, SearchProfileShardResult\u003e searchProfileResults)","target_class":"","rationale":""},"second":0.6714223505747939},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.7130853578233568}},"llmMethodPriority":{"priority_method_names":["parseCompositeProfileShardId","parseProfileResultsEntry","fromXContent"],"llm_response_time":1388},"targetClassMap":{"parseCompositeProfileShardId":{"target_classes":[{"class_name":"BucketUtils","similarity_score":0.5456994242250456},{"class_name":"SearchUtils","similarity_score":0.3495833695494063},{"class_name":"NestedUtils","similarity_score":0.5627556702100112},{"class_name":"GeoTileUtils","similarity_score":0.6035454687280033},{"class_name":"HighlightUtils","similarity_score":0.32441479007614593},{"class_name":"ProfileResult","similarity_score":0.5133872448256878},{"class_name":"ProfileResultTests","similarity_score":0.29603809278206966},{"class_name":"Profilers","similarity_score":0.42528728498430407},{"class_name":"ProfilingAggregator","similarity_score":0.27538285727439626},{"class_name":"QueryProfilerTests","similarity_score":0.32373067051913357},{"class_name":"QueryProfileShardResult","similarity_score":0.4515360820129818},{"class_name":"QueryProfileShardResultTests","similarity_score":0.3447208947626814},{"class_name":"RandomQueryGenerator","similarity_score":0.29627606980435744},{"class_name":"CollectorResult","similarity_score":0.49144748679846717},{"class_name":"CollectorResultTests","similarity_score":0.30057366342402914},{"class_name":"AggregationProfiler","similarity_score":0.33307645140510933},{"class_name":"AggregationProfileShardResult","similarity_score":0.4134125037362069},{"class_name":"AggregationProfileShardResultTests","similarity_score":0.3147261363678048},{"class_name":"SearchProfileDfsPhaseResult","similarity_score":0.37113439312117524},{"class_name":"SearchProfileDfsPhaseResultTests","similarity_score":0.2528902694294366},{"class_name":"SearchProfileQueryPhaseResultTests","similarity_score":0.3274718995976755},{"class_name":"SearchProfileResultsBuilderTests","similarity_score":0.30759342513361604},{"class_name":"SearchProfileResultsTests","similarity_score":0.3845798941306081},{"class_name":"SearchProfileShardResultTests","similarity_score":0.2684845227447727},{"class_name":"InternalAggregationProfileTree","similarity_score":0.3034732780215344},{"class_name":"RestResponseUtils","similarity_score":0.3426611602290625},{"class_name":"AuditUtil","similarity_score":0.36880610079621945},{"class_name":"JwkValidateUtil","similarity_score":0.4130460715853837},{"class_name":"JwkValidateUtilTests","similarity_score":0.3345071863374668}],"target_classes_sorted_by_llm":["QueryProfileShardResult","ProfileResult","AggregationProfileShardResult","CollectorResult","Profilers","SearchProfileResultsTests","NestedUtils","BucketUtils","GeoTileUtils","JwkValidateUtil"],"llm_response_time":12756,"similarity_computation_time":19,"similarity_metric":"voyage"},"parseProfileResultsEntry":{"target_classes":[{"class_name":"SearchUtils","similarity_score":0.3532190696736554},{"class_name":"BucketUtils","similarity_score":0.22806682910039505},{"class_name":"NestedUtils","similarity_score":0.46367101519577636},{"class_name":"GeoTileUtils","similarity_score":0.3412686524883687},{"class_name":"HighlightUtils","similarity_score":0.49539740326949633},{"class_name":"CollectorResult","similarity_score":0.7951412734198006},{"class_name":"CollectorResultTests","similarity_score":0.47152015646925677},{"class_name":"AggregationProfiler","similarity_score":0.6609789738588475},{"class_name":"AggregationProfileShardResult","similarity_score":0.6412960943675939},{"class_name":"AggregationProfileShardResultTests","similarity_score":0.6566605205561474},{"class_name":"SearchProfileDfsPhaseResult","similarity_score":0.747858915787194},{"class_name":"SearchProfileDfsPhaseResultTests","similarity_score":0.5387898765485762},{"class_name":"SearchProfileQueryPhaseResultTests","similarity_score":0.6429439591742536},{"class_name":"SearchProfileResultsBuilderTests","similarity_score":0.6427701222332888},{"class_name":"SearchProfileResultsTests","similarity_score":0.6147045405733321},{"class_name":"SearchProfileShardResultTests","similarity_score":0.5480617324912944},{"class_name":"ProfileResult","similarity_score":0.6025872371795323},{"class_name":"ProfileResultTests","similarity_score":0.4669607678271042},{"class_name":"Profilers","similarity_score":0.4832088451475149},{"class_name":"ProfilingAggregator","similarity_score":0.6204046499257215},{"class_name":"QueryProfilerTests","similarity_score":0.5485868493846822},{"class_name":"QueryProfileShardResult","similarity_score":0.8264000961419166},{"class_name":"QueryProfileShardResultTests","similarity_score":0.6255042573510702},{"class_name":"RandomQueryGenerator","similarity_score":0.564668576126879},{"class_name":"InternalAggregationProfileTree","similarity_score":0.5482418562179228},{"class_name":"RestResponseUtils","similarity_score":0.7147594796552882},{"class_name":"RestTestUtil","similarity_score":0.3553728222840076},{"class_name":"RestUtils","similarity_score":0.5940111197289994},{"class_name":"RestUtilsTests","similarity_score":0.3989266540676834}],"target_classes_sorted_by_llm":["SearchProfileDfsPhaseResult","AggregationProfileShardResult","QueryProfileShardResult","RestResponseUtils","CollectorResult","AggregationProfileShardResultTests","QueryProfileShardResultTests","SearchProfileResultsBuilderTests","AggregationProfiler","SearchProfileQueryPhaseResultTests"],"llm_response_time":9905,"similarity_computation_time":8,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"GeoTileUtils","similarity_score":0.3427486005982175},{"class_name":"SearchUtils","similarity_score":0.3553775184192387},{"class_name":"HighlightUtils","similarity_score":0.5204700480230067},{"class_name":"NestedUtils","similarity_score":0.4407826895373302},{"class_name":"BucketUtils","similarity_score":0.23869090819777047},{"class_name":"AggregationProfiler","similarity_score":0.6706390659339468},{"class_name":"AggregationProfileShardResult","similarity_score":0.6952460665139122},{"class_name":"AggregationProfileShardResultTests","similarity_score":0.6627381311846923},{"class_name":"SearchProfileDfsPhaseResult","similarity_score":0.7473898216651771},{"class_name":"SearchProfileDfsPhaseResultTests","similarity_score":0.5332684918268511},{"class_name":"SearchProfileQueryPhaseResultTests","similarity_score":0.6229977540210903},{"class_name":"SearchProfileResultsBuilderTests","similarity_score":0.6426905254442135},{"class_name":"SearchProfileResultsTests","similarity_score":0.6075637897971239},{"class_name":"SearchProfileShardResultTests","similarity_score":0.558865888278289},{"class_name":"ProfileResult","similarity_score":0.6061156867985726},{"class_name":"ProfileResultTests","similarity_score":0.45391477471880537},{"class_name":"Profilers","similarity_score":0.5108935105724418},{"class_name":"ProfilingAggregator","similarity_score":0.6601278002310398},{"class_name":"QueryProfilerTests","similarity_score":0.5307074834884697},{"class_name":"QueryProfileShardResult","similarity_score":0.8112158094094036},{"class_name":"QueryProfileShardResultTests","similarity_score":0.6280513534390405},{"class_name":"InternalAggregationProfileTree","similarity_score":0.5840573769513535},{"class_name":"RandomQueryGenerator","similarity_score":0.5519335708914304},{"class_name":"CollectorResult","similarity_score":0.7712312413106378},{"class_name":"CollectorResultTests","similarity_score":0.4535469853069621},{"class_name":"RestResponseUtils","similarity_score":0.7372233143331323},{"class_name":"MapperTestUtils","similarity_score":0.4938787354826977},{"class_name":"RestTestUtil","similarity_score":0.3772345609843998},{"class_name":"RestUtils","similarity_score":0.5580756262840084}],"target_classes_sorted_by_llm":["SearchProfileDfsPhaseResult","AggregationProfileShardResult","QueryProfileShardResult","CollectorResult","RestResponseUtils","ProfilingAggregator","AggregationProfiler","SearchProfileResultsBuilderTests","QueryProfileShardResultTests","AggregationProfileShardResultTests"],"llm_response_time":10285,"similarity_computation_time":5,"similarity_metric":"voyage"}}}
{"id":"b92bb5e7-af03-4060-897c-9ef680a7b67a","methodCount":36,"hostFunctionTelemetryData":{"hostFunctionSize":371,"lineStart":41,"lineEnd":411,"bodyLineStart":41,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/DocWriteResponse.java","sourceCode":"/**\n * A base class for the response of a write operation that involves a single doc\n */\npublic abstract class DocWriteResponse extends ReplicationResponse implements WriteResponse, ToXContentObject {\n\n    private static final String _SHARDS \u003d \"_shards\";\n    private static final String _INDEX \u003d \"_index\";\n    private static final String _ID \u003d \"_id\";\n    private static final String _VERSION \u003d \"_version\";\n    private static final String _SEQ_NO \u003d \"_seq_no\";\n    private static final String _PRIMARY_TERM \u003d \"_primary_term\";\n    private static final String RESULT \u003d \"result\";\n    private static final String FORCED_REFRESH \u003d \"forced_refresh\";\n\n    /**\n     * An enum that represents the results of CRUD operations, primarily used to communicate the type of\n     * operation that occurred.\n     */\n    public enum Result implements Writeable {\n        CREATED(0),\n        UPDATED(1),\n        DELETED(2),\n        NOT_FOUND(3),\n        NOOP(4);\n\n        private final byte op;\n        private final String lowercase;\n\n        Result(int op) {\n            this.op \u003d (byte) op;\n            this.lowercase \u003d this.name().toLowerCase(Locale.ROOT);\n        }\n\n        public byte getOp() {\n            return op;\n        }\n\n        public String getLowercase() {\n            return lowercase;\n        }\n\n        public static Result readFrom(StreamInput in) throws IOException {\n            Byte opcode \u003d in.readByte();\n            return switch (opcode) {\n                case 0 -\u003e CREATED;\n                case 1 -\u003e UPDATED;\n                case 2 -\u003e DELETED;\n                case 3 -\u003e NOT_FOUND;\n                case 4 -\u003e NOOP;\n                default -\u003e throw new IllegalArgumentException(\"Unknown result code: \" + opcode);\n            };\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeByte(op);\n        }\n    }\n\n    private final ShardId shardId;\n    private final String id;\n    private final long version;\n    private final long seqNo;\n    private final long primaryTerm;\n    private boolean forcedRefresh;\n    protected final Result result;\n\n    public DocWriteResponse(ShardId shardId, String id, long seqNo, long primaryTerm, long version, Result result) {\n        this.shardId \u003d Objects.requireNonNull(shardId);\n        this.id \u003d Objects.requireNonNull(id);\n        this.seqNo \u003d seqNo;\n        this.primaryTerm \u003d primaryTerm;\n        this.version \u003d version;\n        this.result \u003d Objects.requireNonNull(result);\n    }\n\n    // needed for deserialization\n    protected DocWriteResponse(ShardId shardId, StreamInput in) throws IOException {\n        super(in);\n        this.shardId \u003d shardId;\n        if (in.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            String type \u003d in.readString();\n            assert MapperService.SINGLE_MAPPING_NAME.equals(type) : \"Expected [_doc] but received [\" + type + \"]\";\n        }\n        id \u003d in.readString();\n        version \u003d in.readZLong();\n        seqNo \u003d in.readZLong();\n        primaryTerm \u003d in.readVLong();\n        forcedRefresh \u003d in.readBoolean();\n        result \u003d Result.readFrom(in);\n    }\n\n    /**\n     * Needed for deserialization of single item requests in {@link org.elasticsearch.action.index.TransportIndexAction} and BwC\n     * deserialization path\n     */\n    protected DocWriteResponse(StreamInput in) throws IOException {\n        super(in);\n        shardId \u003d new ShardId(in);\n        if (in.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            String type \u003d in.readString();\n            assert MapperService.SINGLE_MAPPING_NAME.equals(type) : \"Expected [_doc] but received [\" + type + \"]\";\n        }\n        id \u003d in.readString();\n        version \u003d in.readZLong();\n        seqNo \u003d in.readZLong();\n        primaryTerm \u003d in.readVLong();\n        forcedRefresh \u003d in.readBoolean();\n        result \u003d Result.readFrom(in);\n    }\n\n    /**\n     * The change that occurred to the document.\n     */\n    public Result getResult() {\n        return result;\n    }\n\n    /**\n     * The index the document was changed in.\n     */\n    public String getIndex() {\n        return this.shardId.getIndexName();\n    }\n\n    /**\n     * The exact shard the document was changed in.\n     */\n    public ShardId getShardId() {\n        return this.shardId;\n    }\n\n    /**\n     * The id of the document changed.\n     */\n    public String getId() {\n        return this.id;\n    }\n\n    /**\n     * Returns the current version of the doc.\n     */\n    public long getVersion() {\n        return this.version;\n    }\n\n    /**\n     * Returns the sequence number assigned for this change. Returns {@link SequenceNumbers#UNASSIGNED_SEQ_NO} if the operation\n     * wasn\u0027t performed (i.e., an update operation that resulted in a NOOP).\n     */\n    public long getSeqNo() {\n        return seqNo;\n    }\n\n    /**\n     * The primary term for this change.\n     *\n     * @return the primary term\n     */\n    public long getPrimaryTerm() {\n        return primaryTerm;\n    }\n\n    /**\n     * Did this request force a refresh? Requests that set {@link WriteRequest#setRefreshPolicy(RefreshPolicy)} to\n     * {@link RefreshPolicy#IMMEDIATE} will always return true for this. Requests that set it to {@link RefreshPolicy#WAIT_UNTIL} will\n     * only return true here if they run out of refresh listener slots (see {@link IndexSettings#MAX_REFRESH_LISTENERS_PER_SHARD}).\n     */\n    public boolean forcedRefresh() {\n        return forcedRefresh;\n    }\n\n    @Override\n    public void setForcedRefresh(boolean forcedRefresh) {\n        this.forcedRefresh \u003d forcedRefresh;\n    }\n\n    /** returns the rest status for this response (based on {@link ShardInfo#status()} */\n    public RestStatus status() {\n        return getShardInfo().status();\n    }\n\n    /**\n     * Return the relative URI for the location of the document suitable for use in the {@code Location} header. The use of relative URIs is\n     * permitted as of HTTP/1.1 (cf. https://tools.ietf.org/html/rfc7231#section-7.1.2).\n     *\n     * @param routing custom routing or {@code null} if custom routing is not used\n     * @return the relative URI for the location of the document\n     */\n    public String getLocation(@Nullable String routing) {\n        // encode the path components separately otherwise the path separators will be encoded\n        final String encodedIndex \u003d URLEncoder.encode(getIndex(), StandardCharsets.UTF_8);\n        final String encodedType \u003d URLEncoder.encode(MapperService.SINGLE_MAPPING_NAME, StandardCharsets.UTF_8);\n        final String encodedId \u003d URLEncoder.encode(getId(), StandardCharsets.UTF_8);\n        final String encodedRouting \u003d routing \u003d\u003d null ? null : URLEncoder.encode(routing, StandardCharsets.UTF_8);\n        final String routingStart \u003d \"?routing\u003d\";\n        final int bufferSizeExcludingRouting \u003d 3 + encodedIndex.length() + encodedType.length() + encodedId.length();\n        final int bufferSize;\n        if (encodedRouting \u003d\u003d null) {\n            bufferSize \u003d bufferSizeExcludingRouting;\n        } else {\n            bufferSize \u003d bufferSizeExcludingRouting + routingStart.length() + encodedRouting.length();\n        }\n        final StringBuilder location \u003d new StringBuilder(bufferSize);\n        location.append(\u0027/\u0027).append(encodedIndex);\n        location.append(\u0027/\u0027).append(encodedType);\n        location.append(\u0027/\u0027).append(encodedId);\n        if (encodedRouting !\u003d null) {\n            location.append(routingStart).append(encodedRouting);\n        }\n\n        return location.toString();\n    }\n\n    public void writeThin(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        writeWithoutShardId(out);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        shardId.writeTo(out);\n        writeWithoutShardId(out);\n    }\n\n    private void writeWithoutShardId(StreamOutput out) throws IOException {\n        if (out.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            out.writeString(MapperService.SINGLE_MAPPING_NAME);\n        }\n        out.writeString(id);\n        out.writeZLong(version);\n        out.writeZLong(seqNo);\n        out.writeVLong(primaryTerm);\n        out.writeBoolean(forcedRefresh);\n        result.writeTo(out);\n    }\n\n    @Override\n    public final XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        builder.startObject();\n        innerToXContent(builder, params);\n        builder.endObject();\n        return builder;\n    }\n\n    public XContentBuilder innerToXContent(XContentBuilder builder, Params params) throws IOException {\n        ReplicationResponse.ShardInfo shardInfo \u003d getShardInfo();\n        builder.field(_INDEX, shardId.getIndexName());\n        builder.field(_ID, id).field(_VERSION, version).field(RESULT, getResult().getLowercase());\n        if (forcedRefresh) {\n            builder.field(FORCED_REFRESH, true);\n        }\n        builder.field(_SHARDS, shardInfo);\n        if (getSeqNo() \u003e\u003d 0) {\n            builder.field(_SEQ_NO, getSeqNo());\n            builder.field(_PRIMARY_TERM, getPrimaryTerm());\n        }\n        if (builder.getRestApiVersion() \u003d\u003d RestApiVersion.V_7) {\n            builder.field(MapperService.TYPE_FIELD_NAME, MapperService.SINGLE_MAPPING_NAME);\n        }\n        return builder;\n    }\n\n    /**\n     * Parse the output of the {@link #innerToXContent(XContentBuilder, Params)} method.\n     *\n     * This method is intended to be called by subclasses and must be called multiple times to parse all the information concerning\n     * {@link DocWriteResponse} objects. It always parses the current token, updates the given parsing context accordingly\n     * if needed and then immediately returns.\n     */\n    public static void parseInnerToXContent(XContentParser parser, Builder context) throws IOException {\n        XContentParser.Token token \u003d parser.currentToken();\n        ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, parser);\n\n        String currentFieldName \u003d parser.currentName();\n        token \u003d parser.nextToken();\n\n        if (token.isValue()) {\n            if (_INDEX.equals(currentFieldName)) {\n                // index uuid and shard id are unknown and can\u0027t be parsed back for now.\n                context.setShardId(new ShardId(new Index(parser.text(), IndexMetadata.INDEX_UUID_NA_VALUE), -1));\n            } else if (_ID.equals(currentFieldName)) {\n                context.setId(parser.text());\n            } else if (_VERSION.equals(currentFieldName)) {\n                context.setVersion(parser.longValue());\n            } else if (RESULT.equals(currentFieldName)) {\n                String result \u003d parser.text();\n                for (Result r : Result.values()) {\n                    if (r.getLowercase().equals(result)) {\n                        context.setResult(r);\n                        break;\n                    }\n                }\n            } else if (FORCED_REFRESH.equals(currentFieldName)) {\n                context.setForcedRefresh(parser.booleanValue());\n            } else if (_SEQ_NO.equals(currentFieldName)) {\n                context.setSeqNo(parser.longValue());\n            } else if (_PRIMARY_TERM.equals(currentFieldName)) {\n                context.setPrimaryTerm(parser.longValue());\n            }\n        } else if (token \u003d\u003d XContentParser.Token.START_OBJECT) {\n            if (_SHARDS.equals(currentFieldName)) {\n                context.setShardInfo(ShardInfo.fromXContent(parser));\n            } else {\n                parser.skipChildren(); // skip potential inner objects for forward compatibility\n            }\n        } else if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n            parser.skipChildren(); // skip potential inner arrays for forward compatibility\n        }\n    }\n\n    /**\n     * Base class of all {@link DocWriteResponse} builders. These {@link DocWriteResponse.Builder} are used during\n     * xcontent parsing to temporarily store the parsed values, then the {@link Builder#build()} method is called to\n     * instantiate the appropriate {@link DocWriteResponse} with the parsed values.\n     */\n    public abstract static class Builder {\n\n        protected ShardId shardId \u003d null;\n        protected String id \u003d null;\n        protected Long version \u003d null;\n        protected Result result \u003d null;\n        protected boolean forcedRefresh;\n        protected ShardInfo shardInfo \u003d null;\n        protected long seqNo \u003d UNASSIGNED_SEQ_NO;\n        protected long primaryTerm \u003d UNASSIGNED_PRIMARY_TERM;\n\n        public ShardId getShardId() {\n            return shardId;\n        }\n\n        public void setShardId(ShardId shardId) {\n            this.shardId \u003d shardId;\n        }\n\n        public String getId() {\n            return id;\n        }\n\n        public void setId(String id) {\n            this.id \u003d id;\n        }\n\n        public void setVersion(Long version) {\n            this.version \u003d version;\n        }\n\n        public void setResult(Result result) {\n            this.result \u003d result;\n        }\n\n        public void setForcedRefresh(boolean forcedRefresh) {\n            this.forcedRefresh \u003d forcedRefresh;\n        }\n\n        public void setShardInfo(ShardInfo shardInfo) {\n            this.shardInfo \u003d shardInfo;\n        }\n\n        public void setSeqNo(long seqNo) {\n            this.seqNo \u003d seqNo;\n        }\n\n        public void setPrimaryTerm(long primaryTerm) {\n            this.primaryTerm \u003d primaryTerm;\n        }\n\n        public abstract DocWriteResponse build();\n    }\n}","methodCount":36},"candidatesTelemetryData":{"numberOfSuggestions":4,"candidates":[{"lineStart":81,"lineEnd":91,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readFrom to class DocWriteResponse","description":"move method readFrom to PsiClass:DocWriteResponse\nRationale: The readFrom() method is closely related to the Result of document write operations, which are part of the DocWriteResponse class. Moving it here would enhance cohesion since this class handles the results of document operations. It aligns with the Single Responsibility Principle by keeping the logic related to results within the class that represents those results. However, care must be taken to ensure that the static nature of the method does not conflict with the instance-based nature of the class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":91,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readFrom to class DesiredBalanceResponse","description":"move method readFrom to PsiClass:DesiredBalanceResponse\nRationale: The readFrom() method deals with reading a Result based on an opcode, which can be associated with the balance state of a cluster. DesiredBalanceResponse encapsulates various states and responses related to cluster balancing, making it a suitable home for this method. This move improves encapsulation and aligns with the Open/Closed Principle, as DesiredBalanceResponse can be extended to handle more result types in the future. However, the relationship between the opcode and balance states should be clearly defined to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":91,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readFrom to class DesiredShards","description":"move method readFrom to PsiClass:DesiredShards\nRationale: DesiredShards is closely related to the management of shard states, which can be represented by the Result returned by readFrom(). Moving the method here would enhance the clarity of shard-related operations and responsibilities. This aligns with the Single Responsibility Principle by ensuring that the class manages its own state representation. However, the class should not become overloaded with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":266,"lineEnd":276,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method writeWithoutShardId to class Result","description":"Move method writeWithoutShardId to org.elasticsearch.action.DocWriteResponse.Result\nRationale: The writeWithoutShardId() method is primarily responsible for serializing data related to the \u0027Result\u0027 class. Moving it to the Result class would enhance cohesion, as the method directly interacts with the fields of the Result instance, such as \u0027id\u0027, \u0027version\u0027, \u0027seqNo\u0027, and \u0027primaryTerm\u0027. This transfer aligns with the Single Responsibility Principle, as it consolidates serialization logic within the class that holds the data being serialized. Additionally, it adheres to the Interface Segregation Principle by keeping the Result class focused on its own data representation, making the design cleaner and more maintainable. However, care must be taken to ensure that any dependencies on the original class are properly managed, and that the method\u0027s visibility is adjusted as needed to maintain encapsulation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"readFrom","method_signature":"public static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},{"method_name":"getLocation","method_signature":"public getLocation(@Nullable String routing)","target_class":"","rationale":""},{"method_name":"writeThin","method_signature":"public writeThin(StreamOutput out)","target_class":"","rationale":""},{"method_name":"writeWithoutShardId","method_signature":"private writeWithoutShardId(StreamOutput out)","target_class":"","rationale":""},{"method_name":"innerToXContent","method_signature":"public innerToXContent(XContentBuilder builder, Params params)","target_class":"","rationale":""},{"method_name":"parseInnerToXContent","method_signature":"public static parseInnerToXContent(XContentParser parser, Builder context)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"readFrom","method_signature":"public static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"writeThin","method_signature":"public writeThin(StreamOutput out)","target_class":"","rationale":""},{"method_name":"writeWithoutShardId","method_signature":"private writeWithoutShardId(StreamOutput out)","target_class":"","rationale":""},{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},{"method_name":"innerToXContent","method_signature":"public innerToXContent(XContentBuilder builder, Params params)","target_class":"","rationale":""},{"method_name":"parseInnerToXContent","method_signature":"public static parseInnerToXContent(XContentParser parser, Builder context)","target_class":"","rationale":""},{"method_name":"getLocation","method_signature":"public getLocation(@Nullable String routing)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static readFrom(StreamInput in)":{"first":{"method_name":"readFrom","method_signature":"public static readFrom(StreamInput in)","target_class":"","rationale":""},"second":0.2059563622605986},"public writeThin(StreamOutput out)":{"first":{"method_name":"writeThin","method_signature":"public writeThin(StreamOutput out)","target_class":"","rationale":""},"second":0.42420855427067294},"private writeWithoutShardId(StreamOutput out)":{"first":{"method_name":"writeWithoutShardId","method_signature":"private writeWithoutShardId(StreamOutput out)","target_class":"","rationale":""},"second":0.4392887475899577},"public status()":{"first":{"method_name":"status","method_signature":"public status()","target_class":"","rationale":""},"second":0.48480360527421457},"public innerToXContent(XContentBuilder builder, Params params)":{"first":{"method_name":"innerToXContent","method_signature":"public innerToXContent(XContentBuilder builder, Params params)","target_class":"","rationale":""},"second":0.5164150710382266},"public static parseInnerToXContent(XContentParser parser, Builder context)":{"first":{"method_name":"parseInnerToXContent","method_signature":"public static parseInnerToXContent(XContentParser parser, Builder context)","target_class":"","rationale":""},"second":0.5322924119033798},"public getLocation(@Nullable String routing)":{"first":{"method_name":"getLocation","method_signature":"public getLocation(@Nullable String routing)","target_class":"","rationale":""},"second":0.5759193863848393}},"llmMethodPriority":{"priority_method_names":["readFrom","writeThin","writeWithoutShardId","status","innerToXContent","parseInnerToXContent","getLocation"],"llm_response_time":2446},"targetClassMap":{"readFrom":{"target_classes":[{"class_name":"DocWriteResponse","similarity_score":0.311955398649668},{"class_name":"ActionTestUtils","similarity_score":0.2275455136545516},{"class_name":"ClusterStateCreationUtils","similarity_score":0.17372344839563408},{"class_name":"DataStreamsActionUtil","similarity_score":0.2162557113697498},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.2398533110655411},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.24978889931606182},{"class_name":"SynonymsTestUtils","similarity_score":0.28723810604540806},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.10803395392536073},{"class_name":"HdfsUtils","similarity_score":0.23905863383501236},{"class_name":"JwkValidateUtil","similarity_score":0.28467609788742787},{"class_name":"JwkValidateUtilTests","similarity_score":0.22799025134527426},{"class_name":"DesiredBalanceResponse","similarity_score":0.3516693992328046},{"class_name":"RestResponseUtils","similarity_score":0.24481300481223264},{"class_name":"IndexDiskUsageAnalyzer","similarity_score":0.3311986065951061},{"class_name":"IndexDiskUsageAnalyzerTests","similarity_score":0.322295485272883},{"class_name":"IndexDiskUsageStats","similarity_score":0.27329824389047375},{"class_name":"DesiredShards","similarity_score":0.3541683509537503},{"class_name":"JwtUtil","similarity_score":0.2827533393366565},{"class_name":"FunctionTestUtils","similarity_score":0.2805869291623504},{"class_name":"DestructiveOperations","similarity_score":0.18854749418389316},{"class_name":"IndexerUtils","similarity_score":0.24329846425762003},{"class_name":"FutureUtils","similarity_score":0.18934138734018605},{"class_name":"IndexFieldCapabilities","similarity_score":0.17542078362978022},{"class_name":"GatekeeperOptions","similarity_score":0.19933149177494172},{"class_name":"DfsQueryPhaseTests","similarity_score":0.2626316271828732},{"class_name":"GceMockUtils","similarity_score":0.29746483324371764},{"class_name":"HighlightUtils","similarity_score":0.2413075886643423},{"class_name":"ExceptionUtils","similarity_score":0.21437323142813605},{"class_name":"RestTestUtil","similarity_score":0.17118713331043617},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.4128092928270665}],"target_classes_sorted_by_llm":["DocWriteResponse","DesiredBalanceResponse","DesiredShards","IndexDiskUsageAnalyzer","GceMockUtils","JwkValidateUtil","JwtUtil","IndexDiskUsageAnalyzerTests","SynonymsTestUtils","IndexLongFieldRangeTestUtils"],"llm_response_time":11088,"similarity_computation_time":27,"similarity_metric":"voyage"},"writeThin":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":446,"similarity_computation_time":1,"similarity_metric":"voyage"},"writeWithoutShardId":{"target_classes":[{"class_name":"Result","similarity_score":0.39631454350213335}],"target_classes_sorted_by_llm":["Result"],"llm_response_time":2907,"similarity_computation_time":2,"similarity_metric":"voyage"}}}
{"id":"9b21a7bc-2cbe-4e0e-8e9d-25285a175b22","methodCount":9,"hostFunctionTelemetryData":{"hostFunctionSize":114,"lineStart":26,"lineEnd":139,"bodyLineStart":26,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/action/support/broadcast/BaseBroadcastResponse.java","sourceCode":"/**\n * Base class for all broadcast operation based responses.\n */\npublic class BaseBroadcastResponse extends ActionResponse {\n\n    public static final DefaultShardOperationFailedException[] EMPTY \u003d new DefaultShardOperationFailedException[0];\n\n    private static final ParseField _SHARDS_FIELD \u003d new ParseField(\"_shards\");\n    private static final ParseField TOTAL_FIELD \u003d new ParseField(\"total\");\n    private static final ParseField SUCCESSFUL_FIELD \u003d new ParseField(\"successful\");\n    private static final ParseField FAILED_FIELD \u003d new ParseField(\"failed\");\n    private static final ParseField FAILURES_FIELD \u003d new ParseField(\"failures\");\n\n    private final int totalShards;\n    private final int successfulShards;\n    private final int failedShards;\n    private final DefaultShardOperationFailedException[] shardFailures;\n\n    @SuppressWarnings(\"unchecked\")\n    public static \u003cT extends BaseBroadcastResponse\u003e void declareBroadcastFields(ConstructingObjectParser\u003cT, Void\u003e PARSER) {\n        ConstructingObjectParser\u003cBaseBroadcastResponse, Void\u003e shardsParser \u003d new ConstructingObjectParser\u003c\u003e(\n            \"_shards\",\n            true,\n            arg -\u003e new BaseBroadcastResponse((int) arg[0], (int) arg[1], (int) arg[2], (List\u003cDefaultShardOperationFailedException\u003e) arg[3])\n        );\n        shardsParser.declareInt(constructorArg(), TOTAL_FIELD);\n        shardsParser.declareInt(constructorArg(), SUCCESSFUL_FIELD);\n        shardsParser.declareInt(constructorArg(), FAILED_FIELD);\n        shardsParser.declareObjectArray(\n            optionalConstructorArg(),\n            (p, c) -\u003e DefaultShardOperationFailedException.fromXContent(p),\n            FAILURES_FIELD\n        );\n        PARSER.declareObject(constructorArg(), shardsParser, _SHARDS_FIELD);\n    }\n\n    public BaseBroadcastResponse(StreamInput in) throws IOException {\n        totalShards \u003d in.readVInt();\n        successfulShards \u003d in.readVInt();\n        failedShards \u003d in.readVInt();\n        int size \u003d in.readVInt();\n        if (size \u003e 0) {\n            shardFailures \u003d new DefaultShardOperationFailedException[size];\n            for (int i \u003d 0; i \u003c size; i++) {\n                shardFailures[i] \u003d readShardOperationFailed(in);\n            }\n        } else {\n            shardFailures \u003d EMPTY;\n        }\n    }\n\n    public BaseBroadcastResponse(\n        int totalShards,\n        int successfulShards,\n        int failedShards,\n        List\u003cDefaultShardOperationFailedException\u003e shardFailures\n    ) {\n        this.totalShards \u003d totalShards;\n        this.successfulShards \u003d successfulShards;\n        this.failedShards \u003d failedShards;\n        if (shardFailures \u003d\u003d null) {\n            this.shardFailures \u003d EMPTY;\n        } else {\n            this.shardFailures \u003d shardFailures.toArray(new DefaultShardOperationFailedException[shardFailures.size()]);\n        }\n    }\n\n    /**\n     * The total shards this request ran against.\n     */\n    public int getTotalShards() {\n        return totalShards;\n    }\n\n    /**\n     * The successful shards this request was executed on.\n     */\n    public int getSuccessfulShards() {\n        return successfulShards;\n    }\n\n    /**\n     * The failed shards this request was executed on.\n     */\n    public int getFailedShards() {\n        return failedShards;\n    }\n\n    /**\n     * The REST status that should be used for the response\n     */\n    public RestStatus getStatus() {\n        if (failedShards \u003e 0) {\n            return shardFailures[0].status();\n        } else {\n            return RestStatus.OK;\n        }\n    }\n\n    /**\n     * The list of shard failures exception.\n     */\n    public DefaultShardOperationFailedException[] getShardFailures() {\n        return shardFailures;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        out.writeVInt(totalShards);\n        out.writeVInt(successfulShards);\n        out.writeVInt(failedShards);\n        out.writeArray(shardFailures);\n    }\n}","methodCount":9},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":43,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareBroadcastFields to class DefaultShardOperationFailedException","description":"move method declareBroadcastFields to PsiClass:DefaultShardOperationFailedException\nRationale: The declareBroadcastFields() method is closely tied to the parsing of shard operation failures, which is a core function of the DefaultShardOperationFailedException class. Moving this method here would enhance cohesion, as it directly relates to the construction of response objects for shard operations. This aligns with the Single Responsibility Principle, allowing DefaultShardOperationFailedException to encapsulate its parsing logic. However, it may increase the complexity of the class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":43,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareBroadcastFields to class ShardsAcknowledgedResponse","description":"move method declareBroadcastFields to PsiClass:ShardsAcknowledgedResponse\nRationale: The declareBroadcastFields() method is relevant for managing and declaring fields related to broadcast responses, which the ShardsAcknowledgedResponse class deals with. By relocating the method here, we can improve the encapsulation of response handling logic. This move supports the Open/Closed Principle by allowing the class to be extended without modifying existing code. However, this could lead to increased dependencies on the ShardsAcknowledgedResponse class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":43,"lineEnd":59,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareBroadcastFields to class AcknowledgedResponse","description":"move method declareBroadcastFields to PsiClass:AcknowledgedResponse\nRationale: The declareBroadcastFields() method is concerned with parsing and managing broadcast response fields, which aligns with the AcknowledgedResponse class\u0027s purpose. Moving the method here would adhere to the Interface Segregation Principle, as it would allow AcknowledgedResponse to manage its parsing logic internally. A potential drawback is that it may create confusion if the AcknowledgedResponse class is not primarily focused on broadcast logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"declareBroadcastFields","method_signature":"@SuppressWarnings(\"unchecked\")\n    public static declareBroadcastFields(ConstructingObjectParser\u003cT, Void\u003e PARSER)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"declareBroadcastFields","method_signature":"@SuppressWarnings(\"unchecked\")\n    public static declareBroadcastFields(ConstructingObjectParser\u003cT, Void\u003e PARSER)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"@SuppressWarnings(\"unchecked\")\n    public static declareBroadcastFields(ConstructingObjectParser\u003cT, Void\u003e PARSER)":{"first":{"method_name":"declareBroadcastFields","method_signature":"@SuppressWarnings(\"unchecked\")\n    public static declareBroadcastFields(ConstructingObjectParser\u003cT, Void\u003e PARSER)","target_class":"","rationale":""},"second":0.21421910860365675}},"llmMethodPriority":{"priority_method_names":["declareBroadcastFields"],"llm_response_time":1233},"targetClassMap":{"declareBroadcastFields":{"target_classes":[{"class_name":"ActionTestUtils","similarity_score":0.2543468255990385},{"class_name":"ClusterStateCreationUtils","similarity_score":0.18852449646451924},{"class_name":"TransportMasterNodeActionUtils","similarity_score":0.1353329904901917},{"class_name":"TransportBroadcastByNodeActionTests","similarity_score":0.3394481018372642},{"class_name":"TransportBroadcastUnpromotableActionTests","similarity_score":0.31071490018498915},{"class_name":"DataStreamsActionUtil","similarity_score":0.17495705113085475},{"class_name":"SynonymsTestUtils","similarity_score":0.25987009741882106},{"class_name":"ShardMultiGetFromTranslogUtil","similarity_score":0.220927723387861},{"class_name":"PrevalidateShardPathRequestSerializationTestUtils","similarity_score":0.2624388922881486},{"class_name":"DestructiveOperations","similarity_score":0.19475435358871507},{"class_name":"AutoCreateIndex","similarity_score":0.23730491685821758},{"class_name":"AutoCreateIndexTests","similarity_score":0.211831234683921},{"class_name":"AcknowledgedResponse","similarity_score":0.2775157656943414},{"class_name":"ActiveShardCount","similarity_score":0.1916754039240863},{"class_name":"ActiveShardCountTests","similarity_score":0.19734112649214477},{"class_name":"BroadcastReplicationTests","similarity_score":0.3375756642714568},{"class_name":"ListenerTimeouts","similarity_score":0.13325091898737446},{"class_name":"ContextPreservingActionListener","similarity_score":0.20754980866510836},{"class_name":"ConcreteTargetOptions","similarity_score":0.21246799941745018},{"class_name":"DefaultShardOperationFailedException","similarity_score":0.3565965367625507},{"class_name":"DefaultShardOperationFailedExceptionTests","similarity_score":0.37084712551718935},{"class_name":"CancellableActionTestPlugin","similarity_score":0.19092880487314368},{"class_name":"CancellableFanOutTests","similarity_score":0.28757367006602463},{"class_name":"SubscribableListener","similarity_score":0.1155618295261881},{"class_name":"SubscribableListenerTests","similarity_score":0.2963538806302864},{"class_name":"ShardInfo","similarity_score":0.2430876317343525},{"class_name":"ShardsAcknowledgedResponse","similarity_score":0.26934741867955886},{"class_name":"Failure","similarity_score":0.22281936587684686},{"class_name":"FailureStoreOptions","similarity_score":0.28276028708674766}],"target_classes_sorted_by_llm":["DefaultShardOperationFailedException","ShardsAcknowledgedResponse","AcknowledgedResponse","BroadcastReplicationTests","TransportBroadcastByNodeActionTests","TransportBroadcastUnpromotableActionTests","FailureStoreOptions","CancellableFanOutTests","SubscribableListenerTests","DefaultShardOperationFailedExceptionTests"],"llm_response_time":16889,"similarity_computation_time":38,"similarity_metric":"voyage"}}}
{"id":"96110daf-2ae3-4143-a67e-ae5f5942d0be","methodCount":34,"hostFunctionTelemetryData":{"hostFunctionSize":398,"lineStart":41,"lineEnd":438,"bodyLineStart":41,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggestion.java","sourceCode":"/**\n * Suggestion response for {@link CompletionSuggester} results\n *\n * Response format for each entry:\n * {\n *     \"text\" : STRING\n *     \"score\" : FLOAT\n *     \"contexts\" : CONTEXTS\n * }\n *\n * CONTEXTS : {\n *     \"CONTEXT_NAME\" : ARRAY,\n *     ..\n * }\n *\n */\npublic final class CompletionSuggestion extends Suggest.Suggestion\u003cCompletionSuggestion.Entry\u003e {\n\n    private final boolean skipDuplicates;\n\n    /**\n     * Creates a completion suggestion given its name, size and whether it should skip duplicates\n     * @param name The name for the suggestions\n     * @param size The number of suggestions to return\n     * @param skipDuplicates Whether duplicate suggestions should be filtered out\n     */\n    public CompletionSuggestion(String name, int size, boolean skipDuplicates) {\n        super(name, size);\n        this.skipDuplicates \u003d skipDuplicates;\n    }\n\n    public CompletionSuggestion(StreamInput in) throws IOException {\n        super(in);\n        skipDuplicates \u003d in.readBoolean();\n    }\n\n    @Override\n    public String getWriteableName() {\n        return CompletionSuggestionBuilder.SUGGESTION_NAME;\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        super.writeTo(out);\n        out.writeBoolean(skipDuplicates);\n    }\n\n    /**\n     * @return the result options for the suggestion\n     */\n    public List\u003cEntry.Option\u003e getOptions() {\n        if (entries.isEmpty() \u003d\u003d false) {\n            assert entries.size() \u003d\u003d 1 : \"CompletionSuggestion must have only one entry\";\n            return entries.get(0).getOptions();\n        } else {\n            return Collections.emptyList();\n        }\n    }\n\n    /**\n     * @return whether there is any hits for the suggestion\n     */\n    public boolean hasScoreDocs() {\n        return getOptions().size() \u003e 0;\n    }\n\n    @Override\n    public boolean equals(Object other) {\n        return super.equals(other) \u0026\u0026 Objects.equals(skipDuplicates, ((CompletionSuggestion) other).skipDuplicates);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(super.hashCode(), skipDuplicates);\n    }\n\n    public static CompletionSuggestion fromXContent(XContentParser parser, String name) throws IOException {\n        CompletionSuggestion suggestion \u003d new CompletionSuggestion(name, -1, false);\n        parseEntries(parser, suggestion, CompletionSuggestion.Entry::fromXContent);\n        return suggestion;\n    }\n\n    private static final class OptionPriorityQueue extends PriorityQueue\u003cShardOptions\u003e {\n        OptionPriorityQueue(int maxSize) {\n            super(maxSize);\n        }\n\n        @Override\n        protected boolean lessThan(ShardOptions a, ShardOptions b) {\n            int compare \u003d COMPARATOR.compare(a.current, b.current);\n            if (compare !\u003d 0) {\n                return compare \u003c 0;\n            }\n            ScoreDoc aDoc \u003d a.current.getDoc();\n            ScoreDoc bDoc \u003d b.current.getDoc();\n            if (aDoc.shardIndex \u003d\u003d bDoc.shardIndex) {\n                return aDoc.doc \u003c bDoc.doc;\n            }\n            return aDoc.shardIndex \u003c bDoc.shardIndex;\n        }\n    }\n\n    private static class ShardOptions {\n        final Iterator\u003cEntry.Option\u003e optionsIterator;\n        Entry.Option current;\n\n        private ShardOptions(Iterator\u003cEntry.Option\u003e optionsIterator) {\n            assert optionsIterator.hasNext();\n            this.optionsIterator \u003d optionsIterator;\n            this.current \u003d optionsIterator.next();\n            assert this.current.getDoc().shardIndex !\u003d -1 : \"shardIndex is not set\";\n        }\n\n        boolean advanceToNextOption() {\n            if (optionsIterator.hasNext()) {\n                current \u003d optionsIterator.next();\n                return true;\n            } else {\n                return false;\n            }\n        }\n    }\n\n    @Override\n    public CompletionSuggestion reduce(List\u003cSuggest.Suggestion\u003cEntry\u003e\u003e toReduce) {\n        if (toReduce.isEmpty()) {\n            return null;\n        } else {\n            final CompletionSuggestion leader \u003d (CompletionSuggestion) toReduce.get(0);\n            final Entry leaderEntry \u003d leader.getEntries().get(0);\n            final String name \u003d leader.getName();\n            int size \u003d leader.getSize();\n            if (toReduce.size() \u003d\u003d 1) {\n                return leader;\n            } else {\n                // combine suggestion entries from participating shards on the coordinating node\n                // the global top \u003ccode\u003esize\u003c/code\u003e entries are collected from the shard results\n                // using a priority queue\n                OptionPriorityQueue pq \u003d new OptionPriorityQueue(toReduce.size());\n                for (Suggest.Suggestion\u003cEntry\u003e suggestion : toReduce) {\n                    assert suggestion.getName().equals(name) : \"name should be identical across all suggestions\";\n                    Iterator\u003cEntry.Option\u003e it \u003d ((CompletionSuggestion) suggestion).getOptions().iterator();\n                    if (it.hasNext()) {\n                        pq.add(new ShardOptions(it));\n                    }\n                }\n                // Dedup duplicate suggestions (based on the surface form) if skip duplicates is activated\n                final CharArraySet seenSurfaceForms \u003d leader.skipDuplicates ? new CharArraySet(leader.getSize(), false) : null;\n                final Entry entry \u003d new Entry(leaderEntry.getText(), leaderEntry.getOffset(), leaderEntry.getLength());\n                final List\u003cEntry.Option\u003e options \u003d entry.getOptions();\n                while (pq.size() \u003e 0) {\n                    ShardOptions top \u003d pq.top();\n                    Entry.Option current \u003d top.current;\n                    if (top.advanceToNextOption()) {\n                        pq.updateTop();\n                    } else {\n                        // options exhausted for this shard\n                        pq.pop();\n                    }\n                    if (leader.skipDuplicates \u003d\u003d false || seenSurfaceForms.add(current.getText().toString())) {\n                        options.add(current);\n                        if (options.size() \u003e\u003d size) {\n                            break;\n                        }\n                    }\n                }\n                final CompletionSuggestion suggestion \u003d new CompletionSuggestion(leader.getName(), leader.getSize(), leader.skipDuplicates);\n                suggestion.addTerm(entry);\n                return suggestion;\n            }\n        }\n    }\n\n    public void setShardIndex(int shardIndex) {\n        if (entries.isEmpty() \u003d\u003d false) {\n            for (Entry.Option option : getOptions()) {\n                option.setShardIndex(shardIndex);\n            }\n        }\n    }\n\n    @Override\n    protected Entry newEntry(StreamInput in) throws IOException {\n        return new Entry(in);\n    }\n\n    public static final class Entry extends Suggest.Suggestion.Entry\u003cCompletionSuggestion.Entry.Option\u003e {\n\n        public Entry(Text text, int offset, int length) {\n            super(text, offset, length);\n        }\n\n        private Entry() {}\n\n        public Entry(StreamInput in) throws IOException {\n            super(in);\n        }\n\n        @Override\n        protected Option newOption(StreamInput in) throws IOException {\n            return new Option(in);\n        }\n\n        private static final ObjectParser\u003cEntry, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\"CompletionSuggestionEntryParser\", true, Entry::new);\n        static {\n            declareCommonFields(PARSER);\n            /*\n             * The use of a lambda expression instead of the method reference Entry::addOptions is a workaround for a JDK 14 compiler bug.\n             * The bug is: https://bugs.java.com/bugdatabase/view_bug.do?bug_id\u003dJDK-8242214\n             */\n            PARSER.declareObjectArray((e, o) -\u003e e.addOptions(o), (p, c) -\u003e Option.fromXContent(p), new ParseField(OPTIONS));\n        }\n\n        public static Entry fromXContent(XContentParser parser) {\n            return PARSER.apply(parser, null);\n        }\n\n        public static class Option extends Suggest.Suggestion.Entry.Option {\n            private final Map\u003cString, Set\u003cString\u003e\u003e contexts;\n            private final ScoreDoc doc;\n            private SearchHit hit;\n\n            public static final ParseField CONTEXTS \u003d new ParseField(\"contexts\");\n\n            public Option(int docID, Text text, float score, Map\u003cString, Set\u003cString\u003e\u003e contexts) {\n                super(text, score);\n                this.doc \u003d new ScoreDoc(docID, score);\n                this.contexts \u003d Objects.requireNonNull(contexts, \"context map cannot be null\");\n            }\n\n            public Option(StreamInput in) throws IOException {\n                super(in);\n                this.doc \u003d Lucene.readScoreDoc(in);\n                if (in.readBoolean()) {\n                    this.hit \u003d SearchHit.readFrom(in, false);\n                }\n                int contextSize \u003d in.readInt();\n                this.contexts \u003d Maps.newLinkedHashMapWithExpectedSize(contextSize);\n                for (int i \u003d 0; i \u003c contextSize; i++) {\n                    String contextName \u003d in.readString();\n                    int nContexts \u003d in.readVInt();\n                    Set\u003cString\u003e contexts \u003d Sets.newHashSetWithExpectedSize(nContexts);\n                    for (int j \u003d 0; j \u003c nContexts; j++) {\n                        contexts.add(in.readString());\n                    }\n                    this.contexts.put(contextName, contexts);\n                }\n            }\n\n            @Override\n            protected void mergeInto(Suggest.Suggestion.Entry.Option otherOption) {\n                // Completion suggestions are reduced by\n                // org.elasticsearch.search.suggest.completion.CompletionSuggestion.reduce()\n                throw new UnsupportedOperationException();\n            }\n\n            public Map\u003cString, Set\u003cString\u003e\u003e getContexts() {\n                return contexts;\n            }\n\n            public ScoreDoc getDoc() {\n                return doc;\n            }\n\n            public SearchHit getHit() {\n                return hit;\n            }\n\n            public void setShardIndex(int shardIndex) {\n                this.doc.shardIndex \u003d shardIndex;\n            }\n\n            public void setHit(SearchHit hit) {\n                this.hit \u003d hit \u003d\u003d null ? null : hit.asUnpooled();\n            }\n\n            @Override\n            public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n                builder.field(TEXT.getPreferredName(), getText());\n                if (hit !\u003d null) {\n                    hit.toInnerXContent(builder, params);\n                } else {\n                    builder.field(SCORE.getPreferredName(), getScore());\n                }\n                if (contexts.size() \u003e 0) {\n                    builder.startObject(CONTEXTS.getPreferredName());\n                    for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : contexts.entrySet()) {\n                        builder.startArray(entry.getKey());\n                        for (CharSequence context : entry.getValue()) {\n                            builder.value(context.toString());\n                        }\n                        builder.endArray();\n                    }\n                    builder.endObject();\n                }\n                return builder;\n            }\n\n            private static final ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\n                \"CompletionOptionParser\",\n                unknownMetaFieldConsumer,\n                HashMap::new\n            );\n\n            static {\n                SearchHit.declareInnerHitsParseFields(PARSER);\n                PARSER.declareString(\n                    (map, value) -\u003e map.put(Suggestion.Entry.Option.TEXT.getPreferredName(), value),\n                    Suggestion.Entry.Option.TEXT\n                );\n                PARSER.declareFloat(\n                    (map, value) -\u003e map.put(Suggestion.Entry.Option.SCORE.getPreferredName(), value),\n                    Suggestion.Entry.Option.SCORE\n                );\n                PARSER.declareObject(\n                    (map, value) -\u003e map.put(CompletionSuggestion.Entry.Option.CONTEXTS.getPreferredName(), value),\n                    (p, c) -\u003e parseContexts(p),\n                    CompletionSuggestion.Entry.Option.CONTEXTS\n                );\n            }\n\n            private static Map\u003cString, Set\u003cString\u003e\u003e parseContexts(XContentParser parser) throws IOException {\n                Map\u003cString, Set\u003cString\u003e\u003e contexts \u003d new HashMap\u003c\u003e();\n                while ((parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n                    ensureExpectedToken(XContentParser.Token.FIELD_NAME, parser.currentToken(), parser);\n                    String key \u003d parser.currentName();\n                    ensureExpectedToken(XContentParser.Token.START_ARRAY, parser.nextToken(), parser);\n                    Set\u003cString\u003e values \u003d new HashSet\u003c\u003e();\n                    while ((parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                        ensureExpectedToken(XContentParser.Token.VALUE_STRING, parser.currentToken(), parser);\n                        values.add(parser.text());\n                    }\n                    contexts.put(key, values);\n                }\n                return contexts;\n            }\n\n            public static Option fromXContent(XContentParser parser) {\n                Map\u003cString, Object\u003e values \u003d PARSER.apply(parser, null);\n\n                Text text \u003d new Text((String) values.get(Suggestion.Entry.Option.TEXT.getPreferredName()));\n                Float score \u003d (Float) values.get(Suggestion.Entry.Option.SCORE.getPreferredName());\n                @SuppressWarnings(\"unchecked\")\n                Map\u003cString, Set\u003cString\u003e\u003e contexts \u003d (Map\u003cString, Set\u003cString\u003e\u003e) values.get(\n                    CompletionSuggestion.Entry.Option.CONTEXTS.getPreferredName()\n                );\n                if (contexts \u003d\u003d null) {\n                    contexts \u003d Collections.emptyMap();\n                }\n\n                SearchHit hit \u003d null;\n                // the option either prints SCORE or inlines the search hit\n                if (score \u003d\u003d null) {\n                    hit \u003d SearchHit.createFromMap(values);\n                    score \u003d hit.getScore();\n                }\n                CompletionSuggestion.Entry.Option option \u003d new CompletionSuggestion.Entry.Option(-1, text, score, contexts);\n                option.setHit(hit);\n                return option;\n            }\n\n            @Override\n            public void writeTo(StreamOutput out) throws IOException {\n                super.writeTo(out);\n                Lucene.writeScoreDoc(out, doc);\n                if (hit !\u003d null) {\n                    out.writeBoolean(true);\n                    hit.writeTo(out);\n                } else {\n                    out.writeBoolean(false);\n                }\n                out.writeInt(contexts.size());\n                for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : contexts.entrySet()) {\n                    out.writeString(entry.getKey());\n                    out.writeStringCollection(entry.getValue());\n                }\n            }\n\n            @Override\n            public String toString() {\n                StringBuilder stringBuilder \u003d new StringBuilder();\n                stringBuilder.append(\"text:\");\n                stringBuilder.append(getText());\n                stringBuilder.append(\" score:\");\n                stringBuilder.append(getScore());\n                stringBuilder.append(\" context:[\");\n                for (Map.Entry\u003cString, Set\u003cString\u003e\u003e entry : contexts.entrySet()) {\n                    stringBuilder.append(\" \");\n                    stringBuilder.append(entry.getKey());\n                    stringBuilder.append(\":\");\n                    stringBuilder.append(entry.getValue());\n                }\n                stringBuilder.append(\"]\");\n                return stringBuilder.toString();\n            }\n        }\n    }\n}","methodCount":34},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":116,"lineEnd":120,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class CompletionSuggestionBuilder","description":"move method fromXContent to PsiClass:CompletionSuggestionBuilder\nRationale: The fromXContent() method is primarily concerned with creating and populating a CompletionSuggestion object, which is closely related to the responsibilities of the CompletionSuggestionBuilder class. Moving this method enhances cohesion by placing it in a class that directly deals with the construction of CompletionSuggestion objects. This aligns with the Single Responsibility Principle, as it centralizes the logic for building suggestions. However, it may require adjustments in existing code that references the method.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":120,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class CompletionSuggester","description":"move method fromXContent to PsiClass:CompletionSuggester\nRationale: The CompletionSuggester class is likely to have a direct association with completion suggestions, making it a suitable target for the fromXContent() method. By relocating the method here, we ensure that the logic for parsing and creating suggestions is encapsulated within a class that is responsible for managing suggestions, adhering to the Open/Closed Principle by allowing the class to evolve without modifying existing code. However, care must be taken to ensure that dependencies are managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":120,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class Entry","description":"move method fromXContent to PsiClass:Entry\nRationale: The Entry class already contains a fromXContent() method, indicating that it is designed to handle the parsing of suggestion entries. Moving the method here would enhance the logical grouping of functionality related to parsing and building suggestions. This adheres to the Interface Segregation Principle, as it separates concerns between different classes. A potential drawback is that it may increase the complexity of the Entry class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":377,"lineEnd":399,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class CompletionSuggestion","description":"move method fromXContent to PsiClass:CompletionSuggestion\nRationale: The fromXContent() method is responsible for creating a CompletionSuggestion.Entry.Option from an XContentParser, which aligns closely with the purpose of the CompletionSuggestion class. Moving it here would adhere to the Single Responsibility Principle, as it centralizes the logic for creating options related to suggestions. This would enhance cohesion within the CompletionSuggestion class, making it clearer and more maintainable. However, care must be taken to ensure that the parser logic does not introduce tight coupling with the XContentParser.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":377,"lineEnd":399,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class Entry","description":"move method fromXContent to PsiClass:Entry\nRationale: The Entry class is closely related to the Option being created by the fromXContent() method. Since the method creates an instance of CompletionSuggestion.Entry.Option, it makes sense to move it here to maintain the encapsulation of related functionalities. This aligns with the Open/Closed Principle, as the Entry class can be extended without modifying existing code. However, the Entry class already has a fromXContent method, which could lead to confusion if both methods are present.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":377,"lineEnd":399,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class CompletionSuggestionBuilder","description":"move method fromXContent to PsiClass:CompletionSuggestionBuilder\nRationale: The CompletionSuggestionBuilder class is responsible for constructing CompletionSuggestion instances. Since the fromXContent() method is about constructing an Option from parsed content, it fits well here. This move would enhance the Builder pattern\u0027s usability by centralizing construction logic. However, it may increase the complexity of the builder class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"hasScoreDocs","method_signature":"public hasScoreDocs()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String name)","target_class":"","rationale":""},{"method_name":"advanceToNextOption","method_signature":" advanceToNextOption()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseContexts","method_signature":"private static parseContexts(XContentParser parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String name)","target_class":"","rationale":""},{"method_name":"hasScoreDocs","method_signature":"public hasScoreDocs()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseContexts","method_signature":"private static parseContexts(XContentParser parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"advanceToNextOption","method_signature":" advanceToNextOption()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser, String name)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, String name)","target_class":"","rationale":""},"second":0.48386711096277696},"public hasScoreDocs()":{"first":{"method_name":"hasScoreDocs","method_signature":"public hasScoreDocs()","target_class":"","rationale":""},"second":0.524314998679409},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.5632524561621913},"private static parseContexts(XContentParser parser)":{"first":{"method_name":"parseContexts","method_signature":"private static parseContexts(XContentParser parser)","target_class":"","rationale":""},"second":0.5605156711265674}," advanceToNextOption()":{"first":{"method_name":"advanceToNextOption","method_signature":" advanceToNextOption()","target_class":"","rationale":""},"second":0.7400684804557851}},"llmMethodPriority":{"priority_method_names":["fromXContent","hasScoreDocs","fromXContent","parseContexts","fromXContent","advanceToNextOption"],"llm_response_time":2146},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"Entry","similarity_score":0.687014673339362},{"class_name":"FuzzyOptions","similarity_score":0.4743761361525222},{"class_name":"FuzzyOptionsTests","similarity_score":0.3638573807493375},{"class_name":"GeoContextMapping","similarity_score":0.5129463734746591},{"class_name":"GeoQueryContext","similarity_score":0.5275696146255449},{"class_name":"GeoQueryContextTests","similarity_score":0.4783105704279481},{"class_name":"CompletionSuggester","similarity_score":0.6381233682741648},{"class_name":"CompletionSuggesterBuilderTests","similarity_score":0.5908600796655914},{"class_name":"CompletionSuggestion","similarity_score":0.6187802507483473},{"class_name":"CompletionSuggestionBuilder","similarity_score":0.566005516271346},{"class_name":"RegexOptions","similarity_score":0.47759147816085956},{"class_name":"RegexOptionsTests","similarity_score":0.48654170410711123},{"class_name":"ContextMappings","similarity_score":0.4736761318259903},{"class_name":"CategoryContextMapping","similarity_score":0.4223940270794961},{"class_name":"CategoryContextMappingTests","similarity_score":0.5089287748912467},{"class_name":"CategoryQueryContext","similarity_score":0.4911289116904071},{"class_name":"CategoryQueryContextTests","similarity_score":0.3528477166063149},{"class_name":"GeoTileUtils","similarity_score":0.35410989545070576},{"class_name":"SearchUtils","similarity_score":0.35896546008980973},{"class_name":"HighlightUtils","similarity_score":0.4689214383718261},{"class_name":"BucketUtils","similarity_score":0.20921967241458783},{"class_name":"NestedUtils","similarity_score":0.42265346463601633},{"class_name":"TermSuggester","similarity_score":0.5729818563490405},{"class_name":"TermSuggestion","similarity_score":0.5060295352723216},{"class_name":"TermSuggestionBuilder","similarity_score":0.4381530203766242},{"class_name":"TermSuggestionBuilderTests","similarity_score":0.2490920622452478},{"class_name":"TermSuggestionOptionTests","similarity_score":0.6384905007522216},{"class_name":"DirectCandidateGenerator","similarity_score":0.5898317749717523},{"class_name":"DirectCandidateGeneratorBuilder","similarity_score":0.4601845707197586}],"target_classes_sorted_by_llm":["CompletionSuggestion","Entry","CompletionSuggestionBuilder","DirectCandidateGenerator","GeoContextMapping","GeoQueryContext","TermSuggester","CompletionSuggester","TermSuggestionOptionTests","CompletionSuggesterBuilderTests"],"llm_response_time":16694,"similarity_computation_time":26,"similarity_metric":"voyage"},"hasScoreDocs":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":475,"similarity_computation_time":1,"similarity_metric":"voyage"}}}
{"id":"caadd421-bae2-4bfb-8922-41726ed5aa07","methodCount":51,"hostFunctionTelemetryData":{"hostFunctionSize":491,"lineStart":203,"lineEnd":693,"bodyLineStart":203,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/search/suggest/Suggest.java","sourceCode":"/**\n     * The suggestion responses corresponding with the suggestions in the request.\n     */\n    @SuppressWarnings(\"rawtypes\")\n    public abstract static class Suggestion\u003cT extends Suggestion.Entry\u003e implements Iterable\u003cT\u003e, NamedWriteable, ToXContentFragment {\n\n        protected final String name;\n        protected final int size;\n        protected final List\u003cT\u003e entries \u003d new ArrayList\u003c\u003e(5);\n\n        public Suggestion(String name, int size) {\n            this.name \u003d name;\n            this.size \u003d size; // The suggested term size specified in request, only used for merging shard responses\n        }\n\n        @SuppressWarnings(\"this-escape\")\n        public Suggestion(StreamInput in) throws IOException {\n            name \u003d in.readString();\n            size \u003d in.readVInt();\n\n            int entriesCount \u003d in.readVInt();\n            entries.clear();\n            for (int i \u003d 0; i \u003c entriesCount; i++) {\n                T newEntry \u003d newEntry(in);\n                entries.add(newEntry);\n            }\n        }\n\n        public void addTerm(T entry) {\n            entries.add(entry);\n        }\n\n        @Override\n        public Iterator\u003cT\u003e iterator() {\n            return entries.iterator();\n        }\n\n        /**\n         * @return The entries for this suggestion.\n         */\n        public List\u003cT\u003e getEntries() {\n            return entries;\n        }\n\n        /**\n         * @return The name of the suggestion as is defined in the request.\n         */\n        public String getName() {\n            return name;\n        }\n\n        /**\n         * @return The number of requested suggestion option size\n         */\n        public int getSize() {\n            return size;\n        }\n\n        /**\n         * Merges the result of another suggestion into this suggestion.\n         * For internal usage.\n         */\n        @SuppressWarnings(\"unchecked\")\n        public Suggestion\u003cT\u003e reduce(List\u003cSuggestion\u003cT\u003e\u003e toReduce) {\n            if (toReduce.size() \u003d\u003d 1) {\n                return toReduce.get(0);\n            } else if (toReduce.isEmpty()) {\n                return null;\n            }\n            Suggestion\u003cT\u003e leader \u003d toReduce.get(0);\n            List\u003cT\u003e entries \u003d leader.entries;\n            final int size \u003d entries.size();\n            Comparator\u003cOption\u003e sortComparator \u003d sortComparator();\n            List\u003cT\u003e currentEntries \u003d new ArrayList\u003c\u003e();\n            for (int i \u003d 0; i \u003c size; i++) {\n                for (Suggestion\u003cT\u003e suggestion : toReduce) {\n                    if (suggestion.entries.size() !\u003d size) {\n                        throw new IllegalStateException(\n                            \"Can\u0027t merge suggest result, this might be caused by suggest calls \"\n                                + \"across multiple indices with different analysis chains. Suggest entries have different sizes actual [\"\n                                + suggestion.entries.size()\n                                + \"] expected [\"\n                                + size\n                                + \"]\"\n                        );\n                    }\n                    assert suggestion.name.equals(leader.name);\n                    currentEntries.add(suggestion.entries.get(i));\n                }\n                T entry \u003d (T) entries.get(i).reduce(currentEntries);\n                entry.sort(sortComparator);\n                entries.set(i, entry);\n                currentEntries.clear();\n            }\n            return leader;\n        }\n\n        protected Comparator\u003cOption\u003e sortComparator() {\n            return COMPARATOR;\n        }\n\n        /**\n         * Trims the number of options per suggest text term to the requested size.\n         * For internal usage.\n         */\n        public void trim() {\n            for (Entry\u003c?\u003e entry : entries) {\n                entry.trim(size);\n            }\n        }\n\n        protected abstract T newEntry(StreamInput in) throws IOException;\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeString(name);\n            out.writeVInt(size);\n            out.writeCollection(entries);\n        }\n\n        @Override\n        public abstract String getWriteableName();\n\n        @Override\n        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n            if (params.paramAsBoolean(RestSearchAction.TYPED_KEYS_PARAM, false)) {\n                // Concatenates the type and the name of the suggestion (ex: completion#foo)\n                builder.startArray(String.join(Aggregation.TYPED_KEYS_DELIMITER, getWriteableName(), getName()));\n            } else {\n                builder.startArray(getName());\n            }\n            for (Entry\u003c?\u003e entry : entries) {\n                builder.startObject();\n                entry.toXContent(builder, params);\n                builder.endObject();\n            }\n            builder.endArray();\n            return builder;\n        }\n\n        @Override\n        @SuppressWarnings(\"rawtypes\")\n        public boolean equals(Object other) {\n            if (this \u003d\u003d other) {\n                return true;\n            }\n\n            if (other \u003d\u003d null || getClass() !\u003d other.getClass()) {\n                return false;\n            }\n\n            Suggestion otherSuggestion \u003d (Suggestion) other;\n            return Objects.equals(name, otherSuggestion.name)\n                \u0026\u0026 Objects.equals(size, otherSuggestion.size)\n                \u0026\u0026 Objects.equals(entries, otherSuggestion.entries);\n        }\n\n        @Override\n        public int hashCode() {\n            return Objects.hash(name, size, entries);\n        }\n\n        @SuppressWarnings(\"unchecked\")\n        public static Suggestion\u003c? extends Entry\u003c? extends Option\u003e\u003e fromXContent(XContentParser parser) throws IOException {\n            ensureExpectedToken(XContentParser.Token.START_ARRAY, parser.currentToken(), parser);\n            SetOnce\u003cSuggestion\u003e suggestion \u003d new SetOnce\u003c\u003e();\n            XContentParserUtils.parseTypedKeysObject(parser, Aggregation.TYPED_KEYS_DELIMITER, Suggestion.class, suggestion::set);\n            return suggestion.get();\n        }\n\n        protected static \u003cE extends Suggestion.Entry\u003c?\u003e\u003e void parseEntries(\n            XContentParser parser,\n            Suggestion\u003cE\u003e suggestion,\n            CheckedFunction\u003cXContentParser, E, IOException\u003e entryParser\n        ) throws IOException {\n            ensureExpectedToken(XContentParser.Token.START_ARRAY, parser.currentToken(), parser);\n            while ((parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                suggestion.addTerm(entryParser.apply(parser));\n            }\n        }\n\n        /**\n         * Represents a part from the suggest text with suggested options.\n         */\n        public abstract static class Entry\u003cO extends Option\u003e implements Iterable\u003cO\u003e, Writeable, ToXContentFragment {\n\n            private static final String TEXT \u003d \"text\";\n            private static final String OFFSET \u003d \"offset\";\n            private static final String LENGTH \u003d \"length\";\n            protected static final String OPTIONS \u003d \"options\";\n\n            protected Text text;\n            protected int offset;\n            protected int length;\n\n            protected List\u003cO\u003e options \u003d new ArrayList\u003c\u003e(5);\n\n            public Entry(Text text, int offset, int length) {\n                this.text \u003d text;\n                this.offset \u003d offset;\n                this.length \u003d length;\n            }\n\n            protected Entry() {}\n\n            @SuppressWarnings(\"this-escape\")\n            public Entry(StreamInput in) throws IOException {\n                text \u003d in.readText();\n                offset \u003d in.readVInt();\n                length \u003d in.readVInt();\n                int suggestedWords \u003d in.readVInt();\n                options \u003d new ArrayList\u003c\u003e(suggestedWords);\n                for (int j \u003d 0; j \u003c suggestedWords; j++) {\n                    O newOption \u003d newOption(in);\n                    options.add(newOption);\n                }\n            }\n\n            public void addOption(O option) {\n                options.add(option);\n            }\n\n            protected void addOptions(List\u003cO\u003e options) {\n                for (O option : options) {\n                    addOption(option);\n                }\n            }\n\n            protected void sort(Comparator\u003cO\u003e comparator) {\n                CollectionUtil.timSort(options, comparator);\n            }\n\n            protected \u003cT extends Entry\u003cO\u003e\u003e Entry\u003cO\u003e reduce(List\u003cT\u003e toReduce) {\n                if (toReduce.size() \u003d\u003d 1) {\n                    return toReduce.get(0);\n                }\n                final Map\u003cO, O\u003e entries \u003d new HashMap\u003c\u003e();\n                Entry\u003cO\u003e leader \u003d toReduce.get(0);\n                for (Entry\u003cO\u003e entry : toReduce) {\n                    if (leader.text.equals(entry.text) \u003d\u003d false) {\n                        throw new IllegalStateException(\n                            \"Can\u0027t merge suggest entries, this might be caused by suggest calls \"\n                                + \"across multiple indices with different analysis chains. Suggest entries have different text actual [\"\n                                + entry.text\n                                + \"] expected [\"\n                                + leader.text\n                                + \"]\"\n                        );\n                    }\n                    assert leader.offset \u003d\u003d entry.offset;\n                    assert leader.length \u003d\u003d entry.length;\n                    leader.merge(entry);\n                    for (O option : entry) {\n                        O merger \u003d entries.get(option);\n                        if (merger \u003d\u003d null) {\n                            entries.put(option, option);\n                        } else {\n                            merger.mergeInto(option);\n                        }\n                    }\n                }\n                leader.options.clear();\n                for (O option : entries.keySet()) {\n                    leader.addOption(option);\n                }\n                return leader;\n            }\n\n            /**\n             * Merge any extra fields for this subtype.\n             */\n            protected void merge(Entry\u003cO\u003e other) {}\n\n            /**\n             * @return the text (analyzed by suggest analyzer) originating from the suggest text. Usually this is a\n             *         single term.\n             */\n            public Text getText() {\n                return text;\n            }\n\n            /**\n             * @return the start offset (not analyzed) for this entry in the suggest text.\n             */\n            public int getOffset() {\n                return offset;\n            }\n\n            /**\n             * @return the length (not analyzed) for this entry in the suggest text.\n             */\n            public int getLength() {\n                return length;\n            }\n\n            @Override\n            public Iterator\u003cO\u003e iterator() {\n                return options.iterator();\n            }\n\n            /**\n             * @return The suggested options for this particular suggest entry. If there are no suggested terms then\n             *         an empty list is returned.\n             */\n            public List\u003cO\u003e getOptions() {\n                return options;\n            }\n\n            void trim(int size) {\n                int optionsToRemove \u003d Math.max(0, options.size() - size);\n                for (int i \u003d 0; i \u003c optionsToRemove; i++) {\n                    options.remove(options.size() - 1);\n                }\n            }\n\n            @Override\n            public boolean equals(Object o) {\n                if (this \u003d\u003d o) {\n                    return true;\n                }\n                if (o \u003d\u003d null || getClass() !\u003d o.getClass()) {\n                    return false;\n                }\n\n                Entry\u003c?\u003e entry \u003d (Entry\u003c?\u003e) o;\n                return Objects.equals(length, entry.length)\n                    \u0026\u0026 Objects.equals(offset, entry.offset)\n                    \u0026\u0026 Objects.equals(text, entry.text)\n                    \u0026\u0026 Objects.equals(options, entry.options);\n            }\n\n            @Override\n            public int hashCode() {\n                return Objects.hash(text, offset, length, options);\n            }\n\n            protected abstract O newOption(StreamInput in) throws IOException;\n\n            @Override\n            public void writeTo(StreamOutput out) throws IOException {\n                out.writeText(text);\n                out.writeVInt(offset);\n                out.writeVInt(length);\n                out.writeCollection(options);\n            }\n\n            @Override\n            public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n                builder.field(TEXT, text);\n                builder.field(OFFSET, offset);\n                builder.field(LENGTH, length);\n                builder.startArray(OPTIONS);\n                for (Option option : options) {\n                    builder.startObject();\n                    option.toXContent(builder, params);\n                    builder.endObject();\n                }\n                builder.endArray();\n                return builder;\n            }\n\n            protected static void declareCommonFields(ObjectParser\u003c? extends Entry\u003c? extends Option\u003e, Void\u003e parser) {\n                parser.declareString((entry, text) -\u003e entry.text \u003d new Text(text), new ParseField(TEXT));\n                parser.declareInt((entry, offset) -\u003e entry.offset \u003d offset, new ParseField(OFFSET));\n                parser.declareInt((entry, length) -\u003e entry.length \u003d length, new ParseField(LENGTH));\n            }\n\n            /**\n             * Contains the suggested text with its document frequency and score.\n             */\n            public abstract static class Option implements Writeable, ToXContentFragment {\n\n                public static final ParseField TEXT \u003d new ParseField(\"text\");\n                public static final ParseField HIGHLIGHTED \u003d new ParseField(\"highlighted\");\n                public static final ParseField SCORE \u003d new ParseField(\"score\");\n                public static final ParseField COLLATE_MATCH \u003d new ParseField(\"collate_match\");\n\n                private final Text text;\n                private final Text highlighted;\n                private float score;\n                private Boolean collateMatch;\n\n                public Option(Text text, Text highlighted, float score, Boolean collateMatch) {\n                    this.text \u003d text;\n                    this.highlighted \u003d highlighted;\n                    this.score \u003d score;\n                    this.collateMatch \u003d collateMatch;\n                }\n\n                public Option(Text text, Text highlighted, float score) {\n                    this(text, highlighted, score, null);\n                }\n\n                public Option(Text text, float score) {\n                    this(text, null, score);\n                }\n\n                public Option(StreamInput in) throws IOException {\n                    text \u003d in.readText();\n                    score \u003d in.readFloat();\n                    highlighted \u003d in.readOptionalText();\n                    collateMatch \u003d in.readOptionalBoolean();\n                }\n\n                /**\n                 * @return The actual suggested text.\n                 */\n                public Text getText() {\n                    return text;\n                }\n\n                /**\n                 * @return Copy of suggested text with changes from user supplied text highlighted.\n                 */\n                public Text getHighlighted() {\n                    return highlighted;\n                }\n\n                /**\n                 * @return The score based on the edit distance difference between the suggested term and the\n                 *         term in the suggest text.\n                 */\n                public float getScore() {\n                    return score;\n                }\n\n                /**\n                 * @return true if collation has found a match for the entry.\n                 * if collate was not set, the value defaults to \u003ccode\u003etrue\u003c/code\u003e\n                 */\n                public boolean collateMatch() {\n                    return (collateMatch !\u003d null) ? collateMatch : true;\n                }\n\n                @Override\n                public void writeTo(StreamOutput out) throws IOException {\n                    out.writeText(text);\n                    out.writeFloat(score);\n                    out.writeOptionalText(highlighted);\n                    out.writeOptionalBoolean(collateMatch);\n                }\n\n                @Override\n                public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n                    builder.field(TEXT.getPreferredName(), text);\n                    if (highlighted !\u003d null) {\n                        builder.field(HIGHLIGHTED.getPreferredName(), highlighted);\n                    }\n\n                    builder.field(SCORE.getPreferredName(), score);\n                    if (collateMatch !\u003d null) {\n                        builder.field(COLLATE_MATCH.getPreferredName(), collateMatch.booleanValue());\n                    }\n\n                    return builder;\n                }\n\n                protected void mergeInto(Option otherOption) {\n                    score \u003d Math.max(score, otherOption.score);\n                    if (otherOption.collateMatch !\u003d null) {\n                        if (collateMatch \u003d\u003d null) {\n                            collateMatch \u003d otherOption.collateMatch;\n                        } else {\n                            collateMatch |\u003d otherOption.collateMatch;\n                        }\n                    }\n                }\n\n                /*\n                 * We consider options equal if they have the same text, even if their other fields may differ\n                 */\n                @Override\n                public boolean equals(Object o) {\n                    if (this \u003d\u003d o) {\n                        return true;\n                    }\n                    if (o \u003d\u003d null || getClass() !\u003d o.getClass()) {\n                        return false;\n                    }\n\n                    Option that \u003d (Option) o;\n                    return Objects.equals(text, that.text);\n                }\n\n                @Override\n                public int hashCode() {\n                    return Objects.hash(text);\n                }\n            }\n        }\n    }","methodCount":51},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":563,"lineEnd":567,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareCommonFields to class Entry","description":"move method declareCommonFields to PsiClass:Entry\nRationale: The declareCommonFields() method is primarily concerned with parsing and initializing fields that belong to the Entry class. Moving it here adheres to the Single Responsibility Principle, as Entry would manage its own field declarations, improving cohesion. This encapsulation of field management aligns with the Open/Closed Principle, allowing Entry to be easily extended. However, care must be taken to ensure that the static nature of the method does not conflict with instance-specific behavior.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":563,"lineEnd":567,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareCommonFields to class Option","description":"move method declareCommonFields to PsiClass:Option\nRationale: The Option class may also benefit from the declareCommonFields() method as it deals with parsing fields related to options. This would enhance cohesion within the Option class, making it responsible for its own field definitions. This aligns with the Single Responsibility Principle. However, if Option does not directly relate to the fields being declared, it might introduce unnecessary dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":563,"lineEnd":567,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareCommonFields to class CompletionSuggester","description":"move method declareCommonFields to PsiClass:CompletionSuggester\nRationale: The CompletionSuggester class is closely related to the parsing of suggestions, which may include fields declared in the method. Moving declareCommonFields() here would enhance its role in managing the suggestion lifecycle, adhering to the Single Responsibility Principle. However, this could lead to a bloated class if not managed correctly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":364,"lineEnd":370,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class Suggest","description":"move method fromXContent to PsiClass:Suggest\nRationale: The fromXContent() method is responsible for parsing suggestions from an XContentParser, which directly relates to the Suggest class that manages a list of suggestions. Moving this method here enhances cohesion, as the Suggest class is the primary entity that utilizes suggestions. This aligns with the Single Responsibility Principle by keeping parsing logic related to suggestions within the Suggest class. A potential drawback is that it may increase the complexity of the Suggest class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":364,"lineEnd":370,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class CompletionSuggestion","description":"move method fromXContent to PsiClass:CompletionSuggestion\nRationale: The fromXContent() method is closely tied to the concept of suggestions, which is a core functionality of the CompletionSuggestion class. This move would allow for better encapsulation of the suggestion parsing logic within a class that represents a specific type of suggestion. This adheres to the Open/Closed Principle by allowing the CompletionSuggestion class to expand its functionality without modifying existing code. However, it may lead to tighter coupling between the parser and the CompletionSuggestion class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":364,"lineEnd":370,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class PhraseSuggestion","description":"move method fromXContent to PsiClass:PhraseSuggestion\nRationale: Similar to CompletionSuggestion, PhraseSuggestion is another type of suggestion that would benefit from having its parsing logic encapsulated within it. This fosters a clearer separation of concerns by having each suggestion type manage its own parsing. This aligns with the Interface Segregation Principle by ensuring that classes only implement methods relevant to their specific functionality. A consideration is the potential for duplicated parsing logic if multiple suggestion types require similar parsing mechanisms.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"addTerm","method_signature":"public addTerm(T entry)","target_class":"","rationale":""},{"method_name":"reduce","method_signature":"@SuppressWarnings(\"unchecked\")\n        public reduce(List\u003cSuggestion\u003cT\u003e\u003e toReduce)","target_class":"","rationale":""},{"method_name":"trim","method_signature":"public trim()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"@SuppressWarnings(\"unchecked\")\n        public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseEntries","method_signature":"protected static parseEntries(\n            XContentParser parser,\n            Suggestion\u003cE\u003e suggestion,\n            CheckedFunction\u003cXContentParser, E, IOException\u003e entryParser\n        )","target_class":"","rationale":""},{"method_name":"addOption","method_signature":"public addOption(O option)","target_class":"","rationale":""},{"method_name":"addOptions","method_signature":"protected addOptions(List\u003cO\u003e options)","target_class":"","rationale":""},{"method_name":"sort","method_signature":"protected sort(Comparator\u003cO\u003e comparator)","target_class":"","rationale":""},{"method_name":"reduce","method_signature":"protected reduce(List\u003cT\u003e toReduce)","target_class":"","rationale":""},{"method_name":"trim","method_signature":" trim(int size)","target_class":"","rationale":""},{"method_name":"declareCommonFields","method_signature":"protected static declareCommonFields(ObjectParser\u003c? extends Entry\u003c? extends Option\u003e, Void\u003e parser)","target_class":"","rationale":""},{"method_name":"collateMatch","method_signature":"public collateMatch()","target_class":"","rationale":""},{"method_name":"mergeInto","method_signature":"protected mergeInto(Option otherOption)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"declareCommonFields","method_signature":"protected static declareCommonFields(ObjectParser\u003c? extends Entry\u003c? extends Option\u003e, Void\u003e parser)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"@SuppressWarnings(\"unchecked\")\n        public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"collateMatch","method_signature":"public collateMatch()","target_class":"","rationale":""},{"method_name":"sort","method_signature":"protected sort(Comparator\u003cO\u003e comparator)","target_class":"","rationale":""},{"method_name":"parseEntries","method_signature":"protected static parseEntries(\n            XContentParser parser,\n            Suggestion\u003cE\u003e suggestion,\n            CheckedFunction\u003cXContentParser, E, IOException\u003e entryParser\n        )","target_class":"","rationale":""},{"method_name":"trim","method_signature":" trim(int size)","target_class":"","rationale":""},{"method_name":"addOption","method_signature":"public addOption(O option)","target_class":"","rationale":""},{"method_name":"addTerm","method_signature":"public addTerm(T entry)","target_class":"","rationale":""},{"method_name":"trim","method_signature":"public trim()","target_class":"","rationale":""},{"method_name":"addOptions","method_signature":"protected addOptions(List\u003cO\u003e options)","target_class":"","rationale":""},{"method_name":"mergeInto","method_signature":"protected mergeInto(Option otherOption)","target_class":"","rationale":""},{"method_name":"reduce","method_signature":"protected reduce(List\u003cT\u003e toReduce)","target_class":"","rationale":""},{"method_name":"reduce","method_signature":"@SuppressWarnings(\"unchecked\")\n        public reduce(List\u003cSuggestion\u003cT\u003e\u003e toReduce)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"protected static declareCommonFields(ObjectParser\u003c? extends Entry\u003c? extends Option\u003e, Void\u003e parser)":{"first":{"method_name":"declareCommonFields","method_signature":"protected static declareCommonFields(ObjectParser\u003c? extends Entry\u003c? extends Option\u003e, Void\u003e parser)","target_class":"","rationale":""},"second":0.30906030221642455},"@SuppressWarnings(\"unchecked\")\n        public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"@SuppressWarnings(\"unchecked\")\n        public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.4139461904926266},"public collateMatch()":{"first":{"method_name":"collateMatch","method_signature":"public collateMatch()","target_class":"","rationale":""},"second":0.4287698169681643},"protected sort(Comparator\u003cO\u003e comparator)":{"first":{"method_name":"sort","method_signature":"protected sort(Comparator\u003cO\u003e comparator)","target_class":"","rationale":""},"second":0.4826475890223264},"protected static parseEntries(\n            XContentParser parser,\n            Suggestion\u003cE\u003e suggestion,\n            CheckedFunction\u003cXContentParser, E, IOException\u003e entryParser\n        )":{"first":{"method_name":"parseEntries","method_signature":"protected static parseEntries(\n            XContentParser parser,\n            Suggestion\u003cE\u003e suggestion,\n            CheckedFunction\u003cXContentParser, E, IOException\u003e entryParser\n        )","target_class":"","rationale":""},"second":0.49704406397194517}," trim(int size)":{"first":{"method_name":"trim","method_signature":" trim(int size)","target_class":"","rationale":""},"second":0.5057022086395527},"public addOption(O option)":{"first":{"method_name":"addOption","method_signature":"public addOption(O option)","target_class":"","rationale":""},"second":0.557838539439715},"public addTerm(T entry)":{"first":{"method_name":"addTerm","method_signature":"public addTerm(T entry)","target_class":"","rationale":""},"second":0.5578583839298387},"public trim()":{"first":{"method_name":"trim","method_signature":"public trim()","target_class":"","rationale":""},"second":0.574478783842977},"protected addOptions(List\u003cO\u003e options)":{"first":{"method_name":"addOptions","method_signature":"protected addOptions(List\u003cO\u003e options)","target_class":"","rationale":""},"second":0.5758961405280145},"protected mergeInto(Option otherOption)":{"first":{"method_name":"mergeInto","method_signature":"protected mergeInto(Option otherOption)","target_class":"","rationale":""},"second":0.6349783300142561},"protected reduce(List\u003cT\u003e toReduce)":{"first":{"method_name":"reduce","method_signature":"protected reduce(List\u003cT\u003e toReduce)","target_class":"","rationale":""},"second":0.6423683949763994},"@SuppressWarnings(\"unchecked\")\n        public reduce(List\u003cSuggestion\u003cT\u003e\u003e toReduce)":{"first":{"method_name":"reduce","method_signature":"@SuppressWarnings(\"unchecked\")\n        public reduce(List\u003cSuggestion\u003cT\u003e\u003e toReduce)","target_class":"","rationale":""},"second":0.6560110362433186}},"llmMethodPriority":{"priority_method_names":["declareCommonFields","collateMatch","sort","addOption","addTerm","trim","addOptions","mergeInto","reduce","fromXContent","parseEntries","trim","reduce"],"llm_response_time":2504},"targetClassMap":{"declareCommonFields":{"target_classes":[{"class_name":"Suggestion","similarity_score":0.36405643116708747},{"class_name":"NestedUtils","similarity_score":0.18027261705244255},{"class_name":"SearchUtils","similarity_score":0.16416012957049322},{"class_name":"GeoTileUtils","similarity_score":0.1885032365491385},{"class_name":"HighlightUtils","similarity_score":0.3310723631004401},{"class_name":"BucketUtils","similarity_score":0.10250154439874348},{"class_name":"MultiCandidateGeneratorWrapper","similarity_score":0.2718273530940363},{"class_name":"LinearInterpolation","similarity_score":0.3694755588510109},{"class_name":"LinearInterpolationModelTests","similarity_score":0.38210925255900546},{"class_name":"Laplace","similarity_score":0.32132243479058165},{"class_name":"LaplaceModelTests","similarity_score":0.28963717857079385},{"class_name":"Option","similarity_score":0.4160782217557512},{"class_name":"FuzzyOptions","similarity_score":0.2916642711290904},{"class_name":"FuzzyOptionsTests","similarity_score":0.3317002332268085},{"class_name":"DirectCandidateGenerator","similarity_score":0.3643093775636387},{"class_name":"DirectCandidateGeneratorBuilder","similarity_score":0.3197319691465086},{"class_name":"DirectCandidateGeneratorTests","similarity_score":0.4611869636296417},{"class_name":"GeoContextMapping","similarity_score":0.30669807416992184},{"class_name":"RegexOptions","similarity_score":0.3199886719953659},{"class_name":"RegexOptionsTests","similarity_score":0.3515104232838975},{"class_name":"GeoQueryContext","similarity_score":0.35973823167633845},{"class_name":"GeoQueryContextTests","similarity_score":0.3134825331559627},{"class_name":"PhraseSuggester","similarity_score":0.46117945008430117},{"class_name":"PhraseSuggestion","similarity_score":0.3801268046196036},{"class_name":"PhraseSuggestionBuilder","similarity_score":0.35387671520036074},{"class_name":"PhraseSuggestionBuilderTests","similarity_score":0.4272976170511724},{"class_name":"Entry","similarity_score":0.43173544425934585},{"class_name":"CompletionSuggester","similarity_score":0.41379778390907324},{"class_name":"CompletionSuggesterBuilderTests","similarity_score":0.4978592237509267},{"class_name":"CompletionSuggestion","similarity_score":0.3735514912950321}],"target_classes_sorted_by_llm":["Entry","Option","CompletionSuggester","PhraseSuggestion","CompletionSuggestion","PhraseSuggester","CompletionSuggesterBuilderTests","PhraseSuggestionBuilderTests","DirectCandidateGeneratorTests","LinearInterpolationModelTests"],"llm_response_time":10884,"similarity_computation_time":21,"similarity_metric":"voyage"},"fromXContent":{"target_classes":[{"class_name":"Suggest","similarity_score":0.4938663859076096},{"class_name":"BucketUtils","similarity_score":0.1293241612227127},{"class_name":"SearchUtils","similarity_score":0.22062524037095513},{"class_name":"HighlightUtils","similarity_score":0.38138503569823695},{"class_name":"GeoTileUtils","similarity_score":0.22244370356459653},{"class_name":"NestedUtils","similarity_score":0.1839386426473681},{"class_name":"CompletionSuggester","similarity_score":0.3675566310561692},{"class_name":"CompletionSuggesterBuilderTests","similarity_score":0.3466082800095333},{"class_name":"CompletionSuggestion","similarity_score":0.4304853013726322},{"class_name":"CompletionSuggestionBuilder","similarity_score":0.3858246043621551},{"class_name":"CompletionSuggestionOptionTests","similarity_score":0.3495391241135004},{"class_name":"CompletionSuggestSearchIT","similarity_score":0.32127025728283376},{"class_name":"DirectCandidateGenerator","similarity_score":0.3893313815345854},{"class_name":"DirectCandidateGeneratorBuilder","similarity_score":0.3216709844269797},{"class_name":"DirectCandidateGeneratorTests","similarity_score":0.328185195754385},{"class_name":"Option","similarity_score":0.4228825290903887},{"class_name":"Laplace","similarity_score":0.3998335364512792},{"class_name":"LaplaceModelTests","similarity_score":0.3510989038028634},{"class_name":"ContextMappings","similarity_score":0.3031428468932145},{"class_name":"LinearInterpolation","similarity_score":0.3765138209682657},{"class_name":"LinearInterpolationModelTests","similarity_score":0.30221172030558874},{"class_name":"PhraseSuggester","similarity_score":0.35176138987533373},{"class_name":"PhraseSuggestion","similarity_score":0.46079065217591497},{"class_name":"PhraseSuggestionBuilder","similarity_score":0.3488930442686317},{"class_name":"PhraseSuggestionBuilderTests","similarity_score":0.2376623707902169},{"class_name":"Entry","similarity_score":0.44609423007694643},{"class_name":"CategoryContextMapping","similarity_score":0.29712175201878915},{"class_name":"CategoryContextMappingTests","similarity_score":0.2582187090569901},{"class_name":"CategoryQueryContext","similarity_score":0.36556372816668375},{"class_name":"CategoryQueryContextTests","similarity_score":0.323459942681583}],"target_classes_sorted_by_llm":["Suggest","CompletionSuggestion","PhraseSuggestion","CompletionSuggestionBuilder","Entry","Option","DirectCandidateGenerator","HighlightUtils","Laplace","LinearInterpolation"],"llm_response_time":13325,"similarity_computation_time":12,"similarity_metric":"voyage"},"collateMatch":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":410,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"095c5467-8f34-4287-aab7-b9fbdc9cd65c","methodCount":91,"hostFunctionTelemetryData":{"hostFunctionSize":1350,"lineStart":74,"lineEnd":1423,"bodyLineStart":74,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/search/SearchHit.java","sourceCode":"/**\n * A single search hit.\n *\n * @see SearchHits\n */\npublic final class SearchHit implements Writeable, ToXContentObject, RefCounted {\n\n    private final transient int docId;\n\n    private static final float DEFAULT_SCORE \u003d Float.NaN;\n    private float score;\n\n    private static final int NO_RANK \u003d -1;\n    private int rank;\n\n    private final Text id;\n\n    private final NestedIdentity nestedIdentity;\n\n    private long version;\n    private long seqNo;\n    private long primaryTerm;\n\n    private BytesReference source;\n\n    private final Map\u003cString, DocumentField\u003e documentFields;\n    private final Map\u003cString, DocumentField\u003e metaFields;\n\n    private Map\u003cString, HighlightField\u003e highlightFields;\n\n    private SearchSortValues sortValues;\n\n    private Map\u003cString, Float\u003e matchedQueries;\n\n    private Explanation explanation;\n\n    @Nullable\n    private SearchShardTarget shard;\n\n    // These two fields normally get set when setting the shard target, so they hold the same values as the target thus don\u0027t get\n    // serialized over the wire. When parsing hits back from xcontent though, in most of the cases (whenever explanation is disabled)\n    // we can\u0027t rebuild the shard target object so we need to set these manually for users retrieval.\n    private transient String index;\n    private transient String clusterAlias;\n\n    private Map\u003cString, Object\u003e sourceAsMap;\n\n    private Map\u003cString, SearchHits\u003e innerHits;\n\n    private final RefCounted refCounted;\n\n    // used only in tests\n    public SearchHit(int docId) {\n        this(docId, null);\n    }\n\n    public SearchHit(int docId, String id) {\n        this(docId, id, null);\n    }\n\n    public SearchHit(int nestedTopDocId, String id, NestedIdentity nestedIdentity) {\n        this(nestedTopDocId, id, nestedIdentity, null);\n    }\n\n    private SearchHit(int nestedTopDocId, String id, NestedIdentity nestedIdentity, @Nullable RefCounted refCounted) {\n        this(\n            nestedTopDocId,\n            DEFAULT_SCORE,\n            NO_RANK,\n            id \u003d\u003d null ? null : new Text(id),\n            nestedIdentity,\n            -1,\n            SequenceNumbers.UNASSIGNED_SEQ_NO,\n            SequenceNumbers.UNASSIGNED_PRIMARY_TERM,\n            null,\n            null,\n            SearchSortValues.EMPTY,\n            Collections.emptyMap(),\n            null,\n            null,\n            null,\n            null,\n            null,\n            null,\n            new HashMap\u003c\u003e(),\n            new HashMap\u003c\u003e(),\n            refCounted\n        );\n    }\n\n    public SearchHit(\n        int docId,\n        float score,\n        int rank,\n        Text id,\n        NestedIdentity nestedIdentity,\n        long version,\n        long seqNo,\n        long primaryTerm,\n        BytesReference source,\n        Map\u003cString, HighlightField\u003e highlightFields,\n        SearchSortValues sortValues,\n        Map\u003cString, Float\u003e matchedQueries,\n        Explanation explanation,\n        SearchShardTarget shard,\n        String index,\n        String clusterAlias,\n        Map\u003cString, Object\u003e sourceAsMap,\n        Map\u003cString, SearchHits\u003e innerHits,\n        Map\u003cString, DocumentField\u003e documentFields,\n        Map\u003cString, DocumentField\u003e metaFields,\n        @Nullable RefCounted refCounted\n    ) {\n        this.docId \u003d docId;\n        this.score \u003d score;\n        this.rank \u003d rank;\n        this.id \u003d id;\n        this.nestedIdentity \u003d nestedIdentity;\n        this.version \u003d version;\n        this.seqNo \u003d seqNo;\n        this.primaryTerm \u003d primaryTerm;\n        this.source \u003d source;\n        this.highlightFields \u003d highlightFields;\n        this.sortValues \u003d sortValues;\n        this.matchedQueries \u003d matchedQueries;\n        this.explanation \u003d explanation;\n        this.shard \u003d shard;\n        this.index \u003d index;\n        this.clusterAlias \u003d clusterAlias;\n        this.sourceAsMap \u003d sourceAsMap;\n        this.innerHits \u003d innerHits;\n        this.documentFields \u003d documentFields;\n        this.metaFields \u003d metaFields;\n        this.refCounted \u003d refCounted \u003d\u003d null ? LeakTracker.wrap(new SimpleRefCounted()) : refCounted;\n    }\n\n    public static SearchHit readFrom(StreamInput in, boolean pooled) throws IOException {\n        final float score \u003d in.readFloat();\n        final int rank;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_8_0)) {\n            rank \u003d in.readVInt();\n        } else {\n            rank \u003d NO_RANK;\n        }\n        final Text id \u003d in.readOptionalText();\n        if (in.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            in.readOptionalText();\n        }\n        final NestedIdentity nestedIdentity \u003d in.readOptionalWriteable(NestedIdentity::new);\n        final long version \u003d in.readLong();\n        final long seqNo \u003d in.readZLong();\n        final long primaryTerm \u003d in.readVLong();\n        BytesReference source \u003d pooled ? in.readReleasableBytesReference() : in.readBytesReference();\n        if (source.length() \u003d\u003d 0) {\n            source \u003d null;\n        }\n        Explanation explanation \u003d null;\n        if (in.readBoolean()) {\n            explanation \u003d readExplanation(in);\n        }\n        final Map\u003cString, DocumentField\u003e documentFields \u003d in.readMap(DocumentField::new);\n        final Map\u003cString, DocumentField\u003e metaFields \u003d in.readMap(DocumentField::new);\n        Map\u003cString, HighlightField\u003e highlightFields \u003d in.readMapValues(HighlightField::new, HighlightField::name);\n        highlightFields \u003d highlightFields.isEmpty() ? null : unmodifiableMap(highlightFields);\n\n        final SearchSortValues sortValues \u003d SearchSortValues.readFrom(in);\n\n        final Map\u003cString, Float\u003e matchedQueries;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_8_0)) {\n            matchedQueries \u003d in.readOrderedMap(StreamInput::readString, StreamInput::readFloat);\n        } else {\n            int size \u003d in.readVInt();\n            matchedQueries \u003d Maps.newLinkedHashMapWithExpectedSize(size);\n            for (int i \u003d 0; i \u003c size; i++) {\n                matchedQueries.put(in.readString(), Float.NaN);\n            }\n        }\n\n        final SearchShardTarget shardTarget \u003d in.readOptionalWriteable(SearchShardTarget::new);\n        final String index;\n        final String clusterAlias;\n        if (shardTarget \u003d\u003d null) {\n            index \u003d null;\n            clusterAlias \u003d null;\n        } else {\n            index \u003d shardTarget.getIndex();\n            clusterAlias \u003d shardTarget.getClusterAlias();\n        }\n\n        boolean isPooled \u003d pooled \u0026\u0026 source !\u003d null;\n        final Map\u003cString, SearchHits\u003e innerHits;\n        int size \u003d in.readVInt();\n        if (size \u003e 0) {\n            innerHits \u003d Maps.newMapWithExpectedSize(size);\n            for (int i \u003d 0; i \u003c size; i++) {\n                var key \u003d in.readString();\n                var nestedHits \u003d SearchHits.readFrom(in, pooled);\n                innerHits.put(key, nestedHits);\n                isPooled \u003d isPooled || nestedHits.isPooled();\n            }\n        } else {\n            innerHits \u003d null;\n        }\n        return new SearchHit(\n            -1,\n            score,\n            rank,\n            id,\n            nestedIdentity,\n            version,\n            seqNo,\n            primaryTerm,\n            source,\n            highlightFields,\n            sortValues,\n            matchedQueries,\n            explanation,\n            shardTarget,\n            index,\n            clusterAlias,\n            null,\n            innerHits,\n            documentFields,\n            metaFields,\n            isPooled ? null : ALWAYS_REFERENCED\n        );\n    }\n\n    public static SearchHit unpooled(int docId) {\n        return unpooled(docId, null);\n    }\n\n    public static SearchHit unpooled(int docId, String id) {\n        return unpooled(docId, id, null);\n    }\n\n    public static SearchHit unpooled(int nestedTopDocId, String id, NestedIdentity nestedIdentity) {\n        return new SearchHit(nestedTopDocId, id, nestedIdentity, ALWAYS_REFERENCED);\n    }\n\n    private static final Text SINGLE_MAPPING_TYPE \u003d new Text(MapperService.SINGLE_MAPPING_NAME);\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        assert hasReferences();\n        out.writeFloat(score);\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_8_0)) {\n            out.writeVInt(rank);\n        } else if (rank !\u003d NO_RANK) {\n            throw new IllegalArgumentException(\"cannot serialize [rank] to version [\" + out.getTransportVersion() + \"]\");\n        }\n        out.writeOptionalText(id);\n        if (out.getTransportVersion().before(TransportVersions.V_8_0_0)) {\n            out.writeOptionalText(SINGLE_MAPPING_TYPE);\n        }\n        out.writeOptionalWriteable(nestedIdentity);\n        out.writeLong(version);\n        out.writeZLong(seqNo);\n        out.writeVLong(primaryTerm);\n        out.writeBytesReference(source);\n        if (explanation \u003d\u003d null) {\n            out.writeBoolean(false);\n        } else {\n            out.writeBoolean(true);\n            writeExplanation(out, explanation);\n        }\n        out.writeMap(documentFields, StreamOutput::writeWriteable);\n        out.writeMap(metaFields, StreamOutput::writeWriteable);\n        if (highlightFields \u003d\u003d null) {\n            out.writeVInt(0);\n        } else {\n            out.writeCollection(highlightFields.values());\n        }\n        sortValues.writeTo(out);\n\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_8_0)) {\n            out.writeMap(matchedQueries, StreamOutput::writeFloat);\n        } else {\n            out.writeStringCollection(matchedQueries.keySet());\n        }\n        out.writeOptionalWriteable(shard);\n        if (innerHits \u003d\u003d null) {\n            out.writeVInt(0);\n        } else {\n            out.writeMap(innerHits, StreamOutput::writeWriteable);\n        }\n    }\n\n    public int docId() {\n        return this.docId;\n    }\n\n    public void score(float score) {\n        this.score \u003d score;\n    }\n\n    /**\n     * The score.\n     */\n    public float getScore() {\n        return this.score;\n    }\n\n    public void setRank(int rank) {\n        this.rank \u003d rank;\n    }\n\n    public int getRank() {\n        return this.rank;\n    }\n\n    public void version(long version) {\n        this.version \u003d version;\n    }\n\n    /**\n     * The version of the hit.\n     */\n    public long getVersion() {\n        return this.version;\n    }\n\n    public void setSeqNo(long seqNo) {\n        this.seqNo \u003d seqNo;\n    }\n\n    public void setPrimaryTerm(long primaryTerm) {\n        this.primaryTerm \u003d primaryTerm;\n    }\n\n    /**\n     * returns the sequence number of the last modification to the document, or {@link SequenceNumbers#UNASSIGNED_SEQ_NO}\n     * if not requested.\n     **/\n    public long getSeqNo() {\n        return this.seqNo;\n    }\n\n    /**\n     * returns the primary term of the last modification to the document, or {@link SequenceNumbers#UNASSIGNED_PRIMARY_TERM}\n     * if not requested. */\n    public long getPrimaryTerm() {\n        return this.primaryTerm;\n    }\n\n    /**\n     * The index of the hit.\n     */\n    public String getIndex() {\n        return this.index;\n    }\n\n    /**\n     * The id of the document.\n     */\n    public String getId() {\n        return id !\u003d null ? id.string() : null;\n    }\n\n    /**\n     * If this is a nested hit then nested reference information is returned otherwise \u003ccode\u003enull\u003c/code\u003e is returned.\n     */\n    public NestedIdentity getNestedIdentity() {\n        return nestedIdentity;\n    }\n\n    /**\n     * Returns bytes reference, also uncompress the source if needed.\n     */\n    public BytesReference getSourceRef() {\n        assert hasReferences();\n        if (this.source \u003d\u003d null) {\n            return null;\n        }\n\n        try {\n            this.source \u003d CompressorFactory.uncompressIfNeeded(this.source);\n            return this.source;\n        } catch (IOException e) {\n            throw new ElasticsearchParseException(\"failed to decompress source\", e);\n        }\n    }\n\n    /**\n     * Sets representation, might be compressed....\n     */\n    public SearchHit sourceRef(BytesReference source) {\n        this.source \u003d source;\n        this.sourceAsMap \u003d null;\n        return this;\n    }\n\n    /**\n     * Is the source available or not. A source with no fields will return true. This will return false if {@code fields} doesn\u0027t contain\n     * {@code _source} or if source is disabled in the mapping.\n     */\n    public boolean hasSource() {\n        assert hasReferences();\n        return source !\u003d null;\n    }\n\n    /**\n     * The source of the document as string (can be {@code null}).\n     */\n    public String getSourceAsString() {\n        assert hasReferences();\n        if (source \u003d\u003d null) {\n            return null;\n        }\n        try {\n            return XContentHelper.convertToJson(getSourceRef(), false);\n        } catch (IOException e) {\n            throw new ElasticsearchParseException(\"failed to convert source to a json string\");\n        }\n    }\n\n    /**\n     * The source of the document as a map (can be {@code null}).\n     */\n    public Map\u003cString, Object\u003e getSourceAsMap() {\n        assert hasReferences();\n        if (source \u003d\u003d null) {\n            return null;\n        }\n        if (sourceAsMap !\u003d null) {\n            return sourceAsMap;\n        }\n\n        sourceAsMap \u003d Source.fromBytes(source).source();\n        return sourceAsMap;\n    }\n\n    /**\n     * The hit field matching the given field name.\n     */\n    public DocumentField field(String fieldName) {\n        assert hasReferences();\n        DocumentField result \u003d documentFields.get(fieldName);\n        if (result !\u003d null) {\n            return result;\n        } else {\n            return metaFields.get(fieldName);\n        }\n    }\n\n    /*\n    * Adds a new DocumentField to the map in case both parameters are not null.\n    * */\n    public void setDocumentField(String fieldName, DocumentField field) {\n        if (fieldName \u003d\u003d null || field \u003d\u003d null) return;\n        this.documentFields.put(fieldName, field);\n    }\n\n    public void addDocumentFields(Map\u003cString, DocumentField\u003e docFields, Map\u003cString, DocumentField\u003e metaFields) {\n        this.documentFields.putAll(docFields);\n        this.metaFields.putAll(metaFields);\n    }\n\n    /**\n     * @return a map of metadata fields for this hit\n     */\n    public Map\u003cString, DocumentField\u003e getMetadataFields() {\n        return Collections.unmodifiableMap(metaFields);\n    }\n\n    /**\n     * @return a map of non-metadata fields requested for this hit\n     */\n    public Map\u003cString, DocumentField\u003e getDocumentFields() {\n        return Collections.unmodifiableMap(documentFields);\n    }\n\n    /**\n     * A map of hit fields (from field name to hit fields) if additional fields\n     * were required to be loaded. Includes both document and metadata fields.\n     */\n    public Map\u003cString, DocumentField\u003e getFields() {\n        if (metaFields.size() \u003e 0 || documentFields.size() \u003e 0) {\n            final Map\u003cString, DocumentField\u003e fields \u003d new HashMap\u003c\u003e();\n            fields.putAll(metaFields);\n            fields.putAll(documentFields);\n            return fields;\n        } else {\n            return emptyMap();\n        }\n    }\n\n    /**\n     * Whether this search hit has any lookup fields\n     */\n    public boolean hasLookupFields() {\n        return getDocumentFields().values().stream().anyMatch(doc -\u003e doc.getLookupFields().isEmpty() \u003d\u003d false);\n    }\n\n    /**\n     * Resolve the lookup fields with the given results and merge them as regular fetch fields.\n     */\n    public void resolveLookupFields(Map\u003cLookupField, List\u003cObject\u003e\u003e lookupResults) {\n        if (lookupResults.isEmpty()) {\n            return;\n        }\n        for (Iterator\u003cMap.Entry\u003cString, DocumentField\u003e\u003e iterator \u003d documentFields.entrySet().iterator(); iterator.hasNext();) {\n            Map.Entry\u003cString, DocumentField\u003e entry \u003d iterator.next();\n            final DocumentField docField \u003d entry.getValue();\n            if (docField.getLookupFields().isEmpty()) {\n                continue;\n            }\n            final List\u003cObject\u003e newValues \u003d new ArrayList\u003c\u003e(docField.getValues());\n            for (LookupField lookupField : docField.getLookupFields()) {\n                final List\u003cObject\u003e resolvedValues \u003d lookupResults.get(lookupField);\n                if (resolvedValues !\u003d null) {\n                    newValues.addAll(resolvedValues);\n                }\n            }\n            if (newValues.isEmpty() \u0026\u0026 docField.getIgnoredValues().isEmpty()) {\n                iterator.remove();\n            } else {\n                entry.setValue(new DocumentField(docField.getName(), newValues, docField.getIgnoredValues()));\n            }\n        }\n        assert hasLookupFields() \u003d\u003d false : \"Some lookup fields are not resolved\";\n    }\n\n    /**\n     * A map of highlighted fields.\n     */\n    public Map\u003cString, HighlightField\u003e getHighlightFields() {\n        return highlightFields \u003d\u003d null ? emptyMap() : highlightFields;\n    }\n\n    public void highlightFields(Map\u003cString, HighlightField\u003e highlightFields) {\n        this.highlightFields \u003d highlightFields;\n    }\n\n    public void sortValues(Object[] sortValues, DocValueFormat[] sortValueFormats) {\n        sortValues(new SearchSortValues(sortValues, sortValueFormats));\n    }\n\n    public void sortValues(SearchSortValues sortValues) {\n        this.sortValues \u003d sortValues;\n    }\n\n    /**\n     * An array of the (formatted) sort values used.\n     */\n    public Object[] getSortValues() {\n        return sortValues.getFormattedSortValues();\n    }\n\n    /**\n     * An array of the (raw) sort values used.\n     */\n    public Object[] getRawSortValues() {\n        return sortValues.getRawSortValues();\n    }\n\n    /**\n     * If enabled, the explanation of the search hit.\n     */\n    public Explanation getExplanation() {\n        return explanation;\n    }\n\n    public void explanation(Explanation explanation) {\n        this.explanation \u003d explanation;\n    }\n\n    /**\n     * The shard of the search hit.\n     */\n    public SearchShardTarget getShard() {\n        return shard;\n    }\n\n    public void shard(SearchShardTarget target) {\n        if (innerHits !\u003d null) {\n            for (SearchHits innerHits : innerHits.values()) {\n                for (SearchHit innerHit : innerHits) {\n                    innerHit.shard(target);\n                }\n            }\n        }\n\n        this.shard \u003d target;\n        if (target !\u003d null) {\n            this.index \u003d target.getIndex();\n            this.clusterAlias \u003d target.getClusterAlias();\n        }\n    }\n\n    /**\n     * Returns the cluster alias this hit comes from or null if it comes from a local cluster\n     */\n    public String getClusterAlias() {\n        return clusterAlias;\n    }\n\n    public void matchedQueries(Map\u003cString, Float\u003e matchedQueries) {\n        this.matchedQueries \u003d matchedQueries;\n    }\n\n    /**\n     * The set of query and filter names the query matched with. Mainly makes sense for compound filters and queries.\n     */\n    public String[] getMatchedQueries() {\n        return matchedQueries \u003d\u003d null ? new String[0] : matchedQueries.keySet().toArray(new String[0]);\n    }\n\n    /**\n     * @return The score of the provided named query if it matches, {@code null} otherwise.\n     */\n    public Float getMatchedQueryScore(String name) {\n        return getMatchedQueriesAndScores().get(name);\n    }\n\n    /**\n     * @return The map of the named queries that matched and their associated score.\n     */\n    public Map\u003cString, Float\u003e getMatchedQueriesAndScores() {\n        return matchedQueries \u003d\u003d null ? Collections.emptyMap() : matchedQueries;\n    }\n\n    /**\n     * @return Inner hits or \u003ccode\u003enull\u003c/code\u003e if there are none\n     */\n    public Map\u003cString, SearchHits\u003e getInnerHits() {\n        assert hasReferences();\n        return innerHits;\n    }\n\n    public void setInnerHits(Map\u003cString, SearchHits\u003e innerHits) {\n        assert innerHits \u003d\u003d null || innerHits.values().stream().noneMatch(h -\u003e h.hasReferences() \u003d\u003d false);\n        assert this.innerHits \u003d\u003d null;\n        this.innerHits \u003d innerHits;\n    }\n\n    @Override\n    public void incRef() {\n        refCounted.incRef();\n    }\n\n    @Override\n    public boolean tryIncRef() {\n        return refCounted.tryIncRef();\n    }\n\n    @Override\n    public boolean decRef() {\n        if (refCounted.decRef()) {\n            deallocate();\n            return true;\n        }\n        return false;\n    }\n\n    private void deallocate() {\n        if (SearchHit.this.innerHits !\u003d null) {\n            for (SearchHits h : SearchHit.this.innerHits.values()) {\n                h.decRef();\n            }\n            SearchHit.this.innerHits \u003d null;\n        }\n        if (SearchHit.this.source instanceof RefCounted r) {\n            r.decRef();\n        }\n        SearchHit.this.source \u003d null;\n    }\n\n    @Override\n    public boolean hasReferences() {\n        return refCounted.hasReferences();\n    }\n\n    public SearchHit asUnpooled() {\n        assert hasReferences();\n        if (isPooled() \u003d\u003d false) {\n            return this;\n        }\n        return new SearchHit(\n            docId,\n            score,\n            rank,\n            id,\n            nestedIdentity,\n            version,\n            seqNo,\n            primaryTerm,\n            source instanceof RefCounted ? new BytesArray(source.toBytesRef(), true) : source,\n            highlightFields,\n            sortValues,\n            matchedQueries,\n            explanation,\n            shard,\n            index,\n            clusterAlias,\n            sourceAsMap,\n            innerHits \u003d\u003d null\n                ? null\n                : innerHits.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -\u003e e.getValue().asUnpooled())),\n            documentFields,\n            metaFields,\n            ALWAYS_REFERENCED\n        );\n    }\n\n    public boolean isPooled() {\n        return refCounted !\u003d ALWAYS_REFERENCED;\n    }\n\n    public static class Fields {\n        static final String _INDEX \u003d \"_index\";\n        static final String _ID \u003d \"_id\";\n        static final String _VERSION \u003d \"_version\";\n        static final String _SEQ_NO \u003d \"_seq_no\";\n        static final String _PRIMARY_TERM \u003d \"_primary_term\";\n        static final String _SCORE \u003d \"_score\";\n        static final String _RANK \u003d \"_rank\";\n        static final String FIELDS \u003d \"fields\";\n        static final String IGNORED_FIELD_VALUES \u003d \"ignored_field_values\";\n        static final String HIGHLIGHT \u003d \"highlight\";\n        static final String SORT \u003d \"sort\";\n        static final String MATCHED_QUERIES \u003d \"matched_queries\";\n        static final String _EXPLANATION \u003d \"_explanation\";\n        static final String VALUE \u003d \"value\";\n        static final String DESCRIPTION \u003d \"description\";\n        static final String DETAILS \u003d \"details\";\n        static final String INNER_HITS \u003d \"inner_hits\";\n        static final String _SHARD \u003d \"_shard\";\n        static final String _NODE \u003d \"_node\";\n    }\n\n    // Following are the keys for storing the metadata fields and regular fields in the aggregation map.\n    // These do not influence the structure of json serialization: document fields are still stored\n    // under FIELDS and metadata are still scattered at the root level.\n    static final String DOCUMENT_FIELDS \u003d \"document_fields\";\n    static final String METADATA_FIELDS \u003d \"metadata_fields\";\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        assert hasReferences();\n        builder.startObject();\n        toInnerXContent(builder, params);\n        builder.endObject();\n        return builder;\n    }\n\n    // public because we render hit as part of completion suggestion option\n    public XContentBuilder toInnerXContent(XContentBuilder builder, Params params) throws IOException {\n        // For inner_hit hits shard is null and that is ok, because the parent search hit has all this information.\n        // Even if this was included in the inner_hit hits this would be the same, so better leave it out.\n        if (getExplanation() !\u003d null \u0026\u0026 shard !\u003d null) {\n            builder.field(Fields._SHARD, shard.getShardId());\n            builder.field(Fields._NODE, shard.getNodeIdText());\n        }\n        if (index !\u003d null) {\n            builder.field(Fields._INDEX, RemoteClusterAware.buildRemoteIndexName(clusterAlias, index));\n        }\n        if (builder.getRestApiVersion() \u003d\u003d RestApiVersion.V_7 \u0026\u0026 metaFields.containsKey(MapperService.TYPE_FIELD_NAME) \u003d\u003d false) {\n            builder.field(MapperService.TYPE_FIELD_NAME, MapperService.SINGLE_MAPPING_NAME);\n        }\n        if (id !\u003d null) {\n            builder.field(Fields._ID, id);\n        }\n        if (nestedIdentity !\u003d null) {\n            nestedIdentity.toXContent(builder, params);\n        }\n        if (version !\u003d -1) {\n            builder.field(Fields._VERSION, version);\n        }\n\n        if (seqNo !\u003d SequenceNumbers.UNASSIGNED_SEQ_NO) {\n            builder.field(Fields._SEQ_NO, seqNo);\n            builder.field(Fields._PRIMARY_TERM, primaryTerm);\n        }\n\n        if (Float.isNaN(score)) {\n            builder.nullField(Fields._SCORE);\n        } else {\n            builder.field(Fields._SCORE, score);\n        }\n\n        if (rank !\u003d NO_RANK) {\n            builder.field(Fields._RANK, rank);\n        }\n\n        for (DocumentField field : metaFields.values()) {\n            // ignore empty metadata fields\n            if (field.getValues().size() \u003d\u003d 0) {\n                continue;\n            }\n            // _ignored is the only multi-valued meta field\n            // TODO: can we avoid having an exception here?\n            if (field.getName().equals(IgnoredFieldMapper.NAME)) {\n                builder.field(field.getName(), field.getValues());\n            } else {\n                builder.field(field.getName(), field.\u003cObject\u003egetValue());\n            }\n        }\n        if (source !\u003d null) {\n            XContentHelper.writeRawField(SourceFieldMapper.NAME, source, builder, params);\n        }\n        if (documentFields.isEmpty() \u003d\u003d false \u0026\u0026\n        // ignore fields all together if they are all empty\n            documentFields.values().stream().anyMatch(df -\u003e df.getValues().size() \u003e 0)) {\n            builder.startObject(Fields.FIELDS);\n            for (DocumentField field : documentFields.values()) {\n                if (field.getValues().size() \u003e 0) {\n                    field.getValidValuesWriter().toXContent(builder, params);\n                }\n            }\n            builder.endObject();\n        }\n        // ignored field values\n        if (documentFields.isEmpty() \u003d\u003d false \u0026\u0026\n        // omit ignored_field_values all together if there are none\n            documentFields.values().stream().anyMatch(df -\u003e df.getIgnoredValues().size() \u003e 0)) {\n            builder.startObject(Fields.IGNORED_FIELD_VALUES);\n            for (DocumentField field : documentFields.values()) {\n                if (field.getIgnoredValues().size() \u003e 0) {\n                    field.getIgnoredValuesWriter().toXContent(builder, params);\n                }\n            }\n            builder.endObject();\n        }\n        if (highlightFields !\u003d null \u0026\u0026 highlightFields.isEmpty() \u003d\u003d false) {\n            builder.startObject(Fields.HIGHLIGHT);\n            for (HighlightField field : highlightFields.values()) {\n                field.toXContent(builder, params);\n            }\n            builder.endObject();\n        }\n        sortValues.toXContent(builder, params);\n        if (matchedQueries !\u003d null \u0026\u0026 matchedQueries.size() \u003e 0) {\n            boolean includeMatchedQueriesScore \u003d params.paramAsBoolean(RestSearchAction.INCLUDE_NAMED_QUERIES_SCORE_PARAM, false);\n            if (includeMatchedQueriesScore) {\n                builder.startObject(Fields.MATCHED_QUERIES);\n                for (Map.Entry\u003cString, Float\u003e entry : matchedQueries.entrySet()) {\n                    builder.field(entry.getKey(), entry.getValue());\n                }\n                builder.endObject();\n            } else {\n                builder.startArray(Fields.MATCHED_QUERIES);\n                for (String matchedFilter : matchedQueries.keySet()) {\n                    builder.value(matchedFilter);\n                }\n                builder.endArray();\n            }\n        }\n        if (getExplanation() !\u003d null) {\n            builder.field(Fields._EXPLANATION);\n            buildExplanation(builder, getExplanation());\n        }\n        if (innerHits !\u003d null) {\n            builder.startObject(Fields.INNER_HITS);\n            for (Map.Entry\u003cString, SearchHits\u003e entry : innerHits.entrySet()) {\n                builder.startObject(entry.getKey());\n                ChunkedToXContent.wrapAsToXContent(entry.getValue()).toXContent(builder, params);\n                builder.endObject();\n            }\n            builder.endObject();\n        }\n        return builder;\n    }\n\n    // All fields on the root level of the parsed SearhHit are interpreted as metadata fields\n    // public because we use it in a completion suggestion option\n    @SuppressWarnings(\"unchecked\")\n    public static final ObjectParser.UnknownFieldConsumer\u003cMap\u003cString, Object\u003e\u003e unknownMetaFieldConsumer \u003d (map, fieldName, fieldValue) -\u003e {\n        Map\u003cString, DocumentField\u003e fieldMap \u003d (Map\u003cString, DocumentField\u003e) map.computeIfAbsent(\n            METADATA_FIELDS,\n            v -\u003e new HashMap\u003cString, DocumentField\u003e()\n        );\n        if (fieldName.equals(IgnoredFieldMapper.NAME)) {\n            fieldMap.put(fieldName, new DocumentField(fieldName, (List\u003cObject\u003e) fieldValue));\n        } else {\n            fieldMap.put(fieldName, new DocumentField(fieldName, Collections.singletonList(fieldValue)));\n        }\n    };\n\n    /**\n     * This parser outputs a temporary map of the objects needed to create the\n     * SearchHit instead of directly creating the SearchHit. The reason for this\n     * is that this way we can reuse the parser when parsing xContent from\n     * {@link org.elasticsearch.search.suggest.completion.CompletionSuggestion.Entry.Option} which unfortunately inlines\n     * the output of\n     * {@link #toInnerXContent(XContentBuilder, org.elasticsearch.xcontent.ToXContent.Params)}\n     * of the included search hit. The output of the map is used to create the\n     * actual SearchHit instance via {@link #createFromMap(Map)}\n     */\n    private static final ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e MAP_PARSER \u003d new ObjectParser\u003c\u003e(\n        \"innerHitParser\",\n        unknownMetaFieldConsumer,\n        HashMap::new\n    );\n\n    static {\n        declareInnerHitsParseFields(MAP_PARSER);\n    }\n\n    public static SearchHit fromXContent(XContentParser parser) {\n        return createFromMap(MAP_PARSER.apply(parser, null));\n    }\n\n    public static void declareInnerHitsParseFields(ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e parser) {\n        parser.declareString((map, value) -\u003e map.put(Fields._INDEX, value), new ParseField(Fields._INDEX));\n        parser.declareString((map, value) -\u003e map.put(Fields._ID, value), new ParseField(Fields._ID));\n        parser.declareString((map, value) -\u003e map.put(Fields._NODE, value), new ParseField(Fields._NODE));\n        parser.declareField(\n            (map, value) -\u003e map.put(Fields._SCORE, value),\n            SearchHit::parseScore,\n            new ParseField(Fields._SCORE),\n            ValueType.FLOAT_OR_NULL\n        );\n        parser.declareInt((map, value) -\u003e map.put(Fields._RANK, value), new ParseField(Fields._RANK));\n\n        parser.declareLong((map, value) -\u003e map.put(Fields._VERSION, value), new ParseField(Fields._VERSION));\n        parser.declareLong((map, value) -\u003e map.put(Fields._SEQ_NO, value), new ParseField(Fields._SEQ_NO));\n        parser.declareLong((map, value) -\u003e map.put(Fields._PRIMARY_TERM, value), new ParseField(Fields._PRIMARY_TERM));\n        parser.declareField(\n            (map, value) -\u003e map.put(Fields._SHARD, value),\n            (p, c) -\u003e ShardId.fromString(p.text()),\n            new ParseField(Fields._SHARD),\n            ValueType.STRING\n        );\n        parser.declareObject(\n            (map, value) -\u003e map.put(SourceFieldMapper.NAME, value),\n            (p, c) -\u003e parseSourceBytes(p),\n            new ParseField(SourceFieldMapper.NAME)\n        );\n        parser.declareObject(\n            (map, value) -\u003e map.put(Fields.HIGHLIGHT, value),\n            (p, c) -\u003e parseHighlightFields(p),\n            new ParseField(Fields.HIGHLIGHT)\n        );\n        parser.declareObject((map, value) -\u003e {\n            Map\u003cString, DocumentField\u003e fieldMap \u003d get(Fields.FIELDS, map, new HashMap\u003cString, DocumentField\u003e());\n            fieldMap.putAll(value);\n            map.put(DOCUMENT_FIELDS, fieldMap);\n        }, (p, c) -\u003e parseFields(p), new ParseField(Fields.FIELDS));\n        parser.declareObject(\n            (map, value) -\u003e map.put(Fields._EXPLANATION, value),\n            (p, c) -\u003e parseExplanation(p),\n            new ParseField(Fields._EXPLANATION)\n        );\n        parser.declareObject(\n            (map, value) -\u003e map.put(NestedIdentity._NESTED, value),\n            NestedIdentity::fromXContent,\n            new ParseField(NestedIdentity._NESTED)\n        );\n        parser.declareObject(\n            (map, value) -\u003e map.put(Fields.INNER_HITS, value),\n            (p, c) -\u003e parseInnerHits(p),\n            new ParseField(Fields.INNER_HITS)\n        );\n\n        parser.declareField((p, map, context) -\u003e {\n            XContentParser.Token token \u003d p.currentToken();\n            Map\u003cString, Float\u003e matchedQueries \u003d new LinkedHashMap\u003c\u003e();\n            if (token \u003d\u003d XContentParser.Token.START_OBJECT) {\n                String fieldName \u003d null;\n                while ((token \u003d p.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n                    if (token \u003d\u003d XContentParser.Token.FIELD_NAME) {\n                        fieldName \u003d p.currentName();\n                    } else if (token.isValue()) {\n                        matchedQueries.put(fieldName, p.floatValue());\n                    }\n                }\n            } else if (token \u003d\u003d XContentParser.Token.START_ARRAY) {\n                while (p.nextToken() !\u003d XContentParser.Token.END_ARRAY) {\n                    matchedQueries.put(p.text(), Float.NaN);\n                }\n            }\n            map.put(Fields.MATCHED_QUERIES, matchedQueries);\n        }, new ParseField(Fields.MATCHED_QUERIES), ObjectParser.ValueType.OBJECT_ARRAY);\n\n        parser.declareField(\n            (map, list) -\u003e map.put(Fields.SORT, list),\n            SearchSortValues::fromXContent,\n            new ParseField(Fields.SORT),\n            ValueType.OBJECT_ARRAY\n        );\n    }\n\n    public static SearchHit createFromMap(Map\u003cString, Object\u003e values) {\n        String id \u003d get(Fields._ID, values, null);\n        String index \u003d get(Fields._INDEX, values, null);\n        String clusterAlias \u003d null;\n        if (index !\u003d null) {\n            int indexOf \u003d index.indexOf(RemoteClusterAware.REMOTE_CLUSTER_INDEX_SEPARATOR);\n            if (indexOf \u003e 0) {\n                clusterAlias \u003d index.substring(0, indexOf);\n                index \u003d index.substring(indexOf + 1);\n            }\n        }\n        ShardId shardId \u003d get(Fields._SHARD, values, null);\n        String nodeId \u003d get(Fields._NODE, values, null);\n        final SearchShardTarget shardTarget;\n        if (shardId !\u003d null \u0026\u0026 nodeId !\u003d null) {\n            assert shardId.getIndexName().equals(index);\n            shardTarget \u003d new SearchShardTarget(nodeId, shardId, clusterAlias);\n            index \u003d shardTarget.getIndex();\n            clusterAlias \u003d shardTarget.getClusterAlias();\n        } else {\n            shardTarget \u003d null;\n        }\n        return new SearchHit(\n            -1,\n            get(Fields._SCORE, values, DEFAULT_SCORE),\n            get(Fields._RANK, values, NO_RANK),\n            id \u003d\u003d null ? null : new Text(id),\n            get(NestedIdentity._NESTED, values, null),\n            get(Fields._VERSION, values, -1L),\n            get(Fields._SEQ_NO, values, SequenceNumbers.UNASSIGNED_SEQ_NO),\n            get(Fields._PRIMARY_TERM, values, SequenceNumbers.UNASSIGNED_PRIMARY_TERM),\n            get(SourceFieldMapper.NAME, values, null),\n            get(Fields.HIGHLIGHT, values, null),\n            get(Fields.SORT, values, SearchSortValues.EMPTY),\n            get(Fields.MATCHED_QUERIES, values, null),\n            get(Fields._EXPLANATION, values, null),\n            shardTarget,\n            index,\n            clusterAlias,\n            null,\n            get(Fields.INNER_HITS, values, null),\n            get(DOCUMENT_FIELDS, values, Collections.emptyMap()),\n            get(METADATA_FIELDS, values, Collections.emptyMap()),\n            ALWAYS_REFERENCED // TODO: do we ever want pooling here?\n        );\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    private static \u003cT\u003e T get(String key, Map\u003cString, Object\u003e map, T defaultValue) {\n        return (T) map.getOrDefault(key, defaultValue);\n    }\n\n    private static float parseScore(XContentParser parser) throws IOException {\n        if (parser.currentToken() \u003d\u003d XContentParser.Token.VALUE_NUMBER || parser.currentToken() \u003d\u003d XContentParser.Token.VALUE_STRING) {\n            return parser.floatValue();\n        } else {\n            return Float.NaN;\n        }\n    }\n\n    private static BytesReference parseSourceBytes(XContentParser parser) throws IOException {\n        try (XContentBuilder builder \u003d XContentBuilder.builder(parser.contentType().xContent())) {\n            // the original document gets slightly modified: whitespaces or\n            // pretty printing are not preserved,\n            // it all depends on the current builder settings\n            builder.copyCurrentStructure(parser);\n            return BytesReference.bytes(builder);\n        }\n    }\n\n    private static Map\u003cString, DocumentField\u003e parseFields(XContentParser parser) throws IOException {\n        Map\u003cString, DocumentField\u003e fields \u003d new HashMap\u003c\u003e();\n        while (parser.nextToken() !\u003d XContentParser.Token.END_OBJECT) {\n            DocumentField field \u003d DocumentField.fromXContent(parser);\n            fields.put(field.getName(), field);\n        }\n        return fields;\n    }\n\n    private static Map\u003cString, SearchHits\u003e parseInnerHits(XContentParser parser) throws IOException {\n        Map\u003cString, SearchHits\u003e innerHits \u003d new HashMap\u003c\u003e();\n        while ((parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            ensureExpectedToken(XContentParser.Token.FIELD_NAME, parser.currentToken(), parser);\n            String name \u003d parser.currentName();\n            ensureExpectedToken(Token.START_OBJECT, parser.nextToken(), parser);\n            ensureFieldName(parser, parser.nextToken(), SearchHits.Fields.HITS);\n            innerHits.put(name, SearchHits.fromXContent(parser));\n            ensureExpectedToken(XContentParser.Token.END_OBJECT, parser.nextToken(), parser);\n        }\n        return innerHits;\n    }\n\n    private static Map\u003cString, HighlightField\u003e parseHighlightFields(XContentParser parser) throws IOException {\n        Map\u003cString, HighlightField\u003e highlightFields \u003d new HashMap\u003c\u003e();\n        while ((parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            HighlightField highlightField \u003d HighlightField.fromXContent(parser);\n            highlightFields.put(highlightField.name(), highlightField);\n        }\n        return highlightFields;\n    }\n\n    private static Explanation parseExplanation(XContentParser parser) throws IOException {\n        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.currentToken(), parser);\n        XContentParser.Token token;\n        Float value \u003d null;\n        String description \u003d null;\n        List\u003cExplanation\u003e details \u003d new ArrayList\u003c\u003e();\n        while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_OBJECT) {\n            ensureExpectedToken(XContentParser.Token.FIELD_NAME, token, parser);\n            String currentFieldName \u003d parser.currentName();\n            token \u003d parser.nextToken();\n            if (Fields.VALUE.equals(currentFieldName)) {\n                value \u003d parser.floatValue();\n            } else if (Fields.DESCRIPTION.equals(currentFieldName)) {\n                description \u003d parser.textOrNull();\n            } else if (Fields.DETAILS.equals(currentFieldName)) {\n                ensureExpectedToken(XContentParser.Token.START_ARRAY, token, parser);\n                while ((token \u003d parser.nextToken()) !\u003d XContentParser.Token.END_ARRAY) {\n                    details.add(parseExplanation(parser));\n                }\n            } else {\n                parser.skipChildren();\n            }\n        }\n        if (value \u003d\u003d null) {\n            throw new ParsingException(parser.getTokenLocation(), \"missing explanation value\");\n        }\n        if (description \u003d\u003d null) {\n            throw new ParsingException(parser.getTokenLocation(), \"missing explanation description\");\n        }\n        return Explanation.match(value, description, details);\n    }\n\n    private static void buildExplanation(XContentBuilder builder, Explanation explanation) throws IOException {\n        builder.startObject();\n        builder.field(Fields.VALUE, explanation.getValue());\n        builder.field(Fields.DESCRIPTION, explanation.getDescription());\n        Explanation[] innerExps \u003d explanation.getDetails();\n        if (innerExps !\u003d null) {\n            builder.startArray(Fields.DETAILS);\n            for (Explanation exp : innerExps) {\n                buildExplanation(builder, exp);\n            }\n            builder.endArray();\n        }\n        builder.endObject();\n    }\n\n    @Override\n    public boolean equals(Object obj) {\n        if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n            return false;\n        }\n        SearchHit other \u003d (SearchHit) obj;\n        return Objects.equals(id, other.id)\n            \u0026\u0026 Objects.equals(nestedIdentity, other.nestedIdentity)\n            \u0026\u0026 Objects.equals(version, other.version)\n            \u0026\u0026 Objects.equals(seqNo, other.seqNo)\n            \u0026\u0026 Objects.equals(primaryTerm, other.primaryTerm)\n            \u0026\u0026 Objects.equals(source, other.source)\n            \u0026\u0026 Objects.equals(documentFields, other.documentFields)\n            \u0026\u0026 Objects.equals(metaFields, other.metaFields)\n            \u0026\u0026 Objects.equals(getHighlightFields(), other.getHighlightFields())\n            \u0026\u0026 Objects.equals(getMatchedQueriesAndScores(), other.getMatchedQueriesAndScores())\n            \u0026\u0026 Objects.equals(explanation, other.explanation)\n            \u0026\u0026 Objects.equals(shard, other.shard)\n            \u0026\u0026 Objects.equals(innerHits, other.innerHits)\n            \u0026\u0026 Objects.equals(index, other.index)\n            \u0026\u0026 Objects.equals(clusterAlias, other.clusterAlias);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(\n            id,\n            nestedIdentity,\n            version,\n            seqNo,\n            primaryTerm,\n            source,\n            documentFields,\n            metaFields,\n            getHighlightFields(),\n            getMatchedQueriesAndScores(),\n            explanation,\n            shard,\n            innerHits,\n            index,\n            clusterAlias\n        );\n    }\n\n    /**\n     * Encapsulates the nested identity of a hit.\n     */\n    public static final class NestedIdentity implements Writeable, ToXContentFragment {\n\n        private static final String _NESTED \u003d \"_nested\";\n        private static final String FIELD \u003d \"field\";\n        private static final String OFFSET \u003d \"offset\";\n\n        private final Text field;\n        private final int offset;\n        private final NestedIdentity child;\n\n        public NestedIdentity(String field, int offset, NestedIdentity child) {\n            this.field \u003d new Text(field);\n            this.offset \u003d offset;\n            this.child \u003d child;\n        }\n\n        NestedIdentity(StreamInput in) throws IOException {\n            field \u003d in.readOptionalText();\n            offset \u003d in.readInt();\n            child \u003d in.readOptionalWriteable(NestedIdentity::new);\n        }\n\n        /**\n         * Returns the nested field in the source this hit originates from\n         */\n        public Text getField() {\n            return field;\n        }\n\n        /**\n         * Returns the offset in the nested array of objects in the source this hit\n         */\n        public int getOffset() {\n            return offset;\n        }\n\n        /**\n         * Returns the next child nested level if there is any, otherwise \u003ccode\u003enull\u003c/code\u003e is returned.\n         *\n         * In the case of mappings with multiple levels of nested object fields\n         */\n        public NestedIdentity getChild() {\n            return child;\n        }\n\n        /**\n         * Extracts the part of the root source that applies to this particular NestedIdentity, while\n         * preserving the enclosing path structure.\n         *\n         * For a root document that looks like this:\n         * { \"children\" :\n         *    [\n         *      { \"grandchildren\" : [ { \"field\" : \"value1\" }, { \"field\" : \"value2\" } ] },\n         *      { \"grandchildren\" : [ { \"field\" : \"value3\" }, { \"field\" : \"value4\" } ] }\n         *   ]\n         * }\n         *\n         * Extracting the NestedIdentity of the first child and second grandchild results in a source that looks like this:\n         * { \"children\" : { \"grandchildren\" : { \"field\" : \"value2\" } } }\n         *\n         * If the relevant child source object does not exist in the root, then we return {@link Source#empty(XContentType)}\n         */\n        @SuppressWarnings(\"unchecked\")\n        public Source extractSource(Source root) {\n            // Isolate the nested json array object that matches with nested hit and wrap it back into the same json\n            // structure with the nested json array object being the actual content. The latter is important, so that\n            // features like source filtering and highlighting work consistent regardless of whether the field points\n            // to a json object array for consistency reasons on how we refer to fields\n            Map\u003cString, Object\u003e rootSourceAsMap \u003d root.source();\n            Map\u003cString, Object\u003e nestedSourceAsMap \u003d new HashMap\u003c\u003e();\n            Map\u003cString, Object\u003e current \u003d nestedSourceAsMap;\n            for (SearchHit.NestedIdentity nested \u003d this; nested !\u003d null; nested \u003d nested.getChild()) {\n                String nestedPath \u003d nested.getField().string();\n                current.put(nestedPath, new HashMap\u003c\u003e());\n                List\u003cMap\u003c?, ?\u003e\u003e nestedParsedSource \u003d XContentMapValues.extractNestedSources(nestedPath, rootSourceAsMap);\n                if (nestedParsedSource \u003d\u003d null) {\n                    return Source.empty(root.sourceContentType());\n                }\n                if (nested.getOffset() \u003e nestedParsedSource.size() - 1) {\n                    throw new IllegalStateException(\"Error retrieving path \" + this.field);\n                }\n                rootSourceAsMap \u003d (Map\u003cString, Object\u003e) nestedParsedSource.get(nested.getOffset());\n                if (nested.getChild() \u003d\u003d null) {\n                    current.put(nestedPath, rootSourceAsMap);\n                } else {\n                    Map\u003cString, Object\u003e next \u003d new HashMap\u003c\u003e();\n                    current.put(nestedPath, next);\n                    current \u003d next;\n                }\n            }\n            return Source.fromMap(nestedSourceAsMap, root.sourceContentType());\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeOptionalText(field);\n            out.writeInt(offset);\n            out.writeOptionalWriteable(child);\n        }\n\n        @Override\n        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n            builder.field(_NESTED);\n            return innerToXContent(builder, params);\n        }\n\n        @Override\n        public String toString() {\n            return Strings.toString(this);\n        }\n\n        /**\n         * Rendering of the inner XContent object without the leading field name. This way the structure innerToXContent renders and\n         * fromXContent parses correspond to each other.\n         */\n        XContentBuilder innerToXContent(XContentBuilder builder, Params params) throws IOException {\n            builder.startObject();\n            if (field !\u003d null) {\n                builder.field(FIELD, field);\n            }\n            if (offset !\u003d -1) {\n                builder.field(OFFSET, offset);\n            }\n            if (child !\u003d null) {\n                builder \u003d child.toXContent(builder, params);\n            }\n            builder.endObject();\n            return builder;\n        }\n\n        private static final ConstructingObjectParser\u003cNestedIdentity, Void\u003e PARSER \u003d new ConstructingObjectParser\u003c\u003e(\n            \"nested_identity\",\n            true,\n            ctorArgs -\u003e new NestedIdentity((String) ctorArgs[0], (int) ctorArgs[1], (NestedIdentity) ctorArgs[2])\n        );\n        static {\n            PARSER.declareString(constructorArg(), new ParseField(FIELD));\n            PARSER.declareInt(constructorArg(), new ParseField(OFFSET));\n            PARSER.declareObject(optionalConstructorArg(), PARSER, new ParseField(_NESTED));\n        }\n\n        static NestedIdentity fromXContent(XContentParser parser, Void context) {\n            return fromXContent(parser);\n        }\n\n        public static NestedIdentity fromXContent(XContentParser parser) {\n            return PARSER.apply(parser, null);\n        }\n\n        @Override\n        public boolean equals(Object obj) {\n            if (this \u003d\u003d obj) {\n                return true;\n            }\n            if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n                return false;\n            }\n            NestedIdentity other \u003d (NestedIdentity) obj;\n            return Objects.equals(field, other.field) \u0026\u0026 Objects.equals(offset, other.offset) \u0026\u0026 Objects.equals(child, other.child);\n        }\n\n        @Override\n        public int hashCode() {\n            return Objects.hash(field, offset, child);\n        }\n    }\n\n    @Override\n    public String toString() {\n        return Strings.toString(this, true, true);\n    }\n}","methodCount":91},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":976,"lineEnd":1054,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareInnerHitsParseFields to class RestResponseUtils","description":"move method declareInnerHitsParseFields to PsiClass:RestResponseUtils\nRationale: The declareInnerHitsParseFields() method is responsible for parsing various fields related to search hits, which aligns with the utility nature of RestResponseUtils that deals with response handling. Moving this method here would adhere to the Single Responsibility Principle, as it centralizes parsing logic related to REST responses. This would improve cohesion within RestResponseUtils, making it a more comprehensive utility for handling responses. However, it may increase the size of RestResponseUtils, which could lead to a less clear separation of concerns if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":976,"lineEnd":1054,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareInnerHitsParseFields to class DfsPhase","description":"move method declareInnerHitsParseFields to PsiClass:DfsPhase\nRationale: DfsPhase is involved in executing search-related operations, making it a suitable candidate for the declareInnerHitsParseFields() method, which deals with parsing search hit fields. This move would enhance cohesion, as the parsing logic is relevant to the operations performed in DfsPhase. Adhering to the Interface Segregation Principle, it keeps parsing logic close to where it is used. However, care must be taken not to overload DfsPhase with too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":976,"lineEnd":1054,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method declareInnerHitsParseFields to class DfsSearchResult","description":"move method declareInnerHitsParseFields to PsiClass:DfsSearchResult\nRationale: The DfsSearchResult class deals with the results of search operations, making it a logical home for declareInnerHitsParseFields(). This method directly contributes to the construction of search result mappings. Moving it here would improve cohesion and encapsulate parsing logic within the context of search results. However, it could complicate DfsSearchResult by adding parsing logic that may not be directly related to the result data structure.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":518,"lineEnd":524,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method setDocumentField to class NestedIdentity","description":"Move method setDocumentField to org.elasticsearch.search.SearchHit.NestedIdentity\nRationale: The setDocumentField() method deals with the addition of a DocumentField, which is likely related to the structure and organization of nested identities. Moving this method to NestedIdentity adheres to the Single Responsibility Principle, as it centralizes the logic related to managing document fields within a class that likely represents a more complex structure. This enhances cohesion, as NestedIdentity would encapsulate related functionality, making it easier to maintain and extend. However, one consideration is that the method\u0027s logic must be compatible with the existing structure of NestedIdentity, requiring careful integration.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":518,"lineEnd":524,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method setDocumentField to class RefCounted","description":"Move method setDocumentField to org.elasticsearch.core.RefCounted\nRationale: While RefCounted primarily manages reference counting, the method setDocumentField() could be relevant if document fields are part of a resource that requires reference management. Moving this method here could provide a centralized way to manage document fields alongside reference counting. This aligns with the Interface Segregation Principle, as it prevents RefCounted from becoming overloaded with unrelated functionality. However, the method\u0027s context may not align directly with reference counting, which could create confusion about the class\u0027s purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":518,"lineEnd":524,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method setDocumentField to class BytesReference","description":"Move method setDocumentField to org.elasticsearch.common.bytes.BytesReference\nRationale: Although BytesReference primarily deals with byte manipulation, if DocumentField is closely tied to byte data representation, relocating setDocumentField() here might make sense. This would facilitate a more straightforward interface for manipulating document fields as byte data. However, this move might violate the Single Responsibility Principle, as it would mix the concerns of byte manipulation with document field management, potentially leading to a less cohesive class design. Careful consideration of the relationship between DocumentField and byte data is necessary before making this change.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":746,"lineEnd":776,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method asUnpooled to class RefCounted","description":"Move method asUnpooled to org.elasticsearch.core.RefCounted\nRationale: The asUnpooled() method primarily deals with reference counting and the management of pooled resources, which aligns closely with the responsibilities of the RefCounted class. By moving this method to RefCounted, we adhere to the Single Responsibility Principle, ensuring that resource management logic is encapsulated within the class that directly handles reference counting. This improves cohesion and makes the method more reusable in contexts where reference counting is relevant. However, we should consider any dependencies on the current class\u0027s state that might complicate the relocation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":746,"lineEnd":776,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method asUnpooled to class BytesReference","description":"Move method asUnpooled to org.elasticsearch.common.bytes.BytesReference\nRationale: The asUnpooled() method involves the conversion of a source object to a BytesArray, which is a core function of the BytesReference class. Moving this method here would enhance the clarity of the BytesReference class\u0027s purpose and responsibilities, aligning with the Interface Segregation Principle by keeping byte-related operations together. This could also simplify the logic surrounding byte manipulation and conversion. However, care must be taken to ensure that this method does not introduce unnecessary dependencies on other classes, which could lead to tighter coupling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":746,"lineEnd":776,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method asUnpooled to class NestedIdentity","description":"Move method asUnpooled to org.elasticsearch.search.SearchHit.NestedIdentity\nRationale: While the asUnpooled() method does not directly relate to the core responsibilities of NestedIdentity, it does involve creating a new SearchHit that might reference nested structures. Moving it here could promote the idea of handling nested identity logic in one place. However, this move may dilute the focus of NestedIdentity, as it primarily deals with nested document structures rather than resource management or byte manipulation. This could lead to a violation of the Single Responsibility Principle and potentially confuse the class\u0027s purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"readFrom","method_signature":"public static readFrom(StreamInput in, boolean pooled)","target_class":"","rationale":""},{"method_name":"unpooled","method_signature":"public static unpooled(int docId)","target_class":"","rationale":""},{"method_name":"unpooled","method_signature":"public static unpooled(int docId, String id)","target_class":"","rationale":""},{"method_name":"unpooled","method_signature":"public static unpooled(int nestedTopDocId, String id, NestedIdentity nestedIdentity)","target_class":"","rationale":""},{"method_name":"sourceRef","method_signature":"public sourceRef(BytesReference source)","target_class":"","rationale":""},{"method_name":"hasSource","method_signature":"public hasSource()","target_class":"","rationale":""},{"method_name":"field","method_signature":"public field(String fieldName)","target_class":"","rationale":""},{"method_name":"setDocumentField","method_signature":"public setDocumentField(String fieldName, DocumentField field)","target_class":"","rationale":""},{"method_name":"addDocumentFields","method_signature":"public addDocumentFields(Map\u003cString, DocumentField\u003e docFields, Map\u003cString, DocumentField\u003e metaFields)","target_class":"","rationale":""},{"method_name":"hasLookupFields","method_signature":"public hasLookupFields()","target_class":"","rationale":""},{"method_name":"resolveLookupFields","method_signature":"public resolveLookupFields(Map\u003cLookupField, List\u003cObject\u003e\u003e lookupResults)","target_class":"","rationale":""},{"method_name":"sortValues","method_signature":"public sortValues(Object[] sortValues, DocValueFormat[] sortValueFormats)","target_class":"","rationale":""},{"method_name":"shard","method_signature":"public shard(SearchShardTarget target)","target_class":"","rationale":""},{"method_name":"getMatchedQueryScore","method_signature":"public getMatchedQueryScore(String name)","target_class":"","rationale":""},{"method_name":"deallocate","method_signature":"private deallocate()","target_class":"","rationale":""},{"method_name":"asUnpooled","method_signature":"public asUnpooled()","target_class":"","rationale":""},{"method_name":"isPooled","method_signature":"public isPooled()","target_class":"","rationale":""},{"method_name":"toInnerXContent","method_signature":"public toInnerXContent(XContentBuilder builder, Params params)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"declareInnerHitsParseFields","method_signature":"public static declareInnerHitsParseFields(ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e parser)","target_class":"","rationale":""},{"method_name":"createFromMap","method_signature":"public static createFromMap(Map\u003cString, Object\u003e values)","target_class":"","rationale":""},{"method_name":"get","method_signature":"@SuppressWarnings(\"unchecked\")\n    private static get(String key, Map\u003cString, Object\u003e map, T defaultValue)","target_class":"","rationale":""},{"method_name":"parseScore","method_signature":"private static parseScore(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseSourceBytes","method_signature":"private static parseSourceBytes(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseFields","method_signature":"private static parseFields(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseInnerHits","method_signature":"private static parseInnerHits(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseHighlightFields","method_signature":"private static parseHighlightFields(XContentParser parser)","target_class":"","rationale":""},{"method_name":"parseExplanation","method_signature":"private static parseExplanation(XContentParser parser)","target_class":"","rationale":""},{"method_name":"buildExplanation","method_signature":"private static buildExplanation(XContentBuilder builder, Explanation explanation)","target_class":"","rationale":""},{"method_name":"extractSource","method_signature":"@SuppressWarnings(\"unchecked\")\n        public extractSource(Source root)","target_class":"","rationale":""},{"method_name":"innerToXContent","method_signature":" innerToXContent(XContentBuilder builder, Params params)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"static fromXContent(XContentParser parser, Void context)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"declareInnerHitsParseFields","method_signature":"public static declareInnerHitsParseFields(ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e parser)","target_class":"","rationale":""},{"method_name":"setDocumentField","method_signature":"public setDocumentField(String fieldName, DocumentField field)","target_class":"","rationale":""},{"method_name":"asUnpooled","method_signature":"public asUnpooled()","target_class":"","rationale":""},{"method_name":"sortValues","method_signature":"public sortValues(Object[] sortValues, DocValueFormat[] sortValueFormats)","target_class":"","rationale":""},{"method_name":"parseSourceBytes","method_signature":"private static parseSourceBytes(XContentParser parser)","target_class":"","rationale":""},{"method_name":"createFromMap","method_signature":"public static createFromMap(Map\u003cString, Object\u003e values)","target_class":"","rationale":""},{"method_name":"unpooled","method_signature":"public static unpooled(int nestedTopDocId, String id, NestedIdentity nestedIdentity)","target_class":"","rationale":""},{"method_name":"hasLookupFields","method_signature":"public hasLookupFields()","target_class":"","rationale":""},{"method_name":"parseInnerHits","method_signature":"private static parseInnerHits(XContentParser parser)","target_class":"","rationale":""},{"method_name":"get","method_signature":"@SuppressWarnings(\"unchecked\")\n    private static get(String key, Map\u003cString, Object\u003e map, T defaultValue)","target_class":"","rationale":""},{"method_name":"hasSource","method_signature":"public hasSource()","target_class":"","rationale":""},{"method_name":"unpooled","method_signature":"public static unpooled(int docId, String id)","target_class":"","rationale":""},{"method_name":"addDocumentFields","method_signature":"public addDocumentFields(Map\u003cString, DocumentField\u003e docFields, Map\u003cString, DocumentField\u003e metaFields)","target_class":"","rationale":""},{"method_name":"isPooled","method_signature":"public isPooled()","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static declareInnerHitsParseFields(ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e parser)":{"first":{"method_name":"declareInnerHitsParseFields","method_signature":"public static declareInnerHitsParseFields(ObjectParser\u003cMap\u003cString, Object\u003e, Void\u003e parser)","target_class":"","rationale":""},"second":0.3284869847536658},"public setDocumentField(String fieldName, DocumentField field)":{"first":{"method_name":"setDocumentField","method_signature":"public setDocumentField(String fieldName, DocumentField field)","target_class":"","rationale":""},"second":0.3969213231885965},"public asUnpooled()":{"first":{"method_name":"asUnpooled","method_signature":"public asUnpooled()","target_class":"","rationale":""},"second":0.4318142595293319},"public sortValues(Object[] sortValues, DocValueFormat[] sortValueFormats)":{"first":{"method_name":"sortValues","method_signature":"public sortValues(Object[] sortValues, DocValueFormat[] sortValueFormats)","target_class":"","rationale":""},"second":0.4457658600368416},"private static parseSourceBytes(XContentParser parser)":{"first":{"method_name":"parseSourceBytes","method_signature":"private static parseSourceBytes(XContentParser parser)","target_class":"","rationale":""},"second":0.44903787357416564},"public static createFromMap(Map\u003cString, Object\u003e values)":{"first":{"method_name":"createFromMap","method_signature":"public static createFromMap(Map\u003cString, Object\u003e values)","target_class":"","rationale":""},"second":0.4503606822256061},"public static unpooled(int nestedTopDocId, String id, NestedIdentity nestedIdentity)":{"first":{"method_name":"unpooled","method_signature":"public static unpooled(int nestedTopDocId, String id, NestedIdentity nestedIdentity)","target_class":"","rationale":""},"second":0.4702366690571196},"public hasLookupFields()":{"first":{"method_name":"hasLookupFields","method_signature":"public hasLookupFields()","target_class":"","rationale":""},"second":0.47038787184175956},"private static parseInnerHits(XContentParser parser)":{"first":{"method_name":"parseInnerHits","method_signature":"private static parseInnerHits(XContentParser parser)","target_class":"","rationale":""},"second":0.47217161083565357},"@SuppressWarnings(\"unchecked\")\n    private static get(String key, Map\u003cString, Object\u003e map, T defaultValue)":{"first":{"method_name":"get","method_signature":"@SuppressWarnings(\"unchecked\")\n    private static get(String key, Map\u003cString, Object\u003e map, T defaultValue)","target_class":"","rationale":""},"second":0.47710951371651317},"public hasSource()":{"first":{"method_name":"hasSource","method_signature":"public hasSource()","target_class":"","rationale":""},"second":0.4876435396909449},"public static unpooled(int docId, String id)":{"first":{"method_name":"unpooled","method_signature":"public static unpooled(int docId, String id)","target_class":"","rationale":""},"second":0.4952240354783077},"public addDocumentFields(Map\u003cString, DocumentField\u003e docFields, Map\u003cString, DocumentField\u003e metaFields)":{"first":{"method_name":"addDocumentFields","method_signature":"public addDocumentFields(Map\u003cString, DocumentField\u003e docFields, Map\u003cString, DocumentField\u003e metaFields)","target_class":"","rationale":""},"second":0.49854361939794556},"public isPooled()":{"first":{"method_name":"isPooled","method_signature":"public isPooled()","target_class":"","rationale":""},"second":0.5210399819898792},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.5226649421486808}},"llmMethodPriority":{"priority_method_names":["declareInnerHitsParseFields","setDocumentField","asUnpooled","sortValues","parseSourceBytes","createFromMap","unpooled","hasLookupFields","parseInnerHits","get","hasSource","unpooled","addDocumentFields","isPooled","fromXContent"],"llm_response_time":4157},"targetClassMap":{"declareInnerHitsParseFields":{"target_classes":[{"class_name":"GeoTileUtils","similarity_score":0.1531766267474337},{"class_name":"SearchUtils","similarity_score":0.13002540238321997},{"class_name":"HighlightUtils","similarity_score":0.2582169140540944},{"class_name":"BucketUtils","similarity_score":0.10888163678165932},{"class_name":"NestedUtils","similarity_score":0.18735896329777552},{"class_name":"RestResponseUtils","similarity_score":0.30510143863448363},{"class_name":"JwkValidateUtil","similarity_score":0.3055868345400134},{"class_name":"JwkValidateUtilTests","similarity_score":0.2486434567930324},{"class_name":"FunctionTestUtils","similarity_score":0.29402593378641906},{"class_name":"RestTestUtil","similarity_score":0.16781300923658873},{"class_name":"FutureUtils","similarity_score":0.21856603702171226},{"class_name":"FuzzyOptions","similarity_score":0.2435303152715061},{"class_name":"FuzzyOptionsTests","similarity_score":0.3828927097051899},{"class_name":"JwtUtil","similarity_score":0.31953056485406023},{"class_name":"RestUtils","similarity_score":0.2487975424394094},{"class_name":"RestUtilsTests","similarity_score":0.19945988008705728},{"class_name":"ExactMedianAbsoluteDeviation","similarity_score":0.2558140842565233},{"class_name":"GceMockUtils","similarity_score":0.3066437313207603},{"class_name":"ExceptionUtils","similarity_score":0.21299281702156578},{"class_name":"DfsPhase","similarity_score":0.35386383687404077},{"class_name":"DfsSearchResult","similarity_score":0.352329182115567},{"class_name":"CheckedFunctionUtils","similarity_score":0.04384004208905761},{"class_name":"NumberUtils","similarity_score":0.26678504935963404},{"class_name":"GeneratorUtils","similarity_score":0.38912434531194956},{"class_name":"GenericWriteableWrapper","similarity_score":0.19430173051930028},{"class_name":"NumericUtilsTests","similarity_score":0.32950923858434733},{"class_name":"RetentionLeaseUtils","similarity_score":0.1887362317278262},{"class_name":"GeoBoundsAggregationBuilder","similarity_score":0.272430674425483},{"class_name":"GeoBoundsAggregatorFactory","similarity_score":0.19292664866769005},{"class_name":"KeyStoreUtil","similarity_score":0.2396593651239732}],"target_classes_sorted_by_llm":["RestResponseUtils","DfsPhase","DfsSearchResult","GeneratorUtils","JwtUtil","FuzzyOptionsTests","NumericUtilsTests","GceMockUtils","JwkValidateUtil","FunctionTestUtils"],"llm_response_time":13336,"similarity_computation_time":20,"similarity_metric":"voyage"},"setDocumentField":{"target_classes":[{"class_name":"NestedIdentity","similarity_score":0.41965941380015276},{"class_name":"BytesReference","similarity_score":0.4155991268344409},{"class_name":"RefCounted","similarity_score":0.44437772119789243}],"target_classes_sorted_by_llm":["NestedIdentity","RefCounted","BytesReference"],"llm_response_time":4187,"similarity_computation_time":2,"similarity_metric":"voyage"},"asUnpooled":{"target_classes":[{"class_name":"NestedIdentity","similarity_score":0.3760148777373861},{"class_name":"BytesReference","similarity_score":0.21447863530566444},{"class_name":"RefCounted","similarity_score":0.14210646413484113}],"target_classes_sorted_by_llm":["RefCounted","BytesReference","NestedIdentity"],"llm_response_time":3980,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"e47ca90b-8d7d-4f00-bcbd-95eacb9a3e12","methodCount":19,"hostFunctionTelemetryData":{"hostFunctionSize":442,"lineStart":55,"lineEnd":496,"bodyLineStart":55,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/cluster/metadata/MetadataCreateDataStreamService.java","sourceCode":"public class MetadataCreateDataStreamService {\n\n    private static final Logger logger \u003d LogManager.getLogger(MetadataCreateDataStreamService.class);\n\n    public static final String FAILURE_STORE_REFRESH_INTERVAL_SETTING_NAME \u003d \"data_streams.failure_store.refresh_interval\";\n\n    private final ThreadPool threadPool;\n    private final ClusterService clusterService;\n    private final MetadataCreateIndexService metadataCreateIndexService;\n    private final boolean isDslOnlyMode;\n\n    public MetadataCreateDataStreamService(\n        ThreadPool threadPool,\n        ClusterService clusterService,\n        MetadataCreateIndexService metadataCreateIndexService\n    ) {\n        this.threadPool \u003d threadPool;\n        this.clusterService \u003d clusterService;\n        this.metadataCreateIndexService \u003d metadataCreateIndexService;\n        this.isDslOnlyMode \u003d isDataStreamsLifecycleOnlyMode(clusterService.getSettings());\n    }\n\n    public void createDataStream(CreateDataStreamClusterStateUpdateRequest request, ActionListener\u003cAcknowledgedResponse\u003e finalListener) {\n        AtomicReference\u003cString\u003e firstBackingIndexRef \u003d new AtomicReference\u003c\u003e();\n        AtomicReference\u003cString\u003e firstFailureStoreRef \u003d new AtomicReference\u003c\u003e();\n        ActionListener\u003cAcknowledgedResponse\u003e listener \u003d finalListener.delegateFailureAndWrap((l, response) -\u003e {\n            if (response.isAcknowledged()) {\n                String firstBackingIndexName \u003d firstBackingIndexRef.get();\n                assert firstBackingIndexName !\u003d null;\n                String firstFailureStoreName \u003d firstFailureStoreRef.get();\n                var waitForIndices \u003d firstFailureStoreName \u003d\u003d null\n                    ? new String[] { firstBackingIndexName }\n                    : new String[] { firstBackingIndexName, firstFailureStoreName };\n                ActiveShardsObserver.waitForActiveShards(\n                    clusterService,\n                    waitForIndices,\n                    ActiveShardCount.DEFAULT,\n                    request.masterNodeTimeout(),\n                    l.map(shardsAcked -\u003e AcknowledgedResponse.TRUE)\n                );\n            } else {\n                l.onResponse(AcknowledgedResponse.FALSE);\n            }\n        });\n        var delegate \u003d new AllocationActionListener\u003c\u003e(listener, threadPool.getThreadContext());\n        submitUnbatchedTask(\n            \"create-data-stream [\" + request.name + \"]\",\n            new AckedClusterStateUpdateTask(Priority.HIGH, request, delegate.clusterStateUpdate()) {\n                @Override\n                public ClusterState execute(ClusterState currentState) throws Exception {\n                    ClusterState clusterState \u003d createDataStream(\n                        metadataCreateIndexService,\n                        clusterService.getSettings(),\n                        currentState,\n                        isDslOnlyMode,\n                        request,\n                        delegate.reroute()\n                    );\n                    DataStream createdDataStream \u003d clusterState.metadata().dataStreams().get(request.name);\n                    firstBackingIndexRef.set(createdDataStream.getIndices().get(0).getName());\n                    if (createdDataStream.getFailureIndices().isEmpty() \u003d\u003d false) {\n                        firstFailureStoreRef.set(createdDataStream.getFailureIndices().get(0).getName());\n                    }\n                    return clusterState;\n                }\n            }\n        );\n    }\n\n    @SuppressForbidden(reason \u003d \"legacy usage of unbatched task\") // TODO add support for batching here\n    private void submitUnbatchedTask(@SuppressWarnings(\"SameParameterValue\") String source, ClusterStateUpdateTask task) {\n        clusterService.submitUnbatchedStateUpdateTask(source, task);\n    }\n\n    public ClusterState createDataStream(\n        CreateDataStreamClusterStateUpdateRequest request,\n        ClusterState current,\n        ActionListener\u003cVoid\u003e rerouteListener\n    ) throws Exception {\n        return createDataStream(metadataCreateIndexService, clusterService.getSettings(), current, isDslOnlyMode, request, rerouteListener);\n    }\n\n    public static final class CreateDataStreamClusterStateUpdateRequest extends ClusterStateUpdateRequest\u003c\n        CreateDataStreamClusterStateUpdateRequest\u003e {\n\n        private final boolean performReroute;\n        private final String name;\n        private final long startTime;\n        private final SystemDataStreamDescriptor descriptor;\n\n        public CreateDataStreamClusterStateUpdateRequest(String name) {\n            this(name, System.currentTimeMillis(), null, TimeValue.ZERO, TimeValue.ZERO, true);\n        }\n\n        public CreateDataStreamClusterStateUpdateRequest(\n            String name,\n            SystemDataStreamDescriptor systemDataStreamDescriptor,\n            TimeValue masterNodeTimeout,\n            TimeValue timeout,\n            boolean performReroute\n        ) {\n            this(name, System.currentTimeMillis(), systemDataStreamDescriptor, masterNodeTimeout, timeout, performReroute);\n        }\n\n        public CreateDataStreamClusterStateUpdateRequest(\n            String name,\n            long startTime,\n            SystemDataStreamDescriptor systemDataStreamDescriptor,\n            TimeValue masterNodeTimeout,\n            TimeValue timeout,\n            boolean performReroute\n        ) {\n            this.name \u003d name;\n            this.startTime \u003d startTime;\n            this.descriptor \u003d systemDataStreamDescriptor;\n            this.performReroute \u003d performReroute;\n            masterNodeTimeout(masterNodeTimeout);\n            ackTimeout(timeout);\n        }\n\n        public boolean isSystem() {\n            return descriptor !\u003d null;\n        }\n\n        public boolean performReroute() {\n            return performReroute;\n        }\n\n        public SystemDataStreamDescriptor getSystemDataStreamDescriptor() {\n            return descriptor;\n        }\n\n        long getStartTime() {\n            return startTime;\n        }\n    }\n\n    static ClusterState createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener\n    ) throws Exception {\n        return createDataStream(\n            metadataCreateIndexService,\n            settings,\n            currentState,\n            isDslOnlyMode,\n            request,\n            List.of(),\n            null,\n            rerouteListener\n        );\n    }\n\n    /**\n     * Creates a data stream with the specified request, backing indices and write index.\n     *\n     * @param metadataCreateIndexService Used if a new write index must be created\n     * @param currentState               Cluster state\n     * @param request                    The create data stream request\n     * @param backingIndices             List of backing indices. May be empty\n     * @param writeIndex                 Write index for the data stream. If null, a new write index will be created.\n     * @return                           Cluster state containing the new data stream\n     */\n    static ClusterState createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        List\u003cIndexMetadata\u003e backingIndices,\n        IndexMetadata writeIndex,\n        ActionListener\u003cVoid\u003e rerouteListener\n    ) throws Exception {\n        String dataStreamName \u003d request.name;\n        SystemDataStreamDescriptor systemDataStreamDescriptor \u003d request.getSystemDataStreamDescriptor();\n        boolean isSystemDataStreamName \u003d metadataCreateIndexService.getSystemIndices().isSystemDataStream(request.name);\n        assert (isSystemDataStreamName \u0026\u0026 systemDataStreamDescriptor !\u003d null)\n            || (isSystemDataStreamName \u003d\u003d false \u0026\u0026 systemDataStreamDescriptor \u003d\u003d null)\n            : \"dataStream [\" + request.name + \"] is system but no system descriptor was provided!\";\n\n        Objects.requireNonNull(metadataCreateIndexService);\n        Objects.requireNonNull(currentState);\n        Objects.requireNonNull(backingIndices);\n        if (currentState.metadata().dataStreams().containsKey(dataStreamName)) {\n            throw new ResourceAlreadyExistsException(\"data_stream [\" + dataStreamName + \"] already exists\");\n        }\n\n        MetadataCreateIndexService.validateIndexOrAliasName(\n            dataStreamName,\n            (s1, s2) -\u003e new IllegalArgumentException(\"data_stream [\" + s1 + \"] \" + s2)\n        );\n\n        if (dataStreamName.toLowerCase(Locale.ROOT).equals(dataStreamName) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"data_stream [\" + dataStreamName + \"] must be lowercase\");\n        }\n        if (dataStreamName.startsWith(DataStream.BACKING_INDEX_PREFIX)) {\n            throw new IllegalArgumentException(\n                \"data_stream [\" + dataStreamName + \"] must not start with \u0027\" + DataStream.BACKING_INDEX_PREFIX + \"\u0027\"\n            );\n        }\n        if (dataStreamName.startsWith(DataStream.FAILURE_STORE_PREFIX)) {\n            throw new IllegalArgumentException(\n                \"data_stream [\" + dataStreamName + \"] must not start with \u0027\" + DataStream.FAILURE_STORE_PREFIX + \"\u0027\"\n            );\n        }\n\n        final var metadata \u003d currentState.metadata();\n        final boolean isSystem \u003d systemDataStreamDescriptor !\u003d null;\n        final ComposableIndexTemplate template \u003d isSystem\n            ? systemDataStreamDescriptor.getComposableIndexTemplate()\n            : lookupTemplateForDataStream(dataStreamName, currentState.metadata());\n        // The initial backing index and the initial failure store index will have the same initial generation.\n        // This is not a problem as both have different prefixes (`.ds-` vs `.fs-`) and both will be using the same `generation` field\n        // when rolling over in the future.\n        final long initialGeneration \u003d 1;\n\n        // If we need to create a failure store, do so first. Do not reroute during the creation since we will do\n        // that as part of creating the backing index if required.\n        IndexMetadata failureStoreIndex \u003d null;\n        if (template.getDataStreamTemplate().hasFailureStore()) {\n            if (isSystem) {\n                throw new IllegalArgumentException(\"Failure stores are not supported on system data streams\");\n            }\n            String failureStoreIndexName \u003d DataStream.getDefaultFailureStoreName(dataStreamName, initialGeneration, request.getStartTime());\n            currentState \u003d createFailureStoreIndex(\n                metadataCreateIndexService,\n                \"initialize_data_stream\",\n                settings,\n                currentState,\n                request.getStartTime(),\n                dataStreamName,\n                template,\n                failureStoreIndexName,\n                null\n            );\n            failureStoreIndex \u003d currentState.metadata().index(failureStoreIndexName);\n        }\n\n        if (writeIndex \u003d\u003d null) {\n            String firstBackingIndexName \u003d DataStream.getDefaultBackingIndexName(dataStreamName, initialGeneration, request.getStartTime());\n            currentState \u003d createBackingIndex(\n                metadataCreateIndexService,\n                currentState,\n                request,\n                rerouteListener,\n                dataStreamName,\n                systemDataStreamDescriptor,\n                isSystem,\n                template,\n                firstBackingIndexName\n            );\n            writeIndex \u003d currentState.metadata().index(firstBackingIndexName);\n        } else {\n            rerouteListener.onResponse(null);\n        }\n        assert writeIndex !\u003d null;\n        assert writeIndex.mapping() !\u003d null : \"no mapping found for backing index [\" + writeIndex.getIndex().getName() + \"]\";\n        assert template.getDataStreamTemplate().hasFailureStore() \u003d\u003d false || failureStoreIndex !\u003d null;\n        assert failureStoreIndex \u003d\u003d null || failureStoreIndex.mapping() !\u003d null\n            : \"no mapping found for failure store [\" + failureStoreIndex.getIndex().getName() + \"]\";\n\n        List\u003cIndex\u003e dsBackingIndices \u003d backingIndices.stream()\n            .map(IndexMetadata::getIndex)\n            .collect(Collectors.toCollection(ArrayList::new));\n        dsBackingIndices.add(writeIndex.getIndex());\n        boolean hidden \u003d isSystem || template.getDataStreamTemplate().isHidden();\n        final IndexMode indexMode \u003d metadata.isTimeSeriesTemplate(template) ? IndexMode.TIME_SERIES : null;\n        final DataStreamLifecycle lifecycle \u003d isSystem\n            ? MetadataIndexTemplateService.resolveLifecycle(template, systemDataStreamDescriptor.getComponentTemplates())\n            : MetadataIndexTemplateService.resolveLifecycle(template, metadata.componentTemplates());\n        List\u003cIndex\u003e failureIndices \u003d failureStoreIndex \u003d\u003d null ? List.of() : List.of(failureStoreIndex.getIndex());\n        DataStream newDataStream \u003d new DataStream(\n            dataStreamName,\n            dsBackingIndices,\n            initialGeneration,\n            template.metadata() !\u003d null ? Map.copyOf(template.metadata()) : null,\n            hidden,\n            false,\n            isSystem,\n            template.getDataStreamTemplate().isAllowCustomRouting(),\n            indexMode,\n            lifecycle \u003d\u003d null \u0026\u0026 isDslOnlyMode ? DataStreamLifecycle.DEFAULT : lifecycle,\n            template.getDataStreamTemplate().hasFailureStore(),\n            failureIndices,\n            null\n        );\n        Metadata.Builder builder \u003d Metadata.builder(currentState.metadata()).put(newDataStream);\n\n        List\u003cString\u003e aliases \u003d new ArrayList\u003c\u003e();\n        var resolvedAliases \u003d MetadataIndexTemplateService.resolveAliases(currentState.metadata(), template);\n        for (var resolvedAliasMap : resolvedAliases) {\n            for (var alias : resolvedAliasMap.values()) {\n                aliases.add(alias.getAlias());\n                builder.put(alias.getAlias(), dataStreamName, alias.writeIndex(), alias.filter() \u003d\u003d null ? null : alias.filter().string());\n            }\n        }\n\n        logger.info(\n            \"adding data stream [{}] with write index [{}], backing indices [{}], and aliases [{}]\",\n            dataStreamName,\n            writeIndex.getIndex().getName(),\n            Strings.arrayToCommaDelimitedString(backingIndices.stream().map(i -\u003e i.getIndex().getName()).toArray()),\n            Strings.collectionToCommaDelimitedString(aliases)\n        );\n\n        return ClusterState.builder(currentState).metadata(builder).build();\n    }\n\n    private static ClusterState createBackingIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        ClusterState currentState,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener,\n        String dataStreamName,\n        SystemDataStreamDescriptor systemDataStreamDescriptor,\n        boolean isSystem,\n        ComposableIndexTemplate template,\n        String firstBackingIndexName\n    ) throws Exception {\n        CreateIndexClusterStateUpdateRequest createIndexRequest \u003d new CreateIndexClusterStateUpdateRequest(\n            \"initialize_data_stream\",\n            firstBackingIndexName,\n            firstBackingIndexName\n        ).dataStreamName(dataStreamName)\n            .systemDataStreamDescriptor(systemDataStreamDescriptor)\n            .nameResolvedInstant(request.getStartTime())\n            .performReroute(request.performReroute())\n            .setMatchingTemplate(template);\n\n        if (isSystem) {\n            createIndexRequest.settings(SystemIndexDescriptor.DEFAULT_SETTINGS);\n        } else {\n            createIndexRequest.settings(MetadataRolloverService.HIDDEN_INDEX_SETTINGS);\n        }\n\n        try {\n            currentState \u003d metadataCreateIndexService.applyCreateIndexRequest(currentState, createIndexRequest, false, rerouteListener);\n        } catch (ResourceAlreadyExistsException e) {\n            // Rethrow as ElasticsearchStatusException, so that bulk transport action doesn\u0027t ignore it during\n            // auto index/data stream creation.\n            // (otherwise bulk execution fails later, because data stream will also not have been created)\n            throw new ElasticsearchStatusException(\n                \"data stream could not be created because backing index [{}] already exists\",\n                RestStatus.BAD_REQUEST,\n                e,\n                firstBackingIndexName\n            );\n        }\n        return currentState;\n    }\n\n    public static ClusterState createFailureStoreIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        String cause,\n        Settings settings,\n        ClusterState currentState,\n        long nameResolvedInstant,\n        String dataStreamName,\n        ComposableIndexTemplate template,\n        String failureStoreIndexName,\n        @Nullable BiConsumer\u003cMetadata.Builder, IndexMetadata\u003e metadataTransformer\n    ) throws Exception {\n        if (DataStream.isFailureStoreEnabled() \u003d\u003d false) {\n            return currentState;\n        }\n\n        var indexSettings \u003d MetadataRolloverService.HIDDEN_INDEX_SETTINGS;\n        // Optionally set a custom refresh interval for the failure store index.\n        var refreshInterval \u003d getFailureStoreRefreshInterval(settings);\n        if (refreshInterval !\u003d null) {\n            indexSettings \u003d Settings.builder()\n                .put(indexSettings)\n                .put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), refreshInterval)\n                .build();\n        }\n\n        CreateIndexClusterStateUpdateRequest createIndexRequest \u003d new CreateIndexClusterStateUpdateRequest(\n            cause,\n            failureStoreIndexName,\n            failureStoreIndexName\n        ).dataStreamName(dataStreamName)\n            .nameResolvedInstant(nameResolvedInstant)\n            .performReroute(false)\n            .setMatchingTemplate(template)\n            .settings(indexSettings);\n\n        try {\n            currentState \u003d metadataCreateIndexService.applyCreateIndexRequest(\n                currentState,\n                createIndexRequest,\n                false,\n                metadataTransformer,\n                AllocationActionListener.rerouteCompletionIsNotRequired()\n            );\n        } catch (ResourceAlreadyExistsException e) {\n            // Rethrow as ElasticsearchStatusException, so that bulk transport action doesn\u0027t ignore it during\n            // auto index/data stream creation.\n            // (otherwise bulk execution fails later, because data stream will also not have been created)\n            throw new ElasticsearchStatusException(\n                \"data stream could not be created because failure store index [{}] already exists\",\n                RestStatus.BAD_REQUEST,\n                e,\n                failureStoreIndexName\n            );\n        }\n        return currentState;\n    }\n\n    public static ComposableIndexTemplate lookupTemplateForDataStream(String dataStreamName, Metadata metadata) {\n        final String v2Template \u003d MetadataIndexTemplateService.findV2Template(metadata, dataStreamName, false);\n        if (v2Template \u003d\u003d null) {\n            throw new IllegalArgumentException(\"no matching index template found for data stream [\" + dataStreamName + \"]\");\n        }\n        ComposableIndexTemplate composableIndexTemplate \u003d metadata.templatesV2().get(v2Template);\n        if (composableIndexTemplate.getDataStreamTemplate() \u003d\u003d null) {\n            throw new IllegalArgumentException(\n                \"matching index template [\" + v2Template + \"] for data stream [\" + dataStreamName + \"] has no data stream template\"\n            );\n        }\n        return composableIndexTemplate;\n    }\n\n    public static void validateTimestampFieldMapping(MappingLookup mappingLookup) throws IOException {\n        MetadataFieldMapper fieldMapper \u003d (MetadataFieldMapper) mappingLookup.getMapper(DataStreamTimestampFieldMapper.NAME);\n        assert fieldMapper !\u003d null : DataStreamTimestampFieldMapper.NAME + \" meta field mapper must exist\";\n        // Sanity check: if this fails then somehow the mapping for _data_stream_timestamp has been overwritten and\n        // that would be a bug.\n        if (mappingLookup.isDataStreamTimestampFieldEnabled() \u003d\u003d false) {\n            throw new IllegalStateException(\"[\" + DataStreamTimestampFieldMapper.NAME + \"] meta field has been disabled\");\n        }\n        // Sanity check (this validation logic should already have been executed when merging mappings):\n        fieldMapper.validate(mappingLookup);\n    }\n\n    public static TimeValue getFailureStoreRefreshInterval(Settings settings) {\n        return settings.getAsTime(FAILURE_STORE_REFRESH_INTERVAL_SETTING_NAME, null);\n    }\n}","methodCount":19},"candidatesTelemetryData":{"numberOfSuggestions":5,"candidates":[{"lineStart":128,"lineEnd":134,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createDataStream to class CreateDataStreamClusterStateUpdateRequest","description":"Move method createDataStream to org.elasticsearch.cluster.metadata.MetadataCreateDataStreamService.CreateDataStreamClusterStateUpdateRequest\nRationale: The createDataStream() method is closely related to the operation of creating a data stream, which is directly associated with the CreateDataStreamClusterStateUpdateRequest class. Moving this method to the target class adheres to the Single Responsibility Principle, as it consolidates the functionality related to data stream creation within a single class. This enhances cohesion, as the method will now reside alongside the relevant data and operations that pertain to creating a data stream. Furthermore, this move aligns with the Open/Closed Principle, allowing the CreateDataStreamClusterStateUpdateRequest class to be extended with additional functionality related to data streams without modifying existing code. However, one consideration is that the method\u0027s dependencies, such as metadataCreateIndexService and clusterService, may need to be passed into the target class or managed differently, which could complicate the class\u0027s design.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":191,"lineEnd":209,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createDataStream to class ClusterStateTaskExecutorUtils","description":"move method createDataStream to PsiClass:ClusterStateTaskExecutorUtils\nRationale: The createDataStream() method is involved in creating and managing cluster states, which aligns well with the responsibilities of ClusterStateTaskExecutorUtils. Moving it here adheres to the Single Responsibility Principle, as this class is focused on executing tasks related to cluster state management. This change would enhance cohesion and maintainability. However, care must be taken to ensure that dependencies on other components are managed correctly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":191,"lineEnd":209,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createDataStream to class DesiredNodesMetadata","description":"move method createDataStream to PsiClass:DesiredNodesMetadata\nRationale: The createDataStream() method deals with metadata related to cluster states, which is a core aspect of DesiredNodesMetadata. Relocating it here would enhance the encapsulation of metadata-related functionalities. This aligns with the Open/Closed Principle, allowing for future extensions to metadata handling without modifying existing code. A potential drawback is that it may increase the complexity of DesiredNodesMetadata if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":191,"lineEnd":209,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createDataStream to class Builder","description":"move method createDataStream to PsiClass:Builder\nRationale: The Builder class is likely responsible for constructing various components of the cluster state. The createDataStream() method, which constructs a data stream, fits well within this context. This move adheres to the Single Responsibility Principle and enhances the Builder\u0027s role in managing object creation. However, it may lead to a bloated Builder class if too many functionalities are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":123,"lineEnd":126,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method submitUnbatchedTask to class ClusterService","description":"Move method submitUnbatchedTask to org.elasticsearch.cluster.service.ClusterService\nRationale: The submitUnbatchedTask() method directly invokes the submitUnbatchedStateUpdateTask() method of the ClusterService, indicating a strong relationship between the two. Moving submitUnbatchedTask() to ClusterService enhances cohesion, as it centralizes functionality related to task submission within the class that manages cluster state updates. This aligns with the Single Responsibility Principle, as ClusterService is responsible for handling tasks related to cluster state, and it reduces the coupling of the method with its current class. However, care must be taken to ensure that any dependencies or context required by the method are adequately handled in the ClusterService.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"submitUnbatchedTask","method_signature":"@SuppressForbidden(reason \u003d \"legacy usage of unbatched task\") // TODO add support for batching here\n    private submitUnbatchedTask(@SuppressWarnings(\"SameParameterValue\") String source, ClusterStateUpdateTask task)","target_class":"","rationale":""},{"method_name":"createDataStream","method_signature":"public createDataStream(\n        CreateDataStreamClusterStateUpdateRequest request,\n        ClusterState current,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},{"method_name":"isSystem","method_signature":"public isSystem()","target_class":"","rationale":""},{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        List\u003cIndexMetadata\u003e backingIndices,\n        IndexMetadata writeIndex,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},{"method_name":"createBackingIndex","method_signature":"private static createBackingIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        ClusterState currentState,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener,\n        String dataStreamName,\n        SystemDataStreamDescriptor systemDataStreamDescriptor,\n        boolean isSystem,\n        ComposableIndexTemplate template,\n        String firstBackingIndexName\n    )","target_class":"","rationale":""},{"method_name":"createFailureStoreIndex","method_signature":"public static createFailureStoreIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        String cause,\n        Settings settings,\n        ClusterState currentState,\n        long nameResolvedInstant,\n        String dataStreamName,\n        ComposableIndexTemplate template,\n        String failureStoreIndexName,\n        @Nullable BiConsumer\u003cMetadata.Builder, IndexMetadata\u003e metadataTransformer\n    )","target_class":"","rationale":""},{"method_name":"lookupTemplateForDataStream","method_signature":"public static lookupTemplateForDataStream(String dataStreamName, Metadata metadata)","target_class":"","rationale":""},{"method_name":"validateTimestampFieldMapping","method_signature":"public static validateTimestampFieldMapping(MappingLookup mappingLookup)","target_class":"","rationale":""},{"method_name":"getFailureStoreRefreshInterval","method_signature":"public static getFailureStoreRefreshInterval(Settings settings)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"createDataStream","method_signature":"public createDataStream(\n        CreateDataStreamClusterStateUpdateRequest request,\n        ClusterState current,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},{"method_name":"submitUnbatchedTask","method_signature":"@SuppressForbidden(reason \u003d \"legacy usage of unbatched task\") // TODO add support for batching here\n    private submitUnbatchedTask(@SuppressWarnings(\"SameParameterValue\") String source, ClusterStateUpdateTask task)","target_class":"","rationale":""},{"method_name":"getFailureStoreRefreshInterval","method_signature":"public static getFailureStoreRefreshInterval(Settings settings)","target_class":"","rationale":""},{"method_name":"isSystem","method_signature":"public isSystem()","target_class":"","rationale":""},{"method_name":"validateTimestampFieldMapping","method_signature":"public static validateTimestampFieldMapping(MappingLookup mappingLookup)","target_class":"","rationale":""},{"method_name":"createBackingIndex","method_signature":"private static createBackingIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        ClusterState currentState,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener,\n        String dataStreamName,\n        SystemDataStreamDescriptor systemDataStreamDescriptor,\n        boolean isSystem,\n        ComposableIndexTemplate template,\n        String firstBackingIndexName\n    )","target_class":"","rationale":""},{"method_name":"lookupTemplateForDataStream","method_signature":"public static lookupTemplateForDataStream(String dataStreamName, Metadata metadata)","target_class":"","rationale":""},{"method_name":"createFailureStoreIndex","method_signature":"public static createFailureStoreIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        String cause,\n        Settings settings,\n        ClusterState currentState,\n        long nameResolvedInstant,\n        String dataStreamName,\n        ComposableIndexTemplate template,\n        String failureStoreIndexName,\n        @Nullable BiConsumer\u003cMetadata.Builder, IndexMetadata\u003e metadataTransformer\n    )","target_class":"","rationale":""},{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        List\u003cIndexMetadata\u003e backingIndices,\n        IndexMetadata writeIndex,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public createDataStream(\n        CreateDataStreamClusterStateUpdateRequest request,\n        ClusterState current,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )":{"first":{"method_name":"createDataStream","method_signature":"public createDataStream(\n        CreateDataStreamClusterStateUpdateRequest request,\n        ClusterState current,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},"second":0.32086461750127787},"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )":{"first":{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},"second":0.3458452987576967},"@SuppressForbidden(reason \u003d \"legacy usage of unbatched task\") // TODO add support for batching here\n    private submitUnbatchedTask(@SuppressWarnings(\"SameParameterValue\") String source, ClusterStateUpdateTask task)":{"first":{"method_name":"submitUnbatchedTask","method_signature":"@SuppressForbidden(reason \u003d \"legacy usage of unbatched task\") // TODO add support for batching here\n    private submitUnbatchedTask(@SuppressWarnings(\"SameParameterValue\") String source, ClusterStateUpdateTask task)","target_class":"","rationale":""},"second":0.3738527743217639},"public static getFailureStoreRefreshInterval(Settings settings)":{"first":{"method_name":"getFailureStoreRefreshInterval","method_signature":"public static getFailureStoreRefreshInterval(Settings settings)","target_class":"","rationale":""},"second":0.3753770782030127},"public isSystem()":{"first":{"method_name":"isSystem","method_signature":"public isSystem()","target_class":"","rationale":""},"second":0.3979894821048315},"public static validateTimestampFieldMapping(MappingLookup mappingLookup)":{"first":{"method_name":"validateTimestampFieldMapping","method_signature":"public static validateTimestampFieldMapping(MappingLookup mappingLookup)","target_class":"","rationale":""},"second":0.43832014111474155},"private static createBackingIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        ClusterState currentState,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener,\n        String dataStreamName,\n        SystemDataStreamDescriptor systemDataStreamDescriptor,\n        boolean isSystem,\n        ComposableIndexTemplate template,\n        String firstBackingIndexName\n    )":{"first":{"method_name":"createBackingIndex","method_signature":"private static createBackingIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        ClusterState currentState,\n        CreateDataStreamClusterStateUpdateRequest request,\n        ActionListener\u003cVoid\u003e rerouteListener,\n        String dataStreamName,\n        SystemDataStreamDescriptor systemDataStreamDescriptor,\n        boolean isSystem,\n        ComposableIndexTemplate template,\n        String firstBackingIndexName\n    )","target_class":"","rationale":""},"second":0.5689736316470596},"public static lookupTemplateForDataStream(String dataStreamName, Metadata metadata)":{"first":{"method_name":"lookupTemplateForDataStream","method_signature":"public static lookupTemplateForDataStream(String dataStreamName, Metadata metadata)","target_class":"","rationale":""},"second":0.5964376199116994},"public static createFailureStoreIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        String cause,\n        Settings settings,\n        ClusterState currentState,\n        long nameResolvedInstant,\n        String dataStreamName,\n        ComposableIndexTemplate template,\n        String failureStoreIndexName,\n        @Nullable BiConsumer\u003cMetadata.Builder, IndexMetadata\u003e metadataTransformer\n    )":{"first":{"method_name":"createFailureStoreIndex","method_signature":"public static createFailureStoreIndex(\n        MetadataCreateIndexService metadataCreateIndexService,\n        String cause,\n        Settings settings,\n        ClusterState currentState,\n        long nameResolvedInstant,\n        String dataStreamName,\n        ComposableIndexTemplate template,\n        String failureStoreIndexName,\n        @Nullable BiConsumer\u003cMetadata.Builder, IndexMetadata\u003e metadataTransformer\n    )","target_class":"","rationale":""},"second":0.6184968717406322},"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        List\u003cIndexMetadata\u003e backingIndices,\n        IndexMetadata writeIndex,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )":{"first":{"method_name":"createDataStream","method_signature":"static createDataStream(\n        MetadataCreateIndexService metadataCreateIndexService,\n        Settings settings,\n        ClusterState currentState,\n        boolean isDslOnlyMode,\n        CreateDataStreamClusterStateUpdateRequest request,\n        List\u003cIndexMetadata\u003e backingIndices,\n        IndexMetadata writeIndex,\n        ActionListener\u003cVoid\u003e rerouteListener\n    )","target_class":"","rationale":""},"second":0.6288948810399431}},"llmMethodPriority":{"priority_method_names":["createDataStream","createDataStream","submitUnbatchedTask","getFailureStoreRefreshInterval","isSystem","validateTimestampFieldMapping","createBackingIndex","lookupTemplateForDataStream","createFailureStoreIndex","createDataStream"],"llm_response_time":4525},"targetClassMap":{"createDataStream":{"target_classes":[{"class_name":"ClusterChangedEventUtils","similarity_score":0.1965021149155211},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.211088407298143},{"class_name":"DiffableUtils","similarity_score":0.20418207547110073},{"class_name":"DiscoveryNodeUtils","similarity_score":0.19408793885642783},{"class_name":"ClusterInfoServiceUtils","similarity_score":0.1951654938877865},{"class_name":"ClusterStateTaskExecutorUtils","similarity_score":0.2575131682722956},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.11834985557589607},{"class_name":"StringSetValueSerializer","similarity_score":0.18972148249856305},{"class_name":"DesiredNode","similarity_score":0.2531284953253443},{"class_name":"DesiredNodes","similarity_score":0.17613347238883928},{"class_name":"DesiredNodeSerializationTests","similarity_score":0.16943594767957704},{"class_name":"DesiredNodesMetadata","similarity_score":0.22901726378735407},{"class_name":"DesiredNodesMetadataSerializationTests","similarity_score":0.22896057111996093},{"class_name":"DesiredNodesSerializationTests","similarity_score":0.18683693915270333},{"class_name":"DesiredNodesTests","similarity_score":0.13459277385202914},{"class_name":"DesiredNodeWithStatus","similarity_score":0.21245553109475948},{"class_name":"DesiredNodeWithStatusSerializationTests","similarity_score":0.22659023908703443},{"class_name":"AutoExpandReplicas","similarity_score":0.16533867609443648},{"class_name":"AverageShardSize","similarity_score":0.2251446939298139},{"class_name":"DiffableStringMap","similarity_score":0.20706541143256688},{"class_name":"DiffableStringMapDiff","similarity_score":0.18394400695699523},{"class_name":"Retention","similarity_score":0.13279059849505107},{"class_name":"Builder","similarity_score":0.21379466588819068},{"class_name":"Round","similarity_score":0.1974894338931662},{"class_name":"ClusterNameExpressionResolver","similarity_score":0.20657733618514498},{"class_name":"LifecycleExecutionState","similarity_score":0.1759784720205428},{"class_name":"Downsampling","similarity_score":0.20490535202155594},{"class_name":"AliasMetadata","similarity_score":0.22298704766072217},{"class_name":"AliasMetadataTests","similarity_score":0.18125815823448593},{"class_name":"AliasValidator","similarity_score":0.14381193887613006}],"target_classes_sorted_by_llm":["ClusterStateTaskExecutorUtils","DesiredNodesMetadata","Builder","DesiredNodeWithStatus","MetadataIndexStateServiceUtils","AliasMetadata","AverageShardSize","DesiredNode","DesiredNodeWithStatusSerializationTests","DesiredNodesMetadataSerializationTests"],"llm_response_time":13286,"similarity_computation_time":24,"similarity_metric":"voyage"},"submitUnbatchedTask":{"target_classes":[{"class_name":"ClusterService","similarity_score":0.28873951592139746}],"target_classes_sorted_by_llm":["ClusterService"],"llm_response_time":2059,"similarity_computation_time":1,"similarity_metric":"voyage"}}}
{"id":"aefe35cd-cafc-4e2b-ac24-1fb3a0e49593","methodCount":6,"hostFunctionTelemetryData":{"hostFunctionSize":86,"lineStart":39,"lineEnd":124,"bodyLineStart":39,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/security/src/main/java/org/elasticsearch/xpack/security/rest/action/apikey/RestGrantApiKeyAction.java","sourceCode":"/**\n * Rest action to create an API key on behalf of another user. Loosely mimics the API of\n * {@link org.elasticsearch.xpack.security.rest.action.oauth2.RestGetTokenAction} combined with {@link RestCreateApiKeyAction}\n */\n@ServerlessScope(Scope.INTERNAL)\npublic final class RestGrantApiKeyAction extends ApiKeyBaseRestHandler implements RestRequestFilter {\n\n    static final ObjectParser\u003cGrantApiKeyRequest, Void\u003e PARSER \u003d new ObjectParser\u003c\u003e(\"grant_api_key_request\", GrantApiKeyRequest::new);\n    static {\n        PARSER.declareString((req, str) -\u003e req.getGrant().setType(str), new ParseField(\"grant_type\"));\n        PARSER.declareString((req, str) -\u003e req.getGrant().setUsername(str), new ParseField(\"username\"));\n        PARSER.declareField(\n            (req, secStr) -\u003e req.getGrant().setPassword(secStr),\n            SecurityBaseRestHandler::getSecureString,\n            new ParseField(\"password\"),\n            ObjectParser.ValueType.STRING\n        );\n        PARSER.declareField(\n            (req, secStr) -\u003e req.getGrant().setAccessToken(secStr),\n            SecurityBaseRestHandler::getSecureString,\n            new ParseField(\"access_token\"),\n            ObjectParser.ValueType.STRING\n        );\n        PARSER.declareString((req, str) -\u003e req.getGrant().setRunAsUsername(str), new ParseField(\"run_as\"));\n        PARSER.declareObject(\n            (req, clientAuthentication) -\u003e req.getGrant().setClientAuthentication(clientAuthentication),\n            CLIENT_AUTHENTICATION_PARSER,\n            new ParseField(\"client_authentication\")\n        );\n        PARSER.declareObject(\n            (req, api) -\u003e req.setApiKeyRequest(api),\n            (parser, ignore) -\u003e CreateApiKeyRequestBuilder.parse(parser),\n            new ParseField(\"api_key\")\n        );\n    }\n\n    public RestGrantApiKeyAction(Settings settings, XPackLicenseState licenseState) {\n        super(settings, licenseState);\n    }\n\n    @Override\n    public List\u003cRoute\u003e routes() {\n        return List.of(new Route(POST, \"/_security/api_key/grant\"), new Route(PUT, \"/_security/api_key/grant\"));\n    }\n\n    @Override\n    public String getName() {\n        return \"xpack_security_grant_api_key\";\n    }\n\n    public static GrantApiKeyRequest fromXContent(XContentParser parser) throws IOException {\n        return PARSER.parse(parser, null);\n    }\n\n    @Override\n    protected RestChannelConsumer innerPrepareRequest(final RestRequest request, final NodeClient client) throws IOException {\n        String refresh \u003d request.param(\"refresh\");\n        try (XContentParser parser \u003d request.contentParser()) {\n            final GrantApiKeyRequest grantRequest \u003d fromXContent(parser);\n            if (refresh !\u003d null) {\n                grantRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.parse(refresh));\n            } else {\n                grantRequest.setRefreshPolicy(ApiKeyService.defaultCreateDocRefreshPolicy(settings));\n            }\n            return channel -\u003e client.execute(\n                GrantApiKeyAction.INSTANCE,\n                grantRequest,\n                new RestToXContentListener\u003cCreateApiKeyResponse\u003e(channel).delegateResponse((listener, ex) -\u003e {\n                    RestStatus status \u003d ExceptionsHelper.status(ex);\n                    if (status \u003d\u003d RestStatus.UNAUTHORIZED) {\n                        listener.onFailure(\n                            new ElasticsearchSecurityException(\"Failed to authenticate api key grant\", RestStatus.FORBIDDEN, ex)\n                        );\n                    } else {\n                        listener.onFailure(ex);\n                    }\n                })\n            );\n        }\n    }\n\n    @Override\n    public Set\u003cString\u003e getFilteredFields() {\n        return Set.of(\"password\", \"access_token\", \"client_authentication.value\");\n    }\n}","methodCount":6},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":88,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestSamlAuthenticateAction","description":"move method fromXContent to PsiClass:RestSamlAuthenticateAction\nRationale: The fromXContent() method is responsible for parsing requests, which aligns well with the RestSamlAuthenticateAction\u0027s functionality of handling authentication requests. Moving it here enhances cohesion by placing parsing logic directly within the context of the action it supports. This adheres to the Single Responsibility Principle, as it centralizes request parsing related to SAML authentication. However, consider the potential need for additional dependencies in this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":88,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class RestActivateProfileAction","description":"move method fromXContent to PsiClass:RestActivateProfileAction\nRationale: The fromXContent() method is a utility for creating request objects from input parsers, which is relevant for actions like RestActivateProfileAction that handle incoming requests. This relocation improves the organization of request handling logic within the action classes, enhancing maintainability. It follows the Open/Closed Principle by allowing future extensions for different request types without modifying existing implementations. However, it may lead to tighter coupling between the action and parsing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":88,"lineEnd":90,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromXContent to class ActionUtils","description":"move method fromXContent to PsiClass:ActionUtils\nRationale: The fromXContent() method serves as a utility for parsing requests, which aligns with the utility nature of ActionUtils. This class is designed for common action-related functionalities, and moving the method here would encapsulate shared parsing logic. This adheres to the DRY principle, reducing code duplication across different actions. However, it may dilute the focus of ActionUtils if it becomes overloaded with diverse utility methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.436448136915992}},"llmMethodPriority":{"priority_method_names":["fromXContent"],"llm_response_time":1253},"targetClassMap":{"fromXContent":{"target_classes":[{"class_name":"RestGetApiKeyActionTests","similarity_score":0.28958895497038045},{"class_name":"RestInvalidateApiKeyAction","similarity_score":0.43092978905128787},{"class_name":"JwkValidateUtil","similarity_score":0.3117434455959207},{"class_name":"JwkValidateUtilTests","similarity_score":0.4431333960293278},{"class_name":"LdapTestUtils","similarity_score":0.21160368475757949},{"class_name":"LdapUtils","similarity_score":0.328587429046192},{"class_name":"ActionUtils","similarity_score":0.4775669329409193},{"class_name":"ActiveDirectorySIDUtil","similarity_score":0.14864362196288647},{"class_name":"AuditUtil","similarity_score":0.5034635935616699},{"class_name":"AuthorizationUtils","similarity_score":0.15230064305321395},{"class_name":"SamlUtils","similarity_score":0.4654479266975149},{"class_name":"ModelLoaderUtils","similarity_score":0.41896092161101767},{"class_name":"CommandUtils","similarity_score":0.21256643739415104},{"class_name":"AnalyticsTransportActionTestUtils","similarity_score":0.2430086349933022},{"class_name":"SecurityTestUtils","similarity_score":0.4057513356003446},{"class_name":"PreAuthorizationUtils","similarity_score":0.2786519913815596},{"class_name":"CertGenUtils","similarity_score":0.2298096520987102},{"class_name":"CertGenUtilsTests","similarity_score":0.2638702468322713},{"class_name":"SSLEngineUtils","similarity_score":0.3910531815971874},{"class_name":"Utils","similarity_score":0.29673273237950815},{"class_name":"VectorTileUtils","similarity_score":0.35456789308198466},{"class_name":"RestSamlAuthenticateAction","similarity_score":0.49568159709660975},{"class_name":"CreateTokenResponseActionListener","similarity_score":0.35544913281861495},{"class_name":"RestActivateProfileAction","similarity_score":0.5187564749039544},{"class_name":"RestAuthenticateActionTests","similarity_score":0.4437321974201278},{"class_name":"RestGetPrivilegesAction","similarity_score":0.45256282220142047},{"class_name":"RestPutPrivilegesAction","similarity_score":0.46028324996028647},{"class_name":"JwtUtil","similarity_score":0.3790163493744628},{"class_name":"LicenseUtils","similarity_score":0.43301270189221935}],"target_classes_sorted_by_llm":["RestSamlAuthenticateAction","RestActivateProfileAction","ActionUtils","SamlUtils","RestGetPrivilegesAction","RestPutPrivilegesAction","AuditUtil","RestAuthenticateActionTests","JwkValidateUtilTests","LicenseUtils"],"llm_response_time":0,"similarity_computation_time":33,"similarity_metric":"voyage"}}}
{"id":"8223f23b-b288-49bf-be74-b35822bd105b","methodCount":13,"hostFunctionTelemetryData":{"hostFunctionSize":261,"lineStart":236,"lineEnd":496,"bodyLineStart":236,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/index/mapper/TextFieldMapper.java","sourceCode":"public static class Builder extends FieldMapper.Builder {\n\n        private final IndexVersion indexCreatedVersion;\n        private final Parameter\u003cBoolean\u003e store;\n\n        private final boolean isSyntheticSourceEnabledViaIndexMode;\n\n        private final Parameter\u003cBoolean\u003e index \u003d Parameter.indexParam(m -\u003e ((TextFieldMapper) m).index, true);\n\n        final Parameter\u003cSimilarityProvider\u003e similarity \u003d TextParams.similarity(m -\u003e ((TextFieldMapper) m).similarity);\n\n        final Parameter\u003cString\u003e indexOptions \u003d TextParams.textIndexOptions(m -\u003e ((TextFieldMapper) m).indexOptions);\n        final Parameter\u003cBoolean\u003e norms \u003d TextParams.norms(true, m -\u003e ((TextFieldMapper) m).norms);\n        final Parameter\u003cString\u003e termVectors \u003d TextParams.termVectors(m -\u003e ((TextFieldMapper) m).termVectors);\n\n        final Parameter\u003cBoolean\u003e fieldData \u003d Parameter.boolParam(\"fielddata\", true, m -\u003e ((TextFieldMapper) m).fieldData, false);\n        final Parameter\u003cFielddataFrequencyFilter\u003e freqFilter \u003d new Parameter\u003c\u003e(\n            \"fielddata_frequency_filter\",\n            true,\n            () -\u003e DEFAULT_FILTER,\n            TextFieldMapper::parseFrequencyFilter,\n            m -\u003e ((TextFieldMapper) m).freqFilter,\n            XContentBuilder::field,\n            Objects::toString\n        );\n        final Parameter\u003cBoolean\u003e eagerGlobalOrdinals \u003d Parameter.boolParam(\n            \"eager_global_ordinals\",\n            true,\n            m -\u003e ((TextFieldMapper) m).fieldType().eagerGlobalOrdinals,\n            false\n        );\n\n        final Parameter\u003cBoolean\u003e indexPhrases \u003d Parameter.boolParam(\n            \"index_phrases\",\n            false,\n            m -\u003e ((TextFieldMapper) m).fieldType().indexPhrases,\n            false\n        );\n        final Parameter\u003cPrefixConfig\u003e indexPrefixes \u003d new Parameter\u003c\u003e(\n            \"index_prefixes\",\n            false,\n            () -\u003e null,\n            TextFieldMapper::parsePrefixConfig,\n            m -\u003e ((TextFieldMapper) m).indexPrefixes,\n            XContentBuilder::field,\n            Objects::toString\n        ).acceptsNull();\n\n        private final Parameter\u003cMap\u003cString, String\u003e\u003e meta \u003d Parameter.metaParam();\n\n        final TextParams.Analyzers analyzers;\n\n        public Builder(String name, IndexAnalyzers indexAnalyzers, boolean isSyntheticSourceEnabledViaIndexMode) {\n            this(name, IndexVersion.current(), indexAnalyzers, isSyntheticSourceEnabledViaIndexMode);\n        }\n\n        public Builder(\n            String name,\n            IndexVersion indexCreatedVersion,\n            IndexAnalyzers indexAnalyzers,\n            boolean isSyntheticSourceEnabledViaIndexMode\n        ) {\n            super(name);\n\n            // If synthetic source is used we need to either store this field\n            // to recreate the source or use keyword multi-fields for that.\n            // So if there are no suitable multi-fields we will default to\n            // storing the field without requiring users to explicitly set \u0027store\u0027.\n            //\n            // If \u0027store\u0027 parameter was explicitly provided we\u0027ll reject the request.\n            this.store \u003d Parameter.storeParam(\n                m -\u003e ((TextFieldMapper) m).store,\n                () -\u003e isSyntheticSourceEnabledViaIndexMode \u0026\u0026 multiFieldsBuilder.hasSyntheticSourceCompatibleKeywordField() \u003d\u003d false\n            );\n            this.indexCreatedVersion \u003d indexCreatedVersion;\n            this.analyzers \u003d new TextParams.Analyzers(\n                indexAnalyzers,\n                m -\u003e ((TextFieldMapper) m).indexAnalyzer,\n                m -\u003e (((TextFieldMapper) m).positionIncrementGap),\n                indexCreatedVersion\n            );\n            this.isSyntheticSourceEnabledViaIndexMode \u003d isSyntheticSourceEnabledViaIndexMode;\n        }\n\n        public Builder index(boolean index) {\n            this.index.setValue(index);\n            return this;\n        }\n\n        public Builder store(boolean store) {\n            this.store.setValue(store);\n            return this;\n        }\n\n        public Builder fielddata(boolean fielddata) {\n            this.fieldData.setValue(fielddata);\n            return this;\n        }\n\n        public Builder fielddataFrequencyFilter(double min, double max, int segs) {\n            this.freqFilter.setValue(new FielddataFrequencyFilter(min, max, segs));\n            return this;\n        }\n\n        public Builder addMultiField(FieldMapper.Builder builder) {\n            this.multiFieldsBuilder.add(builder);\n            return this;\n        }\n\n        @Override\n        protected Parameter\u003c?\u003e[] getParameters() {\n            return new Parameter\u003c?\u003e[] {\n                index,\n                store,\n                indexOptions,\n                norms,\n                termVectors,\n                analyzers.indexAnalyzer,\n                analyzers.searchAnalyzer,\n                analyzers.searchQuoteAnalyzer,\n                similarity,\n                analyzers.positionIncrementGap,\n                fieldData,\n                freqFilter,\n                eagerGlobalOrdinals,\n                indexPhrases,\n                indexPrefixes,\n                meta };\n        }\n\n        private TextFieldType buildFieldType(\n            FieldType fieldType,\n            MultiFields multiFields,\n            MapperBuilderContext context,\n            IndexVersion indexCreatedVersion\n        ) {\n            NamedAnalyzer searchAnalyzer \u003d analyzers.getSearchAnalyzer();\n            NamedAnalyzer searchQuoteAnalyzer \u003d analyzers.getSearchQuoteAnalyzer();\n            if (analyzers.positionIncrementGap.isConfigured()) {\n                if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) \u003c 0) {\n                    throw new IllegalArgumentException(\n                        \"Cannot set position_increment_gap on field [\" + name() + \"] without positions enabled\"\n                    );\n                }\n            }\n            TextSearchInfo tsi \u003d new TextSearchInfo(fieldType, similarity.getValue(), searchAnalyzer, searchQuoteAnalyzer);\n            TextFieldType ft;\n            if (indexCreatedVersion.isLegacyIndexVersion()) {\n                ft \u003d new LegacyTextFieldType(context.buildFullName(name()), index.getValue(), store.getValue(), tsi, meta.getValue());\n                // ignore fieldData and eagerGlobalOrdinals\n            } else {\n                ft \u003d new TextFieldType(\n                    context.buildFullName(name()),\n                    index.getValue(),\n                    store.getValue(),\n                    tsi,\n                    context.isSourceSynthetic(),\n                    syntheticSourceDelegate(fieldType, multiFields),\n                    meta.getValue(),\n                    eagerGlobalOrdinals.getValue(),\n                    indexPhrases.getValue()\n                );\n                if (fieldData.getValue()) {\n                    ft.setFielddata(true, freqFilter.getValue());\n                }\n            }\n            return ft;\n        }\n\n        private static KeywordFieldMapper.KeywordFieldType syntheticSourceDelegate(FieldType fieldType, MultiFields multiFields) {\n            if (fieldType.stored()) {\n                return null;\n            }\n            var kwd \u003d getKeywordFieldMapperForSyntheticSource(multiFields);\n            if (kwd !\u003d null) {\n                return kwd.fieldType();\n            }\n            return null;\n        }\n\n        private SubFieldInfo buildPrefixInfo(MapperBuilderContext context, FieldType fieldType, TextFieldType tft) {\n            if (indexPrefixes.get() \u003d\u003d null) {\n                return null;\n            }\n            if (index.getValue() \u003d\u003d false) {\n                throw new IllegalArgumentException(\"Cannot set index_prefixes on unindexed field [\" + name() + \"]\");\n            }\n            /*\n             * Mappings before v7.2.1 use {@link Builder#name} instead of {@link Builder#fullName}\n             * to build prefix field names so we preserve the name that was used at creation time\n             * even if it is different from the expected one (in case the field is nested under an object\n             * or a multi-field). This way search will continue to work on old indices and new indices\n             * will use the expected full name.\n             */\n            String fullName \u003d indexCreatedVersion.before(IndexVersions.V_7_2_1) ? name() : context.buildFullName(name());\n            // Copy the index options of the main field to allow phrase queries on\n            // the prefix field.\n            FieldType pft \u003d new FieldType(fieldType);\n            pft.setOmitNorms(true);\n            if (fieldType.indexOptions() \u003d\u003d IndexOptions.DOCS_AND_FREQS) {\n                // frequencies are not needed because prefix queries always use a constant score\n                pft.setIndexOptions(IndexOptions.DOCS);\n            } else {\n                pft.setIndexOptions(fieldType.indexOptions());\n            }\n            if (fieldType.storeTermVectorOffsets()) {\n                pft.setStoreTermVectorOffsets(true);\n            }\n            tft.setIndexPrefixes(indexPrefixes.get().minChars, indexPrefixes.get().maxChars);\n            return new SubFieldInfo(\n                fullName + \"._index_prefix\",\n                pft,\n                new PrefixWrappedAnalyzer(\n                    analyzers.getIndexAnalyzer().analyzer(),\n                    analyzers.positionIncrementGap.get(),\n                    indexPrefixes.get().minChars,\n                    indexPrefixes.get().maxChars\n                )\n            );\n        }\n\n        private SubFieldInfo buildPhraseInfo(FieldType fieldType, TextFieldType parent) {\n            if (indexPhrases.get() \u003d\u003d false) {\n                return null;\n            }\n            if (index.get() \u003d\u003d false) {\n                throw new IllegalArgumentException(\"Cannot set index_phrases on unindexed field [\" + name() + \"]\");\n            }\n            if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) \u003c 0) {\n                throw new IllegalArgumentException(\"Cannot set index_phrases on field [\" + name() + \"] if positions are not enabled\");\n            }\n            FieldType phraseFieldType \u003d new FieldType(fieldType);\n            PhraseWrappedAnalyzer a \u003d new PhraseWrappedAnalyzer(\n                analyzers.getIndexAnalyzer().analyzer(),\n                analyzers.positionIncrementGap.get()\n            );\n            return new SubFieldInfo(parent.name() + FAST_PHRASE_SUFFIX, phraseFieldType, a);\n        }\n\n        @Override\n        public TextFieldMapper build(MapperBuilderContext context) {\n            MultiFields multiFields \u003d multiFieldsBuilder.build(this, context);\n            FieldType fieldType \u003d TextParams.buildFieldType(\n                index,\n                store,\n                indexOptions,\n                // legacy indices do not have access to norms\n                indexCreatedVersion.isLegacyIndexVersion() ? () -\u003e false : norms,\n                termVectors\n            );\n            TextFieldType tft \u003d buildFieldType(fieldType, multiFields, context, indexCreatedVersion);\n            SubFieldInfo phraseFieldInfo \u003d buildPhraseInfo(fieldType, tft);\n            SubFieldInfo prefixFieldInfo \u003d buildPrefixInfo(context, fieldType, tft);\n            for (Mapper mapper : multiFields) {\n                if (mapper.name().endsWith(FAST_PHRASE_SUFFIX) || mapper.name().endsWith(FAST_PREFIX_SUFFIX)) {\n                    throw new MapperParsingException(\"Cannot use reserved field name [\" + mapper.name() + \"]\");\n                }\n            }\n            return new TextFieldMapper(name(), fieldType, tft, prefixFieldInfo, phraseFieldInfo, multiFields, copyTo, this);\n        }\n    }","methodCount":13},"candidatesTelemetryData":{"numberOfSuggestions":0,"candidates":[]},"processingTime":{"llmResponseTime":-1,"pluginProcessingTime":-1,"totalTime":25072},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"index","method_signature":"public index(boolean index)","target_class":"","rationale":""},{"method_name":"store","method_signature":"public store(boolean store)","target_class":"","rationale":""},{"method_name":"fielddata","method_signature":"public fielddata(boolean fielddata)","target_class":"","rationale":""},{"method_name":"fielddataFrequencyFilter","method_signature":"public fielddataFrequencyFilter(double min, double max, int segs)","target_class":"","rationale":""},{"method_name":"addMultiField","method_signature":"public addMultiField(FieldMapper.Builder builder)","target_class":"","rationale":""},{"method_name":"buildFieldType","method_signature":"private buildFieldType(\n            FieldType fieldType,\n            MultiFields multiFields,\n            MapperBuilderContext context,\n            IndexVersion indexCreatedVersion\n        )","target_class":"","rationale":""},{"method_name":"syntheticSourceDelegate","method_signature":"private static syntheticSourceDelegate(FieldType fieldType, MultiFields multiFields)","target_class":"","rationale":""},{"method_name":"buildPrefixInfo","method_signature":"private buildPrefixInfo(MapperBuilderContext context, FieldType fieldType, TextFieldType tft)","target_class":"","rationale":""},{"method_name":"buildPhraseInfo","method_signature":"private buildPhraseInfo(FieldType fieldType, TextFieldType parent)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fielddataFrequencyFilter","method_signature":"public fielddataFrequencyFilter(double min, double max, int segs)","target_class":"","rationale":""},{"method_name":"index","method_signature":"public index(boolean index)","target_class":"","rationale":""},{"method_name":"store","method_signature":"public store(boolean store)","target_class":"","rationale":""},{"method_name":"fielddata","method_signature":"public fielddata(boolean fielddata)","target_class":"","rationale":""},{"method_name":"addMultiField","method_signature":"public addMultiField(FieldMapper.Builder builder)","target_class":"","rationale":""},{"method_name":"buildPrefixInfo","method_signature":"private buildPrefixInfo(MapperBuilderContext context, FieldType fieldType, TextFieldType tft)","target_class":"","rationale":""},{"method_name":"syntheticSourceDelegate","method_signature":"private static syntheticSourceDelegate(FieldType fieldType, MultiFields multiFields)","target_class":"","rationale":""},{"method_name":"buildPhraseInfo","method_signature":"private buildPhraseInfo(FieldType fieldType, TextFieldType parent)","target_class":"","rationale":""},{"method_name":"buildFieldType","method_signature":"private buildFieldType(\n            FieldType fieldType,\n            MultiFields multiFields,\n            MapperBuilderContext context,\n            IndexVersion indexCreatedVersion\n        )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public fielddataFrequencyFilter(double min, double max, int segs)":{"first":{"method_name":"fielddataFrequencyFilter","method_signature":"public fielddataFrequencyFilter(double min, double max, int segs)","target_class":"","rationale":""},"second":0.34902491996027907},"public index(boolean index)":{"first":{"method_name":"index","method_signature":"public index(boolean index)","target_class":"","rationale":""},"second":0.4411755839080195},"public store(boolean store)":{"first":{"method_name":"store","method_signature":"public store(boolean store)","target_class":"","rationale":""},"second":0.4411755839080195},"public fielddata(boolean fielddata)":{"first":{"method_name":"fielddata","method_signature":"public fielddata(boolean fielddata)","target_class":"","rationale":""},"second":0.4411755839080195},"public addMultiField(FieldMapper.Builder builder)":{"first":{"method_name":"addMultiField","method_signature":"public addMultiField(FieldMapper.Builder builder)","target_class":"","rationale":""},"second":0.4411755839080195},"private buildPrefixInfo(MapperBuilderContext context, FieldType fieldType, TextFieldType tft)":{"first":{"method_name":"buildPrefixInfo","method_signature":"private buildPrefixInfo(MapperBuilderContext context, FieldType fieldType, TextFieldType tft)","target_class":"","rationale":""},"second":0.5306901107038065},"private static syntheticSourceDelegate(FieldType fieldType, MultiFields multiFields)":{"first":{"method_name":"syntheticSourceDelegate","method_signature":"private static syntheticSourceDelegate(FieldType fieldType, MultiFields multiFields)","target_class":"","rationale":""},"second":0.5366060516016508},"private buildPhraseInfo(FieldType fieldType, TextFieldType parent)":{"first":{"method_name":"buildPhraseInfo","method_signature":"private buildPhraseInfo(FieldType fieldType, TextFieldType parent)","target_class":"","rationale":""},"second":0.5941196731839499},"private buildFieldType(\n            FieldType fieldType,\n            MultiFields multiFields,\n            MapperBuilderContext context,\n            IndexVersion indexCreatedVersion\n        )":{"first":{"method_name":"buildFieldType","method_signature":"private buildFieldType(\n            FieldType fieldType,\n            MultiFields multiFields,\n            MapperBuilderContext context,\n            IndexVersion indexCreatedVersion\n        )","target_class":"","rationale":""},"second":0.6421422480001349}},"llmMethodPriority":{"priority_method_names":["fielddataFrequencyFilter","index","store","fielddata","addMultiField","buildPrefixInfo","buildPhraseInfo","syntheticSourceDelegate","buildFieldType"],"llm_response_time":2112},"targetClassMap":{"fielddataFrequencyFilter":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":462,"similarity_computation_time":0,"similarity_metric":"voyage"},"index":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":385,"similarity_computation_time":0,"similarity_metric":"voyage"},"store":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":452,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"855b41d5-954d-4c40-afb8-712619eca8c6","methodCount":40,"hostFunctionTelemetryData":{"hostFunctionSize":493,"lineStart":44,"lineEnd":536,"bodyLineStart":44,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/cluster/metadata/DataStreamLifecycle.java","sourceCode":"/**\n * Holds the data stream lifecycle metadata that are configuring how a data stream is managed. Currently, it supports the following\n * configurations:\n * - enabled\n * - data retention\n * - downsampling\n */\npublic class DataStreamLifecycle implements SimpleDiffable\u003cDataStreamLifecycle\u003e, ToXContentObject {\n\n    // Versions over the wire\n    public static final TransportVersion ADDED_ENABLED_FLAG_VERSION \u003d TransportVersions.V_8_10_X;\n\n    public static final String DATA_STREAMS_LIFECYCLE_ONLY_SETTING_NAME \u003d \"data_streams.lifecycle_only.mode\";\n    // The following XContent params are used to enrich the DataStreamLifecycle json with effective retention information\n    // This should be set only when the lifecycle is used in a response to the user and NEVER when we expect the json to\n    // be deserialized.\n    public static final String INCLUDE_EFFECTIVE_RETENTION_PARAM_NAME \u003d \"include_effective_retention\";\n    public static final Map\u003cString, String\u003e INCLUDE_EFFECTIVE_RETENTION_PARAMS \u003d Map.of(\n        DataStreamLifecycle.INCLUDE_EFFECTIVE_RETENTION_PARAM_NAME,\n        \"true\"\n    );\n\n    /**\n     * Check if {@link #DATA_STREAMS_LIFECYCLE_ONLY_SETTING_NAME} is present and set to {@code true}, indicating that\n     * we\u0027re running in a cluster configuration that is only expecting to use data streams lifecycles.\n     *\n     * @param settings the node settings\n     * @return true if {@link #DATA_STREAMS_LIFECYCLE_ONLY_SETTING_NAME} is present and set\n     */\n    public static boolean isDataStreamsLifecycleOnlyMode(final Settings settings) {\n        return settings.getAsBoolean(DATA_STREAMS_LIFECYCLE_ONLY_SETTING_NAME, false);\n    }\n\n    public static final Setting\u003cRolloverConfiguration\u003e CLUSTER_LIFECYCLE_DEFAULT_ROLLOVER_SETTING \u003d new Setting\u003c\u003e(\n        \"cluster.lifecycle.default.rollover\",\n        \"max_age\u003dauto,max_primary_shard_size\u003d50gb,min_docs\u003d1,max_primary_shard_docs\u003d200000000\",\n        (s) -\u003e RolloverConfiguration.parseSetting(s, \"cluster.lifecycle.default.rollover\"),\n        Setting.Property.Dynamic,\n        Setting.Property.NodeScope\n    );\n\n    public static final DataStreamLifecycle DEFAULT \u003d new DataStreamLifecycle();\n\n    public static final String DATA_STREAM_LIFECYCLE_ORIGIN \u003d \"data_stream_lifecycle\";\n\n    public static final ParseField ENABLED_FIELD \u003d new ParseField(\"enabled\");\n    public static final ParseField DATA_RETENTION_FIELD \u003d new ParseField(\"data_retention\");\n    public static final ParseField EFFECTIVE_RETENTION_FIELD \u003d new ParseField(\"effective_retention\");\n    public static final ParseField RETENTION_SOURCE_FIELD \u003d new ParseField(\"retention_determined_by\");\n    public static final ParseField DOWNSAMPLING_FIELD \u003d new ParseField(\"downsampling\");\n    private static final ParseField ROLLOVER_FIELD \u003d new ParseField(\"rollover\");\n\n    public static final ConstructingObjectParser\u003cDataStreamLifecycle, Void\u003e PARSER \u003d new ConstructingObjectParser\u003c\u003e(\n        \"lifecycle\",\n        false,\n        (args, unused) -\u003e new DataStreamLifecycle((Retention) args[0], (Downsampling) args[1], (Boolean) args[2])\n    );\n\n    static {\n        PARSER.declareField(ConstructingObjectParser.optionalConstructorArg(), (p, c) -\u003e {\n            String value \u003d p.textOrNull();\n            if (value \u003d\u003d null) {\n                return Retention.NULL;\n            } else {\n                return new Retention(TimeValue.parseTimeValue(value, DATA_RETENTION_FIELD.getPreferredName()));\n            }\n        }, DATA_RETENTION_FIELD, ObjectParser.ValueType.STRING_OR_NULL);\n        PARSER.declareField(ConstructingObjectParser.optionalConstructorArg(), (p, c) -\u003e {\n            if (p.currentToken() \u003d\u003d XContentParser.Token.VALUE_NULL) {\n                return Downsampling.NULL;\n            } else {\n                return new Downsampling(AbstractObjectParser.parseArray(p, c, Downsampling.Round::fromXContent));\n            }\n        }, DOWNSAMPLING_FIELD, ObjectParser.ValueType.OBJECT_ARRAY_OR_NULL);\n        PARSER.declareBoolean(ConstructingObjectParser.optionalConstructorArg(), ENABLED_FIELD);\n    }\n\n    @Nullable\n    private final Retention dataRetention;\n    @Nullable\n    private final Downsampling downsampling;\n    private final boolean enabled;\n\n    public DataStreamLifecycle() {\n        this(null, null, null);\n    }\n\n    public DataStreamLifecycle(@Nullable Retention dataRetention, @Nullable Downsampling downsampling, @Nullable Boolean enabled) {\n        this.enabled \u003d enabled \u003d\u003d null || enabled;\n        this.dataRetention \u003d dataRetention;\n        this.downsampling \u003d downsampling;\n    }\n\n    /**\n     * Returns true, if this data stream lifecycle configuration is enabled and false otherwise\n     */\n    public boolean isEnabled() {\n        return enabled;\n    }\n\n    /**\n     * The least amount of time data should be kept by elasticsearch.\n     * @return the time period or null, null represents that data should never be deleted.\n     */\n    @Nullable\n    public TimeValue getEffectiveDataRetention(@Nullable DataStreamGlobalRetention globalRetention) {\n        return getEffectiveDataRetentionWithSource(globalRetention).v1();\n    }\n\n    /**\n     * The least amount of time data should be kept by elasticsearch.\n     * @return the time period or null, null represents that data should never be deleted.\n     */\n    @Nullable\n    public Tuple\u003cTimeValue, RetentionSource\u003e getEffectiveDataRetentionWithSource(@Nullable DataStreamGlobalRetention globalRetention) {\n        // If lifecycle is disabled there is no effective retention\n        if (enabled \u003d\u003d false) {\n            return Tuple.tuple(null, RetentionSource.DATA_STREAM_CONFIGURATION);\n        }\n        var dataStreamRetention \u003d getDataStreamRetention();\n        if (globalRetention \u003d\u003d null) {\n            return Tuple.tuple(dataStreamRetention, RetentionSource.DATA_STREAM_CONFIGURATION);\n        }\n        if (dataStreamRetention \u003d\u003d null) {\n            return globalRetention.getDefaultRetention() !\u003d null\n                ? Tuple.tuple(globalRetention.getDefaultRetention(), RetentionSource.DEFAULT_GLOBAL_RETENTION)\n                : Tuple.tuple(globalRetention.getMaxRetention(), RetentionSource.MAX_GLOBAL_RETENTION);\n        }\n        if (globalRetention.getMaxRetention() !\u003d null \u0026\u0026 globalRetention.getMaxRetention().getMillis() \u003c dataStreamRetention.getMillis()) {\n            return Tuple.tuple(globalRetention.getMaxRetention(), RetentionSource.MAX_GLOBAL_RETENTION);\n        } else {\n            return Tuple.tuple(dataStreamRetention, RetentionSource.DATA_STREAM_CONFIGURATION);\n        }\n    }\n\n    /**\n     * The least amount of time data the data stream is requesting es to keep the data.\n     * NOTE: this can be overridden by the {@link DataStreamLifecycle#getEffectiveDataRetention(DataStreamGlobalRetention)}.\n     * @return the time period or null, null represents that data should never be deleted.\n     */\n    @Nullable\n    public TimeValue getDataStreamRetention() {\n        return dataRetention \u003d\u003d null ? null : dataRetention.value;\n    }\n\n    /**\n     * The configuration as provided by the user about the least amount of time data should be kept by elasticsearch.\n     * This method differentiates between a missing retention and a nullified retention and this is useful for template\n     * composition.\n     * @return one of the following:\n     * - `null`, represents that the user did not provide data retention, this represents the user has no opinion about retention\n     * - `Retention{value \u003d null}`, represents that the user explicitly wants to have infinite retention\n     * - `Retention{value \u003d \"10d\"}`, represents that the user has requested the data to be kept at least 10d.\n     */\n    @Nullable\n    Retention getDataRetention() {\n        return dataRetention;\n    }\n\n    /**\n     * The configured downsampling rounds with the `after` and the `fixed_interval` per round. If downsampling is\n     * not configured then it returns null.\n     */\n    @Nullable\n    public List\u003cDownsampling.Round\u003e getDownsamplingRounds() {\n        return downsampling \u003d\u003d null ? null : downsampling.rounds();\n    }\n\n    /**\n     * Returns the configured wrapper object as it was defined in the template. This should be used only during\n     * template composition.\n     */\n    @Nullable\n    Downsampling getDownsampling() {\n        return downsampling;\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this \u003d\u003d o) return true;\n        if (o \u003d\u003d null || getClass() !\u003d o.getClass()) return false;\n\n        final DataStreamLifecycle that \u003d (DataStreamLifecycle) o;\n        return Objects.equals(dataRetention, that.dataRetention)\n            \u0026\u0026 Objects.equals(downsampling, that.downsampling)\n            \u0026\u0026 enabled \u003d\u003d that.enabled;\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(dataRetention, downsampling, enabled);\n    }\n\n    @Override\n    public void writeTo(StreamOutput out) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_9_X)) {\n            out.writeOptionalWriteable(dataRetention);\n        }\n        if (out.getTransportVersion().onOrAfter(ADDED_ENABLED_FLAG_VERSION)) {\n            out.writeOptionalWriteable(downsampling);\n            out.writeBoolean(enabled);\n        }\n    }\n\n    public DataStreamLifecycle(StreamInput in) throws IOException {\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_9_X)) {\n            dataRetention \u003d in.readOptionalWriteable(Retention::read);\n        } else {\n            dataRetention \u003d null;\n        }\n        if (in.getTransportVersion().onOrAfter(ADDED_ENABLED_FLAG_VERSION)) {\n            downsampling \u003d in.readOptionalWriteable(Downsampling::read);\n            enabled \u003d in.readBoolean();\n        } else {\n            downsampling \u003d null;\n            enabled \u003d true;\n        }\n    }\n\n    public static Diff\u003cDataStreamLifecycle\u003e readDiffFrom(StreamInput in) throws IOException {\n        return SimpleDiffable.readDiffFrom(DataStreamLifecycle::new, in);\n    }\n\n    @Override\n    public String toString() {\n        return Strings.toString(this, true, true);\n    }\n\n    @Override\n    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n        return toXContent(builder, params, null, null);\n    }\n\n    /**\n     * Converts the data stream lifecycle to XContent, enriches it with effective retention information when requested\n     * and injects the RolloverConditions if they exist.\n     * In order to request the effective retention you need to set {@link #INCLUDE_EFFECTIVE_RETENTION_PARAM_NAME} to true\n     * in the XContent params.\n     */\n    public XContentBuilder toXContent(\n        XContentBuilder builder,\n        Params params,\n        @Nullable RolloverConfiguration rolloverConfiguration,\n        @Nullable DataStreamGlobalRetention globalRetention\n    ) throws IOException {\n        builder.startObject();\n        builder.field(ENABLED_FIELD.getPreferredName(), enabled);\n        if (dataRetention !\u003d null) {\n            if (dataRetention.value() \u003d\u003d null) {\n                builder.nullField(DATA_RETENTION_FIELD.getPreferredName());\n            } else {\n                builder.field(DATA_RETENTION_FIELD.getPreferredName(), dataRetention.value().getStringRep());\n            }\n        }\n        if (params.paramAsBoolean(INCLUDE_EFFECTIVE_RETENTION_PARAM_NAME, false)) {\n            Tuple\u003cTimeValue, RetentionSource\u003e effectiveRetention \u003d getEffectiveDataRetentionWithSource(globalRetention);\n            if (effectiveRetention.v1() !\u003d null) {\n                builder.field(EFFECTIVE_RETENTION_FIELD.getPreferredName(), effectiveRetention.v1().getStringRep());\n                builder.field(RETENTION_SOURCE_FIELD.getPreferredName(), effectiveRetention.v2().displayName());\n            }\n        }\n\n        if (downsampling !\u003d null) {\n            builder.field(DOWNSAMPLING_FIELD.getPreferredName());\n            downsampling.toXContent(builder, params);\n        }\n        if (rolloverConfiguration !\u003d null) {\n            builder.field(ROLLOVER_FIELD.getPreferredName());\n            rolloverConfiguration.evaluateAndConvertToXContent(builder, params, getEffectiveDataRetention(globalRetention));\n        }\n        builder.endObject();\n        return builder;\n    }\n\n    public static DataStreamLifecycle fromXContent(XContentParser parser) throws IOException {\n        return PARSER.parse(parser, null);\n    }\n\n    public static Builder newBuilder(DataStreamLifecycle lifecycle) {\n        return new Builder().dataRetention(lifecycle.getDataRetention())\n            .downsampling(lifecycle.getDownsampling())\n            .enabled(lifecycle.isEnabled());\n    }\n\n    public static Builder newBuilder() {\n        return new Builder();\n    }\n\n    /**\n     * This builder helps during the composition of the data stream lifecycle templates.\n     */\n    public static class Builder {\n        @Nullable\n        private Retention dataRetention \u003d null;\n        @Nullable\n        private Downsampling downsampling \u003d null;\n        private boolean enabled \u003d true;\n\n        public Builder enabled(boolean value) {\n            enabled \u003d value;\n            return this;\n        }\n\n        public Builder dataRetention(@Nullable Retention value) {\n            dataRetention \u003d value;\n            return this;\n        }\n\n        public Builder dataRetention(@Nullable TimeValue value) {\n            dataRetention \u003d value \u003d\u003d null ? null : new Retention(value);\n            return this;\n        }\n\n        public Builder dataRetention(long value) {\n            dataRetention \u003d new Retention(TimeValue.timeValueMillis(value));\n            return this;\n        }\n\n        public Builder downsampling(@Nullable Downsampling value) {\n            downsampling \u003d value;\n            return this;\n        }\n\n        public DataStreamLifecycle build() {\n            return new DataStreamLifecycle(dataRetention, downsampling, enabled);\n        }\n    }\n\n    /**\n     * Retention is the least amount of time that the data will be kept by elasticsearch. Public for testing.\n     * @param value is a time period or null. Null represents an explicitly set infinite retention period\n     */\n    public record Retention(@Nullable TimeValue value) implements Writeable {\n\n        // For testing\n        public static final Retention NULL \u003d new Retention(null);\n\n        public static Retention read(StreamInput in) throws IOException {\n            return new Retention(in.readOptionalTimeValue());\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeOptionalTimeValue(value);\n        }\n    }\n\n    /**\n     * Downsampling holds the configuration about when should elasticsearch downsample a backing index.\n     * @param rounds is a list of downsampling configuration which instructs when a backing index should be downsampled (`after`) and at\n     *               which interval (`fixed_interval`). Null represents an explicit no downsampling during template composition.\n     */\n    public record Downsampling(@Nullable List\u003cRound\u003e rounds) implements Writeable, ToXContentFragment {\n\n        public static final long FIVE_MINUTES_MILLIS \u003d TimeValue.timeValueMinutes(5).getMillis();\n\n        /**\n         * A round represents the configuration for when and how elasticsearch will downsample a backing index.\n         * @param after is a TimeValue configuring how old (based on generation age) should a backing index be before downsampling\n         * @param config contains the interval that the backing index is going to be downsampled.\n         */\n        public record Round(TimeValue after, DownsampleConfig config) implements Writeable, ToXContentObject {\n\n            public static final ParseField AFTER_FIELD \u003d new ParseField(\"after\");\n            public static final ParseField FIXED_INTERVAL_FIELD \u003d new ParseField(\"fixed_interval\");\n\n            private static final ConstructingObjectParser\u003cRound, Void\u003e PARSER \u003d new ConstructingObjectParser\u003c\u003e(\n                \"downsampling_round\",\n                false,\n                (args, unused) -\u003e new Round((TimeValue) args[0], new DownsampleConfig((DateHistogramInterval) args[1]))\n            );\n\n            static {\n                PARSER.declareString(\n                    ConstructingObjectParser.optionalConstructorArg(),\n                    value -\u003e TimeValue.parseTimeValue(value, AFTER_FIELD.getPreferredName()),\n                    AFTER_FIELD\n                );\n                PARSER.declareField(\n                    constructorArg(),\n                    p -\u003e new DateHistogramInterval(p.text()),\n                    new ParseField(FIXED_INTERVAL_FIELD.getPreferredName()),\n                    ObjectParser.ValueType.STRING\n                );\n            }\n\n            public static Round read(StreamInput in) throws IOException {\n                return new Round(in.readTimeValue(), new DownsampleConfig(in));\n            }\n\n            public Round {\n                if (config.getFixedInterval().estimateMillis() \u003c FIVE_MINUTES_MILLIS) {\n                    throw new IllegalArgumentException(\n                        \"A downsampling round must have a fixed interval of at least five minutes but found: \" + config.getFixedInterval()\n                    );\n                }\n            }\n\n            @Override\n            public void writeTo(StreamOutput out) throws IOException {\n                out.writeTimeValue(after);\n                out.writeWriteable(config);\n            }\n\n            @Override\n            public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n                builder.startObject();\n                builder.field(AFTER_FIELD.getPreferredName(), after.getStringRep());\n                config.toXContentFragment(builder);\n                builder.endObject();\n                return builder;\n            }\n\n            public static Round fromXContent(XContentParser parser, Void context) throws IOException {\n                return PARSER.parse(parser, context);\n            }\n\n            @Override\n            public String toString() {\n                return Strings.toString(this, true, true);\n            }\n        }\n\n        // For testing\n        public static final Downsampling NULL \u003d new Downsampling(null);\n\n        public Downsampling {\n            if (rounds !\u003d null) {\n                if (rounds.isEmpty()) {\n                    throw new IllegalArgumentException(\"Downsampling configuration should have at least one round configured.\");\n                }\n                if (rounds.size() \u003e 10) {\n                    throw new IllegalArgumentException(\n                        \"Downsampling configuration supports maximum 10 configured rounds. Found: \" + rounds.size()\n                    );\n                }\n                Round previous \u003d null;\n                for (Round round : rounds) {\n                    if (previous \u003d\u003d null) {\n                        previous \u003d round;\n                    } else {\n                        if (round.after.compareTo(previous.after) \u003c 0) {\n                            throw new IllegalArgumentException(\n                                \"A downsampling round must have a later \u0027after\u0027 value than the proceeding, \"\n                                    + round.after.getStringRep()\n                                    + \" is not after \"\n                                    + previous.after.getStringRep()\n                                    + \".\"\n                            );\n                        }\n                        DownsampleConfig.validateSourceAndTargetIntervals(previous.config(), round.config());\n                    }\n                }\n            }\n        }\n\n        public static Downsampling read(StreamInput in) throws IOException {\n            return new Downsampling(in.readOptionalCollectionAsList(Round::read));\n        }\n\n        @Override\n        public void writeTo(StreamOutput out) throws IOException {\n            out.writeOptionalCollection(rounds, StreamOutput::writeWriteable);\n        }\n\n        @Override\n        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {\n            if (rounds \u003d\u003d null) {\n                builder.nullValue();\n            } else {\n                builder.startArray();\n                for (Round round : rounds) {\n                    round.toXContent(builder, params);\n                }\n                builder.endArray();\n            }\n            return builder;\n        }\n    }\n\n    /**\n     * This enum represents all configuration sources that can influence the retention of a data stream.\n     */\n    public enum RetentionSource {\n        DATA_STREAM_CONFIGURATION,\n        DEFAULT_GLOBAL_RETENTION,\n        MAX_GLOBAL_RETENTION;\n\n        public String displayName() {\n            return this.toString().toLowerCase(Locale.ROOT);\n        }\n    }\n}","methodCount":40},"candidatesTelemetryData":{"numberOfSuggestions":8,"candidates":[{"lineStart":351,"lineEnd":354,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method dataRetention to class Retention","description":"Move method dataRetention to org.elasticsearch.cluster.metadata.DataStreamLifecycle.Retention\nRationale: The dataRetention() method is directly related to the Retention concept, as it initializes a Retention object based on a TimeValue. Moving this method to the Retention class adheres to the Single Responsibility Principle, as it encapsulates the logic for managing data retention within the class that represents retention behavior. This move would enhance cohesion, making it clearer that Retention handles its own configuration. However, care must be taken to ensure that any existing dependencies on the method\u0027s current location are properly addressed to avoid breaking changes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":351,"lineEnd":354,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method dataRetention to class Downsampling","description":"Move method dataRetention to org.elasticsearch.cluster.metadata.DataStreamLifecycle.Downsampling\nRationale: While the dataRetention() method is not directly related to Downsampling, it could potentially be relevant if Downsampling operations are influenced by retention policies. However, this connection is weaker than with Retention. Moving the method here could promote a broader understanding of how data retention and downsampling interact, but it risks violating the Single Responsibility Principle by introducing unrelated concerns into the Downsampling class. This could lead to confusion and a lack of clarity regarding the responsibilities of each class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":321,"lineEnd":325,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method newBuilder to class DataStreamAction","description":"move method newBuilder to PsiClass:DataStreamAction\nRationale: DataStreamAction is closely tied to the actions performed on data streams, making it a suitable candidate for newBuilder(). This relocation would enhance cohesion by keeping data stream-related logic together. It supports the Open/Closed Principle by allowing for future extensions without modifying existing functionality. However, it may complicate the DataStreamAction class if additional responsibilities are not carefully managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":321,"lineEnd":325,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method newBuilder to class DesiredNodesMetadata","description":"move method newBuilder to PsiClass:DesiredNodesMetadata\nRationale: DesiredNodesMetadata deals with the representation of desired nodes, which may include configurations from DataStreamLifecycle. Relocating newBuilder() here would ensure that the method is closer to where its results might be utilized, promoting cohesion. This move adheres to the Open/Closed Principle by allowing new configurations to be added without modifying existing code. However, it might dilute the focus of DesiredNodesMetadata if it starts handling too many unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":321,"lineEnd":325,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method newBuilder to class DataStreamAutoShardingEvent","description":"move method newBuilder to PsiClass:DataStreamAutoShardingEvent\nRationale: DataStreamAutoShardingEvent is related to the lifecycle of data streams and events associated with them. Moving newBuilder() here would centralize the configuration logic for data streams and their events, enhancing the method\u0027s relevance. This supports the Interface Segregation Principle by ensuring that classes only implement methods that are relevant to them. A potential drawback is that it might introduce dependencies on event-related logic that could complicate the builder\u0027s responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":429,"lineEnd":431,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method read to class Downsampling","description":"move method read to PsiClass:Downsampling\nRationale: The read() method creates a Round object and initializes it with a DownsampleConfig. Since Downsampling is closely related to the concept of rounds and includes a list of Round objects, moving the method here enhances cohesion. This aligns with the Single Responsibility Principle, as Downsampling is responsible for managing rounds. A potential drawback is that it may introduce a dependency on StreamInput in a class that could otherwise be more agnostic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":429,"lineEnd":431,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method read to class DesiredNode","description":"move method read to PsiClass:DesiredNode\nRationale: The read() method constructs a Round using a DownsampleConfig, which might be part of the configuration for DesiredNode instances. Moving it to DesiredNode would encapsulate the logic related to creating a Round within the context of desired node configurations, improving cohesion. This aligns with the Open/Closed Principle, allowing for extensions without modifying existing code. However, it may lead to tighter coupling between DesiredNode and Round.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":429,"lineEnd":431,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method read to class DesiredNodeWithStatus","description":"move method read to PsiClass:DesiredNodeWithStatus\nRationale: Similar to DesiredNode, DesiredNodeWithStatus may also benefit from the read() method since it can represent the status of a node that might include round configurations. This move can enhance the clarity of relationships between nodes and their configurations. It adheres to the Single Responsibility Principle by ensuring that node status management includes relevant configuration logic. However, it could complicate the class\u0027s responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"isDataStreamsLifecycleOnlyMode","method_signature":"public static isDataStreamsLifecycleOnlyMode(final Settings settings)","target_class":"","rationale":""},{"method_name":"getEffectiveDataRetention","method_signature":"@Nullable\n    public getEffectiveDataRetention(@Nullable DataStreamGlobalRetention globalRetention)","target_class":"","rationale":""},{"method_name":"getEffectiveDataRetentionWithSource","method_signature":"@Nullable\n    public getEffectiveDataRetentionWithSource(@Nullable DataStreamGlobalRetention globalRetention)","target_class":"","rationale":""},{"method_name":"readDiffFrom","method_signature":"public static readDiffFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"toXContent","method_signature":"public toXContent(\n        XContentBuilder builder,\n        Params params,\n        @Nullable RolloverConfiguration rolloverConfiguration,\n        @Nullable DataStreamGlobalRetention globalRetention\n    )","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"newBuilder","method_signature":"public static newBuilder(DataStreamLifecycle lifecycle)","target_class":"","rationale":""},{"method_name":"newBuilder","method_signature":"public static newBuilder()","target_class":"","rationale":""},{"method_name":"enabled","method_signature":"public enabled(boolean value)","target_class":"","rationale":""},{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable Retention value)","target_class":"","rationale":""},{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable TimeValue value)","target_class":"","rationale":""},{"method_name":"dataRetention","method_signature":"public dataRetention(long value)","target_class":"","rationale":""},{"method_name":"downsampling","method_signature":"public downsampling(@Nullable Downsampling value)","target_class":"","rationale":""},{"method_name":"build","method_signature":"public build()","target_class":"","rationale":""},{"method_name":"read","method_signature":"public static read(StreamInput in)","target_class":"","rationale":""},{"method_name":"read","method_signature":"public static read(StreamInput in)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, Void context)","target_class":"","rationale":""},{"method_name":"read","method_signature":"public static read(StreamInput in)","target_class":"","rationale":""},{"method_name":"displayName","method_signature":"public displayName()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable TimeValue value)","target_class":"","rationale":""},{"method_name":"newBuilder","method_signature":"public static newBuilder(DataStreamLifecycle lifecycle)","target_class":"","rationale":""},{"method_name":"read","method_signature":"public static read(StreamInput in)","target_class":"","rationale":""},{"method_name":"build","method_signature":"public build()","target_class":"","rationale":""},{"method_name":"readDiffFrom","method_signature":"public static readDiffFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, Void context)","target_class":"","rationale":""},{"method_name":"isDataStreamsLifecycleOnlyMode","method_signature":"public static isDataStreamsLifecycleOnlyMode(final Settings settings)","target_class":"","rationale":""},{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable Retention value)","target_class":"","rationale":""},{"method_name":"enabled","method_signature":"public enabled(boolean value)","target_class":"","rationale":""},{"method_name":"displayName","method_signature":"public displayName()","target_class":"","rationale":""},{"method_name":"getEffectiveDataRetention","method_signature":"@Nullable\n    public getEffectiveDataRetention(@Nullable DataStreamGlobalRetention globalRetention)","target_class":"","rationale":""},{"method_name":"toXContent","method_signature":"public toXContent(\n        XContentBuilder builder,\n        Params params,\n        @Nullable RolloverConfiguration rolloverConfiguration,\n        @Nullable DataStreamGlobalRetention globalRetention\n    )","target_class":"","rationale":""},{"method_name":"dataRetention","method_signature":"public dataRetention(long value)","target_class":"","rationale":""},{"method_name":"downsampling","method_signature":"public downsampling(@Nullable Downsampling value)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public dataRetention(@Nullable TimeValue value)":{"first":{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable TimeValue value)","target_class":"","rationale":""},"second":0.4561832170687319},"public static newBuilder(DataStreamLifecycle lifecycle)":{"first":{"method_name":"newBuilder","method_signature":"public static newBuilder(DataStreamLifecycle lifecycle)","target_class":"","rationale":""},"second":0.46856091653745563},"public static read(StreamInput in)":{"first":{"method_name":"read","method_signature":"public static read(StreamInput in)","target_class":"","rationale":""},"second":0.4686309851229093},"public build()":{"first":{"method_name":"build","method_signature":"public build()","target_class":"","rationale":""},"second":0.4761258482223487},"public static readDiffFrom(StreamInput in)":{"first":{"method_name":"readDiffFrom","method_signature":"public static readDiffFrom(StreamInput in)","target_class":"","rationale":""},"second":0.4764362961417443},"public static fromXContent(XContentParser parser, Void context)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser, Void context)","target_class":"","rationale":""},"second":0.478954783103169},"public static isDataStreamsLifecycleOnlyMode(final Settings settings)":{"first":{"method_name":"isDataStreamsLifecycleOnlyMode","method_signature":"public static isDataStreamsLifecycleOnlyMode(final Settings settings)","target_class":"","rationale":""},"second":0.4833421187954468},"public static fromXContent(XContentParser parser)":{"first":{"method_name":"fromXContent","method_signature":"public static fromXContent(XContentParser parser)","target_class":"","rationale":""},"second":0.4835793408640064},"public dataRetention(@Nullable Retention value)":{"first":{"method_name":"dataRetention","method_signature":"public dataRetention(@Nullable Retention value)","target_class":"","rationale":""},"second":0.514649274234917},"public enabled(boolean value)":{"first":{"method_name":"enabled","method_signature":"public enabled(boolean value)","target_class":"","rationale":""},"second":0.5163780221129186},"public displayName()":{"first":{"method_name":"displayName","method_signature":"public displayName()","target_class":"","rationale":""},"second":0.5317925911856249},"@Nullable\n    public getEffectiveDataRetention(@Nullable DataStreamGlobalRetention globalRetention)":{"first":{"method_name":"getEffectiveDataRetention","method_signature":"@Nullable\n    public getEffectiveDataRetention(@Nullable DataStreamGlobalRetention globalRetention)","target_class":"","rationale":""},"second":0.5380643716669311},"public toXContent(\n        XContentBuilder builder,\n        Params params,\n        @Nullable RolloverConfiguration rolloverConfiguration,\n        @Nullable DataStreamGlobalRetention globalRetention\n    )":{"first":{"method_name":"toXContent","method_signature":"public toXContent(\n        XContentBuilder builder,\n        Params params,\n        @Nullable RolloverConfiguration rolloverConfiguration,\n        @Nullable DataStreamGlobalRetention globalRetention\n    )","target_class":"","rationale":""},"second":0.5385036201495896},"public dataRetention(long value)":{"first":{"method_name":"dataRetention","method_signature":"public dataRetention(long value)","target_class":"","rationale":""},"second":0.5394345221218577},"public downsampling(@Nullable Downsampling value)":{"first":{"method_name":"downsampling","method_signature":"public downsampling(@Nullable Downsampling value)","target_class":"","rationale":""},"second":0.5428330774777665}},"llmMethodPriority":{"priority_method_names":["isDataStreamsLifecycleOnlyMode","read","readDiffFrom","fromXContent","fromXContent","dataRetention","dataRetention","dataRetention","enabled","downsampling","build","displayName","getEffectiveDataRetention","toXContent"],"llm_response_time":2893},"targetClassMap":{"dataRetention":{"target_classes":[{"class_name":"Retention","similarity_score":0.3973165041069235},{"class_name":"Downsampling","similarity_score":0.4154475633484957}],"target_classes_sorted_by_llm":["Retention","Downsampling"],"llm_response_time":3009,"similarity_computation_time":0,"similarity_metric":"voyage"},"newBuilder":{"target_classes":[{"class_name":"ClusterChangedEventUtils","similarity_score":0.37037037037037035},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.271541395543832},{"class_name":"DiffableUtils","similarity_score":0.45426882755540515},{"class_name":"DiscoveryNodeUtils","similarity_score":0.546085655726948},{"class_name":"ClusterInfoServiceUtils","similarity_score":0.45866432210600416},{"class_name":"ClusterStateTaskExecutorUtils","similarity_score":0.39862402096797617},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.3031096741501361},{"class_name":"StringSetValueSerializer","similarity_score":0.450563556889583},{"class_name":"DesiredNode","similarity_score":0.5068959106985514},{"class_name":"DesiredNodes","similarity_score":0.3937642449120322},{"class_name":"DesiredNodeSerializationTests","similarity_score":0.3482204546403616},{"class_name":"DesiredNodesMetadata","similarity_score":0.5645598909866651},{"class_name":"DesiredNodesMetadataSerializationTests","similarity_score":0.4782996923381279},{"class_name":"DesiredNodesSerializationTests","similarity_score":0.36976095499904793},{"class_name":"DesiredNodesTests","similarity_score":0.23365506420501844},{"class_name":"DesiredNodeWithStatus","similarity_score":0.47066598031762974},{"class_name":"DesiredNodeWithStatusSerializationTests","similarity_score":0.4843098022505683},{"class_name":"AutoExpandReplicas","similarity_score":0.3577547022519786},{"class_name":"AverageShardSize","similarity_score":0.5377619483801268},{"class_name":"Retention","similarity_score":0.38225478605399726},{"class_name":"DiffableStringMap","similarity_score":0.518726905009188},{"class_name":"DiffableStringMapDiff","similarity_score":0.5070496933050351},{"class_name":"Round","similarity_score":0.5102670534318382},{"class_name":"DataStream","similarity_score":0.3873959528149826},{"class_name":"DataStreamAction","similarity_score":0.5308976735900756},{"class_name":"DataStreamActionTests","similarity_score":0.3344729377972476},{"class_name":"DataStreamAlias","similarity_score":0.3905277643596179},{"class_name":"DataStreamAutoShardingEvent","similarity_score":0.5338925219279191},{"class_name":"DataStreamAutoShardingEventTests","similarity_score":0.400925916116765},{"class_name":"DataStreamFailureStoreDefinition","similarity_score":0.23159237979522648}],"target_classes_sorted_by_llm":["DataStreamAction","DesiredNodesMetadata","DataStreamAutoShardingEvent","DiscoveryNodeUtils","AverageShardSize","Round","DiffableStringMap","DesiredNode","DiffableStringMapDiff","DesiredNodeWithStatusSerializationTests"],"llm_response_time":13378,"similarity_computation_time":32,"similarity_metric":"voyage"},"read":{"target_classes":[{"class_name":"Downsampling","similarity_score":0.6423081722810499},{"class_name":"ClusterChangedEventUtils","similarity_score":0.3367876570272817},{"class_name":"MetadataIndexStateServiceUtils","similarity_score":0.23516174672003703},{"class_name":"DiffableUtils","similarity_score":0.4746059973729553},{"class_name":"DiscoveryNodeUtils","similarity_score":0.43284574113725904},{"class_name":"ClusterInfoServiceUtils","similarity_score":0.43902705525372265},{"class_name":"ClusterStateTaskExecutorUtils","similarity_score":0.3714376574802821},{"class_name":"CompatibilityVersionsUtils","similarity_score":0.310228073937176},{"class_name":"StringSetValueSerializer","similarity_score":0.5202659817144719},{"class_name":"AliasMetadata","similarity_score":0.4608647745891776},{"class_name":"AliasMetadataTests","similarity_score":0.3823517927262997},{"class_name":"AliasValidator","similarity_score":0.3111320634707073},{"class_name":"DesiredNode","similarity_score":0.5127204530706201},{"class_name":"DesiredNodes","similarity_score":0.3857324410575638},{"class_name":"DesiredNodeSerializationTests","similarity_score":0.39092117015767397},{"class_name":"DesiredNodesMetadata","similarity_score":0.5853306005906922},{"class_name":"DesiredNodesMetadataSerializationTests","similarity_score":0.4796227922166421},{"class_name":"DesiredNodesSerializationTests","similarity_score":0.36388906858723874},{"class_name":"DesiredNodesTests","similarity_score":0.21853931903038443},{"class_name":"DesiredNodeWithStatus","similarity_score":0.4945652173913043},{"class_name":"DesiredNodeWithStatusSerializationTests","similarity_score":0.48156156865093},{"class_name":"AutoExpandReplicas","similarity_score":0.3400514566173125},{"class_name":"AverageShardSize","similarity_score":0.6386955544948194},{"class_name":"DiffableStringMap","similarity_score":0.525599892516388},{"class_name":"DiffableStringMapDiff","similarity_score":0.48415565029437335},{"class_name":"ClusterNameExpressionResolver","similarity_score":0.40793376007219},{"class_name":"DataStream","similarity_score":0.3731473831430125},{"class_name":"DataStreamAction","similarity_score":0.5384158897417989},{"class_name":"DataStreamActionTests","similarity_score":0.35173250265600636},{"class_name":"DataStreamAlias","similarity_score":0.3941411936154898}],"target_classes_sorted_by_llm":["Downsampling","DesiredNode","DesiredNodeWithStatus","AverageShardSize","DataStreamAction","DiffableStringMap","DiffableStringMapDiff","StringSetValueSerializer","DesiredNodesMetadata","DesiredNodeWithStatusSerializationTests"],"llm_response_time":13352,"similarity_computation_time":7,"similarity_metric":"voyage"}}}
{"id":"2f3f9e06-46d8-4e4f-8241-8f7d0404294e","methodCount":4,"hostFunctionTelemetryData":{"hostFunctionSize":76,"lineStart":124,"lineEnd":199,"bodyLineStart":124,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/distribution/tools/server-cli/src/main/java/org/elasticsearch/server/cli/MachineDependentHeap.java","sourceCode":"enum MachineNodeRole {\n        /**\n         * Master-only node.\n         *\n         * \u003cp\u003eHeap is computed as 60% of total system memory up to a maximum of 31 gigabytes.\n         */\n        MASTER_ONLY(m -\u003e mb(min((long) (m * .6), MAX_HEAP_SIZE))),\n\n        /**\n         * Machine learning only node.\n         *\n         * \u003cp\u003eHeap is computed as:\n         * \u003cul\u003e\n         *     \u003cli\u003e40% of total system memory when total system memory 16 gigabytes or less.\u003c/li\u003e\n         *     \u003cli\u003e40% of the first 16 gigabytes plus 10% of memory above that when total system memory is more than 16 gigabytes.\u003c/li\u003e\n         *     \u003cli\u003eThe absolute maximum heap size is 31 gigabytes.\u003c/li\u003e\n         * \u003c/ul\u003e\n         *\n         * In all cases the result is rounded down to the next whole multiple of 4 megabytes.\n         * The reason for doing this is that Java will round requested heap sizes to a multiple\n         * of 4 megabytes (certainly versions 11 to 18 do this), so by doing this ourselves we\n         * are more likely to actually get the amount we request. This is worthwhile for ML where\n         * the ML autoscaling code needs to be able to calculate the JVM size for different sizes\n         * of ML node, and if Java is also rounding then this causes a discrepancy. It\u0027s possible\n         * that a future version of Java could round to an even bigger number of megabytes, which\n         * would cause a discrepancy for people using that version of Java. But there\u0027s no harm\n         * in a bit of extra rounding here - it can only reduce discrepancies.\n         *\n         * If this formula is changed then corresponding changes must be made to the {@code NativeMemoryCalculator} and\n         * {@code MlAutoscalingDeciderServiceTests} classes in the ML plugin code. Failure to keep the logic synchronized\n         * could result in repeated autoscaling up and down.\n         */\n        ML_ONLY(m -\u003e mb(m \u003c\u003d (GB * 16) ? (long) (m * .4) : (long) min((GB * 16) * .4 + (m - GB * 16) * .1, MAX_HEAP_SIZE), 4)),\n\n        /**\n         * Data node. Essentially any node that isn\u0027t a master or ML only node.\n         *\n         * \u003cp\u003eHeap is computed as:\n         * \u003cul\u003e\n         *     \u003cli\u003e40% of total system memory when less than 1 gigabyte with a minimum of 128 megabytes.\u003c/li\u003e\n         *     \u003cli\u003e50% of total system memory when greater than 1 gigabyte up to a maximum of 31 gigabytes.\u003c/li\u003e\n         * \u003c/ul\u003e\n         */\n        DATA(m -\u003e mb(m \u003c GB ? max((long) (m * .4), MIN_HEAP_SIZE) : min((long) (m * .5), MAX_HEAP_SIZE))),\n\n        /**\n         * Unknown role node.\n         *\n         * \u003cp\u003eHard-code heap to a default of 1 gigabyte.\n         */\n        UNKNOWN(m -\u003e DEFAULT_HEAP_SIZE_MB);\n\n        private final Function\u003cLong, Integer\u003e formula;\n\n        MachineNodeRole(Function\u003cLong, Integer\u003e formula) {\n            this.formula \u003d formula;\n        }\n\n        /**\n         * Determine the appropriate heap size for the given role and available system memory.\n         *\n         * @param systemMemory total available system memory in bytes\n         * @return recommended heap size in megabytes\n         */\n        public int heap(long systemMemory) {\n            return formula.apply(systemMemory);\n        }\n\n        private static int mb(long bytes) {\n            return (int) (bytes / (1024 * 1024));\n        }\n\n        private static int mb(long bytes, int toLowerMultipleOfMb) {\n            return toLowerMultipleOfMb * (int) (bytes / (1024 * 1024 * toLowerMultipleOfMb));\n        }\n    }","methodCount":4},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":191,"lineEnd":193,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class NumberUtils","description":"move method mb to PsiClass:NumberUtils\nRationale: The mb() method is a utility function for converting bytes to megabytes, which aligns directly with the responsibilities of NumberUtils as a utility class. Moving it here adheres to the Single Responsibility Principle, as it centralizes numeric conversion logic. This enhances cohesion within NumberUtils and promotes reusability across the application. However, care must be taken to ensure that existing usages of mb() are updated accordingly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":191,"lineEnd":193,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class JvmOption","description":"move method mb to PsiClass:JvmOption\nRationale: The mb() method could fit within JvmOption, as it deals with memory-related conversions that are relevant when configuring JVM options. This move keeps memory management logic together, enhancing the class\u0027s utility. It aligns with the Open/Closed Principle, allowing JvmOption to be extended with more memory-related utilities. However, the class may become cluttered if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":191,"lineEnd":193,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class MachineDependentHeap","description":"move method mb to PsiClass:MachineDependentHeap\nRationale: Since the mb() method relates to memory size calculations, it is contextually relevant to MachineDependentHeap, which deals with heap settings and memory information. This relocation would improve cohesion within the class. It adheres to the Interface Segregation Principle by ensuring that classes only depend on methods they use. However, it may introduce dependencies if the method is used in contexts unrelated to heap settings.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":195,"lineEnd":197,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class MachineDependentHeap","description":"move method mb to PsiClass:MachineDependentHeap\nRationale: The mb() method deals with memory calculations, specifically converting bytes to megabytes. Since MachineDependentHeap is directly concerned with heap settings and memory management, it is a natural fit for this method. Moving it here enhances cohesion, as both the method and the class are focused on memory-related operations. This aligns with the Single Responsibility Principle by encapsulating memory-related logic within a dedicated class. However, care must be taken to ensure that this method does not inadvertently become tightly coupled with the heap settings logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":195,"lineEnd":197,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class JvmOptionsParser","description":"move method mb to PsiClass:JvmOptionsParser\nRationale: The mb() method serves a utility function related to memory size calculations, which can be relevant when parsing JVM options that include memory settings. By placing it in JvmOptionsParser, we can enhance the class\u0027s utility as a helper for JVM configuration. This adheres to the Open/Closed Principle, allowing the class to be extended with additional memory-related functionalities. However, it may dilute the class\u0027s focus on parsing if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":195,"lineEnd":197,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method mb to class ProcessUtil","description":"move method mb to PsiClass:ProcessUtil\nRationale: ProcessUtil may benefit from the mb() method since it can be involved in process management where memory calculations are relevant. By relocating the method here, it becomes a utility for managing process memory requirements, which aligns with the Interface Segregation Principle by keeping related functionalities together. However, this could lead to a bloated utility class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"heap","method_signature":"public heap(long systemMemory)","target_class":"","rationale":""},{"method_name":"mb","method_signature":"private static mb(long bytes)","target_class":"","rationale":""},{"method_name":"mb","method_signature":"private static mb(long bytes, int toLowerMultipleOfMb)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"heap","method_signature":"public heap(long systemMemory)","target_class":"","rationale":""},{"method_name":"mb","method_signature":"private static mb(long bytes)","target_class":"","rationale":""},{"method_name":"mb","method_signature":"private static mb(long bytes, int toLowerMultipleOfMb)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public heap(long systemMemory)":{"first":{"method_name":"heap","method_signature":"public heap(long systemMemory)","target_class":"","rationale":""},"second":0.08038418992031009},"private static mb(long bytes)":{"first":{"method_name":"mb","method_signature":"private static mb(long bytes)","target_class":"","rationale":""},"second":0.32866029515269773},"private static mb(long bytes, int toLowerMultipleOfMb)":{"first":{"method_name":"mb","method_signature":"private static mb(long bytes, int toLowerMultipleOfMb)","target_class":"","rationale":""},"second":0.574187630454812}},"llmMethodPriority":{"priority_method_names":["heap","mb","mb"],"llm_response_time":1217},"targetClassMap":{"heap":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":548,"similarity_computation_time":0,"similarity_metric":"voyage"},"mb":{"target_classes":[{"class_name":"MachineDependentHeap","similarity_score":0.6017278612589412},{"class_name":"ProcessUtil","similarity_score":0.36473112413463404},{"class_name":"ServerProcessUtils","similarity_score":0.3434391961185217},{"class_name":"ProxyUtils","similarity_score":0.39225912575148575},{"class_name":"JvmErgonomics","similarity_score":0.3781077107033635},{"class_name":"JvmOption","similarity_score":0.3207631065104355},{"class_name":"JvmOptionsParser","similarity_score":0.43119456341002},{"class_name":"OverridableSystemMemoryInfoTests","similarity_score":0.1861937422904155},{"class_name":"NodeRoleParser","similarity_score":0.29202397717782225},{"class_name":"NodeRoleParserTests","similarity_score":0.08790998161481535},{"class_name":"MachineDependentHeapTests","similarity_score":0.23366382445653075},{"class_name":"ServerCli","similarity_score":0.23074067140509968},{"class_name":"APMJvmOptions","similarity_score":0.3059170949545603},{"class_name":"ServerProcessBuilder","similarity_score":0.3490295246077134},{"class_name":"ServerProcessTests","similarity_score":0.21404733713198384},{"class_name":"DefaultSystemMemoryInfo","similarity_score":0.2844472538139111},{"class_name":"SystemJvmOptions","similarity_score":0.39464669922219586},{"class_name":"MapperTestUtils","similarity_score":0.14371515142959107},{"class_name":"RestResponseUtils","similarity_score":0.29419867460232685},{"class_name":"LevelUtil","similarity_score":0.11396057645963795},{"class_name":"RestTestUtil","similarity_score":0.30565288093826454},{"class_name":"RestUtils","similarity_score":0.46216039749172444},{"class_name":"RestUtilsTests","similarity_score":0.0929268231259951},{"class_name":"JwkValidateUtil","similarity_score":0.28889811709946633},{"class_name":"JwkValidateUtilTests","similarity_score":0.23933159606721022},{"class_name":"ProcessBuilderUtils","similarity_score":0.29643507578021855},{"class_name":"LicenseUtils","similarity_score":0.37170129207304753},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.36842262757521566},{"class_name":"LifecyclePolicyTestsUtils","similarity_score":0.33987654065040135},{"class_name":"LifecyclePolicyUtils","similarity_score":0.3251967423287923}],"target_classes_sorted_by_llm":["MachineDependentHeap","JvmOptionsParser","ProcessUtil","ServerProcessBuilder","JvmErgonomics","RestUtils","LicenseUtils","SystemJvmOptions","LifecycleExecutionStateUtils","ProxyUtils"],"llm_response_time":12795,"similarity_computation_time":9,"similarity_metric":"voyage"}}}
{"id":"84b87881-7677-4eaf-8156-d6b42d3445da","methodCount":9,"hostFunctionTelemetryData":{"hostFunctionSize":141,"lineStart":24,"lineEnd":164,"bodyLineStart":24,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/libs/native/src/main21/java/org/elasticsearch/nativeaccess/jdk/JdkVectorLibrary.java","sourceCode":"public final class JdkVectorLibrary implements VectorLibrary {\n\n    static {\n        System.loadLibrary(\"vec\");\n    }\n\n    public JdkVectorLibrary() {}\n\n    static final MethodHandle dot8stride$mh \u003d downcallHandle(\"dot8s_stride\", FunctionDescriptor.of(JAVA_INT));\n    static final MethodHandle sqr8stride$mh \u003d downcallHandle(\"sqr8s_stride\", FunctionDescriptor.of(JAVA_INT));\n\n    static final MethodHandle dot8s$mh \u003d downcallHandle(\"dot8s\", FunctionDescriptor.of(JAVA_INT, ADDRESS, ADDRESS, JAVA_INT));\n    static final MethodHandle sqr8s$mh \u003d downcallHandle(\"sqr8s\", FunctionDescriptor.of(JAVA_INT, ADDRESS, ADDRESS, JAVA_INT));\n\n    // Stride of the native implementation - consumes this number of bytes per loop invocation.\n    // There must be at least this number of bytes/elements available when going native\n    static final int DOT_STRIDE \u003d 32;\n    static final int SQR_STRIDE \u003d 16;\n\n    static {\n        assert DOT_STRIDE \u003e 0 \u0026\u0026 (DOT_STRIDE \u0026 (DOT_STRIDE - 1)) \u003d\u003d 0 : \"Not a power of two\";\n        assert dot8Stride() \u003d\u003d DOT_STRIDE : dot8Stride() + \" !\u003d \" + DOT_STRIDE;\n        assert SQR_STRIDE \u003e 0 \u0026\u0026 (SQR_STRIDE \u0026 (SQR_STRIDE - 1)) \u003d\u003d 0 : \"Not a power of two\";\n        assert sqr8Stride() \u003d\u003d SQR_STRIDE : sqr8Stride() + \" !\u003d \" + SQR_STRIDE;\n    }\n\n    /**\n     * Computes the dot product of given byte vectors.\n     * @param a address of the first vector\n     * @param b address of the second vector\n     * @param length the vector dimensions\n     */\n    static int dotProduct(MemorySegment a, MemorySegment b, int length) {\n        assert length \u003e\u003d 0;\n        if (a.byteSize() !\u003d b.byteSize()) {\n            throw new IllegalArgumentException(\"dimensions differ: \" + a.byteSize() + \"!\u003d\" + b.byteSize());\n        }\n        if (length \u003e a.byteSize()) {\n            throw new IllegalArgumentException(\"length: \" + length + \", greater than vector dimensions: \" + a.byteSize());\n        }\n        int i \u003d 0;\n        int res \u003d 0;\n        if (length \u003e\u003d DOT_STRIDE) {\n            i +\u003d length \u0026 ~(DOT_STRIDE - 1);\n            res \u003d dot8s(a, b, i);\n        }\n\n        // tail\n        for (; i \u003c length; i++) {\n            res +\u003d a.get(JAVA_BYTE, i) * b.get(JAVA_BYTE, i);\n        }\n        assert i \u003d\u003d length;\n        return res;\n    }\n\n    /**\n     * Computes the square distance of given byte vectors.\n     * @param a address of the first vector\n     * @param b address of the second vector\n     * @param length the vector dimensions\n     */\n    static int squareDistance(MemorySegment a, MemorySegment b, int length) {\n        assert length \u003e\u003d 0;\n        if (a.byteSize() !\u003d b.byteSize()) {\n            throw new IllegalArgumentException(\"dimensions differ: \" + a.byteSize() + \"!\u003d\" + b.byteSize());\n        }\n        if (length \u003e a.byteSize()) {\n            throw new IllegalArgumentException(\"length: \" + length + \", greater than vector dimensions: \" + a.byteSize());\n        }\n        int i \u003d 0;\n        int res \u003d 0;\n        if (length \u003e\u003d SQR_STRIDE) {\n            i +\u003d length \u0026 ~(SQR_STRIDE - 1);\n            res \u003d sqr8s(a, b, i);\n        }\n\n        // tail\n        for (; i \u003c length; i++) {\n            int dist \u003d a.get(JAVA_BYTE, i) - b.get(JAVA_BYTE, i);\n            res +\u003d dist * dist;\n        }\n        assert i \u003d\u003d length;\n        return res;\n    }\n\n    private static int dot8Stride() {\n        try {\n            return (int) dot8stride$mh.invokeExact();\n        } catch (Throwable t) {\n            throw new AssertionError(t);\n        }\n    }\n\n    private static int sqr8Stride() {\n        try {\n            return (int) sqr8stride$mh.invokeExact();\n        } catch (Throwable t) {\n            throw new AssertionError(t);\n        }\n    }\n\n    private static int dot8s(MemorySegment a, MemorySegment b, int length) {\n        try {\n            return (int) dot8s$mh.invokeExact(a, b, length);\n        } catch (Throwable t) {\n            throw new AssertionError(t);\n        }\n    }\n\n    private static int sqr8s(MemorySegment a, MemorySegment b, int length) {\n        try {\n            return (int) sqr8s$mh.invokeExact(a, b, length);\n        } catch (Throwable t) {\n            throw new AssertionError(t);\n        }\n    }\n\n    static final MethodHandle DOT_HANDLE;\n    static final MethodHandle SQR_HANDLE;\n\n    static {\n        try {\n            var lookup \u003d MethodHandles.lookup();\n            var mt \u003d MethodType.methodType(int.class, MemorySegment.class, MemorySegment.class, int.class);\n            DOT_HANDLE \u003d lookup.findStatic(JdkVectorLibrary.class, \"dotProduct\", mt);\n            SQR_HANDLE \u003d lookup.findStatic(JdkVectorLibrary.class, \"squareDistance\", mt);\n        } catch (NoSuchMethodException | IllegalAccessException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    @Override\n    public MethodHandle dotProductHandle() {\n        return DOT_HANDLE;\n    }\n\n    @Override\n    public MethodHandle squareDistanceHandle() {\n        return SQR_HANDLE;\n    }\n}","methodCount":9},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":108,"lineEnd":114,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8Stride to class ExecutionUtils","description":"move method dot8Stride to PsiClass:ExecutionUtils\nRationale: The dot8Stride() method appears to be a utility function that invokes a method and handles exceptions. ExecutionUtils is a suitable target as it aligns with the utility nature of the method, enhancing its reusability. This move adheres to the Single Responsibility Principle by consolidating execution-related utilities. However, care must be taken to ensure that the method\u0027s context is maintained in its new location.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":108,"lineEnd":114,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8Stride to class FunctionTestUtils","description":"move method dot8Stride to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils is focused on utility methods that assist in testing functions, which may include invoking methods and handling their responses. Moving dot8Stride() here would keep related functionalities together and enhance cohesion. This aligns with the Open/Closed Principle, as the utility class can be extended without modifying existing code. The drawback is that it may dilute the class\u0027s focus if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":108,"lineEnd":114,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8Stride to class DatafeedConfigUtils","description":"move method dot8Stride to PsiClass:DatafeedConfigUtils\nRationale: DatafeedConfigUtils handles configurations related to data feeds, which may involve method invocations like dot8Stride(). Relocating the method here could improve the organization of utility functions related to data feeds. This supports the Interface Segregation Principle, as it keeps configurations and related utilities in one place. However, it may not be directly relevant to data feed configurations, potentially leading to confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sqr8Stride to class FutureUtils","description":"move method sqr8Stride to PsiClass:FutureUtils\nRationale: The sqr8Stride() method appears to involve invoking a method that may be related to asynchronous operations, which aligns with the responsibilities of FutureUtils. Moving it here adheres to the Single Responsibility Principle, as it centralizes utility methods related to future handling. This would enhance cohesion within FutureUtils, making it a more comprehensive utility class. However, consider the implications of adding static methods to a utility class that may not directly relate to its primary function.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sqr8Stride to class GeneratorUtils","description":"move method sqr8Stride to PsiClass:GeneratorUtils\nRationale: GeneratorUtils handles various utility functions related to value generation, which might include generating or manipulating numeric values. The sqr8Stride() method could fit within the context of generating specific numeric strides. This move supports the Open/Closed Principle by allowing the class to be extended with more numeric utility methods. However, it may dilute the focus of GeneratorUtils if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":116,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method sqr8Stride to class FunctionTestUtils","description":"move method sqr8Stride to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils is focused on utility methods for testing functions, and the sqr8Stride() method may be relevant in a testing context, especially if it is used to validate or generate test data. This relocation aligns with the Single Responsibility Principle, allowing FunctionTestUtils to encapsulate more test-related utilities. However, care must be taken to ensure that the method\u0027s functionality is indeed relevant to testing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":124,"lineEnd":130,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8s to class NumberUtils","description":"move method dot8s to PsiClass:NumberUtils\nRationale: The dot8s() method performs a mathematical operation that relates to numeric data processing. Moving it to NumberUtils aligns with the Single Responsibility Principle, as NumberUtils is focused on number-related utilities. This enhances cohesion and makes the method more reusable in numeric contexts. However, care should be taken to ensure that the method\u0027s dependencies and exceptions are handled appropriately in its new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":124,"lineEnd":130,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8s to class AuditUtil","description":"move method dot8s to PsiClass:AuditUtil\nRationale: The method could be relevant for memory auditing, which aligns with the responsibilities of AuditUtil. Moving it here can provide a clear context for memory operations related to auditing. While this adheres to the Single Responsibility Principle, it may introduce unnecessary dependencies on audit logging in contexts where it\u0027s not needed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":124,"lineEnd":130,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method dot8s to class FunctionTestUtils","description":"move method dot8s to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils is geared towards utility functions for testing purposes. The dot8s() method, which seems to deal with memory segments, can be useful in testing scenarios involving memory operations. This move would align with the Single Responsibility Principle by consolidating test-related utilities. However, it may dilute the focus of FunctionTestUtils if not all methods are related to memory operations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"dotProduct","method_signature":"static dotProduct(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"squareDistance","method_signature":"static squareDistance(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"dot8Stride","method_signature":"private static dot8Stride()","target_class":"","rationale":""},{"method_name":"sqr8Stride","method_signature":"private static sqr8Stride()","target_class":"","rationale":""},{"method_name":"dot8s","method_signature":"private static dot8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"sqr8s","method_signature":"private static sqr8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"dot8Stride","method_signature":"private static dot8Stride()","target_class":"","rationale":""},{"method_name":"sqr8Stride","method_signature":"private static sqr8Stride()","target_class":"","rationale":""},{"method_name":"dot8s","method_signature":"private static dot8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"sqr8s","method_signature":"private static sqr8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"dotProduct","method_signature":"static dotProduct(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},{"method_name":"squareDistance","method_signature":"static squareDistance(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static dot8Stride()":{"first":{"method_name":"dot8Stride","method_signature":"private static dot8Stride()","target_class":"","rationale":""},"second":0.5798461159455699},"private static sqr8Stride()":{"first":{"method_name":"sqr8Stride","method_signature":"private static sqr8Stride()","target_class":"","rationale":""},"second":0.5798461159455699},"private static dot8s(MemorySegment a, MemorySegment b, int length)":{"first":{"method_name":"dot8s","method_signature":"private static dot8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},"second":0.5845079665016029},"private static sqr8s(MemorySegment a, MemorySegment b, int length)":{"first":{"method_name":"sqr8s","method_signature":"private static sqr8s(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},"second":0.5845079665016029},"static dotProduct(MemorySegment a, MemorySegment b, int length)":{"first":{"method_name":"dotProduct","method_signature":"static dotProduct(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},"second":0.6859050095963771},"static squareDistance(MemorySegment a, MemorySegment b, int length)":{"first":{"method_name":"squareDistance","method_signature":"static squareDistance(MemorySegment a, MemorySegment b, int length)","target_class":"","rationale":""},"second":0.6910689706410051}},"llmMethodPriority":{"priority_method_names":["dot8Stride","sqr8Stride","dot8s","sqr8s","dotProduct","squareDistance"],"llm_response_time":2233},"targetClassMap":{"dot8Stride":{"target_classes":[{"class_name":"JwkValidateUtil","similarity_score":0.495852189848762},{"class_name":"JwkValidateUtilTests","similarity_score":0.5495094210558729},{"class_name":"FunctionTestUtils","similarity_score":0.6534102628035482},{"class_name":"FutureUtils","similarity_score":0.5601838717325355},{"class_name":"JwtUtil","similarity_score":0.5605194835594477},{"class_name":"CredentialsRedaction","similarity_score":0.573915988663668},{"class_name":"GceMockUtils","similarity_score":0.5958469241734656},{"class_name":"ExceptionUtils","similarity_score":0.586856917541803},{"class_name":"CheckedFunctionUtils","similarity_score":0.13952022959375626},{"class_name":"CryptUtils","similarity_score":0.6230276936934703},{"class_name":"GeneratorUtils","similarity_score":0.6385140125974238},{"class_name":"CsvTestUtils","similarity_score":0.5073099909736067},{"class_name":"KeyStoreUtil","similarity_score":0.5372121733696668},{"class_name":"ExecutionUtils","similarity_score":0.6111111111111112},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.44939710027456564},{"class_name":"DiffableTestUtils","similarity_score":0.3849741916091625},{"class_name":"DiffableUtils","similarity_score":0.5781974462192008},{"class_name":"CIDRUtils","similarity_score":0.5069271526773318},{"class_name":"CircleUtils","similarity_score":0.32546412386541135},{"class_name":"GeometryTestUtils","similarity_score":0.6207425941713967},{"class_name":"GeoTestUtils","similarity_score":0.5088284381333159},{"class_name":"GeoTileUtils","similarity_score":0.36047842300138605},{"class_name":"GeoUtils","similarity_score":0.3820393509712231},{"class_name":"GeoUtilsTests","similarity_score":0.4093174715801813},{"class_name":"DiscoveryNodeUtils","similarity_score":0.5809627087685549},{"class_name":"ClasspathUtils","similarity_score":0.5404325190921689},{"class_name":"DataExtractorUtils","similarity_score":0.5043808594578718},{"class_name":"DatafeedConfigUtils","similarity_score":0.6544185254333574},{"class_name":"LdapTestUtils","similarity_score":0.302353948953476},{"class_name":"LdapUtils","similarity_score":0.540727332622263}],"target_classes_sorted_by_llm":["ExecutionUtils","FunctionTestUtils","DatafeedConfigUtils","DiffableUtils","CryptUtils","GeometryTestUtils","GceMockUtils","ExceptionUtils","GeneratorUtils","DiscoveryNodeUtils"],"llm_response_time":14936,"similarity_computation_time":24,"similarity_metric":"voyage"},"sqr8Stride":{"target_classes":[{"class_name":"RestResponseUtils","similarity_score":0.7203703479149709},{"class_name":"HdfsUtils","similarity_score":0.547423844031089},{"class_name":"RestTestUtil","similarity_score":0.3598548718183264},{"class_name":"RestUtils","similarity_score":0.41758543240993906},{"class_name":"RestUtilsTests","similarity_score":0.2568123929009665},{"class_name":"FunctionTestUtils","similarity_score":0.6534102628035482},{"class_name":"IndexerUtils","similarity_score":0.43437464231754597},{"class_name":"FutureUtils","similarity_score":0.5601838717325355},{"class_name":"JwkValidateUtil","similarity_score":0.495852189848762},{"class_name":"JwkValidateUtilTests","similarity_score":0.5495094210558729},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.5568535147683555},{"class_name":"GceMockUtils","similarity_score":0.5958469241734656},{"class_name":"ResultUtils","similarity_score":0.47809144373375745},{"class_name":"JwtUtil","similarity_score":0.5605194835594477},{"class_name":"RetentionLeaseUtils","similarity_score":0.29375604442524006},{"class_name":"HighlightUtils","similarity_score":0.43082021842766455},{"class_name":"IndexVersionUtils","similarity_score":0.5507513688904067},{"class_name":"IndicesRequestCacheUtils","similarity_score":0.6095569153307366},{"class_name":"GeneratorUtils","similarity_score":0.6385140125974238},{"class_name":"CheckedFunctionUtils","similarity_score":0.13952022959375626},{"class_name":"InferenceModelTestUtils","similarity_score":0.4437059837324712},{"class_name":"KeyStoreUtil","similarity_score":0.5372121733696668},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.44939710027456564},{"class_name":"GeometryTestUtils","similarity_score":0.6207425941713967},{"class_name":"CIDRUtils","similarity_score":0.5069271526773318},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.4866327896836276},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.23671079527325214},{"class_name":"GeoTestUtils","similarity_score":0.5088284381333159},{"class_name":"CircleUtils","similarity_score":0.32546412386541135},{"class_name":"GeoTileUtils","similarity_score":0.36047842300138605}],"target_classes_sorted_by_llm":["FutureUtils","GeneratorUtils","FunctionTestUtils","IndexVersionUtils","IndicesRequestCacheUtils","JwtUtil","GceMockUtils","GeometryTestUtils","IndexLongFieldRangeTestUtils","RestResponseUtils"],"llm_response_time":19024,"similarity_computation_time":22,"similarity_metric":"voyage"},"dot8s":{"target_classes":[{"class_name":"AuditUtil","similarity_score":0.5556768464854216},{"class_name":"RestResponseUtils","similarity_score":0.6284186886676618},{"class_name":"JwkValidateUtil","similarity_score":0.4448630511968435},{"class_name":"JwkValidateUtilTests","similarity_score":0.4798933561933231},{"class_name":"FunctionTestUtils","similarity_score":0.5871586723141177},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.3238045178043823},{"class_name":"AuthorizationUtils","similarity_score":0.1793018170010374},{"class_name":"JwtUtil","similarity_score":0.48554119450410876},{"class_name":"FutureUtils","similarity_score":0.4832494431420683},{"class_name":"GceMockUtils","similarity_score":0.5140146099069096},{"class_name":"CheckedFunctionUtils","similarity_score":0.12035882620060143},{"class_name":"DiffableTestUtils","similarity_score":0.336986540448798},{"class_name":"DiffableUtils","similarity_score":0.5036723223422973},{"class_name":"RestTestUtil","similarity_score":0.310433190231504},{"class_name":"NumberUtils","similarity_score":0.49743882445310905},{"class_name":"GeneratorUtils","similarity_score":0.5508218936610835},{"class_name":"KeyStoreUtil","similarity_score":0.4659789607435976},{"class_name":"NumericUtilsTests","similarity_score":0.1755655688488347},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.3911392944226773},{"class_name":"RestUtils","similarity_score":0.3723162190647543},{"class_name":"RestUtilsTests","similarity_score":0.22154234015617796},{"class_name":"DiscoveryNodeUtils","similarity_score":0.5011745601143587},{"class_name":"AwsEc2Utils","similarity_score":0.48078078944579455},{"class_name":"CIDRUtils","similarity_score":0.440891368150446},{"class_name":"CircleUtils","similarity_score":0.29687509364248366},{"class_name":"ResultUtils","similarity_score":0.4124314097811736},{"class_name":"RetentionLeaseUtils","similarity_score":0.25341223132516877},{"class_name":"ClasspathUtils","similarity_score":0.4662106981042301},{"class_name":"OpenAiUtils","similarity_score":0.21092506540325895},{"class_name":"GeometryTestUtils","similarity_score":0.54480405279129}],"target_classes_sorted_by_llm":["NumberUtils","AuditUtil","FunctionTestUtils","GeneratorUtils","DiffableUtils","RestResponseUtils","JwtUtil","GceMockUtils","DiscoveryNodeUtils","GeometryTestUtils"],"llm_response_time":15686,"similarity_computation_time":12,"similarity_metric":"voyage"}}}
{"id":"3aa7af28-6208-4492-8c43-f0489e6a887d","methodCount":3,"hostFunctionTelemetryData":{"hostFunctionSize":49,"lineStart":103,"lineEnd":151,"bodyLineStart":103,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/search/aggregations/bucket/prefix/IpPrefixAggregator.java","sourceCode":"private class IpPrefixLeafCollector extends LeafBucketCollectorBase {\n        private final IpPrefix ipPrefix;\n        private final LeafBucketCollector sub;\n        private final SortedBinaryDocValues values;\n\n        IpPrefixLeafCollector(final LeafBucketCollector sub, final SortedBinaryDocValues values, final IpPrefix ipPrefix) {\n            super(sub, values);\n            this.sub \u003d sub;\n            this.values \u003d values;\n            this.ipPrefix \u003d ipPrefix;\n        }\n\n        @Override\n        public void collect(int doc, long owningBucketOrd) throws IOException {\n            BytesRef previousSubnet \u003d null;\n            BytesRef subnet \u003d new BytesRef(new byte[ipPrefix.netmask.length]);\n            BytesRef ipAddress;\n            if (values.advanceExact(doc)) {\n                int valuesCount \u003d values.docValueCount();\n\n                for (int i \u003d 0; i \u003c valuesCount; ++i) {\n                    ipAddress \u003d values.nextValue();\n                    maskIpAddress(ipAddress, ipPrefix.netmask, subnet);\n                    if (previousSubnet !\u003d null \u0026\u0026 subnet.bytesEquals(previousSubnet)) {\n                        continue;\n                    }\n                    long bucketOrd \u003d bucketOrds.add(owningBucketOrd, subnet);\n                    if (bucketOrd \u003c 0) {\n                        bucketOrd \u003d -1 - bucketOrd;\n                        collectExistingBucket(sub, doc, bucketOrd);\n                    } else {\n                        collectBucket(sub, doc, bucketOrd);\n                    }\n                    previousSubnet \u003d subnet;\n                }\n            }\n        }\n\n        private static void maskIpAddress(final BytesRef ipAddress, final BytesRef subnetMask, final BytesRef subnet) {\n            assert ipAddress.length \u003d\u003d 16 : \"Invalid length for ip address [\" + ipAddress.length + \"] expected 16 bytes\";\n            // NOTE: IPv4 addresses are encoded as 16-bytes. As a result, we use an\n            // offset (12) to apply the subnet to the last 4 bytes (byes 12, 13, 14, 15)\n            // if the subnet mask is just a 4-bytes subnet mask.\n            int offset \u003d subnetMask.length \u003d\u003d 4 ? 12 : 0;\n            for (int i \u003d 0; i \u003c subnetMask.length; ++i) {\n                subnet.bytes[i] \u003d (byte) (ipAddress.bytes[i + offset] \u0026 subnetMask.bytes[i]);\n            }\n        }\n    }","methodCount":3},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":140,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method maskIpAddress to class IpPrefixAggregator","description":"move method maskIpAddress to PsiClass:IpPrefixAggregator\nRationale: The maskIpAddress method is directly related to IP address manipulation, which aligns well with the responsibilities of IpPrefixAggregator. Moving this method here adheres to the Single Responsibility Principle, as it centralizes IP prefix-related functionality. This enhances cohesion within the class, making it easier to maintain and extend. However, the existing dependencies on BytesRef must be managed to ensure compatibility.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":140,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method maskIpAddress to class IpPrefixAggregationBuilder","description":"move method maskIpAddress to PsiClass:IpPrefixAggregationBuilder\nRationale: The IpPrefixAggregationBuilder class is responsible for building aggregations related to IP prefixes, making it a suitable target for the maskIpAddress method. Relocating this method would enhance the separation of concerns by consolidating IP-related logic within the aggregation builder. This move supports the Open/Closed Principle, allowing future extensions without modifying existing code. However, the method\u0027s static nature might require adjustments to fit into this context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":140,"lineEnd":149,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method maskIpAddress to class IncludeExclude","description":"move method maskIpAddress to PsiClass:IncludeExclude\nRationale: The IncludeExclude class deals with filtering mechanisms which can include IP address filtering. The maskIpAddress method can be logically associated with defining which IPs to include or exclude based on subnet masks. This move would improve the class\u0027s cohesion and keep related functionalities together. Care should be taken to ensure that the purpose of the IncludeExclude class is not diluted by introducing too much unrelated functionality.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"maskIpAddress","method_signature":"private static maskIpAddress(final BytesRef ipAddress, final BytesRef subnetMask, final BytesRef subnet)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"maskIpAddress","method_signature":"private static maskIpAddress(final BytesRef ipAddress, final BytesRef subnetMask, final BytesRef subnet)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static maskIpAddress(final BytesRef ipAddress, final BytesRef subnetMask, final BytesRef subnet)":{"first":{"method_name":"maskIpAddress","method_signature":"private static maskIpAddress(final BytesRef ipAddress, final BytesRef subnetMask, final BytesRef subnet)","target_class":"","rationale":""},"second":0.3341975206046123}},"llmMethodPriority":{"priority_method_names":["maskIpAddress"],"llm_response_time":1005},"targetClassMap":{"maskIpAddress":{"target_classes":[{"class_name":"IpPrefixAggregator","similarity_score":0.5336695953084089},{"class_name":"GeoTileUtils","similarity_score":0.44542187489166646},{"class_name":"BucketUtils","similarity_score":0.336006299011313},{"class_name":"IpPrefixAggregationBuilder","similarity_score":0.4459712771471511},{"class_name":"IpPrefixAggregatorFactory","similarity_score":0.19218285033310883},{"class_name":"Bucket","similarity_score":0.3261952449267647},{"class_name":"HighlightUtils","similarity_score":0.3124470747922782},{"class_name":"HistogramAggregationBuilder","similarity_score":0.3767284914753189},{"class_name":"HistogramAggregatorFactory","similarity_score":0.30034503489640174},{"class_name":"HistogramValuesSourceBuilder","similarity_score":0.3025713102432756},{"class_name":"GeoDistanceAggregationBuilder","similarity_score":0.39438860902565803},{"class_name":"GeoDistanceRangeAggregatorFactory","similarity_score":0.28288255789462013},{"class_name":"GeoHashGridAggregationBuilder","similarity_score":0.24752321469051794},{"class_name":"GeoHashGridAggregatorFactory","similarity_score":0.2094779062288701},{"class_name":"GeoHashGridIT","similarity_score":0.4164252001319032},{"class_name":"DiversifiedAggregationBuilder","similarity_score":0.3339962389023382},{"class_name":"DiversifiedAggregatorFactory","similarity_score":0.2404246318867064},{"class_name":"ReverseNestedAggregationBuilder","similarity_score":0.3547710235934398},{"class_name":"GeoTileGridAggregationBuilder","similarity_score":0.24820395351941812},{"class_name":"GeoTileGridAggregatorFactory","similarity_score":0.19917569615841366},{"class_name":"GeoTileGridValuesSourceBuilder","similarity_score":0.311665697999367},{"class_name":"DoubleBounds","similarity_score":0.3088043118152267},{"class_name":"DoubleBoundsTests","similarity_score":0.30594629649364785},{"class_name":"IncludeExclude","similarity_score":0.4117765871102609},{"class_name":"GlobalAggregationBuilder","similarity_score":0.1883511180122989},{"class_name":"InternalComposite","similarity_score":0.469711612225133},{"class_name":"InternalCompositeTests","similarity_score":0.348706759935658},{"class_name":"SamplerAggregationBuilder","similarity_score":0.3050101475347582},{"class_name":"FiltersIT","similarity_score":0.34126316904793563}],"target_classes_sorted_by_llm":["IpPrefixAggregator","IpPrefixAggregationBuilder","IncludeExclude","GeoDistanceAggregationBuilder","GeoTileUtils","HistogramAggregationBuilder","InternalComposite","GeoHashGridIT","ReverseNestedAggregationBuilder","InternalCompositeTests"],"llm_response_time":18527,"similarity_computation_time":26,"similarity_metric":"voyage"}}}
{"id":"9334468a-ab30-4c12-8dfd-3c01152482a7","methodCount":7,"hostFunctionTelemetryData":{"hostFunctionSize":184,"lineStart":24,"lineEnd":207,"bodyLineStart":24,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/bootstrap/JNANatives.java","sourceCode":"/**\n * This class performs the actual work with JNA and library bindings to call native methods. It should only be used after\n * we are sure that the JNA classes are available to the JVM\n */\nclass JNANatives {\n\n    /** no instantiation */\n    private JNANatives() {}\n\n    private static final Logger logger \u003d LogManager.getLogger(JNANatives.class);\n\n    // Set to true, in case native mlockall call was successful\n    static boolean LOCAL_MLOCKALL \u003d false;\n    // Set to true, in case native system call filter install was successful\n    static boolean LOCAL_SYSTEM_CALL_FILTER \u003d false;\n    // Set to true, in case policy can be applied to all threads of the process (even existing ones)\n    // otherwise they are only inherited for new threads (ES app threads)\n    static boolean LOCAL_SYSTEM_CALL_FILTER_ALL \u003d false;\n\n    static void tryMlockall() {\n        int errno \u003d Integer.MIN_VALUE;\n        String errMsg \u003d null;\n        boolean rlimitSuccess \u003d false;\n        long softLimit \u003d 0;\n        long hardLimit \u003d 0;\n\n        try {\n            int result \u003d JNACLibrary.mlockall(JNACLibrary.MCL_CURRENT);\n            if (result \u003d\u003d 0) {\n                LOCAL_MLOCKALL \u003d true;\n                return;\n            }\n\n            errno \u003d Native.getLastError();\n            errMsg \u003d JNACLibrary.strerror(errno);\n            if (Constants.LINUX || Constants.MAC_OS_X) {\n                // we only know RLIMIT_MEMLOCK for these two at the moment.\n                JNACLibrary.Rlimit rlimit \u003d new JNACLibrary.Rlimit();\n                if (JNACLibrary.getrlimit(JNACLibrary.RLIMIT_MEMLOCK, rlimit) \u003d\u003d 0) {\n                    rlimitSuccess \u003d true;\n                    softLimit \u003d rlimit.rlim_cur.longValue();\n                    hardLimit \u003d rlimit.rlim_max.longValue();\n                } else {\n                    logger.warn(\"Unable to retrieve resource limits: {}\", JNACLibrary.strerror(Native.getLastError()));\n                }\n            }\n        } catch (UnsatisfiedLinkError e) {\n            // this will have already been logged by CLibrary, no need to repeat it\n            return;\n        }\n\n        // mlockall failed for some reason\n        logger.warn(\"Unable to lock JVM Memory: error\u003d{}, reason\u003d{}\", errno, errMsg);\n        logger.warn(\"This can result in part of the JVM being swapped out.\");\n        if (errno \u003d\u003d JNACLibrary.ENOMEM) {\n            if (rlimitSuccess) {\n                logger.warn(\n                    \"Increase RLIMIT_MEMLOCK, soft limit: {}, hard limit: {}\",\n                    rlimitToString(softLimit),\n                    rlimitToString(hardLimit)\n                );\n                if (Constants.LINUX) {\n                    // give specific instructions for the linux case to make it easy\n                    String user \u003d System.getProperty(\"user.name\");\n                    logger.warn(\"\"\"\n                        These can be adjusted by modifying /etc/security/limits.conf, for example:\n                        \\t# allow user \u0027{}\u0027 mlockall\n                        \\t{} soft memlock unlimited\n                        \\t{} hard memlock unlimited\"\"\", user, user, user);\n                    logger.warn(\"If you are logged in interactively, you will have to re-login for the new limits to take effect.\");\n                }\n            } else {\n                logger.warn(\"Increase RLIMIT_MEMLOCK (ulimit).\");\n            }\n        }\n    }\n\n    static String rlimitToString(long value) {\n        assert Constants.LINUX || Constants.MAC_OS_X;\n        if (value \u003d\u003d JNACLibrary.RLIM_INFINITY) {\n            return \"unlimited\";\n        } else {\n            return Long.toUnsignedString(value);\n        }\n    }\n\n    static void tryVirtualLock() {\n        JNAKernel32Library kernel \u003d JNAKernel32Library.getInstance();\n        Pointer process \u003d null;\n        try {\n            process \u003d kernel.GetCurrentProcess();\n            // By default, Windows limits the number of pages that can be locked.\n            // Thus, we need to first increase the working set size of the JVM by\n            // the amount of memory we wish to lock, plus a small overhead (1MB).\n            SizeT size \u003d new SizeT(JvmInfo.jvmInfo().getMem().getHeapInit().getBytes() + (1024 * 1024));\n            if (kernel.SetProcessWorkingSetSize(process, size, size) \u003d\u003d false) {\n                logger.warn(\"Unable to lock JVM memory. Failed to set working set size. Error code {}\", Native.getLastError());\n            } else {\n                JNAKernel32Library.MemoryBasicInformation memInfo \u003d new JNAKernel32Library.MemoryBasicInformation();\n                long address \u003d 0;\n                while (kernel.VirtualQueryEx(process, new Pointer(address), memInfo, memInfo.size()) !\u003d 0) {\n                    boolean lockable \u003d memInfo.State.longValue() \u003d\u003d JNAKernel32Library.MEM_COMMIT\n                        \u0026\u0026 (memInfo.Protect.longValue() \u0026 JNAKernel32Library.PAGE_NOACCESS) !\u003d JNAKernel32Library.PAGE_NOACCESS\n                        \u0026\u0026 (memInfo.Protect.longValue() \u0026 JNAKernel32Library.PAGE_GUARD) !\u003d JNAKernel32Library.PAGE_GUARD;\n                    if (lockable) {\n                        kernel.VirtualLock(memInfo.BaseAddress, new SizeT(memInfo.RegionSize.longValue()));\n                    }\n                    // Move to the next region\n                    address +\u003d memInfo.RegionSize.longValue();\n                }\n                LOCAL_MLOCKALL \u003d true;\n            }\n        } catch (UnsatisfiedLinkError e) {\n            // this will have already been logged by Kernel32Library, no need to repeat it\n        } finally {\n            if (process !\u003d null) {\n                kernel.CloseHandle(process);\n            }\n        }\n    }\n\n    /**\n     * Retrieves the short path form of the specified path.\n     *\n     * @param path the path\n     * @return the short path name (or the original path if getting the short path name fails for any reason)\n     */\n    static String getShortPathName(String path) {\n        assert Constants.WINDOWS;\n        try {\n            final WString longPath \u003d new WString(\"\\\\\\\\?\\\\\" + path);\n            // first we get the length of the buffer needed\n            final int length \u003d JNAKernel32Library.getInstance().GetShortPathNameW(longPath, null, 0);\n            if (length \u003d\u003d 0) {\n                logger.warn(\"failed to get short path name: {}\", Native.getLastError());\n                return path;\n            }\n            final char[] shortPath \u003d new char[length];\n            // knowing the length of the buffer, now we get the short name\n            if (JNAKernel32Library.getInstance().GetShortPathNameW(longPath, shortPath, length) \u003e 0) {\n                return Native.toString(shortPath);\n            } else {\n                logger.warn(\"failed to get short path name: {}\", Native.getLastError());\n                return path;\n            }\n        } catch (final UnsatisfiedLinkError e) {\n            return path;\n        }\n    }\n\n    static void addConsoleCtrlHandler(ConsoleCtrlHandler handler) {\n        // The console Ctrl handler is necessary on Windows platforms only.\n        if (Constants.WINDOWS) {\n            try {\n                boolean result \u003d JNAKernel32Library.getInstance().addConsoleCtrlHandler(handler);\n                if (result) {\n                    logger.debug(\"console ctrl handler correctly set\");\n                } else {\n                    logger.warn(\"unknown error {} when adding console ctrl handler\", Native.getLastError());\n                }\n            } catch (UnsatisfiedLinkError e) {\n                // this will have already been logged by Kernel32Library, no need to repeat it\n            }\n        }\n    }\n\n    static void tryInstallSystemCallFilter(Path tmpFile) {\n        try {\n            int ret \u003d SystemCallFilter.init(tmpFile);\n            LOCAL_SYSTEM_CALL_FILTER \u003d true;\n            if (ret \u003d\u003d 1) {\n                LOCAL_SYSTEM_CALL_FILTER_ALL \u003d true;\n            }\n        } catch (Exception e) {\n            // this is likely to happen unless the kernel is newish, its a best effort at the moment\n            // so we log stacktrace at debug for now...\n            if (logger.isDebugEnabled()) {\n                logger.debug(\"unable to install syscall filter\", e);\n            }\n            logger.warn(\"unable to install syscall filter: \", e);\n        }\n    }\n\n}","methodCount":7},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":100,"lineEnd":107,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rlimitToString to class GeneratorUtils","description":"move method rlimitToString to PsiClass:GeneratorUtils\nRationale: The rlimitToString() method deals with converting a long value into a string representation, which aligns well with the utility functions provided by GeneratorUtils for handling value transformations. Moving it here adheres to the Single Responsibility Principle, as it centralizes utility functions related to value manipulation. This enhances cohesion and makes the method more reusable across various contexts. A potential drawback is that it may introduce a dependency on the GeneratorUtils class for any future modifications.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":100,"lineEnd":107,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rlimitToString to class RestResponseUtils","description":"move method rlimitToString to PsiClass:RestResponseUtils\nRationale: The rlimitToString() method could be relevant in the context of generating responses, particularly when dealing with limits in a REST API context. Moving it here would improve the separation of concerns by placing utility functions that aid in response formatting together. This aligns with the Open/Closed Principle as it allows for easier extension of response utilities. However, it may dilute the focus of RestResponseUtils if too many unrelated utility functions are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":100,"lineEnd":107,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rlimitToString to class JwtUtil","description":"move method rlimitToString to PsiClass:JwtUtil\nRationale: While not directly related, the rlimitToString() method could potentially be useful in generating string representations of limits when dealing with JWT claims or settings. This move could enhance the utility of JwtUtil for string manipulations, adhering to the Interface Segregation Principle by not forcing unrelated methods into a single interface. The drawback is that it may not fit naturally into the JWT processing context, leading to potential confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":144,"lineEnd":171,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getShortPathName to class FilePermissionUtils","description":"move method getShortPathName to PsiClass:FilePermissionUtils\nRationale: The getShortPathName() method deals with file paths, which aligns closely with the responsibilities of FilePermissionUtils, a class that likely handles file-related operations. Moving this method here adheres to the Single Responsibility Principle by consolidating file path manipulations into one utility class, improving cohesion. However, care must be taken to ensure that this class does not become overly burdened with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":144,"lineEnd":171,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getShortPathName to class RestUtils","description":"move method getShortPathName to PsiClass:RestUtils\nRationale: RestUtils handles various utilities related to REST operations, and since paths can be relevant in RESTful API contexts (like handling file uploads or downloads), moving getShortPathName() here can enhance the utility of the class. This aligns with the Open/Closed Principle, as the class can be extended with more path-related utilities without modifying existing code. A potential drawback is that it may dilute the focus of RestUtils if too many unrelated utilities are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":144,"lineEnd":171,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method getShortPathName to class JwtUtil","description":"move method getShortPathName to PsiClass:JwtUtil\nRationale: JwtUtil includes methods for resolving paths, which suggests that it might benefit from incorporating path manipulation utilities like getShortPathName(). This move could enhance the utility of JwtUtil when dealing with token storage or retrieval that involves file paths. This aligns with the Interface Segregation Principle, as it allows JwtUtil to handle more specific responsibilities. However, it could lead to a mixing of concerns if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":173,"lineEnd":187,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addConsoleCtrlHandler to class BootstrapUtil","description":"move method addConsoleCtrlHandler to PsiClass:BootstrapUtil\nRationale: The addConsoleCtrlHandler() method deals with application startup and environment configuration, which aligns well with the responsibilities of BootstrapUtil. Moving it here adheres to the Single Responsibility Principle, as it centralizes application bootstrap logic. This enhances cohesion and maintainability. However, care should be taken to ensure that the bootstrap process remains clear and that the method does not introduce platform-specific dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":173,"lineEnd":187,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addConsoleCtrlHandler to class JwtUtil","description":"move method addConsoleCtrlHandler to PsiClass:JwtUtil\nRationale: JwtUtil handles various utility functions related to JSON Web Tokens, including security aspects. Since the addConsoleCtrlHandler() method involves security-related console control handling, it fits well here. This move respects the Interface Segregation Principle by keeping security-related utilities together. However, it may dilute the focus of JwtUtil if it becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":173,"lineEnd":187,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method addConsoleCtrlHandler to class CIDRUtils","description":"move method addConsoleCtrlHandler to PsiClass:CIDRUtils\nRationale: CIDRUtils deals with network-related utilities, and since console control handlers are often related to network operations in server applications, this could be a relevant home. This move would maintain the Single Responsibility Principle, but it may not be the most intuitive fit as the class is primarily focused on CIDR notation and not console operations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"tryMlockall","method_signature":"static tryMlockall()","target_class":"","rationale":""},{"method_name":"rlimitToString","method_signature":"static rlimitToString(long value)","target_class":"","rationale":""},{"method_name":"tryVirtualLock","method_signature":"static tryVirtualLock()","target_class":"","rationale":""},{"method_name":"getShortPathName","method_signature":"static getShortPathName(String path)","target_class":"","rationale":""},{"method_name":"addConsoleCtrlHandler","method_signature":"static addConsoleCtrlHandler(ConsoleCtrlHandler handler)","target_class":"","rationale":""},{"method_name":"tryInstallSystemCallFilter","method_signature":"static tryInstallSystemCallFilter(Path tmpFile)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"rlimitToString","method_signature":"static rlimitToString(long value)","target_class":"","rationale":""},{"method_name":"getShortPathName","method_signature":"static getShortPathName(String path)","target_class":"","rationale":""},{"method_name":"addConsoleCtrlHandler","method_signature":"static addConsoleCtrlHandler(ConsoleCtrlHandler handler)","target_class":"","rationale":""},{"method_name":"tryInstallSystemCallFilter","method_signature":"static tryInstallSystemCallFilter(Path tmpFile)","target_class":"","rationale":""},{"method_name":"tryMlockall","method_signature":"static tryMlockall()","target_class":"","rationale":""},{"method_name":"tryVirtualLock","method_signature":"static tryVirtualLock()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static rlimitToString(long value)":{"first":{"method_name":"rlimitToString","method_signature":"static rlimitToString(long value)","target_class":"","rationale":""},"second":0.5255111115885573},"static getShortPathName(String path)":{"first":{"method_name":"getShortPathName","method_signature":"static getShortPathName(String path)","target_class":"","rationale":""},"second":0.6354846868513044},"static addConsoleCtrlHandler(ConsoleCtrlHandler handler)":{"first":{"method_name":"addConsoleCtrlHandler","method_signature":"static addConsoleCtrlHandler(ConsoleCtrlHandler handler)","target_class":"","rationale":""},"second":0.6486382403965162},"static tryInstallSystemCallFilter(Path tmpFile)":{"first":{"method_name":"tryInstallSystemCallFilter","method_signature":"static tryInstallSystemCallFilter(Path tmpFile)","target_class":"","rationale":""},"second":0.7010777891297644},"static tryMlockall()":{"first":{"method_name":"tryMlockall","method_signature":"static tryMlockall()","target_class":"","rationale":""},"second":0.751050901394627},"static tryVirtualLock()":{"first":{"method_name":"tryVirtualLock","method_signature":"static tryVirtualLock()","target_class":"","rationale":""},"second":0.7843511144580619}},"llmMethodPriority":{"priority_method_names":["rlimitToString","getShortPathName","addConsoleCtrlHandler","tryInstallSystemCallFilter","tryMlockall","tryVirtualLock"],"llm_response_time":1969},"targetClassMap":{"rlimitToString":{"target_classes":[{"class_name":"FilePermissionUtils","similarity_score":0.27455077931778304},{"class_name":"BootstrapUtil","similarity_score":0.4731747551321276},{"class_name":"PolicyUtil","similarity_score":0.43469775449455206},{"class_name":"RestResponseUtils","similarity_score":0.6774581282657175},{"class_name":"JwkValidateUtil","similarity_score":0.49571815762848703},{"class_name":"JwkValidateUtilTests","similarity_score":0.5488877058641847},{"class_name":"FunctionTestUtils","similarity_score":0.6177868548127127},{"class_name":"FutureUtils","similarity_score":0.49401419025107285},{"class_name":"IndexerUtils","similarity_score":0.4500496321575605},{"class_name":"JwtUtil","similarity_score":0.5730760128578027},{"class_name":"EvilSecurityTests","similarity_score":0.3188972059152157},{"class_name":"GceMockUtils","similarity_score":0.6083343997201066},{"class_name":"ExceptionUtils","similarity_score":0.5932237473453119},{"class_name":"RestTestUtil","similarity_score":0.3667487486188731},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.6397134261545293},{"class_name":"GeneratorUtils","similarity_score":0.6751094770703313},{"class_name":"RestUtils","similarity_score":0.4375365174062345},{"class_name":"RestUtilsTests","similarity_score":0.25218354557893113},{"class_name":"DiffableTestUtils","similarity_score":0.34222378222022665},{"class_name":"TemplateUtils","similarity_score":0.563051695463262},{"class_name":"DiffableUtils","similarity_score":0.547489297401972},{"class_name":"TemplateUtilsTests","similarity_score":0.5300256618193545},{"class_name":"Term","similarity_score":0.4741991826910554},{"class_name":"KeyStoreUtil","similarity_score":0.5119498506303257},{"class_name":"ExecutionUtils","similarity_score":0.43915774636553956},{"class_name":"DiscoveryNodeUtils","similarity_score":0.60353714607593},{"class_name":"ResultUtils","similarity_score":0.4168275107825463},{"class_name":"RetentionLeaseUtils","similarity_score":0.2630695140178147},{"class_name":"IndexVersionUtils","similarity_score":0.5426428129303112},{"class_name":"GeometryTestUtils","similarity_score":0.5697491621116964}],"target_classes_sorted_by_llm":["GeneratorUtils","RestResponseUtils","JwtUtil","TemplateUtils","ExceptionUtils","FunctionTestUtils","GeometryTestUtils","IndexLongFieldRangeTestUtils","DiscoveryNodeUtils","GceMockUtils"],"llm_response_time":16142,"similarity_computation_time":16,"similarity_metric":"voyage"},"getShortPathName":{"target_classes":[{"class_name":"PolicyUtil","similarity_score":0.5397881941594052},{"class_name":"FilePermissionUtils","similarity_score":0.5973717920254451},{"class_name":"BootstrapUtil","similarity_score":0.3219963251455568},{"class_name":"RestResponseUtils","similarity_score":0.43555270412186625},{"class_name":"RestTestUtil","similarity_score":0.5229862790310308},{"class_name":"RestUtils","similarity_score":0.6370246845175817},{"class_name":"RestUtilsTests","similarity_score":0.2247596866926135},{"class_name":"FunctionTestUtils","similarity_score":0.3832712342289273},{"class_name":"FutureUtils","similarity_score":0.5616036116984415},{"class_name":"JwkValidateUtil","similarity_score":0.4400721826416927},{"class_name":"JwkValidateUtilTests","similarity_score":0.40831427591060426},{"class_name":"ResultUtils","similarity_score":0.2362354777105931},{"class_name":"GceMockUtils","similarity_score":0.45422601711278293},{"class_name":"JwtUtil","similarity_score":0.5531530630310529},{"class_name":"RetentionLeaseUtils","similarity_score":0.3357382755985635},{"class_name":"CheckedFunctionUtils","similarity_score":0.34611523217289264},{"class_name":"GeneratorUtils","similarity_score":0.4156617493146263},{"class_name":"NumberUtils","similarity_score":0.49389597567391985},{"class_name":"TemplateUtils","similarity_score":0.4844367785182857},{"class_name":"TemplateUtilsTests","similarity_score":0.3583822026196762},{"class_name":"NumericUtilsTests","similarity_score":0.13633142907430854},{"class_name":"Term","similarity_score":0.2825883226534008},{"class_name":"KeyStoreUtil","similarity_score":0.5754987502765838},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.5495142596092746},{"class_name":"GeometryTestUtils","similarity_score":0.40609548431586645},{"class_name":"CIDRUtils","similarity_score":0.42599471803987293},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.5908487961241089},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.3123367502012428},{"class_name":"GeoTestUtils","similarity_score":0.3309055063601556},{"class_name":"CircleUtils","similarity_score":0.45447729618967536}],"target_classes_sorted_by_llm":["FilePermissionUtils","RestUtils","JwtUtil","PolicyUtil","RollupJobIdentifierUtils","KeyStoreUtil","FutureUtils","RestTestUtil","ChunkedLoggingStreamTestUtils","NumberUtils"],"llm_response_time":16168,"similarity_computation_time":15,"similarity_metric":"voyage"},"addConsoleCtrlHandler":{"target_classes":[{"class_name":"BootstrapUtil","similarity_score":0.5188507935492721},{"class_name":"FilePermissionUtils","similarity_score":0.36511608721414307},{"class_name":"PolicyUtil","similarity_score":0.5105172275199129},{"class_name":"RestResponseUtils","similarity_score":0.6263026404943398},{"class_name":"RestTestUtil","similarity_score":0.40717826903293186},{"class_name":"JwkValidateUtil","similarity_score":0.46606688099751165},{"class_name":"JwkValidateUtilTests","similarity_score":0.5732458811884558},{"class_name":"RestUtils","similarity_score":0.4461615617299208},{"class_name":"RestUtilsTests","similarity_score":0.29803358873905567},{"class_name":"JwtUtil","similarity_score":0.5586146927856934},{"class_name":"CredentialsRedaction","similarity_score":0.6165864769195791},{"class_name":"ResultUtils","similarity_score":0.3688036016357173},{"class_name":"RetentionLeaseUtils","similarity_score":0.2737346241762229},{"class_name":"CryptUtils","similarity_score":0.4844894130136815},{"class_name":"CheckedFunctionUtils","similarity_score":0.18063278119512569},{"class_name":"SnapshotInfoTestUtils","similarity_score":0.24480278905993902},{"class_name":"SnapshotInfoUtils","similarity_score":0.4191756062750766},{"class_name":"CsvTestUtils","similarity_score":0.4922000988194758},{"class_name":"TemplateUtils","similarity_score":0.4914526521238857},{"class_name":"TemplateUtilsTests","similarity_score":0.5700216792849608},{"class_name":"Term","similarity_score":0.42825453898646954},{"class_name":"SnapshotUtils","similarity_score":0.6368150994702136},{"class_name":"KeyStoreUtil","similarity_score":0.5177495344419049},{"class_name":"ChunkedLoggingStreamTestUtils","similarity_score":0.47428829545352946},{"class_name":"CIDRUtils","similarity_score":0.5207394346400119},{"class_name":"CircleUtils","similarity_score":0.36599230295882346},{"class_name":"RollupJobIdentifierUtils","similarity_score":0.5942762358965535},{"class_name":"RollupJobIdentifierUtilTests","similarity_score":0.21104543625294708},{"class_name":"DiffableTestUtils","similarity_score":0.3708793100482759},{"class_name":"DiffableUtils","similarity_score":0.5282255186611272}],"target_classes_sorted_by_llm":["BootstrapUtil","JwtUtil","CIDRUtils","RestResponseUtils","RollupJobIdentifierUtils","SnapshotUtils","DiffableUtils","CredentialsRedaction","TemplateUtilsTests","JwkValidateUtilTests"],"llm_response_time":11698,"similarity_computation_time":19,"similarity_metric":"voyage"}}}
{"id":"b49b8726-9f06-4874-979b-351446cfc92f","methodCount":9,"hostFunctionTelemetryData":{"hostFunctionSize":75,"lineStart":19,"lineEnd":93,"bodyLineStart":19,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql-core/src/main/java/org/elasticsearch/xpack/esql/core/util/SourceUtils.java","sourceCode":"public final class SourceUtils {\n\n    private SourceUtils() {}\n\n    public static void writeSource(StreamOutput out, Source source) throws IOException {\n        writeSource(out, source, true);\n    }\n\n    public static void writeSourceNoText(StreamOutput out, Source source) throws IOException {\n        writeSource(out, source, false);\n    }\n\n    public static Source readSource(StreamInput in) throws IOException {\n        return readSource(in, null);\n    }\n\n    public static Source readSourceWithText(StreamInput in, String queryText) throws IOException {\n        return readSource(in, queryText);\n    }\n\n    private static void writeSource(StreamOutput out, Source source, boolean writeText) throws IOException {\n        out.writeInt(source.source().getLineNumber());\n        out.writeInt(source.source().getColumnNumber());\n        if (writeText) {\n            out.writeString(source.text());\n        } else {\n            out.writeInt(source.text().length());\n        }\n    }\n\n    private static Source readSource(StreamInput in, @Nullable String queryText) throws IOException {\n        int line \u003d in.readInt();\n        int column \u003d in.readInt();\n        int charPositionInLine \u003d column - 1;\n\n        String text;\n        if (queryText \u003d\u003d null) {\n            text \u003d in.readString();\n        } else {\n            int length \u003d in.readInt();\n            text \u003d sourceText(queryText, line, column, length);\n        }\n        return new Source(new Location(line, charPositionInLine), text);\n    }\n\n    private static String sourceText(String query, int line, int column, int length) {\n        if (line \u003c\u003d 0 || column \u003c\u003d 0 || query.isEmpty()) {\n            return StringUtils.EMPTY;\n        }\n        int offset \u003d textOffset(query, line, column);\n        if (offset + length \u003e query.length()) {\n            throw new QlIllegalArgumentException(\n                \"location [@\" + line + \":\" + column + \"] and length [\" + length + \"] overrun query size [\" + query.length() + \"]\"\n            );\n        }\n        return query.substring(offset, offset + length);\n    }\n\n    private static int textOffset(String query, int line, int column) {\n        int offset \u003d 0;\n        if (line \u003e 1) {\n            String[] lines \u003d query.split(\"\\n\");\n            if (line \u003e lines.length) {\n                throw new QlIllegalArgumentException(\n                    \"line location [\" + line + \"] higher than max [\" + lines.length + \"] in query [\" + query + \"]\"\n                );\n            }\n            for (int i \u003d 0; i \u003c line - 1; i++) {\n                offset +\u003d lines[i].length() + 1; // +1 accounts for the removed \\n\n            }\n        }\n        offset +\u003d column - 1; // -1 since column is 1-based indexed\n        return offset;\n    }\n}","methodCount":9},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":26,"lineEnd":28,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSourceNoText to class SerializationTestUtils","description":"move method writeSourceNoText to PsiClass:SerializationTestUtils\nRationale: The writeSourceNoText() method is concerned with writing a Source object to an output stream, which is closely related to serialization. Moving it to SerializationTestUtils aligns with the class\u0027s focus on serialization utilities, enhancing cohesion. This move adheres to the Single Responsibility Principle, as it consolidates serialization-related functionality. However, care must be taken to ensure that the method\u0027s static nature aligns with the intended use of this utility class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":26,"lineEnd":28,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSourceNoText to class TestUtils","description":"move method writeSourceNoText to PsiClass:TestUtils\nRationale: The writeSourceNoText() method can be seen as a utility function for testing purposes. TestUtils serves as a collection of various utility methods for testing, making it a suitable target. This move improves organization and follows the Open/Closed Principle by allowing the class to be extended with more testing utilities without modifying existing code. However, it could lead to a bloated TestUtils class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":26,"lineEnd":28,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSourceNoText to class EsqlTestUtils","description":"move method writeSourceNoText to PsiClass:EsqlTestUtils\nRationale: The method involves writing source data, which can be relevant in the context of ESQL operations. EsqlTestUtils focuses on utilities related to ESQL, making it a fitting candidate. This relocation would enhance cohesion and maintainability, adhering to the Single Responsibility Principle. However, it may introduce unnecessary dependencies if the method is not specifically tied to ESQL functionalities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":22,"lineEnd":24,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSource to class SerializationTestUtils","description":"move method writeSource to PsiClass:SerializationTestUtils\nRationale: The writeSource() method is related to serialization functionality, which aligns well with the purpose of SerializationTestUtils. This move would enhance cohesion by placing serialization logic in a class dedicated to testing serialization. It adheres to the Single Responsibility Principle, ensuring that SerializationTestUtils handles all serialization-related methods. However, care must be taken to ensure that the context for using this method is clear and that it doesn\u0027t inadvertently introduce dependencies on the SerializationTestUtils class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":22,"lineEnd":24,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSource to class TestUtils","description":"move method writeSource to PsiClass:TestUtils\nRationale: TestUtils serves as a general utility class for various test-related functionalities. Moving writeSource() here would centralize utility methods related to tests, improving code organization. This aligns with the Open/Closed Principle, allowing TestUtils to be extended with new methods without modifying existing code. The drawback is that TestUtils may become too broad, potentially violating the Single Responsibility Principle if overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":22,"lineEnd":24,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeSource to class EsqlTestUtils","description":"move method writeSource to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils is focused on utilities for Esql-related functionalities, which could include serialization tasks. Relocating writeSource() here would maintain a clear context for Esql operations. This aligns with the Interface Segregation Principle, ensuring that clients only need to know about relevant functionalities. A potential concern is ensuring that EsqlTestUtils does not become too specific or lose utility for broader serialization tasks.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":30,"lineEnd":32,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readSource to class ParserUtils","description":"move method readSource to PsiClass:ParserUtils\nRationale: The readSource() method seems to be related to reading and processing input streams, which aligns with the responsibilities of ParserUtils. Moving it here adheres to the Single Responsibility Principle, as it centralizes stream parsing functionality. This enhances cohesion within ParserUtils. However, we should ensure that the method\u0027s dependencies do not introduce unnecessary coupling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":30,"lineEnd":32,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readSource to class TestUtils","description":"move method readSource to PsiClass:TestUtils\nRationale: TestUtils is designed to provide utility methods for testing, and readSource() could be useful for initializing test scenarios with input streams. This move aligns with the Open/Closed Principle, allowing TestUtils to be extended for testing without modifying existing code. However, care should be taken to ensure that this utility does not bloat the TestUtils class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":30,"lineEnd":32,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readSource to class InternalQlScriptUtils","description":"move method readSource to PsiClass:InternalQlScriptUtils\nRationale: Given that readSource() may relate to reading data for internal query language scripts, moving it to InternalQlScriptUtils could enhance logical grouping. This aligns with the Interface Segregation Principle, ensuring that classes only have methods they need. However, it may introduce complexity if not all users of InternalQlScriptUtils require this functionality.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"writeSource","method_signature":"public static writeSource(StreamOutput out, Source source)","target_class":"","rationale":""},{"method_name":"writeSourceNoText","method_signature":"public static writeSourceNoText(StreamOutput out, Source source)","target_class":"","rationale":""},{"method_name":"readSource","method_signature":"public static readSource(StreamInput in)","target_class":"","rationale":""},{"method_name":"readSourceWithText","method_signature":"public static readSourceWithText(StreamInput in, String queryText)","target_class":"","rationale":""},{"method_name":"writeSource","method_signature":"private static writeSource(StreamOutput out, Source source, boolean writeText)","target_class":"","rationale":""},{"method_name":"readSource","method_signature":"private static readSource(StreamInput in, @Nullable String queryText)","target_class":"","rationale":""},{"method_name":"sourceText","method_signature":"private static sourceText(String query, int line, int column, int length)","target_class":"","rationale":""},{"method_name":"textOffset","method_signature":"private static textOffset(String query, int line, int column)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"writeSourceNoText","method_signature":"public static writeSourceNoText(StreamOutput out, Source source)","target_class":"","rationale":""},{"method_name":"writeSource","method_signature":"public static writeSource(StreamOutput out, Source source)","target_class":"","rationale":""},{"method_name":"readSource","method_signature":"public static readSource(StreamInput in)","target_class":"","rationale":""},{"method_name":"readSourceWithText","method_signature":"public static readSourceWithText(StreamInput in, String queryText)","target_class":"","rationale":""},{"method_name":"writeSource","method_signature":"private static writeSource(StreamOutput out, Source source, boolean writeText)","target_class":"","rationale":""},{"method_name":"readSource","method_signature":"private static readSource(StreamInput in, @Nullable String queryText)","target_class":"","rationale":""},{"method_name":"sourceText","method_signature":"private static sourceText(String query, int line, int column, int length)","target_class":"","rationale":""},{"method_name":"textOffset","method_signature":"private static textOffset(String query, int line, int column)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static writeSourceNoText(StreamOutput out, Source source)":{"first":{"method_name":"writeSourceNoText","method_signature":"public static writeSourceNoText(StreamOutput out, Source source)","target_class":"","rationale":""},"second":0.39442132525787926},"public static writeSource(StreamOutput out, Source source)":{"first":{"method_name":"writeSource","method_signature":"public static writeSource(StreamOutput out, Source source)","target_class":"","rationale":""},"second":0.3946456194615392},"public static readSource(StreamInput in)":{"first":{"method_name":"readSource","method_signature":"public static readSource(StreamInput in)","target_class":"","rationale":""},"second":0.42591770999996},"public static readSourceWithText(StreamInput in, String queryText)":{"first":{"method_name":"readSourceWithText","method_signature":"public static readSourceWithText(StreamInput in, String queryText)","target_class":"","rationale":""},"second":0.4271301169785416},"private static writeSource(StreamOutput out, Source source, boolean writeText)":{"first":{"method_name":"writeSource","method_signature":"private static writeSource(StreamOutput out, Source source, boolean writeText)","target_class":"","rationale":""},"second":0.4776178513007948},"private static readSource(StreamInput in, @Nullable String queryText)":{"first":{"method_name":"readSource","method_signature":"private static readSource(StreamInput in, @Nullable String queryText)","target_class":"","rationale":""},"second":0.47901105999970206},"private static sourceText(String query, int line, int column, int length)":{"first":{"method_name":"sourceText","method_signature":"private static sourceText(String query, int line, int column, int length)","target_class":"","rationale":""},"second":0.5125098609039297},"private static textOffset(String query, int line, int column)":{"first":{"method_name":"textOffset","method_signature":"private static textOffset(String query, int line, int column)","target_class":"","rationale":""},"second":0.5771814597306805}},"llmMethodPriority":{"priority_method_names":["writeSource","writeSourceNoText","readSource","readSourceWithText","readSource","writeSource","sourceText","textOffset"],"llm_response_time":3895},"targetClassMap":{"writeSourceNoText":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.1394849051956293},{"class_name":"DateUtils","similarity_score":0.3370001361406861},{"class_name":"LoggingUtils","similarity_score":0.2857142857142857},{"class_name":"ReflectionUtils","similarity_score":0.27961639470054006},{"class_name":"StringUtils","similarity_score":0.34840955241938615},{"class_name":"FunctionTestUtils","similarity_score":0.41160977606560634},{"class_name":"ParserUtils","similarity_score":0.38556199959808113},{"class_name":"InternalQlScriptUtils","similarity_score":0.3941175257186923},{"class_name":"StringContainsRegex","similarity_score":0.3499271061118826},{"class_name":"TransportActionUtils","similarity_score":0.2435169845989848},{"class_name":"TestUtils","similarity_score":0.39990628857583216},{"class_name":"CsvTestUtils","similarity_score":0.3019145614502269},{"class_name":"ActionListeners","similarity_score":0.2788866755113585},{"class_name":"AnalyzerTestUtils","similarity_score":0.4040122832518559},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2856236259354797},{"class_name":"SerializationTestUtils","similarity_score":0.42415751690093956},{"class_name":"PlannerUtils","similarity_score":0.28588309771466514},{"class_name":"EsqlTestUtils","similarity_score":0.39620475066361016},{"class_name":"ExceptionUtils","similarity_score":0.19906827984171396},{"class_name":"Queries","similarity_score":0.27049696802258916},{"class_name":"QueriesTests","similarity_score":0.28928142803420803},{"class_name":"SpatialCoordinateTypesTests","similarity_score":0.2979270115341686},{"class_name":"SpatialRelatesUtils","similarity_score":0.23107613638657787},{"class_name":"ResponseValueUtils","similarity_score":0.23072128399527259},{"class_name":"ResponseXContentUtils","similarity_score":0.2462215245327527},{"class_name":"Not","similarity_score":0.3425256962885708},{"class_name":"ChainingProcessorTests","similarity_score":0.2966578008488663},{"class_name":"FunctionRegistry","similarity_score":0.28657271350442},{"class_name":"FunctionRegistryTests","similarity_score":0.324768105571616}],"target_classes_sorted_by_llm":["SerializationTestUtils","TestUtils","EsqlTestUtils","FunctionTestUtils","ParserUtils","InternalQlScriptUtils","StringUtils","AnalyzerTestUtils","Not","StringContainsRegex"],"llm_response_time":15356,"similarity_computation_time":58,"similarity_metric":"voyage"},"writeSource":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.1394849051956293},{"class_name":"LoggingUtils","similarity_score":0.2857142857142857},{"class_name":"StringUtils","similarity_score":0.34840955241938615},{"class_name":"DateUtils","similarity_score":0.3370001361406861},{"class_name":"ReflectionUtils","similarity_score":0.27961639470054006},{"class_name":"TestUtils","similarity_score":0.39835626420150727},{"class_name":"ParserUtils","similarity_score":0.38556199959808113},{"class_name":"TransportActionUtils","similarity_score":0.2435169845989848},{"class_name":"StringContainsRegex","similarity_score":0.3499271061118826},{"class_name":"FunctionTestUtils","similarity_score":0.41160977606560634},{"class_name":"InternalQlScriptUtils","similarity_score":0.3941175257186923},{"class_name":"ActionListeners","similarity_score":0.2788866755113585},{"class_name":"AnalyzerTestUtils","similarity_score":0.4040122832518559},{"class_name":"SerializationTestUtils","similarity_score":0.42415751690093956},{"class_name":"PlannerUtils","similarity_score":0.28588309771466514},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2856236259354797},{"class_name":"EsqlTestUtils","similarity_score":0.39884611566803424},{"class_name":"ExceptionUtils","similarity_score":0.19906827984171396},{"class_name":"CsvTestUtils","similarity_score":0.3019145614502269},{"class_name":"SpatialCoordinateTypesTests","similarity_score":0.2979270115341686},{"class_name":"SpatialRelatesUtils","similarity_score":0.23107613638657787},{"class_name":"Queries","similarity_score":0.27049696802258916},{"class_name":"QueriesTests","similarity_score":0.28928142803420803},{"class_name":"ResponseValueUtils","similarity_score":0.23072128399527259},{"class_name":"ResponseXContentUtils","similarity_score":0.2462215245327527},{"class_name":"Not","similarity_score":0.3425256962885708},{"class_name":"ChainingProcessorTests","similarity_score":0.2966578008488663},{"class_name":"NotProcessor","similarity_score":0.4409963617950228},{"class_name":"Nots","similarity_score":0.30457245193658633}],"target_classes_sorted_by_llm":["SerializationTestUtils","TestUtils","EsqlTestUtils","InternalQlScriptUtils","ParserUtils","AnalyzerTestUtils","FunctionTestUtils","StringUtils","NotProcessor","StringContainsRegex"],"llm_response_time":18458,"similarity_computation_time":10,"similarity_metric":"voyage"},"readSource":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.155092120426572},{"class_name":"LoggingUtils","similarity_score":0.27003086243366087},{"class_name":"StringUtils","similarity_score":0.4089076071325209},{"class_name":"DateUtils","similarity_score":0.4246687078775427},{"class_name":"ReflectionUtils","similarity_score":0.34676396186057923},{"class_name":"TestUtils","similarity_score":0.4871973432412704},{"class_name":"ParserUtils","similarity_score":0.5037756739021773},{"class_name":"TransportActionUtils","similarity_score":0.2539584604576875},{"class_name":"StringContainsRegex","similarity_score":0.41996052556580804},{"class_name":"FunctionTestUtils","similarity_score":0.5246154580968143},{"class_name":"InternalQlScriptUtils","similarity_score":0.5294365215047317},{"class_name":"ActionListeners","similarity_score":0.34426518632954817},{"class_name":"AnalyzerTestUtils","similarity_score":0.5140952073482212},{"class_name":"SerializationTestUtils","similarity_score":0.433152890546691},{"class_name":"PlannerUtils","similarity_score":0.39581140290126393},{"class_name":"LuceneComponent2DUtils","similarity_score":0.31536452675272875},{"class_name":"EsqlTestUtils","similarity_score":0.5021280493832919},{"class_name":"ExceptionUtils","similarity_score":0.21501831715537348},{"class_name":"CsvTestUtils","similarity_score":0.3505269578143296},{"class_name":"SpatialCoordinateTypesTests","similarity_score":0.30942110718021076},{"class_name":"SpatialRelatesUtils","similarity_score":0.3026951692416539},{"class_name":"Queries","similarity_score":0.31231978157044604},{"class_name":"QueriesTests","similarity_score":0.31814073861051767},{"class_name":"ResponseValueUtils","similarity_score":0.2869661766501469},{"class_name":"ResponseXContentUtils","similarity_score":0.35056998326545263},{"class_name":"Not","similarity_score":0.4820821690306906},{"class_name":"NotProcessor","similarity_score":0.5689503333268354},{"class_name":"Nots","similarity_score":0.39477101697586137},{"class_name":"JwkValidateUtil","similarity_score":0.3117434455959207}],"target_classes_sorted_by_llm":["ParserUtils","TestUtils","InternalQlScriptUtils","FunctionTestUtils","EsqlTestUtils","SerializationTestUtils","AnalyzerTestUtils","NotProcessor","DateUtils","Not"],"llm_response_time":14871,"similarity_computation_time":16,"similarity_metric":"voyage"}}}
{"id":"e8332e62-4de2-49dc-b51b-bd9e5f1b782c","methodCount":75,"hostFunctionTelemetryData":{"hostFunctionSize":817,"lineStart":74,"lineEnd":890,"bodyLineStart":74,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/optimizer/OptimizerRulesTests.java","sourceCode":"public class OptimizerRulesTests extends ESTestCase {\n    private static final Literal ONE \u003d new Literal(Source.EMPTY, 1, DataType.INTEGER);\n    private static final Literal TWO \u003d new Literal(Source.EMPTY, 2, DataType.INTEGER);\n    private static final Literal THREE \u003d new Literal(Source.EMPTY, 3, DataType.INTEGER);\n    private static final Literal FOUR \u003d new Literal(Source.EMPTY, 4, DataType.INTEGER);\n    private static final Literal FIVE \u003d new Literal(Source.EMPTY, 5, DataType.INTEGER);\n    private static final Literal SIX \u003d new Literal(Source.EMPTY, 6, DataType.INTEGER);\n    private static final Expression DUMMY_EXPRESSION \u003d\n        new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRulesTests.DummyBooleanExpression(EMPTY, 0);\n\n    private static Equals equalsOf(Expression left, Expression right) {\n        return new Equals(EMPTY, left, right, null);\n    }\n\n    private static LessThan lessThanOf(Expression left, Expression right) {\n        return new LessThan(EMPTY, left, right, null);\n    }\n\n    public static GreaterThan greaterThanOf(Expression left, Expression right) {\n        return new GreaterThan(EMPTY, left, right, randomZone());\n    }\n\n    public static NotEquals notEqualsOf(Expression left, Expression right) {\n        return new NotEquals(EMPTY, left, right, randomZone());\n    }\n\n    public static LessThanOrEqual lessThanOrEqualOf(Expression left, Expression right) {\n        return new LessThanOrEqual(EMPTY, left, right, randomZone());\n    }\n\n    public static GreaterThanOrEqual greaterThanOrEqualOf(Expression left, Expression right) {\n        return new GreaterThanOrEqual(EMPTY, left, right, randomZone());\n    }\n\n    private static FieldAttribute getFieldAttribute() {\n        return TestUtils.getFieldAttribute(\"a\");\n    }\n\n    //\n    // Constant folding\n    //\n\n    public void testConstantFolding() {\n        Expression exp \u003d new Add(EMPTY, TWO, THREE);\n\n        assertTrue(exp.foldable());\n        Expression result \u003d new ConstantFolding().rule(exp);\n        assertTrue(result instanceof Literal);\n        assertEquals(5, ((Literal) result).value());\n\n        // check now with an alias\n        result \u003d new ConstantFolding().rule(new Alias(EMPTY, \"a\", exp));\n        assertEquals(\"a\", Expressions.name(result));\n        assertEquals(Alias.class, result.getClass());\n    }\n\n    public void testConstantFoldingBinaryComparison() {\n        assertEquals(FALSE, new ConstantFolding().rule(greaterThanOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(greaterThanOrEqualOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(equalsOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(nullEqualsOf(TWO, THREE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(nullEqualsOf(TWO, NULL)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(notEqualsOf(TWO, THREE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(lessThanOrEqualOf(TWO, THREE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(lessThanOf(TWO, THREE)).canonical());\n    }\n\n    public void testConstantFoldingBinaryLogic() {\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, greaterThanOf(TWO, THREE), TRUE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, greaterThanOrEqualOf(TWO, THREE), TRUE)).canonical());\n    }\n\n    public void testConstantFoldingBinaryLogic_WithNullHandling() {\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, NULL, TRUE)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, TRUE, NULL)).canonical().nullable());\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, NULL, FALSE)).canonical());\n        assertEquals(FALSE, new ConstantFolding().rule(new And(EMPTY, FALSE, NULL)).canonical());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new And(EMPTY, NULL, NULL)).canonical().nullable());\n\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, TRUE)).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new Or(EMPTY, TRUE, NULL)).canonical());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, FALSE)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, FALSE, NULL)).canonical().nullable());\n        assertEquals(Nullability.TRUE, new ConstantFolding().rule(new Or(EMPTY, NULL, NULL)).canonical().nullable());\n    }\n\n    public void testConstantFoldingRange() {\n        assertEquals(true, new ConstantFolding().rule(rangeOf(FIVE, FIVE, true, new Literal(EMPTY, 10, DataType.INTEGER), false)).fold());\n        assertEquals(false, new ConstantFolding().rule(rangeOf(FIVE, FIVE, false, new Literal(EMPTY, 10, DataType.INTEGER), false)).fold());\n    }\n\n    public void testConstantNot() {\n        assertEquals(FALSE, new ConstantFolding().rule(new Not(EMPTY, TRUE)));\n        assertEquals(TRUE, new ConstantFolding().rule(new Not(EMPTY, FALSE)));\n    }\n\n    public void testConstantFoldingLikes() {\n        assertEquals(TRUE, new ConstantFolding().rule(new Like(EMPTY, of(\"test_emp\"), new LikePattern(\"test%\", (char) 0))).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new WildcardLike(EMPTY, of(\"test_emp\"), new WildcardPattern(\"test*\"))).canonical());\n        assertEquals(TRUE, new ConstantFolding().rule(new RLike(EMPTY, of(\"test_emp\"), new RLikePattern(\"test.emp\"))).canonical());\n    }\n\n    public void testArithmeticFolding() {\n        assertEquals(10, foldOperator(new Add(EMPTY, new Literal(EMPTY, 7, DataType.INTEGER), THREE)));\n        assertEquals(4, foldOperator(new Sub(EMPTY, new Literal(EMPTY, 7, DataType.INTEGER), THREE)));\n        assertEquals(21, foldOperator(new Mul(EMPTY, new Literal(EMPTY, 7, DataType.INTEGER), THREE)));\n        assertEquals(2, foldOperator(new Div(EMPTY, new Literal(EMPTY, 7, DataType.INTEGER), THREE)));\n        assertEquals(1, foldOperator(new Mod(EMPTY, new Literal(EMPTY, 7, DataType.INTEGER), THREE)));\n    }\n\n    private static Object foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b) {\n        return ((Literal) new ConstantFolding().rule(b)).value();\n    }\n\n    //\n    // CombineDisjunction in Equals\n    //\n    public void testTwoEqualsWithOr() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), equalsOf(fa, TWO));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testTwoEqualsWithSameValue() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), equalsOf(fa, ONE));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(ONE, eq.right());\n    }\n\n    public void testOneEqualsOneIn() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), new In(EMPTY, fa, List.of(TWO)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testOneEqualsOneInWithSameValue() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, equalsOf(fa, ONE), new In(EMPTY, fa, asList(ONE, TWO)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO));\n    }\n\n    public void testSingleValueInToEquals() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Equals equals \u003d equalsOf(fa, ONE);\n        Or or \u003d new Or(EMPTY, equals, new In(EMPTY, fa, List.of(ONE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(equals, e);\n    }\n\n    public void testEqualsBehindAnd() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And and \u003d new And(EMPTY, equalsOf(fa, ONE), equalsOf(fa, TWO));\n        Filter dummy \u003d new Filter(EMPTY, relation(), and);\n        LogicalPlan transformed \u003d new CombineDisjunctionsToIn().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(and, ((Filter) transformed).condition());\n    }\n\n    public void testTwoEqualsDifferentFields() {\n        FieldAttribute fieldOne \u003d TestUtils.getFieldAttribute(\"ONE\");\n        FieldAttribute fieldTwo \u003d TestUtils.getFieldAttribute(\"TWO\");\n\n        Or or \u003d new Or(EMPTY, equalsOf(fieldOne, ONE), equalsOf(fieldTwo, TWO));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(or);\n        assertEquals(or, e);\n    }\n\n    public void testMultipleIn() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or firstOr \u003d new Or(EMPTY, new In(EMPTY, fa, List.of(ONE)), new In(EMPTY, fa, List.of(TWO)));\n        Or secondOr \u003d new Or(EMPTY, firstOr, new In(EMPTY, fa, List.of(THREE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(secondOr);\n        assertEquals(In.class, e.getClass());\n        In in \u003d (In) e;\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, TWO, THREE));\n    }\n\n    public void testOrWithNonCombinableExpressions() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or firstOr \u003d new Or(EMPTY, new In(EMPTY, fa, List.of(ONE)), lessThanOf(fa, TWO));\n        Or secondOr \u003d new Or(EMPTY, firstOr, new In(EMPTY, fa, List.of(THREE)));\n        Expression e \u003d new CombineDisjunctionsToIn().rule(secondOr);\n        assertEquals(Or.class, e.getClass());\n        Or or \u003d (Or) e;\n        assertEquals(or.left(), firstOr.right());\n        assertEquals(In.class, or.right().getClass());\n        In in \u003d (In) or.right();\n        assertEquals(fa, in.value());\n        assertThat(in.list(), contains(ONE, THREE));\n    }\n\n    // Test BooleanFunctionEqualsElimination\n    public void testBoolEqualsSimplificationOnExpressions() {\n        BooleanFunctionEqualsElimination s \u003d new BooleanFunctionEqualsElimination();\n        Expression exp \u003d new GreaterThan(EMPTY, getFieldAttribute(), new Literal(EMPTY, 0, DataType.INTEGER), null);\n\n        assertEquals(exp, s.rule(new Equals(EMPTY, exp, TRUE)));\n        // TODO: Replace use of QL Not with ESQL Not\n        assertEquals(new Not(EMPTY, exp), s.rule(new Equals(EMPTY, exp, FALSE)));\n    }\n\n    public void testBoolEqualsSimplificationOnFields() {\n        BooleanFunctionEqualsElimination s \u003d new BooleanFunctionEqualsElimination();\n\n        FieldAttribute field \u003d getFieldAttribute();\n\n        List\u003c? extends BinaryComparison\u003e comparisons \u003d asList(\n            new Equals(EMPTY, field, TRUE),\n            new Equals(EMPTY, field, FALSE),\n            notEqualsOf(field, TRUE),\n            notEqualsOf(field, FALSE),\n            new Equals(EMPTY, NULL, TRUE),\n            new Equals(EMPTY, NULL, FALSE),\n            notEqualsOf(NULL, TRUE),\n            notEqualsOf(NULL, FALSE)\n        );\n\n        for (BinaryComparison comparison : comparisons) {\n            assertEquals(comparison, s.rule(comparison));\n        }\n    }\n\n    // Test Propagate Equals\n\n    // a \u003d\u003d 1 AND a \u003d\u003d 2 -\u003e FALSE\n    public void testDualEqualsConjunction() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Equals eq2 \u003d equalsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, eq2));\n        assertEquals(FALSE, exp);\n    }\n\n    // 1 \u003c a \u003c 10 AND a \u003d\u003d 10 -\u003e FALSE\n    public void testEliminateRangeByEqualsOutsideInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, new Literal(EMPTY, 10, DataType.INTEGER));\n        Range r \u003d rangeOf(fa, ONE, false, new Literal(EMPTY, 10, DataType.INTEGER), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(FALSE, exp);\n    }\n\n    // a !\u003d 3 AND a \u003d 3 -\u003e FALSE\n    public void testPropagateEquals_VarNeq3AndVarEq3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NotEquals neq \u003d notEqualsOf(fa, THREE);\n        Equals eq \u003d equalsOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, neq, eq));\n        assertEquals(FALSE, exp);\n    }\n\n    // a !\u003d 4 AND a \u003d 3 -\u003e a \u003d 3\n    public void testPropagateEquals_VarNeq4AndVarEq3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n        Equals eq \u003d equalsOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, neq, eq));\n        assertEquals(Equals.class, exp.getClass());\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003c 2 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLt2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003c\u003d 2 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarLte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThanOrEqual lt \u003d lessThanOrEqualOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003c\u003d 1 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLte1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThanOrEqual lt \u003d lessThanOrEqualOf(fa, ONE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, lt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003e 2 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarGt2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003e\u003d 2 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarGte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThanOrEqual gte \u003d greaterThanOrEqualOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gte));\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND a \u003e 3 -\u003e FALSE\n    public void testPropagateEquals_VarEq2AndVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq, gt));\n        assertEquals(FALSE, exp);\n    }\n\n    // a \u003d 2 AND a \u003c 3 AND a \u003e 1 AND a !\u003d 4 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n        GreaterThan gt \u003d greaterThanOf(fa, ONE);\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression and \u003d Predicates.combineAnd(asList(eq, lt, gt, neq));\n        Expression exp \u003d rule.rule((And) and);\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 AND 1 \u003c a \u003c 3 AND a \u003e 0 AND a !\u003d 4 -\u003e a \u003d 2\n    public void testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n        GreaterThan gt \u003d greaterThanOf(fa, new Literal(EMPTY, 0, DataType.INTEGER));\n        NotEquals neq \u003d notEqualsOf(fa, FOUR);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression and \u003d Predicates.combineAnd(asList(eq, range, gt, neq));\n        Expression exp \u003d rule.rule((And) and);\n        assertEquals(eq, exp);\n    }\n\n    // a \u003d 2 OR a \u003e 1 -\u003e a \u003e 1\n    public void testPropagateEquals_VarEq2OrVarGt1() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, ONE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, gt));\n        assertEquals(gt, exp);\n    }\n\n    // a \u003d 2 OR a \u003e 2 -\u003e a \u003e\u003d 2\n    public void testPropagateEquals_VarEq2OrVarGte2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, gt));\n        assertEquals(GreaterThanOrEqual.class, exp.getClass());\n        GreaterThanOrEqual gte \u003d (GreaterThanOrEqual) exp;\n        assertEquals(TWO, gte.right());\n    }\n\n    // a \u003d 2 OR a \u003c 3 -\u003e a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, lt));\n        assertEquals(lt, exp);\n    }\n\n    // a \u003d 3 OR a \u003c 3 -\u003e a \u003c\u003d 3\n    public void testPropagateEquals_VarEq3OrVarLt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, THREE);\n        LessThan lt \u003d lessThanOf(fa, THREE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, lt));\n        assertEquals(LessThanOrEqual.class, exp.getClass());\n        LessThanOrEqual lte \u003d (LessThanOrEqual) exp;\n        assertEquals(THREE, lte.right());\n    }\n\n    // a \u003d 2 OR 1 \u003c a \u003c 3 -\u003e 1 \u003c a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarRangeGt1Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, ONE, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(range, exp);\n    }\n\n    // a \u003d 2 OR 2 \u003c a \u003c 3 -\u003e 2 \u003c\u003d a \u003c 3\n    public void testPropagateEquals_VarEq2OrVarRangeGt2Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, TWO, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertTrue(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertFalse(r.includeUpper());\n    }\n\n    // a \u003d 3 OR 2 \u003c a \u003c 3 -\u003e 2 \u003c a \u003c\u003d 3\n    public void testPropagateEquals_VarEq3OrVarRangeGt2Lt3() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, THREE);\n        Range range \u003d rangeOf(fa, TWO, false, THREE, false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, range));\n        assertEquals(Range.class, exp.getClass());\n        Range r \u003d (Range) exp;\n        assertEquals(TWO, r.lower());\n        assertFalse(r.includeLower());\n        assertEquals(THREE, r.upper());\n        assertTrue(r.includeUpper());\n    }\n\n    // a \u003d 2 OR a !\u003d 2 -\u003e TRUE\n    public void testPropagateEquals_VarEq2OrVarNeq2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, neq));\n        assertEquals(TRUE, exp);\n    }\n\n    // a \u003d 2 OR a !\u003d 5 -\u003e a !\u003d 5\n    public void testPropagateEquals_VarEq2OrVarNeq5() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, FIVE);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new Or(EMPTY, eq, neq));\n        assertEquals(NotEquals.class, exp.getClass());\n        NotEquals ne \u003d (NotEquals) exp;\n        assertEquals(FIVE, ne.right());\n    }\n\n    // a \u003d 2 OR 3 \u003c a \u003c 4 OR a \u003e 2 OR a!\u003d 2 -\u003e TRUE\n    public void testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq \u003d equalsOf(fa, TWO);\n        Range range \u003d rangeOf(fa, THREE, false, FOUR, false);\n        GreaterThan gt \u003d greaterThanOf(fa, TWO);\n        NotEquals neq \u003d notEqualsOf(fa, TWO);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule((Or) Predicates.combineOr(asList(eq, range, neq, gt)));\n        assertEquals(TRUE, exp);\n    }\n\n    // a \u003d\u003d 1 AND a \u003d\u003d 2 -\u003e nop for date/time fields\n    public void testPropagateEquals_ignoreDateTimeFields() {\n        FieldAttribute fa \u003d TestUtils.getFieldAttribute(\"a\", DataType.DATETIME);\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Equals eq2 \u003d equalsOf(fa, TWO);\n        And and \u003d new And(EMPTY, eq1, eq2);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(and);\n        assertEquals(and, exp);\n    }\n\n    // 1 \u003c\u003d a \u003c 10 AND a \u003d\u003d 1 -\u003e a \u003d\u003d 1\n    public void testEliminateRangeByEqualsInInterval() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        Equals eq1 \u003d equalsOf(fa, ONE);\n        Range r \u003d rangeOf(fa, ONE, true, new Literal(EMPTY, 10, DataType.INTEGER), false);\n\n        PropagateEquals rule \u003d new PropagateEquals();\n        Expression exp \u003d rule.rule(new And(EMPTY, eq1, r));\n        assertEquals(eq1, exp);\n    }\n    //\n    // Null folding\n\n    public void testNullFoldingIsNull() {\n        FoldNull foldNull \u003d new FoldNull();\n        assertEquals(true, foldNull.rule(new IsNull(EMPTY, NULL)).fold());\n        assertEquals(false, foldNull.rule(new IsNull(EMPTY, TRUE)).fold());\n    }\n\n    public void testGenericNullableExpression() {\n        FoldNull rule \u003d new FoldNull();\n        // arithmetic\n        assertNullLiteral(rule.rule(new Add(EMPTY, getFieldAttribute(), NULL)));\n        // comparison\n        assertNullLiteral(rule.rule(greaterThanOf(getFieldAttribute(), NULL)));\n        // regex\n        assertNullLiteral(rule.rule(new RLike(EMPTY, NULL, new RLikePattern(\"123\"))));\n    }\n\n    public void testNullFoldingDoesNotApplyOnLogicalExpressions() {\n        org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.FoldNull rule \u003d\n            new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.FoldNull();\n\n        Or or \u003d new Or(EMPTY, NULL, TRUE);\n        assertEquals(or, rule.rule(or));\n        or \u003d new Or(EMPTY, NULL, NULL);\n        assertEquals(or, rule.rule(or));\n\n        And and \u003d new And(EMPTY, NULL, TRUE);\n        assertEquals(and, rule.rule(and));\n        and \u003d new And(EMPTY, NULL, NULL);\n        assertEquals(and, rule.rule(and));\n    }\n\n    //\n    // Propagate nullability (IS NULL / IS NOT NULL)\n    //\n\n    // a IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNull() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And and \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        assertEquals(FALSE, new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b IS NOT NULL AND c IS NULL AND d IS NOT NULL AND e IS NULL AND a IS NOT NULL \u003d\u003e false\n    public void testIsNullAndNotNullMultiField() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        And andOne \u003d new And(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, getFieldAttribute()));\n        And andTwo \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute()), new IsNotNull(EMPTY, getFieldAttribute()));\n        And andThree \u003d new And(EMPTY, new IsNull(EMPTY, getFieldAttribute()), new IsNotNull(EMPTY, fa));\n\n        And and \u003d new And(EMPTY, andOne, new And(EMPTY, andThree, andTwo));\n\n        assertEquals(FALSE, new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND a \u003e 1 \u003d\u003e a IS NULL AND false\n    public void testIsNullAndComparison() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        And and \u003d new And(EMPTY, isNull, greaterThanOf(fa, ONE));\n        assertEquals(new And(EMPTY, isNull, nullOf(BOOLEAN)), new PropagateNullable().rule(and));\n    }\n\n    // a IS NULL AND b \u003c 1 AND c \u003c 1 AND a \u003c 1 \u003d\u003e a IS NULL AND b \u003c 1 AND c \u003c 1 \u003d\u003e a IS NULL AND b \u003c 1 AND c \u003c 1\n    public void testIsNullAndMultipleComparison() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        And nestedAnd \u003d new And(\n            EMPTY,\n            lessThanOf(TestUtils.getFieldAttribute(\"b\"), ONE),\n            lessThanOf(TestUtils.getFieldAttribute(\"c\"), ONE)\n        );\n        And and \u003d new And(EMPTY, isNull, nestedAnd);\n        And top \u003d new And(EMPTY, and, lessThanOf(fa, ONE));\n\n        Expression optimized \u003d new PropagateNullable().rule(top);\n        Expression expected \u003d new And(EMPTY, and, nullOf(BOOLEAN));\n        assertEquals(Predicates.splitAnd(expected), Predicates.splitAnd(optimized));\n    }\n\n    // ((a+1)/2) \u003e 1 AND a + 2 AND a IS NULL AND b \u003c 3 \u003d\u003e NULL AND NULL AND a IS NULL AND b \u003c 3\n    public void testIsNullAndDeeplyNestedExpression() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Expression nullified \u003d new And(\n            EMPTY,\n            greaterThanOf(new Div(EMPTY, new Add(EMPTY, fa, ONE), TWO), ONE),\n            greaterThanOf(new Add(EMPTY, fa, TWO), ONE)\n        );\n        Expression kept \u003d new And(EMPTY, isNull, lessThanOf(TestUtils.getFieldAttribute(\"b\"), THREE));\n        And and \u003d new And(EMPTY, nullified, kept);\n\n        Expression optimized \u003d new PropagateNullable().rule(and);\n        Expression expected \u003d new And(EMPTY, new And(EMPTY, nullOf(BOOLEAN), nullOf(BOOLEAN)), kept);\n\n        assertEquals(Predicates.splitAnd(expected), Predicates.splitAnd(optimized));\n    }\n\n    // a IS NULL OR a IS NOT NULL \u003d\u003e no change\n    // a IS NULL OR a \u003e 1 \u003d\u003e no change\n    public void testIsNullInDisjunction() {\n        FieldAttribute fa \u003d getFieldAttribute();\n\n        Or or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), new IsNotNull(EMPTY, fa));\n        Filter dummy \u003d new Filter(EMPTY, relation(), or);\n        LogicalPlan transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n\n        or \u003d new Or(EMPTY, new IsNull(EMPTY, fa), greaterThanOf(fa, ONE));\n        dummy \u003d new Filter(EMPTY, relation(), or);\n        transformed \u003d new PropagateNullable().apply(dummy);\n        assertSame(dummy, transformed);\n        assertEquals(or, ((Filter) transformed).condition());\n    }\n\n    // a + 1 AND (a IS NULL OR a \u003e 3) \u003d\u003e no change\n    public void testIsNullDisjunction() {\n        FieldAttribute fa \u003d getFieldAttribute();\n        IsNull isNull \u003d new IsNull(EMPTY, fa);\n\n        Or or \u003d new Or(EMPTY, isNull, greaterThanOf(fa, THREE));\n        And and \u003d new And(EMPTY, new Add(EMPTY, fa, ONE), or);\n\n        assertEquals(and, new PropagateNullable().rule(and));\n    }\n\n    //\n    // Like / Regex\n    //\n    public void testMatchAllLikeToExist() {\n        for (String s : asList(\"%\", \"%%\", \"%%%\")) {\n            LikePattern pattern \u003d new LikePattern(s, (char) 0);\n            FieldAttribute fa \u003d getFieldAttribute();\n            Like l \u003d new Like(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(IsNotNull.class, e.getClass());\n            IsNotNull inn \u003d (IsNotNull) e;\n            assertEquals(fa, inn.field());\n        }\n    }\n\n    public void testMatchAllWildcardLikeToExist() {\n        for (String s : asList(\"*\", \"**\", \"***\")) {\n            WildcardPattern pattern \u003d new WildcardPattern(s);\n            FieldAttribute fa \u003d getFieldAttribute();\n            WildcardLike l \u003d new WildcardLike(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(IsNotNull.class, e.getClass());\n            IsNotNull inn \u003d (IsNotNull) e;\n            assertEquals(fa, inn.field());\n        }\n    }\n\n    public void testMatchAllRLikeToExist() {\n        RLikePattern pattern \u003d new RLikePattern(\".*\");\n        FieldAttribute fa \u003d getFieldAttribute();\n        RLike l \u003d new RLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(IsNotNull.class, e.getClass());\n        IsNotNull inn \u003d (IsNotNull) e;\n        assertEquals(fa, inn.field());\n    }\n\n    public void testExactMatchLike() {\n        for (String s : asList(\"ab\", \"ab0%\", \"ab0_c\")) {\n            LikePattern pattern \u003d new LikePattern(s, \u00270\u0027);\n            FieldAttribute fa \u003d getFieldAttribute();\n            Like l \u003d new Like(EMPTY, fa, pattern);\n            Expression e \u003d new ReplaceRegexMatch().rule(l);\n            assertEquals(Equals.class, e.getClass());\n            Equals eq \u003d (Equals) e;\n            assertEquals(fa, eq.left());\n            assertEquals(s.replace(\"0\", StringUtils.EMPTY), eq.right().fold());\n        }\n    }\n\n    public void testExactMatchWildcardLike() {\n        String s \u003d \"ab\";\n        WildcardPattern pattern \u003d new WildcardPattern(s);\n        FieldAttribute fa \u003d getFieldAttribute();\n        WildcardLike l \u003d new WildcardLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(s, eq.right().fold());\n    }\n\n    public void testExactMatchRLike() {\n        RLikePattern pattern \u003d new RLikePattern(\"abc\");\n        FieldAttribute fa \u003d getFieldAttribute();\n        RLike l \u003d new RLike(EMPTY, fa, pattern);\n        Expression e \u003d new ReplaceRegexMatch().rule(l);\n        assertEquals(Equals.class, e.getClass());\n        Equals eq \u003d (Equals) e;\n        assertEquals(fa, eq.left());\n        assertEquals(\"abc\", eq.right().fold());\n    }\n\n    private void assertNullLiteral(Expression expression) {\n        assertEquals(Literal.class, expression.getClass());\n        assertNull(expression.fold());\n    }\n\n    private IsNotNull isNotNull(Expression field) {\n        return new IsNotNull(EMPTY, field);\n    }\n\n    private IsNull isNull(Expression field) {\n        return new IsNull(EMPTY, field);\n    }\n\n    private Literal nullOf(DataType dataType) {\n        return new Literal(Source.EMPTY, null, dataType);\n    }\n    //\n    // Logical simplifications\n    //\n\n    public void testLiteralsOnTheRight() {\n        Alias a \u003d new Alias(EMPTY, \"a\", new Literal(EMPTY, 10, INTEGER));\n        Expression result \u003d new LiteralsOnTheRight().rule(equalsOf(FIVE, a));\n        assertTrue(result instanceof Equals);\n        Equals eq \u003d (Equals) result;\n        assertEquals(a, eq.left());\n        assertEquals(FIVE, eq.right());\n\n        // Note: Null Equals test removed here\n    }\n\n    public void testBoolSimplifyOr() {\n        org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification simplification \u003d\n            new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification();\n\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, TRUE, TRUE)));\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, TRUE, DUMMY_EXPRESSION)));\n        assertEquals(TRUE, simplification.rule(new Or(EMPTY, DUMMY_EXPRESSION, TRUE)));\n\n        assertEquals(FALSE, simplification.rule(new Or(EMPTY, FALSE, FALSE)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new Or(EMPTY, FALSE, DUMMY_EXPRESSION)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new Or(EMPTY, DUMMY_EXPRESSION, FALSE)));\n    }\n\n    public void testBoolSimplifyAnd() {\n        org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification simplification \u003d\n            new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification();\n\n        assertEquals(TRUE, simplification.rule(new And(EMPTY, TRUE, TRUE)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new And(EMPTY, TRUE, DUMMY_EXPRESSION)));\n        assertEquals(DUMMY_EXPRESSION, simplification.rule(new And(EMPTY, DUMMY_EXPRESSION, TRUE)));\n\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, FALSE, FALSE)));\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, FALSE, DUMMY_EXPRESSION)));\n        assertEquals(FALSE, simplification.rule(new And(EMPTY, DUMMY_EXPRESSION, FALSE)));\n    }\n\n    public void testBoolCommonFactorExtraction() {\n        org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification simplification \u003d\n            new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRules.BooleanSimplification();\n\n        Expression a1 \u003d new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRulesTests.DummyBooleanExpression(EMPTY, 1);\n        Expression a2 \u003d new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRulesTests.DummyBooleanExpression(EMPTY, 1);\n        Expression b \u003d new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRulesTests.DummyBooleanExpression(EMPTY, 2);\n        Expression c \u003d new org.elasticsearch.xpack.esql.core.optimizer.OptimizerRulesTests.DummyBooleanExpression(EMPTY, 3);\n\n        Or actual \u003d new Or(EMPTY, new And(EMPTY, a1, b), new And(EMPTY, a2, c));\n        And expected \u003d new And(EMPTY, a1, new Or(EMPTY, b, c));\n\n        assertEquals(expected, simplification.rule(actual));\n    }\n}","methodCount":75},"candidatesTelemetryData":{"numberOfSuggestions":4,"candidates":[{"lineStart":818,"lineEnd":821,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertNullLiteral to class Expression","description":"Move method assertNullLiteral to org.elasticsearch.xpack.esql.core.expression.Expression\nRationale: The assertNullLiteral() method evaluates properties of an Expression object, specifically checking if it is an instance of Literal and if its fold() method returns null. This method should be moved to the Expression class because it directly relates to the behavior of expressions and their evaluation. This move aligns with the Single Responsibility Principle by encapsulating related functionality within the class that owns the data, thus improving cohesion. However, it is important to ensure that moving this method does not lead to a tight coupling between the Expression class and the testing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":818,"lineEnd":821,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertNullLiteral to class Expression","description":"Move method assertNullLiteral to org.elasticsearch.xpack.esql.core.expression.Expression\nRationale: The assertNullLiteral() method evaluates properties of an Expression object, specifically checking if it is an instance of Literal and if its fold() method returns null. This method should be moved to the Expression class because it directly relates to the behavior of expressions and their evaluation. This move aligns with the Single Responsibility Principle by encapsulating related functionality within the class that owns the data, thus improving cohesion. However, it is important to ensure that moving this method does not lead to a tight coupling between the Expression class and the testing logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":818,"lineEnd":821,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertNullLiteral to class Literal","description":"Move method assertNullLiteral to org.elasticsearch.xpack.esql.core.expression.Literal\nRationale: As assertNullLiteral() specifically checks for instances of Literal, moving this method to the Literal class could be considered. This would encapsulate the assertion logic directly within the class that represents the data being validated. This adheres to the Open/Closed Principle, allowing the Literal class to handle its validation without modifying external classes. However, this approach may lead to a violation of the Single Responsibility Principle if the Literal class becomes responsible for its own validation logic, potentially complicating its design.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":849,"lineEnd":860,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method testBoolSimplifyOr to class Expression","description":"Move method testBoolSimplifyOr to org.elasticsearch.xpack.esql.core.expression.Expression\nRationale: The testBoolSimplifyOr() method is primarily concerned with the logical simplification of boolean expressions, specifically using the \u0027Or\u0027 operation. Moving this method to the Expression class is appropriate because it directly relates to the evaluation and manipulation of expressions. This aligns with the Single Responsibility Principle, as Expression would encapsulate all behaviors related to expression evaluation, thus improving cohesion. Additionally, it enhances reusability, as other components that deal with expressions can leverage this method without needing to instantiate or reference the original class. However, one consideration is ensuring that the Expression class has access to the necessary context or dependencies required for the simplification logic, which may necessitate additional refactoring or dependency injection.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"equalsOf","method_signature":"private static equalsOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOf","method_signature":"private static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"notEqualsOf","method_signature":"public static notEqualsOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOrEqualOf","method_signature":"public static lessThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"testConstantFolding","method_signature":"public testConstantFolding()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},{"method_name":"testConstantFoldingRange","method_signature":"public testConstantFoldingRange()","target_class":"","rationale":""},{"method_name":"testConstantNot","method_signature":"public testConstantNot()","target_class":"","rationale":""},{"method_name":"testConstantFoldingLikes","method_signature":"public testConstantFoldingLikes()","target_class":"","rationale":""},{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""},{"method_name":"testTwoEqualsWithOr","method_signature":"public testTwoEqualsWithOr()","target_class":"","rationale":""},{"method_name":"testTwoEqualsWithSameValue","method_signature":"public testTwoEqualsWithSameValue()","target_class":"","rationale":""},{"method_name":"testOneEqualsOneIn","method_signature":"public testOneEqualsOneIn()","target_class":"","rationale":""},{"method_name":"testOneEqualsOneInWithSameValue","method_signature":"public testOneEqualsOneInWithSameValue()","target_class":"","rationale":""},{"method_name":"testSingleValueInToEquals","method_signature":"public testSingleValueInToEquals()","target_class":"","rationale":""},{"method_name":"testEqualsBehindAnd","method_signature":"public testEqualsBehindAnd()","target_class":"","rationale":""},{"method_name":"testTwoEqualsDifferentFields","method_signature":"public testTwoEqualsDifferentFields()","target_class":"","rationale":""},{"method_name":"testMultipleIn","method_signature":"public testMultipleIn()","target_class":"","rationale":""},{"method_name":"testOrWithNonCombinableExpressions","method_signature":"public testOrWithNonCombinableExpressions()","target_class":"","rationale":""},{"method_name":"testBoolEqualsSimplificationOnExpressions","method_signature":"public testBoolEqualsSimplificationOnExpressions()","target_class":"","rationale":""},{"method_name":"testBoolEqualsSimplificationOnFields","method_signature":"public testBoolEqualsSimplificationOnFields()","target_class":"","rationale":""},{"method_name":"testDualEqualsConjunction","method_signature":"public testDualEqualsConjunction()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByEqualsOutsideInterval","method_signature":"public testEliminateRangeByEqualsOutsideInterval()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarNeq3AndVarEq3","method_signature":"public testPropagateEquals_VarNeq3AndVarEq3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarNeq4AndVarEq3","method_signature":"public testPropagateEquals_VarNeq4AndVarEq3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt2","method_signature":"public testPropagateEquals_VarEq2AndVarLt2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLte2","method_signature":"public testPropagateEquals_VarEq2AndVarLte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLte1","method_signature":"public testPropagateEquals_VarEq2AndVarLte1()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarGt2","method_signature":"public testPropagateEquals_VarEq2AndVarGt2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarGte2","method_signature":"public testPropagateEquals_VarEq2AndVarGte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt3","method_signature":"public testPropagateEquals_VarEq2AndVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4","method_signature":"public testPropagateEquals_VarEq2AndVarLt3AndVarGt1AndVarNeq4()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4","method_signature":"public testPropagateEquals_VarEq2AndVarRangeGt1Lt3AndVarGt0AndVarNeq4()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarGt1","method_signature":"public testPropagateEquals_VarEq2OrVarGt1()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarGte2","method_signature":"public testPropagateEquals_VarEq2OrVarGte2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarLt3","method_signature":"public testPropagateEquals_VarEq2OrVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq3OrVarLt3","method_signature":"public testPropagateEquals_VarEq3OrVarLt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt1Lt3","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt1Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt2Lt3","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt2Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq3OrVarRangeGt2Lt3","method_signature":"public testPropagateEquals_VarEq3OrVarRangeGt2Lt3()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarNeq2","method_signature":"public testPropagateEquals_VarEq2OrVarNeq2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarNeq5","method_signature":"public testPropagateEquals_VarEq2OrVarNeq5()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2","method_signature":"public testPropagateEquals_VarEq2OrVarRangeGt3Lt4OrVarGt2OrVarNe2()","target_class":"","rationale":""},{"method_name":"testPropagateEquals_ignoreDateTimeFields","method_signature":"public testPropagateEquals_ignoreDateTimeFields()","target_class":"","rationale":""},{"method_name":"testEliminateRangeByEqualsInInterval","method_signature":"public testEliminateRangeByEqualsInInterval()","target_class":"","rationale":""},{"method_name":"testNullFoldingIsNull","method_signature":"public testNullFoldingIsNull()","target_class":"","rationale":""},{"method_name":"testGenericNullableExpression","method_signature":"public testGenericNullableExpression()","target_class":"","rationale":""},{"method_name":"testNullFoldingDoesNotApplyOnLogicalExpressions","method_signature":"public testNullFoldingDoesNotApplyOnLogicalExpressions()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNull","method_signature":"public testIsNullAndNotNull()","target_class":"","rationale":""},{"method_name":"testIsNullAndNotNullMultiField","method_signature":"public testIsNullAndNotNullMultiField()","target_class":"","rationale":""},{"method_name":"testIsNullAndComparison","method_signature":"public testIsNullAndComparison()","target_class":"","rationale":""},{"method_name":"testIsNullAndMultipleComparison","method_signature":"public testIsNullAndMultipleComparison()","target_class":"","rationale":""},{"method_name":"testIsNullAndDeeplyNestedExpression","method_signature":"public testIsNullAndDeeplyNestedExpression()","target_class":"","rationale":""},{"method_name":"testIsNullInDisjunction","method_signature":"public testIsNullInDisjunction()","target_class":"","rationale":""},{"method_name":"testIsNullDisjunction","method_signature":"public testIsNullDisjunction()","target_class":"","rationale":""},{"method_name":"testMatchAllLikeToExist","method_signature":"public testMatchAllLikeToExist()","target_class":"","rationale":""},{"method_name":"testMatchAllWildcardLikeToExist","method_signature":"public testMatchAllWildcardLikeToExist()","target_class":"","rationale":""},{"method_name":"testMatchAllRLikeToExist","method_signature":"public testMatchAllRLikeToExist()","target_class":"","rationale":""},{"method_name":"testExactMatchLike","method_signature":"public testExactMatchLike()","target_class":"","rationale":""},{"method_name":"testExactMatchWildcardLike","method_signature":"public testExactMatchWildcardLike()","target_class":"","rationale":""},{"method_name":"testExactMatchRLike","method_signature":"public testExactMatchRLike()","target_class":"","rationale":""},{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},{"method_name":"isNotNull","method_signature":"private isNotNull(Expression field)","target_class":"","rationale":""},{"method_name":"isNull","method_signature":"private isNull(Expression field)","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},{"method_name":"testLiteralsOnTheRight","method_signature":"public testLiteralsOnTheRight()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},{"method_name":"testBoolCommonFactorExtraction","method_signature":"public testBoolCommonFactorExtraction()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOrEqualOf","method_signature":"public static lessThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"notEqualsOf","method_signature":"public static notEqualsOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"lessThanOf","method_signature":"private static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"equalsOf","method_signature":"private static equalsOf(Expression left, Expression right)","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private assertNullLiteral(Expression expression)":{"first":{"method_name":"assertNullLiteral","method_signature":"private assertNullLiteral(Expression expression)","target_class":"","rationale":""},"second":0.15560537519018347},"public testBoolSimplifyOr()":{"first":{"method_name":"testBoolSimplifyOr","method_signature":"public testBoolSimplifyOr()","target_class":"","rationale":""},"second":0.2104979110150979},"public testArithmeticFolding()":{"first":{"method_name":"testArithmeticFolding","method_signature":"public testArithmeticFolding()","target_class":"","rationale":""},"second":0.21914478376341218},"public testBoolSimplifyAnd()":{"first":{"method_name":"testBoolSimplifyAnd","method_signature":"public testBoolSimplifyAnd()","target_class":"","rationale":""},"second":0.22283731339313492},"public static greaterThanOrEqualOf(Expression left, Expression right)":{"first":{"method_name":"greaterThanOrEqualOf","method_signature":"public static greaterThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.30880481048859293},"public static lessThanOrEqualOf(Expression left, Expression right)":{"first":{"method_name":"lessThanOrEqualOf","method_signature":"public static lessThanOrEqualOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.30880631278267157},"public static notEqualsOf(Expression left, Expression right)":{"first":{"method_name":"notEqualsOf","method_signature":"public static notEqualsOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.30881382458195955},"private static lessThanOf(Expression left, Expression right)":{"first":{"method_name":"lessThanOf","method_signature":"private static lessThanOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.30950934424247234},"public static greaterThanOf(Expression left, Expression right)":{"first":{"method_name":"greaterThanOf","method_signature":"public static greaterThanOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.30959365747231804},"private static equalsOf(Expression left, Expression right)":{"first":{"method_name":"equalsOf","method_signature":"private static equalsOf(Expression left, Expression right)","target_class":"","rationale":""},"second":0.31424513692391237},"public testConstantFoldingBinaryLogic_WithNullHandling()":{"first":{"method_name":"testConstantFoldingBinaryLogic_WithNullHandling","method_signature":"public testConstantFoldingBinaryLogic_WithNullHandling()","target_class":"","rationale":""},"second":0.3254185688893922},"public testConstantFoldingBinaryLogic()":{"first":{"method_name":"testConstantFoldingBinaryLogic","method_signature":"public testConstantFoldingBinaryLogic()","target_class":"","rationale":""},"second":0.3300666387633933},"private nullOf(DataType dataType)":{"first":{"method_name":"nullOf","method_signature":"private nullOf(DataType dataType)","target_class":"","rationale":""},"second":0.3307347018218935},"public testConstantFoldingBinaryComparison()":{"first":{"method_name":"testConstantFoldingBinaryComparison","method_signature":"public testConstantFoldingBinaryComparison()","target_class":"","rationale":""},"second":0.3380866492033296},"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)":{"first":{"method_name":"foldOperator","method_signature":"private static foldOperator(BinaryOperator\u003c?, ?, ?, ?\u003e b)","target_class":"","rationale":""},"second":0.34102486003985044}},"llmMethodPriority":{"priority_method_names":["assertNullLiteral","testBoolSimplifyOr","testArithmeticFolding","testBoolSimplifyAnd","greaterThanOrEqualOf","lessThanOrEqualOf","notEqualsOf","lessThanOf","greaterThanOf","equalsOf","testConstantFoldingBinaryLogic_WithNullHandling","testConstantFoldingBinaryLogic","nullOf","testConstantFoldingBinaryComparison","foldOperator"],"llm_response_time":3406},"targetClassMap":{"assertNullLiteral":{"target_classes":[{"class_name":"Expression","similarity_score":0.28427489620315727},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Literal","similarity_score":0.3046872965993534},{"class_name":"Expression","similarity_score":0.28427489620315727}],"target_classes_sorted_by_llm":["Expression","Expression","Literal","Literal","Literal","Literal","Literal","Literal"],"llm_response_time":0,"similarity_computation_time":2,"similarity_metric":"voyage"},"testBoolSimplifyOr":{"target_classes":[{"class_name":"Expression","similarity_score":0.11411166938747436}],"target_classes_sorted_by_llm":["Expression"],"llm_response_time":1965,"similarity_computation_time":1,"similarity_metric":"voyage"},"testArithmeticFolding":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":479,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"c2b82891-fdba-40b3-8c4a-5f806b9d9d12","methodCount":177,"hostFunctionTelemetryData":{"hostFunctionSize":1547,"lineStart":189,"lineEnd":1735,"bodyLineStart":189,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/io/stream/PlanNamedTypes.java","sourceCode":"/**\n * A utility class that consists solely of static methods that describe how to serialize and\n * deserialize QL and ESQL plan types.\n * \u003cP\u003e\n * All types that require to be serialized should have a pair of co-located `readFoo` and `writeFoo`\n * methods that deserialize and serialize respectively.\n * \u003cP\u003e\n * A type can be named or non-named. A named type has a name written to the stream before its\n * contents (similar to NamedWriteable), whereas a non-named type does not (similar to Writable).\n * Named types allow to determine specific deserialization implementations for more general types,\n * e.g. Literal, which is an Expression. Named types must have an entries in the namedTypeEntries\n * list.\n */\npublic final class PlanNamedTypes {\n\n    private PlanNamedTypes() {}\n\n    /**\n     * Determines the writeable name of the give class. The simple class name is commonly used for\n     * {@link NamedWriteable}s and is sufficient here too, but it could be almost anything else.\n     */\n    public static String name(Class\u003c?\u003e cls) {\n        return cls.getSimpleName();\n    }\n\n    static final Class\u003corg.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction\u003e QL_UNARY_SCLR_CLS \u003d\n        org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction.class;\n\n    static final Class\u003cUnaryScalarFunction\u003e ESQL_UNARY_SCLR_CLS \u003d UnaryScalarFunction.class;\n\n    /**\n     * List of named type entries that link concrete names to stream reader and writer implementations.\n     * Entries have the form:  category,  name,  serializer method,  deserializer method.\n     */\n    public static List\u003cPlanNameRegistry.Entry\u003e namedTypeEntries() {\n        List\u003cPlanNameRegistry.Entry\u003e declared \u003d List.of(\n            // Physical Plan Nodes\n            of(PhysicalPlan.class, AggregateExec.class, PlanNamedTypes::writeAggregateExec, PlanNamedTypes::readAggregateExec),\n            of(PhysicalPlan.class, DissectExec.class, PlanNamedTypes::writeDissectExec, PlanNamedTypes::readDissectExec),\n            of(PhysicalPlan.class, EsQueryExec.class, PlanNamedTypes::writeEsQueryExec, PlanNamedTypes::readEsQueryExec),\n            of(PhysicalPlan.class, EsSourceExec.class, PlanNamedTypes::writeEsSourceExec, PlanNamedTypes::readEsSourceExec),\n            of(PhysicalPlan.class, EvalExec.class, PlanNamedTypes::writeEvalExec, PlanNamedTypes::readEvalExec),\n            of(PhysicalPlan.class, EnrichExec.class, PlanNamedTypes::writeEnrichExec, PlanNamedTypes::readEnrichExec),\n            of(PhysicalPlan.class, ExchangeExec.class, PlanNamedTypes::writeExchangeExec, PlanNamedTypes::readExchangeExec),\n            of(PhysicalPlan.class, ExchangeSinkExec.class, PlanNamedTypes::writeExchangeSinkExec, PlanNamedTypes::readExchangeSinkExec),\n            of(\n                PhysicalPlan.class,\n                ExchangeSourceExec.class,\n                PlanNamedTypes::writeExchangeSourceExec,\n                PlanNamedTypes::readExchangeSourceExec\n            ),\n            of(PhysicalPlan.class, FieldExtractExec.class, PlanNamedTypes::writeFieldExtractExec, PlanNamedTypes::readFieldExtractExec),\n            of(PhysicalPlan.class, FilterExec.class, PlanNamedTypes::writeFilterExec, PlanNamedTypes::readFilterExec),\n            of(PhysicalPlan.class, FragmentExec.class, PlanNamedTypes::writeFragmentExec, PlanNamedTypes::readFragmentExec),\n            of(PhysicalPlan.class, GrokExec.class, PlanNamedTypes::writeGrokExec, PlanNamedTypes::readGrokExec),\n            of(PhysicalPlan.class, LimitExec.class, PlanNamedTypes::writeLimitExec, PlanNamedTypes::readLimitExec),\n            of(PhysicalPlan.class, LocalSourceExec.class, (out, v) -\u003e v.writeTo(out), LocalSourceExec::new),\n            of(PhysicalPlan.class, HashJoinExec.class, (out, v) -\u003e v.writeTo(out), HashJoinExec::new),\n            of(PhysicalPlan.class, MvExpandExec.class, PlanNamedTypes::writeMvExpandExec, PlanNamedTypes::readMvExpandExec),\n            of(PhysicalPlan.class, OrderExec.class, PlanNamedTypes::writeOrderExec, PlanNamedTypes::readOrderExec),\n            of(PhysicalPlan.class, ProjectExec.class, PlanNamedTypes::writeProjectExec, PlanNamedTypes::readProjectExec),\n            of(PhysicalPlan.class, RowExec.class, PlanNamedTypes::writeRowExec, PlanNamedTypes::readRowExec),\n            of(PhysicalPlan.class, ShowExec.class, PlanNamedTypes::writeShowExec, PlanNamedTypes::readShowExec),\n            of(PhysicalPlan.class, TopNExec.class, PlanNamedTypes::writeTopNExec, PlanNamedTypes::readTopNExec),\n            // Logical Plan Nodes - a subset of plans that end up being actually serialized\n            of(LogicalPlan.class, Aggregate.class, PlanNamedTypes::writeAggregate, PlanNamedTypes::readAggregate),\n            of(LogicalPlan.class, Dissect.class, PlanNamedTypes::writeDissect, PlanNamedTypes::readDissect),\n            of(LogicalPlan.class, EsRelation.class, PlanNamedTypes::writeEsRelation, PlanNamedTypes::readEsRelation),\n            of(LogicalPlan.class, Eval.class, PlanNamedTypes::writeEval, PlanNamedTypes::readEval),\n            of(LogicalPlan.class, Enrich.class, PlanNamedTypes::writeEnrich, PlanNamedTypes::readEnrich),\n            of(LogicalPlan.class, EsqlProject.class, PlanNamedTypes::writeEsqlProject, PlanNamedTypes::readEsqlProject),\n            of(LogicalPlan.class, Filter.class, PlanNamedTypes::writeFilter, PlanNamedTypes::readFilter),\n            of(LogicalPlan.class, Grok.class, PlanNamedTypes::writeGrok, PlanNamedTypes::readGrok),\n            of(LogicalPlan.class, Join.class, (out, p) -\u003e p.writeTo(out), Join::new),\n            of(LogicalPlan.class, Limit.class, PlanNamedTypes::writeLimit, PlanNamedTypes::readLimit),\n            of(LogicalPlan.class, LocalRelation.class, (out, p) -\u003e p.writeTo(out), LocalRelation::new),\n            of(LogicalPlan.class, Lookup.class, (out, p) -\u003e p.writeTo(out), Lookup::new),\n            of(LogicalPlan.class, MvExpand.class, PlanNamedTypes::writeMvExpand, PlanNamedTypes::readMvExpand),\n            of(LogicalPlan.class, OrderBy.class, PlanNamedTypes::writeOrderBy, PlanNamedTypes::readOrderBy),\n            of(LogicalPlan.class, Project.class, PlanNamedTypes::writeProject, PlanNamedTypes::readProject),\n            of(LogicalPlan.class, TopN.class, PlanNamedTypes::writeTopN, PlanNamedTypes::readTopN),\n            // BinaryComparison\n            of(EsqlBinaryComparison.class, Equals.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            of(EsqlBinaryComparison.class, NotEquals.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            of(EsqlBinaryComparison.class, GreaterThan.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            of(EsqlBinaryComparison.class, GreaterThanOrEqual.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            of(EsqlBinaryComparison.class, LessThan.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            of(EsqlBinaryComparison.class, LessThanOrEqual.class, PlanNamedTypes::writeBinComparison, PlanNamedTypes::readBinComparison),\n            // InsensitiveEquals\n            of(\n                InsensitiveEquals.class,\n                InsensitiveEquals.class,\n                PlanNamedTypes::writeInsensitiveEquals,\n                PlanNamedTypes::readInsensitiveEquals\n            ),\n            // InComparison\n            of(ScalarFunction.class, In.class, PlanNamedTypes::writeInComparison, PlanNamedTypes::readInComparison),\n            // RegexMatch\n            of(RegexMatch.class, WildcardLike.class, PlanNamedTypes::writeWildcardLike, PlanNamedTypes::readWildcardLike),\n            of(RegexMatch.class, RLike.class, PlanNamedTypes::writeRLike, PlanNamedTypes::readRLike),\n            // BinaryLogic\n            of(BinaryLogic.class, And.class, PlanNamedTypes::writeBinaryLogic, PlanNamedTypes::readBinaryLogic),\n            of(BinaryLogic.class, Or.class, PlanNamedTypes::writeBinaryLogic, PlanNamedTypes::readBinaryLogic),\n            // UnaryScalarFunction\n            of(QL_UNARY_SCLR_CLS, IsNotNull.class, PlanNamedTypes::writeQLUnaryScalar, PlanNamedTypes::readQLUnaryScalar),\n            of(QL_UNARY_SCLR_CLS, IsNull.class, PlanNamedTypes::writeQLUnaryScalar, PlanNamedTypes::readQLUnaryScalar),\n            of(QL_UNARY_SCLR_CLS, Not.class, PlanNamedTypes::writeQLUnaryScalar, PlanNamedTypes::readQLUnaryScalar),\n            // ScalarFunction\n            of(ScalarFunction.class, Atan2.class, PlanNamedTypes::writeAtan2, PlanNamedTypes::readAtan2),\n            of(ScalarFunction.class, Case.class, PlanNamedTypes::writeVararg, PlanNamedTypes::readVarag),\n            of(ScalarFunction.class, CIDRMatch.class, PlanNamedTypes::writeCIDRMatch, PlanNamedTypes::readCIDRMatch),\n            of(ScalarFunction.class, Coalesce.class, PlanNamedTypes::writeVararg, PlanNamedTypes::readVarag),\n            of(ScalarFunction.class, Concat.class, PlanNamedTypes::writeVararg, PlanNamedTypes::readVarag),\n            of(ScalarFunction.class, DateDiff.class, PlanNamedTypes::writeDateDiff, PlanNamedTypes::readDateDiff),\n            of(ScalarFunction.class, DateExtract.class, PlanNamedTypes::writeDateExtract, PlanNamedTypes::readDateExtract),\n            of(ScalarFunction.class, DateFormat.class, PlanNamedTypes::writeDateFormat, PlanNamedTypes::readDateFormat),\n            of(ScalarFunction.class, DateParse.class, PlanNamedTypes::writeDateTimeParse, PlanNamedTypes::readDateTimeParse),\n            of(ScalarFunction.class, DateTrunc.class, PlanNamedTypes::writeDateTrunc, PlanNamedTypes::readDateTrunc),\n            of(ScalarFunction.class, E.class, PlanNamedTypes::writeNoArgScalar, PlanNamedTypes::readNoArgScalar),\n            of(ScalarFunction.class, Greatest.class, PlanNamedTypes::writeVararg, PlanNamedTypes::readVarag),\n            of(ScalarFunction.class, IpPrefix.class, (out, prefix) -\u003e prefix.writeTo(out), IpPrefix::readFrom),\n            of(ScalarFunction.class, Least.class, PlanNamedTypes::writeVararg, PlanNamedTypes::readVarag),\n            of(ScalarFunction.class, Log.class, PlanNamedTypes::writeLog, PlanNamedTypes::readLog),\n            of(ScalarFunction.class, Now.class, PlanNamedTypes::writeNow, PlanNamedTypes::readNow),\n            of(ScalarFunction.class, Pi.class, PlanNamedTypes::writeNoArgScalar, PlanNamedTypes::readNoArgScalar),\n            of(ScalarFunction.class, Round.class, PlanNamedTypes::writeRound, PlanNamedTypes::readRound),\n            of(ScalarFunction.class, Pow.class, PlanNamedTypes::writePow, PlanNamedTypes::readPow),\n            of(ScalarFunction.class, StartsWith.class, PlanNamedTypes::writeStartsWith, PlanNamedTypes::readStartsWith),\n            of(ScalarFunction.class, EndsWith.class, PlanNamedTypes::writeEndsWith, PlanNamedTypes::readEndsWith),\n            of(ScalarFunction.class, SpatialIntersects.class, PlanNamedTypes::writeSpatialRelatesFunction, PlanNamedTypes::readIntersects),\n            of(ScalarFunction.class, SpatialDisjoint.class, PlanNamedTypes::writeSpatialRelatesFunction, PlanNamedTypes::readDisjoint),\n            of(ScalarFunction.class, SpatialContains.class, PlanNamedTypes::writeSpatialRelatesFunction, PlanNamedTypes::readContains),\n            of(ScalarFunction.class, SpatialWithin.class, PlanNamedTypes::writeSpatialRelatesFunction, PlanNamedTypes::readWithin),\n            of(ScalarFunction.class, Substring.class, PlanNamedTypes::writeSubstring, PlanNamedTypes::readSubstring),\n            of(ScalarFunction.class, Locate.class, PlanNamedTypes::writeLocate, PlanNamedTypes::readLocate),\n            of(ScalarFunction.class, Left.class, PlanNamedTypes::writeLeft, PlanNamedTypes::readLeft),\n            of(ScalarFunction.class, Repeat.class, PlanNamedTypes::writeRepeat, PlanNamedTypes::readRepeat),\n            of(ScalarFunction.class, Right.class, PlanNamedTypes::writeRight, PlanNamedTypes::readRight),\n            of(ScalarFunction.class, Split.class, PlanNamedTypes::writeSplit, PlanNamedTypes::readSplit),\n            of(ScalarFunction.class, Tau.class, PlanNamedTypes::writeNoArgScalar, PlanNamedTypes::readNoArgScalar),\n            of(ScalarFunction.class, Replace.class, PlanNamedTypes::writeReplace, PlanNamedTypes::readReplace),\n            of(ScalarFunction.class, ToLower.class, PlanNamedTypes::writeToLower, PlanNamedTypes::readToLower),\n            of(ScalarFunction.class, ToUpper.class, PlanNamedTypes::writeToUpper, PlanNamedTypes::readToUpper),\n            // ArithmeticOperations\n            of(ArithmeticOperation.class, Add.class, PlanNamedTypes::writeArithmeticOperation, PlanNamedTypes::readArithmeticOperation),\n            of(ArithmeticOperation.class, Sub.class, PlanNamedTypes::writeArithmeticOperation, PlanNamedTypes::readArithmeticOperation),\n            of(ArithmeticOperation.class, Mul.class, PlanNamedTypes::writeArithmeticOperation, PlanNamedTypes::readArithmeticOperation),\n            of(ArithmeticOperation.class, Div.class, PlanNamedTypes::writeArithmeticOperation, PlanNamedTypes::readArithmeticOperation),\n            of(ArithmeticOperation.class, Mod.class, PlanNamedTypes::writeArithmeticOperation, PlanNamedTypes::readArithmeticOperation),\n            // GroupingFunctions\n            of(GroupingFunction.class, Bucket.class, PlanNamedTypes::writeBucket, PlanNamedTypes::readBucket),\n            // AggregateFunctions\n            of(AggregateFunction.class, Avg.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Count.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, CountDistinct.class, PlanNamedTypes::writeCountDistinct, PlanNamedTypes::readCountDistinct),\n            of(AggregateFunction.class, Min.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Max.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Median.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, MedianAbsoluteDeviation.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Percentile.class, PlanNamedTypes::writePercentile, PlanNamedTypes::readPercentile),\n            of(AggregateFunction.class, SpatialCentroid.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Sum.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            of(AggregateFunction.class, Values.class, PlanNamedTypes::writeAggFunction, PlanNamedTypes::readAggFunction),\n            // Multivalue functions\n            of(ScalarFunction.class, MvAppend.class, PlanNamedTypes::writeMvAppend, PlanNamedTypes::readMvAppend),\n            of(ScalarFunction.class, MvAvg.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvCount.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvConcat.class, PlanNamedTypes::writeMvConcat, PlanNamedTypes::readMvConcat),\n            of(ScalarFunction.class, MvDedupe.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvFirst.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvLast.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvMax.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvMedian.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvMin.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvSort.class, PlanNamedTypes::writeMvSort, PlanNamedTypes::readMvSort),\n            of(ScalarFunction.class, MvSlice.class, PlanNamedTypes::writeMvSlice, PlanNamedTypes::readMvSlice),\n            of(ScalarFunction.class, MvSum.class, PlanNamedTypes::writeMvFunction, PlanNamedTypes::readMvFunction),\n            of(ScalarFunction.class, MvZip.class, PlanNamedTypes::writeMvZip, PlanNamedTypes::readMvZip),\n            // Expressions (other)\n            of(Expression.class, Literal.class, PlanNamedTypes::writeLiteral, PlanNamedTypes::readLiteral),\n            of(Expression.class, Order.class, PlanNamedTypes::writeOrder, PlanNamedTypes::readOrder)\n        );\n        List\u003cPlanNameRegistry.Entry\u003e entries \u003d new ArrayList\u003c\u003e(declared);\n\n        // From NamedWriteables\n        for (NamedWriteableRegistry.Entry e : UnaryScalarFunction.getNamedWriteables()) {\n            entries.add(of(ESQL_UNARY_SCLR_CLS, e));\n        }\n        for (NamedWriteableRegistry.Entry e : NamedExpression.getNamedWriteables()) {\n            entries.add(of(Expression.class, e));\n        }\n        entries.add(of(Expression.class, UnsupportedAttribute.ENTRY));\n\n        return entries;\n    }\n\n    // -- physical plan nodes\n    static AggregateExec readAggregateExec(PlanStreamInput in) throws IOException {\n        return new AggregateExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression)),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class),\n            in.readEnum(AggregateExec.Mode.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(aggregateExec.child());\n        out.writeCollection(aggregateExec.groupings(), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n        out.writeNamedWriteableCollection(aggregateExec.aggregates());\n        out.writeEnum(aggregateExec.getMode());\n        out.writeOptionalVInt(aggregateExec.estimatedRowSize());\n    }\n\n    static DissectExec readDissectExec(PlanStreamInput in) throws IOException {\n        return new DissectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readExpression(),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissectExec(PlanStreamOutput out, DissectExec dissectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(dissectExec.child());\n        out.writeExpression(dissectExec.inputExpression());\n        writeDissectParser(out, dissectExec.parser());\n        out.writeNamedWriteableCollection(dissectExec.extractedFields());\n    }\n\n    static EsQueryExec readEsQueryExec(PlanStreamInput in) throws IOException {\n        return new EsQueryExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            readIndexMode(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalNamed(Expression.class),\n            in.readOptionalCollectionAsList(readerFromPlanReader(PlanNamedTypes::readFieldSort)),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec) throws IOException {\n        assert esQueryExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esQueryExec.index());\n        writeIndexMode(out, esQueryExec.indexMode());\n        out.writeNamedWriteableCollection(esQueryExec.output());\n        out.writeOptionalNamedWriteable(esQueryExec.query());\n        out.writeOptionalExpression(esQueryExec.limit());\n        out.writeOptionalCollection(esQueryExec.sorts(), writerFromPlanWriter(PlanNamedTypes::writeFieldSort));\n        out.writeOptionalInt(esQueryExec.estimatedRowSize());\n    }\n\n    static EsSourceExec readEsSourceExec(PlanStreamInput in) throws IOException {\n        return new EsSourceExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            readIndexMode(in)\n        );\n    }\n\n    static void writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esSourceExec.index());\n        out.writeNamedWriteableCollection(esSourceExec.output());\n        out.writeOptionalNamedWriteable(esSourceExec.query());\n        writeIndexMode(out, esSourceExec.indexMode());\n    }\n\n    static IndexMode readIndexMode(StreamInput in) throws IOException {\n        if (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            return IndexMode.fromString(in.readString());\n        } else {\n            return IndexMode.STANDARD;\n        }\n    }\n\n    static void writeIndexMode(StreamOutput out, IndexMode indexMode) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            out.writeString(indexMode.getName());\n        } else if (indexMode !\u003d IndexMode.STANDARD) {\n            throw new IllegalStateException(\"not ready to support index mode [\" + indexMode + \"]\");\n        }\n    }\n\n    static EvalExec readEvalExec(PlanStreamInput in) throws IOException {\n        return new EvalExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEvalExec(PlanStreamOutput out, EvalExec evalExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(evalExec.child());\n        out.writeCollection(evalExec.fields());\n    }\n\n    static EnrichExec readEnrichExec(PlanStreamInput in) throws IOException {\n        final Source source \u003d Source.readFrom(in);\n        final PhysicalPlan child \u003d in.readPhysicalPlanNode();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        final String policyName \u003d in.readString();\n        final String matchType \u003d (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_EXTENDED_ENRICH_TYPES))\n            ? in.readString()\n            : \"match\";\n        final String policyMatchField \u003d in.readString();\n        final Map\u003cString, String\u003e concreteIndices;\n        final Enrich.Mode mode;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            mode \u003d Enrich.Mode.ANY;\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() !\u003d 1) {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + esIndex.concreteIndices());\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new EnrichExec(\n            source,\n            child,\n            mode,\n            matchType,\n            matchField,\n            policyName,\n            policyMatchField,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrichExec(PlanStreamOutput out, EnrichExec enrich) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(enrich.child());\n        out.writeNamedWriteable(enrich.matchField());\n        out.writeString(enrich.policyName());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_EXTENDED_ENRICH_TYPES)) {\n            out.writeString(enrich.matchType());\n        }\n        out.writeString(enrich.policyMatchField());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            if (enrich.concreteIndices().keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String concreteIndex \u003d enrich.concreteIndices().get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                writeEsIndex(out, new EsIndex(concreteIndex, Map.of(), Set.of(concreteIndex)));\n            } else {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + enrich.concreteIndices());\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static ExchangeExec readExchangeExec(PlanStreamInput in) throws IOException {\n        return new ExchangeExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeExec.output());\n        out.writeBoolean(exchangeExec.isInBetweenAggs());\n        out.writePhysicalPlanNode(exchangeExec.child());\n    }\n\n    static ExchangeSinkExec readExchangeSinkExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSinkExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeSinkExec.output());\n        out.writeBoolean(exchangeSinkExec.isIntermediateAgg());\n        out.writePhysicalPlanNode(exchangeSinkExec.child());\n    }\n\n    static ExchangeSourceExec readExchangeSourceExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSourceExec(Source.readFrom(in), in.readNamedWriteableCollectionAsList(Attribute.class), in.readBoolean());\n    }\n\n    static void writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec) throws IOException {\n        out.writeNamedWriteableCollection(exchangeSourceExec.output());\n        out.writeBoolean(exchangeSourceExec.isIntermediateAgg());\n    }\n\n    static FieldExtractExec readFieldExtractExec(PlanStreamInput in) throws IOException {\n        return new FieldExtractExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteableCollectionAsList(Attribute.class));\n    }\n\n    static void writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(fieldExtractExec.child());\n        out.writeNamedWriteableCollection(fieldExtractExec.attributesToExtract());\n    }\n\n    static FilterExec readFilterExec(PlanStreamInput in) throws IOException {\n        return new FilterExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readExpression());\n    }\n\n    static void writeFilterExec(PlanStreamOutput out, FilterExec filterExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(filterExec.child());\n        out.writeExpression(filterExec.condition());\n    }\n\n    static FragmentExec readFragmentExec(PlanStreamInput in) throws IOException {\n        return new FragmentExec(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalVInt(),\n            in.getTransportVersion().onOrAfter(TransportVersions.ESQL_REDUCER_NODE_FRAGMENT) ? in.readOptionalPhysicalPlanNode() : null\n        );\n    }\n\n    static void writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(fragmentExec.fragment());\n        out.writeOptionalNamedWriteable(fragmentExec.esFilter());\n        out.writeOptionalVInt(fragmentExec.estimatedRowSize());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_REDUCER_NODE_FRAGMENT)) {\n            out.writeOptionalPhysicalPlanNode(fragmentExec.reducer());\n        }\n    }\n\n    static GrokExec readGrokExec(PlanStreamInput in) throws IOException {\n        Source source;\n        return new GrokExec(\n            source \u003d Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readExpression(),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrokExec(PlanStreamOutput out, GrokExec grokExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(grokExec.child());\n        out.writeExpression(grokExec.inputExpression());\n        out.writeString(grokExec.pattern().pattern());\n        out.writeNamedWriteableCollection(grokExec.extractedFields());\n    }\n\n    static LimitExec readLimitExec(PlanStreamInput in) throws IOException {\n        return new LimitExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamed(Expression.class));\n    }\n\n    static void writeLimitExec(PlanStreamOutput out, LimitExec limitExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(limitExec.child());\n        out.writeExpression(limitExec.limit());\n    }\n\n    static MvExpandExec readMvExpandExec(PlanStreamInput in) throws IOException {\n        return new MvExpandExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(mvExpandExec.child());\n        out.writeNamedWriteable(mvExpandExec.target());\n        out.writeNamedWriteable(mvExpandExec.expanded());\n    }\n\n    static OrderExec readOrderExec(PlanStreamInput in) throws IOException {\n        return new OrderExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanNamedTypes::readOrder))\n        );\n    }\n\n    static void writeOrderExec(PlanStreamOutput out, OrderExec orderExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(orderExec.child());\n        out.writeCollection(orderExec.order(), writerFromPlanWriter(PlanNamedTypes::writeOrder));\n    }\n\n    static ProjectExec readProjectExec(PlanStreamInput in) throws IOException {\n        return new ProjectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeProjectExec(PlanStreamOutput out, ProjectExec projectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(projectExec.child());\n        out.writeNamedWriteableCollection(projectExec.projections());\n    }\n\n    static RowExec readRowExec(PlanStreamInput in) throws IOException {\n        return new RowExec(Source.readFrom(in), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeRowExec(PlanStreamOutput out, RowExec rowExec) throws IOException {\n        assert rowExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        out.writeCollection(rowExec.fields());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static ShowExec readShowExec(PlanStreamInput in) throws IOException {\n        return new ShowExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            (List\u003cList\u003cObject\u003e\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeShowExec(PlanStreamOutput out, ShowExec showExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(showExec.output());\n        out.writeGenericValue(showExec.values());\n    }\n\n    static TopNExec readTopNExec(PlanStreamInput in) throws IOException {\n        return new TopNExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanNamedTypes::readOrder)),\n            in.readNamed(Expression.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeTopNExec(PlanStreamOutput out, TopNExec topNExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(topNExec.child());\n        out.writeCollection(topNExec.order(), writerFromPlanWriter(PlanNamedTypes::writeOrder));\n        out.writeExpression(topNExec.limit());\n        out.writeOptionalVInt(topNExec.estimatedRowSize());\n    }\n\n    // -- Logical plan nodes\n    static Aggregate readAggregate(PlanStreamInput in) throws IOException {\n        return new Aggregate(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression)),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeAggregate(PlanStreamOutput out, Aggregate aggregate) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(aggregate.child());\n        out.writeCollection(aggregate.groupings(), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n        out.writeNamedWriteableCollection(aggregate.aggregates());\n    }\n\n    static Dissect readDissect(PlanStreamInput in) throws IOException {\n        return new Dissect(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readExpression(),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissect(PlanStreamOutput out, Dissect dissect) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(dissect.child());\n        out.writeExpression(dissect.input());\n        writeDissectParser(out, dissect.parser());\n        out.writeNamedWriteableCollection(dissect.extractedFields());\n    }\n\n    static EsRelation readEsRelation(PlanStreamInput in) throws IOException {\n        Source source \u003d Source.readFrom(in);\n        EsIndex esIndex \u003d readEsIndex(in);\n        List\u003cAttribute\u003e attributes \u003d in.readNamedWriteableCollectionAsList(Attribute.class);\n        if (supportingEsSourceOptions(in.getTransportVersion())) {\n            readEsSourceOptions(in); // consume optional strings sent by remote\n        }\n        final IndexMode indexMode \u003d readIndexMode(in);\n        boolean frozen \u003d in.readBoolean();\n        return new EsRelation(source, esIndex, attributes, indexMode, frozen);\n    }\n\n    static void writeEsRelation(PlanStreamOutput out, EsRelation relation) throws IOException {\n        assert relation.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, relation.index());\n        out.writeNamedWriteableCollection(relation.output());\n        if (supportingEsSourceOptions(out.getTransportVersion())) {\n            writeEsSourceOptions(out); // write (null) string fillers expected by remote\n        }\n        writeIndexMode(out, relation.indexMode());\n        out.writeBoolean(relation.frozen());\n    }\n\n    private static boolean supportingEsSourceOptions(TransportVersion version) {\n        return version.onOrAfter(TransportVersions.ESQL_ES_SOURCE_OPTIONS)\n            \u0026\u0026 version.before(TransportVersions.ESQL_REMOVE_ES_SOURCE_OPTIONS);\n    }\n\n    private static void readEsSourceOptions(PlanStreamInput in) throws IOException {\n        // allowNoIndices\n        in.readOptionalString();\n        // ignoreUnavailable\n        in.readOptionalString();\n        // preference\n        in.readOptionalString();\n    }\n\n    private static void writeEsSourceOptions(PlanStreamOutput out) throws IOException {\n        // allowNoIndices\n        out.writeOptionalString(null);\n        // ignoreUnavailable\n        out.writeOptionalString(null);\n        // preference\n        out.writeOptionalString(null);\n    }\n\n    static Eval readEval(PlanStreamInput in) throws IOException {\n        return new Eval(Source.readFrom(in), in.readLogicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEval(PlanStreamOutput out, Eval eval) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(eval.child());\n        out.writeCollection(eval.fields());\n    }\n\n    static Enrich readEnrich(PlanStreamInput in) throws IOException {\n        Enrich.Mode mode \u003d Enrich.Mode.ANY;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n        }\n        final Source source \u003d Source.readFrom(in);\n        final LogicalPlan child \u003d in.readLogicalPlanNode();\n        final Expression policyName \u003d in.readExpression();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        if (in.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            in.readString(); // discard the old policy name\n        }\n        final EnrichPolicy policy \u003d new EnrichPolicy(in);\n        final Map\u003cString, String\u003e concreteIndices;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() \u003e 1) {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + esIndex);\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new Enrich(\n            source,\n            child,\n            mode,\n            policyName,\n            matchField,\n            policy,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrich(PlanStreamOutput out, Enrich enrich) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n        }\n\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(enrich.child());\n        out.writeExpression(enrich.policyName());\n        out.writeNamedWriteable(enrich.matchField());\n        if (out.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            out.writeString(BytesRefs.toString(enrich.policyName().fold())); // old policy name\n        }\n        enrich.policy().writeTo(out);\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            Map\u003cString, String\u003e concreteIndices \u003d enrich.concreteIndices();\n            if (concreteIndices.keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String enrichIndex \u003d concreteIndices.get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                EsIndex esIndex \u003d new EsIndex(enrichIndex, Map.of(), Set.of(enrichIndex));\n                writeEsIndex(out, esIndex);\n            } else {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + concreteIndices);\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static EsqlProject readEsqlProject(PlanStreamInput in) throws IOException {\n        return new EsqlProject(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeEsqlProject(PlanStreamOutput out, EsqlProject project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    static Filter readFilter(PlanStreamInput in) throws IOException {\n        return new Filter(Source.readFrom(in), in.readLogicalPlanNode(), in.readExpression());\n    }\n\n    static void writeFilter(PlanStreamOutput out, Filter filter) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(filter.child());\n        out.writeExpression(filter.condition());\n    }\n\n    static Grok readGrok(PlanStreamInput in) throws IOException {\n        Source source;\n        return new Grok(\n            source \u003d Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readExpression(),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrok(PlanStreamOutput out, Grok grok) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(grok.child());\n        out.writeExpression(grok.input());\n        out.writeString(grok.parser().pattern());\n        out.writeNamedWriteableCollection(grok.extractedFields());\n    }\n\n    static Limit readLimit(PlanStreamInput in) throws IOException {\n        return new Limit(Source.readFrom(in), in.readNamed(Expression.class), in.readLogicalPlanNode());\n    }\n\n    static void writeLimit(PlanStreamOutput out, Limit limit) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(limit.limit());\n        out.writeLogicalPlanNode(limit.child());\n    }\n\n    static MvExpand readMvExpand(PlanStreamInput in) throws IOException {\n        return new MvExpand(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpand(PlanStreamOutput out, MvExpand mvExpand) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(mvExpand.child());\n        out.writeNamedWriteable(mvExpand.target());\n        out.writeNamedWriteable(mvExpand.expanded());\n    }\n\n    static OrderBy readOrderBy(PlanStreamInput in) throws IOException {\n        return new OrderBy(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanNamedTypes::readOrder))\n        );\n    }\n\n    static void writeOrderBy(PlanStreamOutput out, OrderBy order) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(order.child());\n        out.writeCollection(order.order(), writerFromPlanWriter(PlanNamedTypes::writeOrder));\n    }\n\n    static Project readProject(PlanStreamInput in) throws IOException {\n        return new Project(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeProject(PlanStreamOutput out, Project project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    static TopN readTopN(PlanStreamInput in) throws IOException {\n        return new TopN(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanNamedTypes::readOrder)),\n            in.readNamed(Expression.class)\n        );\n    }\n\n    static void writeTopN(PlanStreamOutput out, TopN topN) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(topN.child());\n        out.writeCollection(topN.order(), writerFromPlanWriter(PlanNamedTypes::writeOrder));\n        out.writeExpression(topN.limit());\n    }\n\n    // -- BinaryComparison\n\n    public static EsqlBinaryComparison readBinComparison(PlanStreamInput in, String name) throws IOException {\n        var source \u003d Source.readFrom(in);\n        EsqlBinaryComparison.BinaryComparisonOperation operation \u003d EsqlBinaryComparison.BinaryComparisonOperation.readFromStream(in);\n        var left \u003d in.readExpression();\n        var right \u003d in.readExpression();\n        // TODO: Remove zoneId entirely\n        var zoneId \u003d in.readOptionalZoneId();\n        return operation.buildNewInstance(source, left, right);\n    }\n\n    public static void writeBinComparison(PlanStreamOutput out, EsqlBinaryComparison binaryComparison) throws IOException {\n        binaryComparison.source().writeTo(out);\n        binaryComparison.getFunctionType().writeTo(out);\n        out.writeExpression(binaryComparison.left());\n        out.writeExpression(binaryComparison.right());\n        out.writeOptionalZoneId(binaryComparison.zoneId());\n    }\n\n    // -- InsensitiveEquals\n    static InsensitiveEquals readInsensitiveEquals(PlanStreamInput in, String name) throws IOException {\n        var source \u003d Source.readFrom(in);\n        var left \u003d in.readExpression();\n        var right \u003d in.readExpression();\n        return new InsensitiveEquals(source, left, right);\n    }\n\n    static void writeInsensitiveEquals(PlanStreamOutput out, InsensitiveEquals eq) throws IOException {\n        eq.source().writeTo(out);\n        out.writeExpression(eq.left());\n        out.writeExpression(eq.right());\n    }\n\n    // -- InComparison\n\n    static In readInComparison(PlanStreamInput in) throws IOException {\n        return new In(\n            Source.readFrom(in),\n            in.readExpression(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression))\n        );\n    }\n\n    static void writeInComparison(PlanStreamOutput out, In in) throws IOException {\n        in.source().writeTo(out);\n        out.writeExpression(in.value());\n        out.writeCollection(in.list(), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n    }\n\n    // -- RegexMatch\n\n    static WildcardLike readWildcardLike(PlanStreamInput in, String name) throws IOException {\n        return new WildcardLike(Source.readFrom(in), in.readExpression(), new WildcardPattern(in.readString()));\n    }\n\n    static void writeWildcardLike(PlanStreamOutput out, WildcardLike like) throws IOException {\n        like.source().writeTo(out);\n        out.writeExpression(like.field());\n        out.writeString(like.pattern().pattern());\n    }\n\n    static RLike readRLike(PlanStreamInput in, String name) throws IOException {\n        return new RLike(Source.readFrom(in), in.readExpression(), new RLikePattern(in.readString()));\n    }\n\n    static void writeRLike(PlanStreamOutput out, RLike like) throws IOException {\n        like.source().writeTo(out);\n        out.writeExpression(like.field());\n        out.writeString(like.pattern().asJavaRegex());\n    }\n\n    // -- BinaryLogic\n\n    static final Map\u003cString, TriFunction\u003cSource, Expression, Expression, BinaryLogic\u003e\u003e BINARY_LOGIC_CTRS \u003d Map.ofEntries(\n        entry(name(And.class), And::new),\n        entry(name(Or.class), Or::new)\n    );\n\n    static BinaryLogic readBinaryLogic(PlanStreamInput in, String name) throws IOException {\n        var source \u003d Source.readFrom(in);\n        var left \u003d in.readExpression();\n        var right \u003d in.readExpression();\n        return BINARY_LOGIC_CTRS.get(name).apply(source, left, right);\n    }\n\n    static void writeBinaryLogic(PlanStreamOutput out, BinaryLogic binaryLogic) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(binaryLogic.left());\n        out.writeExpression(binaryLogic.right());\n    }\n\n    static final Map\u003cString, Function\u003cSource, ScalarFunction\u003e\u003e NO_ARG_SCALAR_CTRS \u003d Map.ofEntries(\n        entry(name(E.class), E::new),\n        entry(name(Pi.class), Pi::new),\n        entry(name(Tau.class), Tau::new)\n    );\n\n    static ScalarFunction readNoArgScalar(PlanStreamInput in, String name) throws IOException {\n        var ctr \u003d NO_ARG_SCALAR_CTRS.get(name);\n        if (ctr \u003d\u003d null) {\n            throw new IOException(\"Constructor not found:\" + name);\n        }\n        return ctr.apply(Source.readFrom(in));\n    }\n\n    static void writeNoArgScalar(PlanStreamOutput out, ScalarFunction function) throws IOException {\n        Source.EMPTY.writeTo(out);\n    }\n\n    static final Map\u003c\n        String,\n        BiFunction\u003c\n            Source,\n            Expression,\n            org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction\u003e\u003e QL_UNARY_SCALAR_CTRS \u003d Map.ofEntries(\n                entry(name(IsNotNull.class), IsNotNull::new),\n                entry(name(IsNull.class), IsNull::new),\n                entry(name(Not.class), Not::new)\n            );\n\n    static org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction readQLUnaryScalar(\n        PlanStreamInput in,\n        String name\n    ) throws IOException {\n        var ctr \u003d QL_UNARY_SCALAR_CTRS.get(name);\n        if (ctr \u003d\u003d null) {\n            throw new IOException(\"Constructor for QLUnaryScalar not found for name:\" + name);\n        }\n        return ctr.apply(Source.readFrom(in), in.readExpression());\n    }\n\n    static void writeQLUnaryScalar(\n        PlanStreamOutput out,\n        org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction function\n    ) throws IOException {\n        function.source().writeTo(out);\n        out.writeExpression(function.field());\n    }\n\n    // -- ScalarFunction\n\n    static Atan2 readAtan2(PlanStreamInput in) throws IOException {\n        return new Atan2(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeAtan2(PlanStreamOutput out, Atan2 atan2) throws IOException {\n        atan2.source().writeTo(out);\n        out.writeExpression(atan2.y());\n        out.writeExpression(atan2.x());\n    }\n\n    static Bucket readBucket(PlanStreamInput in) throws IOException {\n        return new Bucket(\n            Source.readFrom(in),\n            in.readExpression(),\n            in.readExpression(),\n            in.readOptionalNamed(Expression.class),\n            in.readOptionalNamed(Expression.class)\n        );\n    }\n\n    static void writeBucket(PlanStreamOutput out, Bucket bucket) throws IOException {\n        bucket.source().writeTo(out);\n        out.writeExpression(bucket.field());\n        out.writeExpression(bucket.buckets());\n        out.writeOptionalExpression(bucket.from());\n        out.writeOptionalExpression(bucket.to());\n    }\n\n    static final Map\u003cString, TriFunction\u003cSource, Expression, List\u003cExpression\u003e, ScalarFunction\u003e\u003e VARARG_CTORS \u003d Map.ofEntries(\n        entry(name(Case.class), Case::new),\n        entry(name(Coalesce.class), Coalesce::new),\n        entry(name(Concat.class), Concat::new),\n        entry(name(Greatest.class), Greatest::new),\n        entry(name(Least.class), Least::new)\n    );\n\n    static ScalarFunction readVarag(PlanStreamInput in, String name) throws IOException {\n        return VARARG_CTORS.get(name)\n            .apply(\n                Source.readFrom(in),\n                in.readExpression(),\n                in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression))\n            );\n    }\n\n    static void writeVararg(PlanStreamOutput out, ScalarFunction vararg) throws IOException {\n        vararg.source().writeTo(out);\n        out.writeExpression(vararg.children().get(0));\n        out.writeCollection(\n            vararg.children().subList(1, vararg.children().size()),\n            writerFromPlanWriter(PlanStreamOutput::writeExpression)\n        );\n    }\n\n    static CountDistinct readCountDistinct(PlanStreamInput in) throws IOException {\n        return new CountDistinct(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeCountDistinct(PlanStreamOutput out, CountDistinct countDistinct) throws IOException {\n        List\u003cExpression\u003e fields \u003d countDistinct.children();\n        assert fields.size() \u003d\u003d 1 || fields.size() \u003d\u003d 2;\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(fields.get(0));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 2 ? o -\u003e out.writeExpression(fields.get(1)) : null);\n    }\n\n    static DateDiff readDateDiff(PlanStreamInput in) throws IOException {\n        return new DateDiff(Source.readFrom(in), in.readExpression(), in.readExpression(), in.readExpression());\n    }\n\n    static void writeDateDiff(PlanStreamOutput out, DateDiff function) throws IOException {\n        Source.EMPTY.writeTo(out);\n        List\u003cExpression\u003e fields \u003d function.children();\n        assert fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeExpression(fields.get(2));\n    }\n\n    static DateExtract readDateExtract(PlanStreamInput in) throws IOException {\n        return new DateExtract(Source.readFrom(in), in.readExpression(), in.readExpression(), in.configuration());\n    }\n\n    static void writeDateExtract(PlanStreamOutput out, DateExtract function) throws IOException {\n        function.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d function.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static DateFormat readDateFormat(PlanStreamInput in) throws IOException {\n        return new DateFormat(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class), in.configuration());\n    }\n\n    static void writeDateFormat(PlanStreamOutput out, DateFormat dateFormat) throws IOException {\n        dateFormat.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d dateFormat.children();\n        assert fields.size() \u003d\u003d 1 || fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 2 ? o -\u003e out.writeExpression(fields.get(1)) : null);\n    }\n\n    static DateParse readDateTimeParse(PlanStreamInput in) throws IOException {\n        return new DateParse(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeDateTimeParse(PlanStreamOutput out, DateParse function) throws IOException {\n        function.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d function.children();\n        assert fields.size() \u003d\u003d 1 || fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 2 ? o -\u003e out.writeExpression(fields.get(1)) : null);\n    }\n\n    static DateTrunc readDateTrunc(PlanStreamInput in) throws IOException {\n        return new DateTrunc(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeDateTrunc(PlanStreamOutput out, DateTrunc dateTrunc) throws IOException {\n        dateTrunc.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d dateTrunc.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static SpatialIntersects readIntersects(PlanStreamInput in) throws IOException {\n        return new SpatialIntersects(Source.EMPTY, in.readExpression(), in.readExpression());\n    }\n\n    static SpatialDisjoint readDisjoint(PlanStreamInput in) throws IOException {\n        return new SpatialDisjoint(Source.EMPTY, in.readExpression(), in.readExpression());\n    }\n\n    static SpatialContains readContains(PlanStreamInput in) throws IOException {\n        return new SpatialContains(Source.EMPTY, in.readExpression(), in.readExpression());\n    }\n\n    static SpatialWithin readWithin(PlanStreamInput in) throws IOException {\n        return new SpatialWithin(Source.EMPTY, in.readExpression(), in.readExpression());\n    }\n\n    static void writeSpatialRelatesFunction(PlanStreamOutput out, SpatialRelatesFunction spatialRelatesFunction) throws IOException {\n        out.writeExpression(spatialRelatesFunction.left());\n        out.writeExpression(spatialRelatesFunction.right());\n    }\n\n    static Now readNow(PlanStreamInput in) throws IOException {\n        return new Now(Source.readFrom(in), in.configuration());\n    }\n\n    static void writeNow(PlanStreamOutput out, Now function) throws IOException {\n        Source.EMPTY.writeTo(out);\n    }\n\n    static Round readRound(PlanStreamInput in) throws IOException {\n        return new Round(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeRound(PlanStreamOutput out, Round round) throws IOException {\n        round.source().writeTo(out);\n        out.writeExpression(round.field());\n        out.writeOptionalExpression(round.decimals());\n    }\n\n    static Pow readPow(PlanStreamInput in) throws IOException {\n        return new Pow(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writePow(PlanStreamOutput out, Pow pow) throws IOException {\n        pow.source().writeTo(out);\n        out.writeExpression(pow.base());\n        out.writeExpression(pow.exponent());\n    }\n\n    static Percentile readPercentile(PlanStreamInput in) throws IOException {\n        return new Percentile(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writePercentile(PlanStreamOutput out, Percentile percentile) throws IOException {\n        List\u003cExpression\u003e fields \u003d percentile.children();\n        assert fields.size() \u003d\u003d 2 : \"percentile() aggregation must have two arguments\";\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static StartsWith readStartsWith(PlanStreamInput in) throws IOException {\n        return new StartsWith(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeStartsWith(PlanStreamOutput out, StartsWith startsWith) throws IOException {\n        startsWith.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d startsWith.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static EndsWith readEndsWith(PlanStreamInput in) throws IOException {\n        return new EndsWith(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeEndsWith(PlanStreamOutput out, EndsWith endsWith) throws IOException {\n        List\u003cExpression\u003e fields \u003d endsWith.children();\n        assert fields.size() \u003d\u003d 2;\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static Substring readSubstring(PlanStreamInput in) throws IOException {\n        return new Substring(Source.readFrom(in), in.readExpression(), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeSubstring(PlanStreamOutput out, Substring substring) throws IOException {\n        substring.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d substring.children();\n        assert fields.size() \u003d\u003d 2 || fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 3 ? o -\u003e out.writeExpression(fields.get(2)) : null);\n    }\n\n    static Locate readLocate(PlanStreamInput in) throws IOException {\n        return new Locate(Source.readFrom(in), in.readExpression(), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeLocate(PlanStreamOutput out, Locate locate) throws IOException {\n        locate.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d locate.children();\n        assert fields.size() \u003d\u003d 2 || fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 3 ? o -\u003e out.writeExpression(fields.get(2)) : null);\n    }\n\n    static Replace readReplace(PlanStreamInput in) throws IOException {\n        return new Replace(Source.EMPTY, in.readExpression(), in.readExpression(), in.readExpression());\n    }\n\n    static void writeReplace(PlanStreamOutput out, Replace replace) throws IOException {\n        List\u003cExpression\u003e fields \u003d replace.children();\n        assert fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeExpression(fields.get(2));\n    }\n\n    static ToLower readToLower(PlanStreamInput in) throws IOException {\n        return new ToLower(Source.EMPTY, in.readExpression(), in.configuration());\n    }\n\n    static void writeToLower(PlanStreamOutput out, ToLower toLower) throws IOException {\n        out.writeExpression(toLower.field());\n    }\n\n    static ToUpper readToUpper(PlanStreamInput in) throws IOException {\n        return new ToUpper(Source.EMPTY, in.readExpression(), in.configuration());\n    }\n\n    static void writeToUpper(PlanStreamOutput out, ToUpper toUpper) throws IOException {\n        out.writeExpression(toUpper.field());\n    }\n\n    static Left readLeft(PlanStreamInput in) throws IOException {\n        return new Left(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeLeft(PlanStreamOutput out, Left left) throws IOException {\n        left.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d left.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static Repeat readRepeat(PlanStreamInput in) throws IOException {\n        return new Repeat(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeRepeat(PlanStreamOutput out, Repeat repeat) throws IOException {\n        repeat.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d repeat.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static Right readRight(PlanStreamInput in) throws IOException {\n        return new Right(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeRight(PlanStreamOutput out, Right right) throws IOException {\n        right.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d right.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n\n    static Split readSplit(PlanStreamInput in) throws IOException {\n        return new Split(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeSplit(PlanStreamOutput out, Split split) throws IOException {\n        split.source().writeTo(out);\n        out.writeExpression(split.left());\n        out.writeExpression(split.right());\n    }\n\n    static CIDRMatch readCIDRMatch(PlanStreamInput in) throws IOException {\n        return new CIDRMatch(\n            Source.readFrom(in),\n            in.readExpression(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression))\n        );\n    }\n\n    static void writeCIDRMatch(PlanStreamOutput out, CIDRMatch cidrMatch) throws IOException {\n        cidrMatch.source().writeTo(out);\n        List\u003cExpression\u003e children \u003d cidrMatch.children();\n        assert children.size() \u003e 1;\n        out.writeExpression(children.get(0));\n        out.writeCollection(children.subList(1, children.size()), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n    }\n\n    // -- ArithmeticOperations\n\n    static final Map\u003cString, TriFunction\u003cSource, Expression, Expression, ArithmeticOperation\u003e\u003e ARITHMETIC_CTRS \u003d Map.ofEntries(\n        entry(name(Add.class), Add::new),\n        entry(name(Sub.class), Sub::new),\n        entry(name(Mul.class), Mul::new),\n        entry(name(Div.class), Div::new),\n        entry(name(Mod.class), Mod::new)\n    );\n\n    static ArithmeticOperation readArithmeticOperation(PlanStreamInput in, String name) throws IOException {\n        var source \u003d Source.readFrom(in);\n        var left \u003d in.readExpression();\n        var right \u003d in.readExpression();\n        return ARITHMETIC_CTRS.get(name).apply(source, left, right);\n    }\n\n    static void writeArithmeticOperation(PlanStreamOutput out, ArithmeticOperation arithmeticOperation) throws IOException {\n        arithmeticOperation.source().writeTo(out);\n        out.writeExpression(arithmeticOperation.left());\n        out.writeExpression(arithmeticOperation.right());\n    }\n\n    // -- Aggregations\n    static final Map\u003cString, BiFunction\u003cSource, Expression, AggregateFunction\u003e\u003e AGG_CTRS \u003d Map.ofEntries(\n        entry(name(Avg.class), Avg::new),\n        entry(name(Count.class), Count::new),\n        entry(name(Sum.class), Sum::new),\n        entry(name(Min.class), Min::new),\n        entry(name(Max.class), Max::new),\n        entry(name(Median.class), Median::new),\n        entry(name(MedianAbsoluteDeviation.class), MedianAbsoluteDeviation::new),\n        entry(name(SpatialCentroid.class), SpatialCentroid::new),\n        entry(name(Values.class), Values::new)\n    );\n\n    static AggregateFunction readAggFunction(PlanStreamInput in, String name) throws IOException {\n        return AGG_CTRS.get(name).apply(Source.readFrom(in), in.readExpression());\n    }\n\n    static void writeAggFunction(PlanStreamOutput out, AggregateFunction aggregateFunction) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(aggregateFunction.field());\n    }\n\n    // -- Multivalue functions\n    static final Map\u003cString, BiFunction\u003cSource, Expression, AbstractMultivalueFunction\u003e\u003e MV_CTRS \u003d Map.ofEntries(\n        entry(name(MvAvg.class), MvAvg::new),\n        entry(name(MvCount.class), MvCount::new),\n        entry(name(MvDedupe.class), MvDedupe::new),\n        entry(name(MvFirst.class), MvFirst::new),\n        entry(name(MvLast.class), MvLast::new),\n        entry(name(MvMax.class), MvMax::new),\n        entry(name(MvMedian.class), MvMedian::new),\n        entry(name(MvMin.class), MvMin::new),\n        entry(name(MvSum.class), MvSum::new)\n    );\n\n    static AbstractMultivalueFunction readMvFunction(PlanStreamInput in, String name) throws IOException {\n        return MV_CTRS.get(name).apply(Source.readFrom(in), in.readExpression());\n    }\n\n    static void writeMvFunction(PlanStreamOutput out, AbstractMultivalueFunction fn) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(fn.field());\n    }\n\n    static MvConcat readMvConcat(PlanStreamInput in) throws IOException {\n        return new MvConcat(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeMvConcat(PlanStreamOutput out, MvConcat fn) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(fn.left());\n        out.writeExpression(fn.right());\n    }\n\n    // -- Expressions (other)\n\n    static Literal readLiteral(PlanStreamInput in) throws IOException {\n        Source source \u003d Source.readFrom(in);\n        Object value \u003d in.readGenericValue();\n        DataType dataType \u003d DataType.readFrom(in);\n        return new Literal(source, mapToLiteralValue(in, dataType, value), dataType);\n    }\n\n    static void writeLiteral(PlanStreamOutput out, Literal literal) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeGenericValue(mapFromLiteralValue(out, literal.dataType(), literal.value()));\n        out.writeString(literal.dataType().typeName());\n    }\n\n    /**\n     * Not all literal values are currently supported in StreamInput/StreamOutput as generic values.\n     * This mapper allows for addition of new and interesting values without (yet) adding to StreamInput/Output.\n     * This makes the most sense during the pre-GA version of ESQL. When we get near GA we might want to push this down.\n     * \u003cp\u003e\n     * For the spatial point type support we need to care about the fact that 8.12.0 uses encoded longs for serializing\n     * while 8.13 uses WKB.\n     */\n    private static Object mapFromLiteralValue(PlanStreamOutput out, DataType dataType, Object value) {\n        if (dataType \u003d\u003d GEO_POINT || dataType \u003d\u003d CARTESIAN_POINT) {\n            // In 8.12.0 we serialized point literals as encoded longs, but now use WKB\n            if (out.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n                if (value instanceof List\u003c?\u003e list) {\n                    return list.stream().map(v -\u003e mapFromLiteralValue(out, dataType, v)).toList();\n                }\n                return wkbAsLong(dataType, (BytesRef) value);\n            }\n        }\n        return value;\n    }\n\n    /**\n     * Not all literal values are currently supported in StreamInput/StreamOutput as generic values.\n     * This mapper allows for addition of new and interesting values without (yet) changing StreamInput/Output.\n     */\n    private static Object mapToLiteralValue(PlanStreamInput in, DataType dataType, Object value) {\n        if (dataType \u003d\u003d GEO_POINT || dataType \u003d\u003d CARTESIAN_POINT) {\n            // In 8.12.0 we serialized point literals as encoded longs, but now use WKB\n            if (in.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n                if (value instanceof List\u003c?\u003e list) {\n                    return list.stream().map(v -\u003e mapToLiteralValue(in, dataType, v)).toList();\n                }\n                return longAsWKB(dataType, (Long) value);\n            }\n        }\n        return value;\n    }\n\n    private static BytesRef longAsWKB(DataType dataType, long encoded) {\n        return dataType \u003d\u003d GEO_POINT ? GEO.longAsWkb(encoded) : CARTESIAN.longAsWkb(encoded);\n    }\n\n    private static long wkbAsLong(DataType dataType, BytesRef wkb) {\n        return dataType \u003d\u003d GEO_POINT ? GEO.wkbAsLong(wkb) : CARTESIAN.wkbAsLong(wkb);\n    }\n\n    static Order readOrder(PlanStreamInput in) throws IOException {\n        return new org.elasticsearch.xpack.esql.expression.Order(\n            Source.readFrom(in),\n            in.readNamed(Expression.class),\n            in.readEnum(Order.OrderDirection.class),\n            in.readEnum(Order.NullsPosition.class)\n        );\n    }\n\n    static void writeOrder(PlanStreamOutput out, Order order) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(order.child());\n        out.writeEnum(order.direction());\n        out.writeEnum(order.nullsPosition());\n    }\n\n    // -- ancillary supporting classes of plan nodes, etc\n\n    static EsQueryExec.FieldSort readFieldSort(PlanStreamInput in) throws IOException {\n        return new EsQueryExec.FieldSort(\n            new FieldAttribute(in),\n            in.readEnum(Order.OrderDirection.class),\n            in.readEnum(Order.NullsPosition.class)\n        );\n    }\n\n    static void writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort) throws IOException {\n        fieldSort.field().writeTo(out);\n        out.writeEnum(fieldSort.direction());\n        out.writeEnum(fieldSort.nulls());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static EsIndex readEsIndex(PlanStreamInput in) throws IOException {\n        return new EsIndex(\n            in.readString(),\n            in.readImmutableMap(StreamInput::readString, i -\u003e i.readNamedWriteable(EsField.class)),\n            (Set\u003cString\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeEsIndex(PlanStreamOutput out, EsIndex esIndex) throws IOException {\n        out.writeString(esIndex.name());\n        out.writeMap(esIndex.mapping(), StreamOutput::writeNamedWriteable);\n        out.writeGenericValue(esIndex.concreteIndices());\n    }\n\n    static Parser readDissectParser(PlanStreamInput in) throws IOException {\n        String pattern \u003d in.readString();\n        String appendSeparator \u003d in.readString();\n        return new Parser(pattern, appendSeparator, new DissectParser(pattern, appendSeparator));\n    }\n\n    static void writeDissectParser(PlanStreamOutput out, Parser dissectParser) throws IOException {\n        out.writeString(dissectParser.pattern());\n        out.writeString(dissectParser.appendSeparator());\n    }\n\n    static Log readLog(PlanStreamInput in) throws IOException {\n        return new Log(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeLog(PlanStreamOutput out, Log log) throws IOException {\n        log.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d log.children();\n        assert fields.size() \u003d\u003d 1 || fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 2 ? o -\u003e out.writeExpression(fields.get(1)) : null);\n    }\n\n    static MvSort readMvSort(PlanStreamInput in) throws IOException {\n        return new MvSort(Source.readFrom(in), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeMvSort(PlanStreamOutput out, MvSort mvSort) throws IOException {\n        mvSort.source().writeTo(out);\n        List\u003cExpression\u003e fields \u003d mvSort.children();\n        assert fields.size() \u003d\u003d 1 || fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 2 ? o -\u003e out.writeExpression(fields.get(1)) : null);\n    }\n\n    static MvSlice readMvSlice(PlanStreamInput in) throws IOException {\n        return new MvSlice(Source.readFrom(in), in.readExpression(), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeMvSlice(PlanStreamOutput out, MvSlice fn) throws IOException {\n        Source.EMPTY.writeTo(out);\n        List\u003cExpression\u003e fields \u003d fn.children();\n        assert fields.size() \u003d\u003d 2 || fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 3 ? o -\u003e out.writeExpression(fields.get(2)) : null);\n    }\n\n    static MvZip readMvZip(PlanStreamInput in) throws IOException {\n        return new MvZip(Source.readFrom(in), in.readExpression(), in.readExpression(), in.readOptionalNamed(Expression.class));\n    }\n\n    static void writeMvZip(PlanStreamOutput out, MvZip fn) throws IOException {\n        Source.EMPTY.writeTo(out);\n        List\u003cExpression\u003e fields \u003d fn.children();\n        assert fields.size() \u003d\u003d 2 || fields.size() \u003d\u003d 3;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n        out.writeOptionalWriteable(fields.size() \u003d\u003d 3 ? o -\u003e out.writeExpression(fields.get(2)) : null);\n    }\n\n    static MvAppend readMvAppend(PlanStreamInput in) throws IOException {\n        return new MvAppend(Source.readFrom(in), in.readExpression(), in.readExpression());\n    }\n\n    static void writeMvAppend(PlanStreamOutput out, MvAppend fn) throws IOException {\n        Source.EMPTY.writeTo(out);\n        List\u003cExpression\u003e fields \u003d fn.children();\n        assert fields.size() \u003d\u003d 2;\n        out.writeExpression(fields.get(0));\n        out.writeExpression(fields.get(1));\n    }\n}","methodCount":177},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":218,"lineEnd":382,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanNamedTypesTests","description":"move method namedTypeEntries to PsiClass:PlanNamedTypesTests\nRationale: The namedTypeEntries() method is primarily concerned with defining and managing the registry of plan types and their serialization methods, which is directly related to testing the various plan entries. Moving this method to PlanNamedTypesTests aligns with the Single Responsibility Principle, as it consolidates related functionality in a dedicated test class. This enhances cohesion and makes it easier to manage the test cases associated with plan type entries. However, it may introduce dependencies between the method and test cases that could complicate the testing environment.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":218,"lineEnd":382,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlannerUtils","description":"move method namedTypeEntries to PsiClass:PlannerUtils\nRationale: The method is focused on defining and managing plan type entries, which fits into the broader context of planning utility operations. Moving it to PlannerUtils would centralize the logic related to planning, enhancing the organization of related functionalities. This aligns with the Open/Closed Principle, allowing for future extensions of planning-related utilities without modifying existing code. However, it may lead to a bloated utility class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":218,"lineEnd":382,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class InternalQlScriptUtils","description":"move method namedTypeEntries to PsiClass:InternalQlScriptUtils\nRationale: The method involves serialization and deserialization of plan entries, which can be viewed as part of the internal scripting utilities that handle various data manipulations. Moving it to InternalQlScriptUtils would encapsulate related functionalities, promoting better organization and adherence to the Single Responsibility Principle. However, this could lead to confusion if the utility class becomes too focused on serialization tasks rather than its original purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":820,"lineEnd":827,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class PlanStreamInput","description":"move method writeEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The writeEsSourceOptions() method is responsible for writing options to a stream, which aligns closely with the responsibilities of PlanStreamInput, as it handles reading and writing data streams. This move adheres to the Single Responsibility Principle by ensuring that the method is located within a class that directly manages stream operations, improving cohesion. However, care must be taken to ensure that the method\u0027s dependencies are properly managed in the new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":820,"lineEnd":827,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class TestUtils","description":"move method writeEsSourceOptions to PsiClass:TestUtils\nRationale: The method seems to be used for preparing or configuring outputs, which is a common utility function in testing scenarios. Moving this method to TestUtils would enhance its reusability in various test cases. This aligns with the Open/Closed Principle, allowing the utility class to be extended with additional functionality without modifying existing code. However, it may lead to an overcrowded utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":820,"lineEnd":827,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class EsqlTestUtils","description":"move method writeEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils is focused on providing utility methods for testing Esql-related functionality. Since writeEsSourceOptions() appears to be related to the configuration of Esql sources, moving it here would improve cohesion and maintainability. This aligns with the Single Responsibility Principle, as it groups related functionalities. The drawback could be that it might not be directly related to Esql operations, leading to potential confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":811,"lineEnd":818,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class PlanStreamInput","description":"move method readEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The readEsSourceOptions() method directly interacts with the PlanStreamInput class for reading source options. Moving it here enhances cohesion, as it deals with the input stream\u0027s properties. This aligns with the Single Responsibility Principle, as PlanStreamInput is responsible for managing input operations. However, it may increase the complexity of PlanStreamInput if too many methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":811,"lineEnd":818,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class EsqlTestUtils","description":"move method readEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils provides utility methods for Esql-related operations, and since readEsSourceOptions seems to deal with options relevant to Esql, this class is a good candidate. It adheres to the Open/Closed Principle by allowing for extension without modifying existing code. However, it may dilute the purpose of EsqlTestUtils if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":811,"lineEnd":818,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class InternalQlScriptUtils","description":"move method readEsSourceOptions to PsiClass:InternalQlScriptUtils\nRationale: This class contains various utility methods for query language scripts, potentially making it a suitable target for readEsSourceOptions, which may relate to query options. This move would improve modularity and maintainability, adhering to the Interface Segregation Principle. However, the method\u0027s context needs to be closely aligned with the operations of InternalQlScriptUtils to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"name","method_signature":"public static name(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"readAggregateExec","method_signature":"static readAggregateExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},{"method_name":"readDissectExec","method_signature":"static readDissectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"readEsSourceExec","method_signature":"static readEsSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},{"method_name":"readIndexMode","method_signature":"static readIndexMode(StreamInput in)","target_class":"","rationale":""},{"method_name":"writeIndexMode","method_signature":"static writeIndexMode(StreamOutput out, IndexMode indexMode)","target_class":"","rationale":""},{"method_name":"readEvalExec","method_signature":"static readEvalExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEvalExec","method_signature":"static writeEvalExec(PlanStreamOutput out, EvalExec evalExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrichExec","method_signature":"static writeEnrichExec(PlanStreamOutput out, EnrichExec enrich)","target_class":"","rationale":""},{"method_name":"readExchangeExec","method_signature":"static readExchangeExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},{"method_name":"readExchangeSinkExec","method_signature":"static readExchangeSinkExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},{"method_name":"readExchangeSourceExec","method_signature":"static readExchangeSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},{"method_name":"readFieldExtractExec","method_signature":"static readFieldExtractExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldExtractExec","method_signature":"static writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec)","target_class":"","rationale":""},{"method_name":"readFilterExec","method_signature":"static readFilterExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilterExec","method_signature":"static writeFilterExec(PlanStreamOutput out, FilterExec filterExec)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFragmentExec","method_signature":"static writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec)","target_class":"","rationale":""},{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},{"method_name":"readLimitExec","method_signature":"static readLimitExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimitExec","method_signature":"static writeLimitExec(PlanStreamOutput out, LimitExec limitExec)","target_class":"","rationale":""},{"method_name":"readMvExpandExec","method_signature":"static readMvExpandExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},{"method_name":"readOrderExec","method_signature":"static readOrderExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderExec","method_signature":"static writeOrderExec(PlanStreamOutput out, OrderExec orderExec)","target_class":"","rationale":""},{"method_name":"readProjectExec","method_signature":"static readProjectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProjectExec","method_signature":"static writeProjectExec(PlanStreamOutput out, ProjectExec projectExec)","target_class":"","rationale":""},{"method_name":"readRowExec","method_signature":"static readRowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readShowExec","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readShowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeShowExec","method_signature":"static writeShowExec(PlanStreamOutput out, ShowExec showExec)","target_class":"","rationale":""},{"method_name":"readTopNExec","method_signature":"static readTopNExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},{"method_name":"readAggregate","method_signature":"static readAggregate(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAggregate","method_signature":"static writeAggregate(PlanStreamOutput out, Aggregate aggregate)","target_class":"","rationale":""},{"method_name":"readDissect","method_signature":"static readDissect(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsRelation","method_signature":"static writeEsRelation(PlanStreamOutput out, EsRelation relation)","target_class":"","rationale":""},{"method_name":"supportingEsSourceOptions","method_signature":"private static supportingEsSourceOptions(TransportVersion version)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEval","method_signature":"static readEval(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEval","method_signature":"static writeEval(PlanStreamOutput out, Eval eval)","target_class":"","rationale":""},{"method_name":"readEnrich","method_signature":"static readEnrich(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrich","method_signature":"static writeEnrich(PlanStreamOutput out, Enrich enrich)","target_class":"","rationale":""},{"method_name":"readEsqlProject","method_signature":"static readEsqlProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsqlProject","method_signature":"static writeEsqlProject(PlanStreamOutput out, EsqlProject project)","target_class":"","rationale":""},{"method_name":"readFilter","method_signature":"static readFilter(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilter","method_signature":"static writeFilter(PlanStreamOutput out, Filter filter)","target_class":"","rationale":""},{"method_name":"readGrok","method_signature":"static readGrok(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrok","method_signature":"static writeGrok(PlanStreamOutput out, Grok grok)","target_class":"","rationale":""},{"method_name":"readLimit","method_signature":"static readLimit(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimit","method_signature":"static writeLimit(PlanStreamOutput out, Limit limit)","target_class":"","rationale":""},{"method_name":"readMvExpand","method_signature":"static readMvExpand(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpand","method_signature":"static writeMvExpand(PlanStreamOutput out, MvExpand mvExpand)","target_class":"","rationale":""},{"method_name":"readOrderBy","method_signature":"static readOrderBy(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderBy","method_signature":"static writeOrderBy(PlanStreamOutput out, OrderBy order)","target_class":"","rationale":""},{"method_name":"readProject","method_signature":"static readProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProject","method_signature":"static writeProject(PlanStreamOutput out, Project project)","target_class":"","rationale":""},{"method_name":"readTopN","method_signature":"static readTopN(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopN","method_signature":"static writeTopN(PlanStreamOutput out, TopN topN)","target_class":"","rationale":""},{"method_name":"readBinComparison","method_signature":"public static readBinComparison(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeBinComparison","method_signature":"public static writeBinComparison(PlanStreamOutput out, EsqlBinaryComparison binaryComparison)","target_class":"","rationale":""},{"method_name":"readInsensitiveEquals","method_signature":"static readInsensitiveEquals(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeInsensitiveEquals","method_signature":"static writeInsensitiveEquals(PlanStreamOutput out, InsensitiveEquals eq)","target_class":"","rationale":""},{"method_name":"readInComparison","method_signature":"static readInComparison(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeInComparison","method_signature":"static writeInComparison(PlanStreamOutput out, In in)","target_class":"","rationale":""},{"method_name":"readWildcardLike","method_signature":"static readWildcardLike(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeWildcardLike","method_signature":"static writeWildcardLike(PlanStreamOutput out, WildcardLike like)","target_class":"","rationale":""},{"method_name":"readRLike","method_signature":"static readRLike(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeRLike","method_signature":"static writeRLike(PlanStreamOutput out, RLike like)","target_class":"","rationale":""},{"method_name":"readBinaryLogic","method_signature":"static readBinaryLogic(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeBinaryLogic","method_signature":"static writeBinaryLogic(PlanStreamOutput out, BinaryLogic binaryLogic)","target_class":"","rationale":""},{"method_name":"readNoArgScalar","method_signature":"static readNoArgScalar(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeNoArgScalar","method_signature":"static writeNoArgScalar(PlanStreamOutput out, ScalarFunction function)","target_class":"","rationale":""},{"method_name":"readQLUnaryScalar","method_signature":"static readQLUnaryScalar(\n        PlanStreamInput in,\n        String name\n    )","target_class":"","rationale":""},{"method_name":"writeQLUnaryScalar","method_signature":"static writeQLUnaryScalar(\n        PlanStreamOutput out,\n        org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction function\n    )","target_class":"","rationale":""},{"method_name":"readAtan2","method_signature":"static readAtan2(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAtan2","method_signature":"static writeAtan2(PlanStreamOutput out, Atan2 atan2)","target_class":"","rationale":""},{"method_name":"readBucket","method_signature":"static readBucket(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeBucket","method_signature":"static writeBucket(PlanStreamOutput out, Bucket bucket)","target_class":"","rationale":""},{"method_name":"readVarag","method_signature":"static readVarag(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeVararg","method_signature":"static writeVararg(PlanStreamOutput out, ScalarFunction vararg)","target_class":"","rationale":""},{"method_name":"readCountDistinct","method_signature":"static readCountDistinct(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeCountDistinct","method_signature":"static writeCountDistinct(PlanStreamOutput out, CountDistinct countDistinct)","target_class":"","rationale":""},{"method_name":"readDateDiff","method_signature":"static readDateDiff(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDateDiff","method_signature":"static writeDateDiff(PlanStreamOutput out, DateDiff function)","target_class":"","rationale":""},{"method_name":"readDateExtract","method_signature":"static readDateExtract(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDateExtract","method_signature":"static writeDateExtract(PlanStreamOutput out, DateExtract function)","target_class":"","rationale":""},{"method_name":"readDateFormat","method_signature":"static readDateFormat(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDateFormat","method_signature":"static writeDateFormat(PlanStreamOutput out, DateFormat dateFormat)","target_class":"","rationale":""},{"method_name":"readDateTimeParse","method_signature":"static readDateTimeParse(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDateTimeParse","method_signature":"static writeDateTimeParse(PlanStreamOutput out, DateParse function)","target_class":"","rationale":""},{"method_name":"readDateTrunc","method_signature":"static readDateTrunc(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDateTrunc","method_signature":"static writeDateTrunc(PlanStreamOutput out, DateTrunc dateTrunc)","target_class":"","rationale":""},{"method_name":"readIntersects","method_signature":"static readIntersects(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readDisjoint","method_signature":"static readDisjoint(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readContains","method_signature":"static readContains(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readWithin","method_signature":"static readWithin(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeSpatialRelatesFunction","method_signature":"static writeSpatialRelatesFunction(PlanStreamOutput out, SpatialRelatesFunction spatialRelatesFunction)","target_class":"","rationale":""},{"method_name":"readNow","method_signature":"static readNow(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeNow","method_signature":"static writeNow(PlanStreamOutput out, Now function)","target_class":"","rationale":""},{"method_name":"readRound","method_signature":"static readRound(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRound","method_signature":"static writeRound(PlanStreamOutput out, Round round)","target_class":"","rationale":""},{"method_name":"readPow","method_signature":"static readPow(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writePow","method_signature":"static writePow(PlanStreamOutput out, Pow pow)","target_class":"","rationale":""},{"method_name":"readPercentile","method_signature":"static readPercentile(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writePercentile","method_signature":"static writePercentile(PlanStreamOutput out, Percentile percentile)","target_class":"","rationale":""},{"method_name":"readStartsWith","method_signature":"static readStartsWith(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeStartsWith","method_signature":"static writeStartsWith(PlanStreamOutput out, StartsWith startsWith)","target_class":"","rationale":""},{"method_name":"readEndsWith","method_signature":"static readEndsWith(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEndsWith","method_signature":"static writeEndsWith(PlanStreamOutput out, EndsWith endsWith)","target_class":"","rationale":""},{"method_name":"readSubstring","method_signature":"static readSubstring(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeSubstring","method_signature":"static writeSubstring(PlanStreamOutput out, Substring substring)","target_class":"","rationale":""},{"method_name":"readLocate","method_signature":"static readLocate(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLocate","method_signature":"static writeLocate(PlanStreamOutput out, Locate locate)","target_class":"","rationale":""},{"method_name":"readReplace","method_signature":"static readReplace(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeReplace","method_signature":"static writeReplace(PlanStreamOutput out, Replace replace)","target_class":"","rationale":""},{"method_name":"readToLower","method_signature":"static readToLower(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeToLower","method_signature":"static writeToLower(PlanStreamOutput out, ToLower toLower)","target_class":"","rationale":""},{"method_name":"readToUpper","method_signature":"static readToUpper(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeToUpper","method_signature":"static writeToUpper(PlanStreamOutput out, ToUpper toUpper)","target_class":"","rationale":""},{"method_name":"readLeft","method_signature":"static readLeft(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLeft","method_signature":"static writeLeft(PlanStreamOutput out, Left left)","target_class":"","rationale":""},{"method_name":"readRepeat","method_signature":"static readRepeat(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRepeat","method_signature":"static writeRepeat(PlanStreamOutput out, Repeat repeat)","target_class":"","rationale":""},{"method_name":"readRight","method_signature":"static readRight(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRight","method_signature":"static writeRight(PlanStreamOutput out, Right right)","target_class":"","rationale":""},{"method_name":"readSplit","method_signature":"static readSplit(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeSplit","method_signature":"static writeSplit(PlanStreamOutput out, Split split)","target_class":"","rationale":""},{"method_name":"readCIDRMatch","method_signature":"static readCIDRMatch(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeCIDRMatch","method_signature":"static writeCIDRMatch(PlanStreamOutput out, CIDRMatch cidrMatch)","target_class":"","rationale":""},{"method_name":"readArithmeticOperation","method_signature":"static readArithmeticOperation(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeArithmeticOperation","method_signature":"static writeArithmeticOperation(PlanStreamOutput out, ArithmeticOperation arithmeticOperation)","target_class":"","rationale":""},{"method_name":"readAggFunction","method_signature":"static readAggFunction(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeAggFunction","method_signature":"static writeAggFunction(PlanStreamOutput out, AggregateFunction aggregateFunction)","target_class":"","rationale":""},{"method_name":"readMvFunction","method_signature":"static readMvFunction(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeMvFunction","method_signature":"static writeMvFunction(PlanStreamOutput out, AbstractMultivalueFunction fn)","target_class":"","rationale":""},{"method_name":"readMvConcat","method_signature":"static readMvConcat(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvConcat","method_signature":"static writeMvConcat(PlanStreamOutput out, MvConcat fn)","target_class":"","rationale":""},{"method_name":"readLiteral","method_signature":"static readLiteral(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLiteral","method_signature":"static writeLiteral(PlanStreamOutput out, Literal literal)","target_class":"","rationale":""},{"method_name":"mapFromLiteralValue","method_signature":"private static mapFromLiteralValue(PlanStreamOutput out, DataType dataType, Object value)","target_class":"","rationale":""},{"method_name":"mapToLiteralValue","method_signature":"private static mapToLiteralValue(PlanStreamInput in, DataType dataType, Object value)","target_class":"","rationale":""},{"method_name":"longAsWKB","method_signature":"private static longAsWKB(DataType dataType, long encoded)","target_class":"","rationale":""},{"method_name":"wkbAsLong","method_signature":"private static wkbAsLong(DataType dataType, BytesRef wkb)","target_class":"","rationale":""},{"method_name":"readOrder","method_signature":"static readOrder(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrder","method_signature":"static writeOrder(PlanStreamOutput out, Order order)","target_class":"","rationale":""},{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""},{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectParser","method_signature":"static writeDissectParser(PlanStreamOutput out, Parser dissectParser)","target_class":"","rationale":""},{"method_name":"readLog","method_signature":"static readLog(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLog","method_signature":"static writeLog(PlanStreamOutput out, Log log)","target_class":"","rationale":""},{"method_name":"readMvSort","method_signature":"static readMvSort(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvSort","method_signature":"static writeMvSort(PlanStreamOutput out, MvSort mvSort)","target_class":"","rationale":""},{"method_name":"readMvSlice","method_signature":"static readMvSlice(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvSlice","method_signature":"static writeMvSlice(PlanStreamOutput out, MvSlice fn)","target_class":"","rationale":""},{"method_name":"readMvZip","method_signature":"static readMvZip(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvZip","method_signature":"static writeMvZip(PlanStreamOutput out, MvZip fn)","target_class":"","rationale":""},{"method_name":"readMvAppend","method_signature":"static readMvAppend(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvAppend","method_signature":"static writeMvAppend(PlanStreamOutput out, MvAppend fn)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readBinComparison","method_signature":"public static readBinComparison(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"writeCIDRMatch","method_signature":"static writeCIDRMatch(PlanStreamOutput out, CIDRMatch cidrMatch)","target_class":"","rationale":""},{"method_name":"readArithmeticOperation","method_signature":"static readArithmeticOperation(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"readBinaryLogic","method_signature":"static readBinaryLogic(PlanStreamInput in, String name)","target_class":"","rationale":""},{"method_name":"writeVararg","method_signature":"static writeVararg(PlanStreamOutput out, ScalarFunction vararg)","target_class":"","rationale":""},{"method_name":"writeSubstring","method_signature":"static writeSubstring(PlanStreamOutput out, Substring substring)","target_class":"","rationale":""},{"method_name":"writeLocate","method_signature":"static writeLocate(PlanStreamOutput out, Locate locate)","target_class":"","rationale":""},{"method_name":"writeDateFormat","method_signature":"static writeDateFormat(PlanStreamOutput out, DateFormat dateFormat)","target_class":"","rationale":""},{"method_name":"writeLog","method_signature":"static writeLog(PlanStreamOutput out, Log log)","target_class":"","rationale":""},{"method_name":"writeMvSort","method_signature":"static writeMvSort(PlanStreamOutput out, MvSort mvSort)","target_class":"","rationale":""},{"method_name":"writeDateTimeParse","method_signature":"static writeDateTimeParse(PlanStreamOutput out, DateParse function)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static namedTypeEntries()":{"first":{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},"second":0.06546334191452194},"private static writeEsSourceOptions(PlanStreamOutput out)":{"first":{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},"second":0.22428561074808628},"private static readEsSourceOptions(PlanStreamInput in)":{"first":{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},"second":0.22435213683789695},"public static readBinComparison(PlanStreamInput in, String name)":{"first":{"method_name":"readBinComparison","method_signature":"public static readBinComparison(PlanStreamInput in, String name)","target_class":"","rationale":""},"second":0.2570045994949508},"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)":{"first":{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},"second":0.26482312928910073},"static writeCIDRMatch(PlanStreamOutput out, CIDRMatch cidrMatch)":{"first":{"method_name":"writeCIDRMatch","method_signature":"static writeCIDRMatch(PlanStreamOutput out, CIDRMatch cidrMatch)","target_class":"","rationale":""},"second":0.28501254270157844},"static readArithmeticOperation(PlanStreamInput in, String name)":{"first":{"method_name":"readArithmeticOperation","method_signature":"static readArithmeticOperation(PlanStreamInput in, String name)","target_class":"","rationale":""},"second":0.3004772097069064},"static readBinaryLogic(PlanStreamInput in, String name)":{"first":{"method_name":"readBinaryLogic","method_signature":"static readBinaryLogic(PlanStreamInput in, String name)","target_class":"","rationale":""},"second":0.30047959040326105},"static writeVararg(PlanStreamOutput out, ScalarFunction vararg)":{"first":{"method_name":"writeVararg","method_signature":"static writeVararg(PlanStreamOutput out, ScalarFunction vararg)","target_class":"","rationale":""},"second":0.3048539075851952},"static writeSubstring(PlanStreamOutput out, Substring substring)":{"first":{"method_name":"writeSubstring","method_signature":"static writeSubstring(PlanStreamOutput out, Substring substring)","target_class":"","rationale":""},"second":0.3050186811202819},"static writeLocate(PlanStreamOutput out, Locate locate)":{"first":{"method_name":"writeLocate","method_signature":"static writeLocate(PlanStreamOutput out, Locate locate)","target_class":"","rationale":""},"second":0.3050186811202819},"static writeDateFormat(PlanStreamOutput out, DateFormat dateFormat)":{"first":{"method_name":"writeDateFormat","method_signature":"static writeDateFormat(PlanStreamOutput out, DateFormat dateFormat)","target_class":"","rationale":""},"second":0.30786545454710795},"static writeLog(PlanStreamOutput out, Log log)":{"first":{"method_name":"writeLog","method_signature":"static writeLog(PlanStreamOutput out, Log log)","target_class":"","rationale":""},"second":0.30786545454710795},"static writeMvSort(PlanStreamOutput out, MvSort mvSort)":{"first":{"method_name":"writeMvSort","method_signature":"static writeMvSort(PlanStreamOutput out, MvSort mvSort)","target_class":"","rationale":""},"second":0.30786545454710795},"static writeDateTimeParse(PlanStreamOutput out, DateParse function)":{"first":{"method_name":"writeDateTimeParse","method_signature":"static writeDateTimeParse(PlanStreamOutput out, DateParse function)","target_class":"","rationale":""},"second":0.30926204958875214}},"llmMethodPriority":{"priority_method_names":["namedTypeEntries","writeEsSourceOptions","readEsSourceOptions","readBinComparison","writeEsQueryExec","writeCIDRMatch","readArithmeticOperation","readBinaryLogic","writeVararg","writeSubstring","writeLocate","writeDateFormat","writeLog","writeMvSort","writeDateTimeParse"],"llm_response_time":4640},"targetClassMap":{"namedTypeEntries":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.06372524103520504},{"class_name":"ExceptionUtils","similarity_score":0.0530541909901383},{"class_name":"Entry","similarity_score":0.062399987370935245},{"class_name":"EsqlTestUtils","similarity_score":0.0915258761334571},{"class_name":"AnalyzerTestUtils","similarity_score":0.06607288796112014},{"class_name":"LoggingUtils","similarity_score":0.04867314882149263},{"class_name":"LuceneComponent2DUtils","similarity_score":0.06920206845485767},{"class_name":"StringContainsRegex","similarity_score":0.10385768107685442},{"class_name":"StringUtils","similarity_score":0.10056156131591049},{"class_name":"SourceUtils","similarity_score":0.04983839844886332},{"class_name":"SpatialRelatesUtils","similarity_score":0.07879742684273822},{"class_name":"CsvTestUtils","similarity_score":0.1109912674791423},{"class_name":"TestUtils","similarity_score":0.10494641054708752},{"class_name":"InternalQlScriptUtils","similarity_score":0.10616065221354391},{"class_name":"SerializationTestUtils","similarity_score":0.06573722754406806},{"class_name":"DateUtils","similarity_score":0.12241544030987983},{"class_name":"NumericUtilsTests","similarity_score":0.0675402561245003},{"class_name":"TransportActionUtils","similarity_score":0.09338323023901268},{"class_name":"ReflectionUtils","similarity_score":0.07677949329400625},{"class_name":"ParserUtils","similarity_score":0.0633945037716948},{"class_name":"PlanNamedTypesTests","similarity_score":0.11959931088902062},{"class_name":"PlanNameRegistry","similarity_score":0.09243063056069098},{"class_name":"PlannerUtils","similarity_score":0.11206751536600211},{"class_name":"PlanStreamInput","similarity_score":0.09278158829090732},{"class_name":"PlanStreamOutput","similarity_score":0.07459126294720264},{"class_name":"ResponseValueUtils","similarity_score":0.10767122098449121},{"class_name":"ResponseXContentUtils","similarity_score":0.08694120701360636},{"class_name":"JwkValidateUtil","similarity_score":0.07539925297850675},{"class_name":"JwkValidateUtilTests","similarity_score":0.08778255416663902}],"target_classes_sorted_by_llm":["PlanNamedTypesTests","PlannerUtils","InternalQlScriptUtils","ResponseValueUtils","TestUtils","CsvTestUtils","StringUtils","DateUtils","TransportActionUtils","StringContainsRegex"],"llm_response_time":8292,"similarity_computation_time":18,"similarity_metric":"voyage"},"writeEsSourceOptions":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"LoggingUtils","similarity_score":0.17078251276599332},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"CsvTestUtils","similarity_score":0.25552033264319435},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.2400396792595916},{"class_name":"PlanNamedTypesTests","similarity_score":0.2680587808989956},{"class_name":"PlanNameRegistry","similarity_score":0.2304929349447907},{"class_name":"PlannerUtils","similarity_score":0.23790522644345063},{"class_name":"PlanStreamInput","similarity_score":0.2596260935667953},{"class_name":"PlanStreamOutput","similarity_score":0.2397869506903664},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"EsqlTestUtils","similarity_score":0.2566640053653935},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"SourceUtils","similarity_score":0.1561349078609147},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"TestUtils","similarity_score":0.311307259615},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"TransportActionUtils","similarity_score":0.22371713913234212},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"ResponseValueUtils","similarity_score":0.1623887831995765},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"FunctionTestUtils","similarity_score":0.22494640587370257},{"class_name":"InternalQlScriptUtils","similarity_score":0.3393699900875004},{"class_name":"JwkValidateUtil","similarity_score":0.18692158795056743},{"class_name":"JwkValidateUtilTests","similarity_score":0.3223014929097608}],"target_classes_sorted_by_llm":["PlanStreamInput","TestUtils","EsqlTestUtils","InternalQlScriptUtils","StringUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","JwkValidateUtilTests"],"llm_response_time":9627,"similarity_computation_time":7,"similarity_metric":"voyage"},"readEsSourceOptions":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.22494640587370257},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"EsqlTestUtils","similarity_score":0.2566640053653935},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"CsvTestUtils","similarity_score":0.25552033264319435},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.2454951265154914},{"class_name":"LoggingUtils","similarity_score":0.17078251276599332},{"class_name":"PlanNamedTypesTests","similarity_score":0.2671376167034664},{"class_name":"PlanNameRegistry","similarity_score":0.23630368120390308},{"class_name":"PlannerUtils","similarity_score":0.23790522644345063},{"class_name":"PlanStreamInput","similarity_score":0.2596260935667953},{"class_name":"PlanStreamOutput","similarity_score":0.2397869506903664},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"SourceUtils","similarity_score":0.16728740127955144},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"InternalQlScriptUtils","similarity_score":0.3393699900875004},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"ResponseValueUtils","similarity_score":0.1623887831995765},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"TransportActionUtils","similarity_score":0.22371713913234212},{"class_name":"TestUtils","similarity_score":0.311307259615},{"class_name":"JwkValidateUtil","similarity_score":0.18692158795056743},{"class_name":"JwkValidateUtilTests","similarity_score":0.3223014929097608}],"target_classes_sorted_by_llm":["PlanStreamInput","EsqlTestUtils","InternalQlScriptUtils","StringUtils","TestUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","JwkValidateUtilTests"],"llm_response_time":6501,"similarity_computation_time":13,"similarity_metric":"voyage"}}}
{"id":"875a8a35-6764-4215-b746-fba4150b373c","methodCount":22,"hostFunctionTelemetryData":{"hostFunctionSize":167,"lineStart":39,"lineEnd":205,"bodyLineStart":39,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/type/EsqlDataTypes.java","sourceCode":"public final class EsqlDataTypes {\n\n    private static final Map\u003cString, DataType\u003e NAME_TO_TYPE \u003d DataType.types()\n        .stream()\n        .collect(toUnmodifiableMap(DataType::typeName, t -\u003e t));\n\n    private static final Map\u003cString, DataType\u003e ES_TO_TYPE;\n\n    static {\n        Map\u003cString, DataType\u003e map \u003d DataType.types().stream().filter(e -\u003e e.esType() !\u003d null).collect(toMap(DataType::esType, t -\u003e t));\n        // ES calls this \u0027point\u0027, but ESQL calls it \u0027cartesian_point\u0027\n        map.put(\"point\", DataType.CARTESIAN_POINT);\n        map.put(\"shape\", DataType.CARTESIAN_SHAPE);\n        ES_TO_TYPE \u003d Collections.unmodifiableMap(map);\n    }\n\n    private static final Map\u003cString, DataType\u003e NAME_OR_ALIAS_TO_TYPE;\n    static {\n        Map\u003cString, DataType\u003e map \u003d DataType.types().stream().collect(toMap(DataType::typeName, Function.identity()));\n        map.put(\"bool\", BOOLEAN);\n        map.put(\"int\", INTEGER);\n        map.put(\"string\", KEYWORD);\n        NAME_OR_ALIAS_TO_TYPE \u003d Collections.unmodifiableMap(map);\n    }\n\n    private EsqlDataTypes() {}\n\n    public static DataType fromTypeName(String name) {\n        return NAME_TO_TYPE.get(name.toLowerCase(Locale.ROOT));\n    }\n\n    public static DataType fromName(String name) {\n        DataType type \u003d ES_TO_TYPE.get(name);\n        return type !\u003d null ? type : UNSUPPORTED;\n    }\n\n    public static DataType fromNameOrAlias(String typeName) {\n        DataType type \u003d NAME_OR_ALIAS_TO_TYPE.get(typeName.toLowerCase(Locale.ROOT));\n        return type !\u003d null ? type : UNSUPPORTED;\n    }\n\n    public static DataType fromJava(Object value) {\n        if (value \u003d\u003d null) {\n            return NULL;\n        }\n        if (value instanceof Boolean) {\n            return BOOLEAN;\n        }\n        if (value instanceof Integer) {\n            return INTEGER;\n        }\n        if (value instanceof Long) {\n            return LONG;\n        }\n        if (value instanceof Double) {\n            return DOUBLE;\n        }\n        if (value instanceof Float) {\n            return FLOAT;\n        }\n        if (value instanceof String || value instanceof Character || value instanceof BytesRef) {\n            return KEYWORD;\n        }\n\n        return null;\n    }\n\n    public static boolean isUnsupported(DataType type) {\n        return DataType.isUnsupported(type);\n    }\n\n    public static String outputType(DataType type) {\n        if (type !\u003d null \u0026\u0026 type.esType() !\u003d null) {\n            return type.esType();\n        }\n        return \"unsupported\";\n    }\n\n    public static boolean isString(DataType t) {\n        return t \u003d\u003d KEYWORD || t \u003d\u003d TEXT;\n    }\n\n    public static boolean isPrimitive(DataType t) {\n        return t !\u003d OBJECT \u0026\u0026 t !\u003d NESTED;\n    }\n\n    public static boolean isDateTimeOrTemporal(DataType t) {\n        return DataType.isDateTime(t) || isTemporalAmount(t);\n    }\n\n    public static boolean isTemporalAmount(DataType t) {\n        return t \u003d\u003d DataType.DATE_PERIOD || t \u003d\u003d DataType.TIME_DURATION;\n    }\n\n    public static boolean isNullOrTemporalAmount(DataType t) {\n        return isTemporalAmount(t) || isNull(t);\n    }\n\n    public static boolean isNullOrDatePeriod(DataType t) {\n        return t \u003d\u003d DataType.DATE_PERIOD || isNull(t);\n    }\n\n    public static boolean isNullOrTimeDuration(DataType t) {\n        return t \u003d\u003d DataType.TIME_DURATION || isNull(t);\n    }\n\n    public static boolean isSpatial(DataType t) {\n        return t \u003d\u003d DataType.GEO_POINT || t \u003d\u003d DataType.CARTESIAN_POINT || t \u003d\u003d DataType.GEO_SHAPE || t \u003d\u003d DataType.CARTESIAN_SHAPE;\n    }\n\n    public static boolean isSpatialGeo(DataType t) {\n        return t \u003d\u003d DataType.GEO_POINT || t \u003d\u003d DataType.GEO_SHAPE;\n    }\n\n    public static boolean isSpatialPoint(DataType t) {\n        return t \u003d\u003d DataType.GEO_POINT || t \u003d\u003d DataType.CARTESIAN_POINT;\n    }\n\n    /**\n     * Supported types that can be contained in a block.\n     */\n    public static boolean isRepresentable(DataType t) {\n        return t !\u003d OBJECT\n            \u0026\u0026 t !\u003d NESTED\n            \u0026\u0026 t !\u003d UNSUPPORTED\n            \u0026\u0026 t !\u003d DATE_PERIOD\n            \u0026\u0026 t !\u003d TIME_DURATION\n            \u0026\u0026 t !\u003d BYTE\n            \u0026\u0026 t !\u003d SHORT\n            \u0026\u0026 t !\u003d FLOAT\n            \u0026\u0026 t !\u003d SCALED_FLOAT\n            \u0026\u0026 t !\u003d SOURCE\n            \u0026\u0026 t !\u003d HALF_FLOAT\n            \u0026\u0026 isCounterType(t) \u003d\u003d false;\n    }\n\n    public static boolean areCompatible(DataType left, DataType right) {\n        if (left \u003d\u003d right) {\n            return true;\n        } else {\n            return (left \u003d\u003d NULL || right \u003d\u003d NULL) || (isString(left) \u0026\u0026 isString(right)) || (left.isNumeric() \u0026\u0026 right.isNumeric());\n        }\n    }\n\n    public static DataType widenSmallNumericTypes(DataType type) {\n        if (type \u003d\u003d BYTE || type \u003d\u003d SHORT) {\n            return INTEGER;\n        }\n        if (type \u003d\u003d HALF_FLOAT || type \u003d\u003d FLOAT || type \u003d\u003d SCALED_FLOAT) {\n            return DOUBLE;\n        }\n        return type;\n    }\n\n    public static DataType getCounterType(String typeName) {\n        final DataType rootType \u003d widenSmallNumericTypes(fromName(typeName));\n        if (rootType \u003d\u003d UNSUPPORTED) {\n            return rootType;\n        }\n        assert rootType \u003d\u003d LONG || rootType \u003d\u003d INTEGER || rootType \u003d\u003d DOUBLE : rootType;\n        return fromTypeName(\"counter_\" + rootType.typeName());\n    }\n\n    public static boolean isCounterType(DataType dt) {\n        return dt \u003d\u003d DataType.COUNTER_LONG || dt \u003d\u003d DataType.COUNTER_INTEGER || dt \u003d\u003d DataType.COUNTER_DOUBLE;\n    }\n}","methodCount":22},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":156,"lineEnd":172,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isRepresentable to class EsqlDataTypeConverter","description":"move method isRepresentable to PsiClass:EsqlDataTypeConverter\nRationale: The isRepresentable() method checks whether a DataType can be represented, which is closely related to data type conversion and validation. Moving it to EsqlDataTypeConverter aligns with the Single Responsibility Principle, as this class deals with data type conversions. This enhances cohesion within the class by grouping related functionalities together. However, ensure that this move does not introduce circular dependencies with other utility classes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":156,"lineEnd":172,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isRepresentable to class ParserUtils","description":"move method isRepresentable to PsiClass:ParserUtils\nRationale: ParserUtils is likely involved in parsing and validating data types, making it a suitable candidate for isRepresentable(). This move would improve cohesion as it centralizes type validation logic within a class that handles parsing. It adheres to the Open/Closed Principle by allowing for future extensions of data type handling without modifying the original class. However, consider the potential increase in complexity if ParserUtils becomes overloaded with responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":156,"lineEnd":172,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method isRepresentable to class TransportActionUtils","description":"move method isRepresentable to PsiClass:TransportActionUtils\nRationale: While TransportActionUtils primarily handles request execution, it may also involve data types during transport actions. Relocating isRepresentable() here could enhance the clarity of how data types are validated before transport actions. This aligns with the Interface Segregation Principle, ensuring that classes remain focused on specific functionalities. Nonetheless, this class may not be the most intuitive location for type validation, which could lead to confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":69,"lineEnd":72,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromName to class EsqlDataTypeConverter","description":"move method fromName to PsiClass:EsqlDataTypeConverter\nRationale: The fromName() method is responsible for converting a string name to a DataType, which closely aligns with the conversion responsibilities of EsqlDataTypeConverter. Moving it here adheres to the Single Responsibility Principle, as it centralizes data type conversion logic. This enhances cohesion within EsqlDataTypeConverter and improves code organization. However, care must be taken to ensure that the static nature of the method does not conflict with instance methods in this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":69,"lineEnd":72,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromName to class ParserUtils","description":"move method fromName to PsiClass:ParserUtils\nRationale: ParserUtils is likely to handle various parsing tasks, and converting a name to a DataType fits well within its domain. This move would enhance the cohesion of ParserUtils by consolidating parsing-related methods. It aligns with the Open/Closed Principle by allowing ParserUtils to be extended with new parsing functionalities. However, it may introduce dependencies if ParserUtils is heavily used in contexts where DataType conversions are not relevant.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":69,"lineEnd":72,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromName to class TestUtils","description":"move method fromName to PsiClass:TestUtils\nRationale: TestUtils often contains utility methods that facilitate testing, including conversions and assertions. Moving fromName() here could make it a utility for test cases that need to convert names to DataTypes. This aligns with the Interface Segregation Principle by keeping utility methods focused on testing. However, this could lead to TestUtils becoming too bloated if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":74,"lineEnd":77,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromNameOrAlias to class EsqlDataTypeConverter","description":"move method fromNameOrAlias to PsiClass:EsqlDataTypeConverter\nRationale: The fromNameOrAlias() method is responsible for mapping type names or aliases to their corresponding DataType, which aligns closely with the conversion responsibilities of EsqlDataTypeConverter. Moving it here adheres to the Single Responsibility Principle, as this class already handles various conversions related to data types. This relocation would enhance cohesion, making the codebase easier to maintain and understand. However, existing dependencies on the static method may require refactoring elsewhere.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":74,"lineEnd":77,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromNameOrAlias to class ParserUtils","description":"move method fromNameOrAlias to PsiClass:ParserUtils\nRationale: ParserUtils is likely involved in parsing operations, and the fromNameOrAlias() method can be considered a parsing utility for DataType names. Relocating this method here would enhance the logical grouping of parsing-related functionalities. This move supports the Open/Closed Principle, allowing ParserUtils to grow without altering its existing code significantly. A potential drawback is that it might dilute the focus of ParserUtils if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":74,"lineEnd":77,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromNameOrAlias to class TestUtils","description":"move method fromNameOrAlias to PsiClass:TestUtils\nRationale: TestUtils often contains utility methods for testing purposes, and fromNameOrAlias() may be useful in unit tests where DataType mapping is necessary. This move would consolidate utility methods in one place, enhancing reusability and maintainability. It aligns with the Single Responsibility Principle, as TestUtils can serve as a dedicated utility class for testing-related operations. However, it may not be the most semantically accurate fit for production code.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"fromTypeName","method_signature":"public static fromTypeName(String name)","target_class":"","rationale":""},{"method_name":"fromName","method_signature":"public static fromName(String name)","target_class":"","rationale":""},{"method_name":"fromNameOrAlias","method_signature":"public static fromNameOrAlias(String typeName)","target_class":"","rationale":""},{"method_name":"fromJava","method_signature":"public static fromJava(Object value)","target_class":"","rationale":""},{"method_name":"isUnsupported","method_signature":"public static isUnsupported(DataType type)","target_class":"","rationale":""},{"method_name":"outputType","method_signature":"public static outputType(DataType type)","target_class":"","rationale":""},{"method_name":"isString","method_signature":"public static isString(DataType t)","target_class":"","rationale":""},{"method_name":"isPrimitive","method_signature":"public static isPrimitive(DataType t)","target_class":"","rationale":""},{"method_name":"isDateTimeOrTemporal","method_signature":"public static isDateTimeOrTemporal(DataType t)","target_class":"","rationale":""},{"method_name":"isTemporalAmount","method_signature":"public static isTemporalAmount(DataType t)","target_class":"","rationale":""},{"method_name":"isNullOrTemporalAmount","method_signature":"public static isNullOrTemporalAmount(DataType t)","target_class":"","rationale":""},{"method_name":"isNullOrDatePeriod","method_signature":"public static isNullOrDatePeriod(DataType t)","target_class":"","rationale":""},{"method_name":"isNullOrTimeDuration","method_signature":"public static isNullOrTimeDuration(DataType t)","target_class":"","rationale":""},{"method_name":"isSpatial","method_signature":"public static isSpatial(DataType t)","target_class":"","rationale":""},{"method_name":"isSpatialGeo","method_signature":"public static isSpatialGeo(DataType t)","target_class":"","rationale":""},{"method_name":"isSpatialPoint","method_signature":"public static isSpatialPoint(DataType t)","target_class":"","rationale":""},{"method_name":"isRepresentable","method_signature":"public static isRepresentable(DataType t)","target_class":"","rationale":""},{"method_name":"areCompatible","method_signature":"public static areCompatible(DataType left, DataType right)","target_class":"","rationale":""},{"method_name":"widenSmallNumericTypes","method_signature":"public static widenSmallNumericTypes(DataType type)","target_class":"","rationale":""},{"method_name":"getCounterType","method_signature":"public static getCounterType(String typeName)","target_class":"","rationale":""},{"method_name":"isCounterType","method_signature":"public static isCounterType(DataType dt)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"isRepresentable","method_signature":"public static isRepresentable(DataType t)","target_class":"","rationale":""},{"method_name":"fromName","method_signature":"public static fromName(String name)","target_class":"","rationale":""},{"method_name":"fromNameOrAlias","method_signature":"public static fromNameOrAlias(String typeName)","target_class":"","rationale":""},{"method_name":"isCounterType","method_signature":"public static isCounterType(DataType dt)","target_class":"","rationale":""},{"method_name":"fromJava","method_signature":"public static fromJava(Object value)","target_class":"","rationale":""},{"method_name":"getCounterType","method_signature":"public static getCounterType(String typeName)","target_class":"","rationale":""},{"method_name":"isDateTimeOrTemporal","method_signature":"public static isDateTimeOrTemporal(DataType t)","target_class":"","rationale":""},{"method_name":"fromTypeName","method_signature":"public static fromTypeName(String name)","target_class":"","rationale":""},{"method_name":"isUnsupported","method_signature":"public static isUnsupported(DataType type)","target_class":"","rationale":""},{"method_name":"isNullOrTemporalAmount","method_signature":"public static isNullOrTemporalAmount(DataType t)","target_class":"","rationale":""},{"method_name":"outputType","method_signature":"public static outputType(DataType type)","target_class":"","rationale":""},{"method_name":"isPrimitive","method_signature":"public static isPrimitive(DataType t)","target_class":"","rationale":""},{"method_name":"isSpatial","method_signature":"public static isSpatial(DataType t)","target_class":"","rationale":""},{"method_name":"widenSmallNumericTypes","method_signature":"public static widenSmallNumericTypes(DataType type)","target_class":"","rationale":""},{"method_name":"areCompatible","method_signature":"public static areCompatible(DataType left, DataType right)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static isRepresentable(DataType t)":{"first":{"method_name":"isRepresentable","method_signature":"public static isRepresentable(DataType t)","target_class":"","rationale":""},"second":0.26803634315545716},"public static fromName(String name)":{"first":{"method_name":"fromName","method_signature":"public static fromName(String name)","target_class":"","rationale":""},"second":0.38730580558137395},"public static fromNameOrAlias(String typeName)":{"first":{"method_name":"fromNameOrAlias","method_signature":"public static fromNameOrAlias(String typeName)","target_class":"","rationale":""},"second":0.38730580558137395},"public static isCounterType(DataType dt)":{"first":{"method_name":"isCounterType","method_signature":"public static isCounterType(DataType dt)","target_class":"","rationale":""},"second":0.4717871793381579},"public static fromJava(Object value)":{"first":{"method_name":"fromJava","method_signature":"public static fromJava(Object value)","target_class":"","rationale":""},"second":0.4728631612524017},"public static getCounterType(String typeName)":{"first":{"method_name":"getCounterType","method_signature":"public static getCounterType(String typeName)","target_class":"","rationale":""},"second":0.5197505587216427},"public static isDateTimeOrTemporal(DataType t)":{"first":{"method_name":"isDateTimeOrTemporal","method_signature":"public static isDateTimeOrTemporal(DataType t)","target_class":"","rationale":""},"second":0.5515504182545358},"public static fromTypeName(String name)":{"first":{"method_name":"fromTypeName","method_signature":"public static fromTypeName(String name)","target_class":"","rationale":""},"second":0.555269152072104},"public static isUnsupported(DataType type)":{"first":{"method_name":"isUnsupported","method_signature":"public static isUnsupported(DataType type)","target_class":"","rationale":""},"second":0.5555859961218946},"public static isNullOrTemporalAmount(DataType t)":{"first":{"method_name":"isNullOrTemporalAmount","method_signature":"public static isNullOrTemporalAmount(DataType t)","target_class":"","rationale":""},"second":0.5604340666589162},"public static outputType(DataType type)":{"first":{"method_name":"outputType","method_signature":"public static outputType(DataType type)","target_class":"","rationale":""},"second":0.5910235585502945},"public static isPrimitive(DataType t)":{"first":{"method_name":"isPrimitive","method_signature":"public static isPrimitive(DataType t)","target_class":"","rationale":""},"second":0.5931498430585709},"public static isSpatial(DataType t)":{"first":{"method_name":"isSpatial","method_signature":"public static isSpatial(DataType t)","target_class":"","rationale":""},"second":0.5975935538102428},"public static widenSmallNumericTypes(DataType type)":{"first":{"method_name":"widenSmallNumericTypes","method_signature":"public static widenSmallNumericTypes(DataType type)","target_class":"","rationale":""},"second":0.6444054915219994},"public static areCompatible(DataType left, DataType right)":{"first":{"method_name":"areCompatible","method_signature":"public static areCompatible(DataType left, DataType right)","target_class":"","rationale":""},"second":0.65828182373244}},"llmMethodPriority":{"priority_method_names":["isRepresentable","fromName","fromNameOrAlias","isCounterType","fromJava","getCounterType","isDateTimeOrTemporal","fromTypeName","isUnsupported","isNullOrTemporalAmount","outputType","isPrimitive","isSpatial","widenSmallNumericTypes","areCompatible"],"llm_response_time":2762},"targetClassMap":{"isRepresentable":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.11130558014561667},{"class_name":"ExceptionUtils","similarity_score":0.08307269778254268},{"class_name":"AnalyzerTestUtils","similarity_score":0.08937970662417725},{"class_name":"LoggingUtils","similarity_score":0.04694710030129924},{"class_name":"LuceneComponent2DUtils","similarity_score":0.11800096893388091},{"class_name":"SerializationTestUtils","similarity_score":0.140968990232848},{"class_name":"EsqlTestUtils","similarity_score":0.11143068992657701},{"class_name":"NumericUtilsTests","similarity_score":0.03158645708519922},{"class_name":"CsvTestUtils","similarity_score":0.12827704852697414},{"class_name":"ParserUtils","similarity_score":0.16349306460968294},{"class_name":"PlannerUtils","similarity_score":0.12445281920103317},{"class_name":"InternalQlScriptUtils","similarity_score":0.11443671266945953},{"class_name":"DateUtils","similarity_score":0.08325290726682506},{"class_name":"SourceUtils","similarity_score":0.08584112109796833},{"class_name":"SpatialRelatesUtils","similarity_score":0.13387331149495482},{"class_name":"ReflectionUtils","similarity_score":0.08168022444022892},{"class_name":"ResponseValueUtils","similarity_score":0.07418070088090176},{"class_name":"ResponseXContentUtils","similarity_score":0.12294983938214732},{"class_name":"StringContainsRegex","similarity_score":0.08761633572681565},{"class_name":"StringUtils","similarity_score":0.06984118988203952},{"class_name":"TransportActionUtils","similarity_score":0.14349653564062095},{"class_name":"TestUtils","similarity_score":0.1141020268407573},{"class_name":"EsqlDataTypeConverter","similarity_score":0.14704840509450426},{"class_name":"AuditUtil","similarity_score":0.11410331818012687},{"class_name":"JwkValidateUtil","similarity_score":0.0929128767627008},{"class_name":"JwkValidateUtilTests","similarity_score":0.07511634821175768},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.06641118706587516},{"class_name":"AuthorizationUtils","similarity_score":0.12785442604146388},{"class_name":"JwtUtil","similarity_score":0.11663437869620294}],"target_classes_sorted_by_llm":["EsqlDataTypeConverter","ParserUtils","TransportActionUtils","AuthorizationUtils","SpatialRelatesUtils","ResponseXContentUtils","CsvTestUtils","SerializationTestUtils","PlannerUtils","LuceneComponent2DUtils"],"llm_response_time":10574,"similarity_computation_time":12,"similarity_metric":"voyage"},"fromName":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.1270278319684304},{"class_name":"SourceUtils","similarity_score":0.18809216422895952},{"class_name":"SpatialRelatesUtils","similarity_score":0.22657884013410354},{"class_name":"TestUtils","similarity_score":0.4006960967322246},{"class_name":"ParserUtils","similarity_score":0.47019062897536545},{"class_name":"AnalyzerTestUtils","similarity_score":0.36664154322508796},{"class_name":"StringContainsRegex","similarity_score":0.2939723678960656},{"class_name":"SerializationTestUtils","similarity_score":0.3335316870154712},{"class_name":"StringUtils","similarity_score":0.3320830325209054},{"class_name":"TransportActionUtils","similarity_score":0.2297719404140982},{"class_name":"LoggingUtils","similarity_score":0.25717224993681986},{"class_name":"PlannerUtils","similarity_score":0.3799040888366741},{"class_name":"LuceneComponent2DUtils","similarity_score":0.26051852210008025},{"class_name":"FunctionTestUtils","similarity_score":0.4090222215670078},{"class_name":"ExceptionUtils","similarity_score":0.12741826201799908},{"class_name":"InternalQlScriptUtils","similarity_score":0.39588496653056515},{"class_name":"EsqlTestUtils","similarity_score":0.4312788577432849},{"class_name":"ReflectionUtils","similarity_score":0.4399800806403048},{"class_name":"CsvTestUtils","similarity_score":0.43457676008811663},{"class_name":"DateUtils","similarity_score":0.29147696474957885},{"class_name":"ResponseValueUtils","similarity_score":0.2466902220325824},{"class_name":"ResponseXContentUtils","similarity_score":0.3022155028150454},{"class_name":"EsqlDataTypeConverter","similarity_score":0.4461085725244495},{"class_name":"MatchersUtils","similarity_score":0.2817523134601342},{"class_name":"JwkValidateUtil","similarity_score":0.2726068225557402},{"class_name":"JwkValidateUtilTests","similarity_score":0.324964490421507},{"class_name":"ResultUtils","similarity_score":0.24653342054454627},{"class_name":"MathUtils","similarity_score":0.1730969289631662},{"class_name":"JwtUtil","similarity_score":0.34364149009951295}],"target_classes_sorted_by_llm":["EsqlDataTypeConverter","ParserUtils","TestUtils","FunctionTestUtils","InternalQlScriptUtils","EsqlTestUtils","CsvTestUtils","PlannerUtils","ReflectionUtils","AnalyzerTestUtils"],"llm_response_time":9005,"similarity_computation_time":7,"similarity_metric":"voyage"},"fromNameOrAlias":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.1270278319684304},{"class_name":"LoggingUtils","similarity_score":0.25717224993681986},{"class_name":"LuceneComponent2DUtils","similarity_score":0.26051852210008025},{"class_name":"ParserUtils","similarity_score":0.47019062897536545},{"class_name":"ReflectionUtils","similarity_score":0.4399800806403048},{"class_name":"CsvTestUtils","similarity_score":0.4336216463296812},{"class_name":"AnalyzerTestUtils","similarity_score":0.36664154322508796},{"class_name":"SerializationTestUtils","similarity_score":0.3335316870154712},{"class_name":"PlannerUtils","similarity_score":0.3799040888366741},{"class_name":"DateUtils","similarity_score":0.29147696474957885},{"class_name":"EsqlTestUtils","similarity_score":0.4282838656756232},{"class_name":"ResponseValueUtils","similarity_score":0.2466902220325824},{"class_name":"ResponseXContentUtils","similarity_score":0.2941564227399775},{"class_name":"ExceptionUtils","similarity_score":0.12741826201799908},{"class_name":"SourceUtils","similarity_score":0.18809216422895952},{"class_name":"SpatialRelatesUtils","similarity_score":0.22657884013410354},{"class_name":"TestUtils","similarity_score":0.39957995161597887},{"class_name":"StringContainsRegex","similarity_score":0.2939723678960656},{"class_name":"StringUtils","similarity_score":0.3320830325209054},{"class_name":"TransportActionUtils","similarity_score":0.2297719404140982},{"class_name":"FunctionTestUtils","similarity_score":0.4090222215670078},{"class_name":"InternalQlScriptUtils","similarity_score":0.3982698157265324},{"class_name":"EsqlDataTypeConverter","similarity_score":0.4461085725244495},{"class_name":"JwkValidateUtil","similarity_score":0.2726068225557402},{"class_name":"JwkValidateUtilTests","similarity_score":0.324964490421507},{"class_name":"MatchersUtils","similarity_score":0.2817523134601342},{"class_name":"ProcessBuilderUtils","similarity_score":0.3806246282964429},{"class_name":"LicenseUtils","similarity_score":0.33070996777269307},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.14590459321216856}],"target_classes_sorted_by_llm":["EsqlDataTypeConverter","ParserUtils","TestUtils","InternalQlScriptUtils","EsqlTestUtils","FunctionTestUtils","ReflectionUtils","ProcessBuilderUtils","PlannerUtils","CsvTestUtils"],"llm_response_time":10039,"similarity_computation_time":7,"similarity_metric":"voyage"}}}
{"id":"ec67c7b6-97e8-4e98-a730-3688ca0753d6","methodCount":12,"hostFunctionTelemetryData":{"hostFunctionSize":233,"lineStart":65,"lineEnd":297,"bodyLineStart":65,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/build-tools-internal/src/main/java/org/elasticsearch/gradle/internal/release/UpdateVersionsTask.java","sourceCode":"public class UpdateVersionsTask extends DefaultTask {\n\n    static {\n        replaceDefaultJavaParserClassCsm();\n    }\n\n    /*\n     * The default JavaParser CSM which it uses to format any new declarations added to a class\n     * inserts two newlines after each declaration. Our version classes only have one newline.\n     * In order to get javaparser lexical printer to use our format, we have to completely replace\n     * the statically declared CSM pattern using hacky reflection\n     * to access the static map where these are stored, and insert a replacement that is identical\n     * apart from only one newline at the end of each member declaration, rather than two.\n     */\n    private static void replaceDefaultJavaParserClassCsm() {\n        try {\n            Field classCsms \u003d ConcreteSyntaxModel.class.getDeclaredField(\"concreteSyntaxModelByClass\");\n            classCsms.setAccessible(true);\n            @SuppressWarnings({ \"unchecked\", \"rawtypes\" })\n            Map\u003cClass, CsmElement\u003e csms \u003d (Map) classCsms.get(null);\n\n            // copied from the static initializer in ConcreteSyntaxModel\n            csms.put(\n                ClassOrInterfaceDeclaration.class,\n                sequence(\n                    comment(),\n                    list(ObservableProperty.ANNOTATIONS, newline(), none(), newline()),\n                    list(ObservableProperty.MODIFIERS, space(), none(), space()),\n                    conditional(\n                        ObservableProperty.INTERFACE,\n                        FLAG,\n                        token(GeneratedJavaParserConstants.INTERFACE),\n                        token(GeneratedJavaParserConstants.CLASS)\n                    ),\n                    space(),\n                    child(ObservableProperty.NAME),\n                    list(\n                        TYPE_PARAMETERS,\n                        sequence(comma(), space()),\n                        string(GeneratedJavaParserConstants.LT),\n                        string(GeneratedJavaParserConstants.GT)\n                    ),\n                    list(\n                        ObservableProperty.EXTENDED_TYPES,\n                        sequence(string(GeneratedJavaParserConstants.COMMA), space()),\n                        sequence(space(), token(GeneratedJavaParserConstants.EXTENDS), space()),\n                        none()\n                    ),\n                    list(\n                        ObservableProperty.IMPLEMENTED_TYPES,\n                        sequence(string(GeneratedJavaParserConstants.COMMA), space()),\n                        sequence(space(), token(GeneratedJavaParserConstants.IMPLEMENTS), space()),\n                        none()\n                    ),\n                    space(),\n                    block(sequence(newline(), list(ObservableProperty.MEMBERS, sequence(newline()/*, newline()*/), newline(), newline())))\n                )\n            );\n        } catch (ReflectiveOperationException e) {\n            throw new AssertionError(e);\n        }\n    }\n\n    private static final Logger LOGGER \u003d Logging.getLogger(UpdateVersionsTask.class);\n\n    static final String SERVER_MODULE_PATH \u003d \"server/src/main/java/\";\n    static final String VERSION_FILE_PATH \u003d SERVER_MODULE_PATH + \"org/elasticsearch/Version.java\";\n\n    static final Pattern VERSION_FIELD \u003d Pattern.compile(\"V_(\\\\d+)_(\\\\d+)_(\\\\d+)(?:_(\\\\w+))?\");\n\n    final Path rootDir;\n\n    @Nullable\n    private Version addVersion;\n    private boolean setCurrent;\n    @Nullable\n    private Version removeVersion;\n\n    @Inject\n    public UpdateVersionsTask(BuildLayout layout) {\n        rootDir \u003d layout.getRootDirectory().toPath();\n    }\n\n    @Option(option \u003d \"add-version\", description \u003d \"Specifies the version to add\")\n    public void addVersion(String version) {\n        this.addVersion \u003d Version.fromString(version);\n    }\n\n    @Option(option \u003d \"set-current\", description \u003d \"Set the \u0027current\u0027 constant to the new version\")\n    public void setCurrent(boolean setCurrent) {\n        this.setCurrent \u003d setCurrent;\n    }\n\n    @Option(option \u003d \"remove-version\", description \u003d \"Specifies the version to remove\")\n    public void removeVersion(String version) {\n        this.removeVersion \u003d Version.fromString(version);\n    }\n\n    static String toVersionField(Version version) {\n        return String.format(\"V_%d_%d_%d\", version.getMajor(), version.getMinor(), version.getRevision());\n    }\n\n    static Optional\u003cVersion\u003e parseVersionField(CharSequence field) {\n        Matcher m \u003d VERSION_FIELD.matcher(field);\n        if (m.find() \u003d\u003d false) return Optional.empty();\n\n        return Optional.of(\n            new Version(Integer.parseInt(m.group(1)), Integer.parseInt(m.group(2)), Integer.parseInt(m.group(3)), m.group(4))\n        );\n    }\n\n    @TaskAction\n    public void executeTask() throws IOException {\n        if (addVersion \u003d\u003d null \u0026\u0026 removeVersion \u003d\u003d null) {\n            throw new IllegalArgumentException(\"No versions to add or remove specified\");\n        }\n        if (setCurrent \u0026\u0026 addVersion \u003d\u003d null) {\n            throw new IllegalArgumentException(\"No new version added to set as the current version\");\n        }\n        if (Objects.equals(addVersion, removeVersion)) {\n            throw new IllegalArgumentException(\"Same version specified to add and remove\");\n        }\n\n        Path versionJava \u003d rootDir.resolve(VERSION_FILE_PATH);\n        CompilationUnit file \u003d LexicalPreservingPrinter.setup(StaticJavaParser.parse(versionJava));\n\n        Optional\u003cCompilationUnit\u003e modifiedFile \u003d Optional.empty();\n        if (addVersion !\u003d null) {\n            LOGGER.lifecycle(\"Adding new version [{}] to [{}]\", addVersion, versionJava);\n            var added \u003d addVersionConstant(modifiedFile.orElse(file), addVersion, setCurrent);\n            if (added.isPresent()) {\n                modifiedFile \u003d added;\n            }\n        }\n        if (removeVersion !\u003d null) {\n            LOGGER.lifecycle(\"Removing version [{}] from [{}]\", removeVersion, versionJava);\n            var removed \u003d removeVersionConstant(modifiedFile.orElse(file), removeVersion);\n            if (removed.isPresent()) {\n                modifiedFile \u003d removed;\n            }\n        }\n\n        if (modifiedFile.isPresent()) {\n            writeOutNewContents(versionJava, modifiedFile.get());\n        }\n    }\n\n    @VisibleForTesting\n    static Optional\u003cCompilationUnit\u003e addVersionConstant(CompilationUnit versionJava, Version version, boolean updateCurrent) {\n        String newFieldName \u003d toVersionField(version);\n\n        ClassOrInterfaceDeclaration versionClass \u003d versionJava.getClassByName(\"Version\").get();\n        if (versionClass.getFieldByName(newFieldName).isPresent()) {\n            LOGGER.lifecycle(\"New version constant [{}] already present, skipping\", newFieldName);\n            return Optional.empty();\n        }\n\n        NavigableMap\u003cVersion, FieldDeclaration\u003e versions \u003d versionClass.getFields()\n            .stream()\n            .map(f -\u003e Map.entry(f, parseVersionField(f.getVariable(0).getNameAsString())))\n            .filter(e -\u003e e.getValue().isPresent())\n            .collect(Collectors.toMap(e -\u003e e.getValue().get(), Map.Entry::getKey, (v1, v2) -\u003e {\n                throw new IllegalArgumentException(\"Duplicate version constants \" + v1);\n            }, TreeMap::new));\n\n        // find the version this should be inserted after\n        var previousVersion \u003d versions.lowerEntry(version);\n        if (previousVersion \u003d\u003d null) {\n            throw new IllegalStateException(String.format(\"Could not find previous version to [%s]\", version));\n        }\n        FieldDeclaration newVersion \u003d createNewVersionConstant(\n            previousVersion.getValue(),\n            newFieldName,\n            String.format(\"%d_%02d_%02d_99\", version.getMajor(), version.getMinor(), version.getRevision())\n        );\n        versionClass.getMembers().addAfter(newVersion, previousVersion.getValue());\n\n        if (updateCurrent) {\n            versionClass.getFieldByName(\"CURRENT\")\n                .orElseThrow(() -\u003e new IllegalArgumentException(\"Could not find CURRENT constant\"))\n                .getVariable(0)\n                .setInitializer(new NameExpr(newFieldName));\n        }\n\n        return Optional.of(versionJava);\n    }\n\n    private static FieldDeclaration createNewVersionConstant(FieldDeclaration lastVersion, String newName, String newExpr) {\n        return new FieldDeclaration(\n            new NodeList\u003c\u003e(lastVersion.getModifiers()),\n            new VariableDeclarator(\n                lastVersion.getCommonType(),\n                newName,\n                StaticJavaParser.parseExpression(String.format(\"new Version(%s)\", newExpr))\n            )\n        );\n    }\n\n    @VisibleForTesting\n    static Optional\u003cCompilationUnit\u003e removeVersionConstant(CompilationUnit versionJava, Version version) {\n        String removeFieldName \u003d toVersionField(version);\n\n        ClassOrInterfaceDeclaration versionClass \u003d versionJava.getClassByName(\"Version\").get();\n        var declaration \u003d versionClass.getFieldByName(removeFieldName);\n        if (declaration.isEmpty()) {\n            LOGGER.lifecycle(\"Version constant [{}] not found, skipping\", removeFieldName);\n            return Optional.empty();\n        }\n\n        // check if this is referenced by CURRENT\n        String currentReference \u003d versionClass.getFieldByName(\"CURRENT\")\n            .orElseThrow(() -\u003e new IllegalArgumentException(\"Could not find CURRENT constant\"))\n            .getVariable(0)\n            .getInitializer()\n            .get()\n            .asNameExpr()\n            .getNameAsString();\n        if (currentReference.equals(removeFieldName)) {\n            throw new IllegalArgumentException(String.format(\"Cannot remove version [%s], it is referenced by CURRENT\", version));\n        }\n\n        declaration.get().remove();\n\n        return Optional.of(versionJava);\n    }\n\n    static void writeOutNewContents(Path file, CompilationUnit unit) throws IOException {\n        if (unit.containsData(LexicalPreservingPrinter.NODE_TEXT_DATA) \u003d\u003d false) {\n            throw new IllegalArgumentException(\"CompilationUnit has no lexical information for output\");\n        }\n        Files.writeString(file, LexicalPreservingPrinter.print(unit), StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING);\n    }\n}","methodCount":12},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":70,"lineEnd":125,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method replaceDefaultJavaParserClassCsm to class GenerateReleaseNotesTask","description":"move method replaceDefaultJavaParserClassCsm to PsiClass:GenerateReleaseNotesTask\nRationale: The replaceDefaultJavaParserClassCsm() method is primarily concerned with formatting and structuring class declarations, which is relevant to generating release notes. Moving it here aligns with the Single Responsibility Principle, as this class is already tasked with managing release notes and changelogs. This enhances cohesion and makes it easier to understand how class formatting impacts the release notes generation process. However, this move may introduce dependencies on JavaParser within a task that could be seen as unrelated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":70,"lineEnd":125,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method replaceDefaultJavaParserClassCsm to class ReleaseNotesGenerator","description":"move method replaceDefaultJavaParserClassCsm to PsiClass:ReleaseNotesGenerator\nRationale: This class is responsible for generating release notes, and the method in question directly influences how classes are represented in the generated notes. Relocating the method here would enhance the cohesion between class formatting and release note generation. This move adheres to the Open/Closed Principle, as it allows for easier modifications related to class formatting without altering unrelated components. However, it could increase the complexity of the ReleaseNotesGenerator if it becomes too tightly coupled with the JavaParser.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":70,"lineEnd":125,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method replaceDefaultJavaParserClassCsm to class AstUtils","description":"move method replaceDefaultJavaParserClassCsm to PsiClass:AstUtils\nRationale: AstUtils is focused on abstract syntax trees, which aligns with the method\u0027s role in manipulating JavaParser\u0027s concrete syntax model. Moving the method here emphasizes the relationship between AST manipulation and class formatting. This adheres to the Interface Segregation Principle by keeping formatting logic separate from other unrelated tasks. However, it may lead to a broader responsibility for AstUtils, which could dilute its original purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":251,"lineEnd":260,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createNewVersionConstant to class QualifiedVersion","description":"move method createNewVersionConstant to PsiClass:QualifiedVersion\nRationale: The createNewVersionConstant() method is focused on creating a new version constant, which directly relates to the concept of versioning encapsulated in the QualifiedVersion class. Moving it here adheres to the Single Responsibility Principle by aligning the method\u0027s functionality with the class\u0027s purpose. This change enhances cohesion and makes the method more relevant to version management. A consideration is that it may increase the complexity of the QualifiedVersion class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":251,"lineEnd":260,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createNewVersionConstant to class MinorVersion","description":"move method createNewVersionConstant to PsiClass:MinorVersion\nRationale: Similar to QualifiedVersion, MinorVersion deals with versioning aspects. The createNewVersionConstant() method can be relevant here as it focuses on creating a new version representation. This move would align with the Open/Closed Principle, allowing for extension in version handling without modifying existing code. However, it may blur the lines between major and minor version management, requiring careful documentation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":251,"lineEnd":260,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createNewVersionConstant to class ChangelogEntry","description":"move method createNewVersionConstant to PsiClass:ChangelogEntry\nRationale: The ChangelogEntry class deals with version changes and related metadata. Moving createNewVersionConstant() here would enhance the class\u0027s ability to manage version-related entries. This aligns with the Interface Segregation Principle, as it would allow ChangelogEntry to handle version creation without bloating it with unrelated methods. However, care must be taken to ensure that it does not introduce unnecessary dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toVersionField to class QualifiedVersion","description":"move method toVersionField to PsiClass:QualifiedVersion\nRationale: The toVersionField() method formats a Version object into a specific string format, which is closely related to the representation of versions. Moving it to QualifiedVersion adheres to the Single Responsibility Principle, as QualifiedVersion is responsible for version-related operations. This enhances cohesion and makes the version formatting reusable. However, care should be taken to ensure that this method does not introduce unnecessary dependencies on the QualifiedVersion class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toVersionField to class Util","description":"move method toVersionField to PsiClass:Util\nRationale: Util is a class designed for utility methods, which often include string manipulation and formatting. Since toVersionField() is a static utility function that doesn\u0027t depend on instance state, moving it to Util aligns with the Open/Closed Principle, allowing for easy extension of utility functions without altering existing classes. However, this could lead to a bloated Util class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":162,"lineEnd":164,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method toVersionField to class MinorVersion","description":"move method toVersionField to PsiClass:MinorVersion\nRationale: The MinorVersion class encapsulates version details and could logically contain methods related to version formatting. Moving toVersionField() here would enhance cohesion by keeping version-related functionalities together. This adheres to the Single Responsibility Principle. However, it may introduce complexity if MinorVersion is not intended to handle formatting responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"replaceDefaultJavaParserClassCsm","method_signature":"private static replaceDefaultJavaParserClassCsm()","target_class":"","rationale":""},{"method_name":"toVersionField","method_signature":"static toVersionField(Version version)","target_class":"","rationale":""},{"method_name":"parseVersionField","method_signature":"static parseVersionField(CharSequence field)","target_class":"","rationale":""},{"method_name":"executeTask","method_signature":"@TaskAction\n    public executeTask()","target_class":"","rationale":""},{"method_name":"addVersionConstant","method_signature":"@VisibleForTesting\n    static addVersionConstant(CompilationUnit versionJava, Version version, boolean updateCurrent)","target_class":"","rationale":""},{"method_name":"createNewVersionConstant","method_signature":"private static createNewVersionConstant(FieldDeclaration lastVersion, String newName, String newExpr)","target_class":"","rationale":""},{"method_name":"removeVersionConstant","method_signature":"@VisibleForTesting\n    static removeVersionConstant(CompilationUnit versionJava, Version version)","target_class":"","rationale":""},{"method_name":"writeOutNewContents","method_signature":"static writeOutNewContents(Path file, CompilationUnit unit)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"replaceDefaultJavaParserClassCsm","method_signature":"private static replaceDefaultJavaParserClassCsm()","target_class":"","rationale":""},{"method_name":"createNewVersionConstant","method_signature":"private static createNewVersionConstant(FieldDeclaration lastVersion, String newName, String newExpr)","target_class":"","rationale":""},{"method_name":"toVersionField","method_signature":"static toVersionField(Version version)","target_class":"","rationale":""},{"method_name":"parseVersionField","method_signature":"static parseVersionField(CharSequence field)","target_class":"","rationale":""},{"method_name":"writeOutNewContents","method_signature":"static writeOutNewContents(Path file, CompilationUnit unit)","target_class":"","rationale":""},{"method_name":"removeVersionConstant","method_signature":"@VisibleForTesting\n    static removeVersionConstant(CompilationUnit versionJava, Version version)","target_class":"","rationale":""},{"method_name":"addVersionConstant","method_signature":"@VisibleForTesting\n    static addVersionConstant(CompilationUnit versionJava, Version version, boolean updateCurrent)","target_class":"","rationale":""},{"method_name":"executeTask","method_signature":"@TaskAction\n    public executeTask()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static replaceDefaultJavaParserClassCsm()":{"first":{"method_name":"replaceDefaultJavaParserClassCsm","method_signature":"private static replaceDefaultJavaParserClassCsm()","target_class":"","rationale":""},"second":0.3203331189417027},"private static createNewVersionConstant(FieldDeclaration lastVersion, String newName, String newExpr)":{"first":{"method_name":"createNewVersionConstant","method_signature":"private static createNewVersionConstant(FieldDeclaration lastVersion, String newName, String newExpr)","target_class":"","rationale":""},"second":0.33870441402980783},"static toVersionField(Version version)":{"first":{"method_name":"toVersionField","method_signature":"static toVersionField(Version version)","target_class":"","rationale":""},"second":0.3505993137207123},"static parseVersionField(CharSequence field)":{"first":{"method_name":"parseVersionField","method_signature":"static parseVersionField(CharSequence field)","target_class":"","rationale":""},"second":0.4337396730192293},"static writeOutNewContents(Path file, CompilationUnit unit)":{"first":{"method_name":"writeOutNewContents","method_signature":"static writeOutNewContents(Path file, CompilationUnit unit)","target_class":"","rationale":""},"second":0.44495974252411946},"@VisibleForTesting\n    static removeVersionConstant(CompilationUnit versionJava, Version version)":{"first":{"method_name":"removeVersionConstant","method_signature":"@VisibleForTesting\n    static removeVersionConstant(CompilationUnit versionJava, Version version)","target_class":"","rationale":""},"second":0.6114103139058884},"@VisibleForTesting\n    static addVersionConstant(CompilationUnit versionJava, Version version, boolean updateCurrent)":{"first":{"method_name":"addVersionConstant","method_signature":"@VisibleForTesting\n    static addVersionConstant(CompilationUnit versionJava, Version version, boolean updateCurrent)","target_class":"","rationale":""},"second":0.6480160426857331},"@TaskAction\n    public executeTask()":{"first":{"method_name":"executeTask","method_signature":"@TaskAction\n    public executeTask()","target_class":"","rationale":""},"second":0.6790722377864766}},"llmMethodPriority":{"priority_method_names":["replaceDefaultJavaParserClassCsm","createNewVersionConstant","toVersionField","parseVersionField","writeOutNewContents","removeVersionConstant","addVersionConstant","executeTask"],"llm_response_time":2409},"targetClassMap":{"replaceDefaultJavaParserClassCsm":{"target_classes":[{"class_name":"TemplateUtils","similarity_score":0.4089958616639783},{"class_name":"RestTestUtil","similarity_score":0.3845826453449507},{"class_name":"ParsingUtils","similarity_score":0.3254418878836039},{"class_name":"AstUtils","similarity_score":0.35450754405777934},{"class_name":"DependenciesUtils","similarity_score":0.13036941562346388},{"class_name":"Util","similarity_score":0.36083286010027077},{"class_name":"TestUtil","similarity_score":0.1472568769654581},{"class_name":"TestUtils","similarity_score":0.16607974960134217},{"class_name":"JarUtils","similarity_score":0.4388327650896954},{"class_name":"PruneChangelogsTask","similarity_score":0.4960665260263703},{"class_name":"QualifiedVersion","similarity_score":0.33225984491469346},{"class_name":"Qualifier","similarity_score":0.24434444010614054},{"class_name":"MigrationIndexGenerator","similarity_score":0.3248308612948156},{"class_name":"MinorVersion","similarity_score":0.22913611722086452},{"class_name":"ChangelogEntry","similarity_score":0.24974987749132496},{"class_name":"ReleaseHighlightsGenerator","similarity_score":0.23374843635602188},{"class_name":"ReleaseNotesGenerator","similarity_score":0.3369023924328052},{"class_name":"ReleaseNotesIndexGenerator","similarity_score":0.34140540891760096},{"class_name":"ExtractCurrentVersionsTask","similarity_score":0.30035947856766376},{"class_name":"BreakingChangesGenerator","similarity_score":0.19040186781476814},{"class_name":"TagVersionsTask","similarity_score":0.3008805435892628},{"class_name":"UpdateVersionsTaskTests","similarity_score":0.21786626208440674},{"class_name":"GenerateReleaseNotesTask","similarity_score":0.47665296634275534},{"class_name":"PermissionUtils","similarity_score":0.2154850822803917},{"class_name":"FileUtils","similarity_score":0.3123848191643792},{"class_name":"Descriptor","similarity_score":0.3487743387585507},{"class_name":"MrjarPlugin","similarity_score":0.291265448826258},{"class_name":"DistroTestPlugin","similarity_score":0.301188871536184},{"class_name":"PublishPlugin","similarity_score":0.23027332834025013}],"target_classes_sorted_by_llm":["GenerateReleaseNotesTask","ReleaseNotesGenerator","AstUtils","Util","JarUtils","TemplateUtils","ReleaseNotesIndexGenerator","Descriptor","PruneChangelogsTask","RestTestUtil"],"llm_response_time":10451,"similarity_computation_time":19,"similarity_metric":"voyage"},"createNewVersionConstant":{"target_classes":[{"class_name":"TemplateUtils","similarity_score":0.2522624895547565},{"class_name":"JarUtils","similarity_score":0.1707684583271952},{"class_name":"DependenciesUtils","similarity_score":0.19733244073364778},{"class_name":"AstUtils","similarity_score":0.15983740793871878},{"class_name":"RestTestUtil","similarity_score":0.1649732529336643},{"class_name":"Util","similarity_score":0.2679655772091986},{"class_name":"TestUtil","similarity_score":0.30550504633038933},{"class_name":"TestUtils","similarity_score":0.3093969872615047},{"class_name":"ParsingUtils","similarity_score":0.22505828156569235},{"class_name":"ChangelogEntry","similarity_score":0.34653731036534086},{"class_name":"GenerateReleaseNotesTask","similarity_score":0.26178361020973023},{"class_name":"ExtractCurrentVersionsTask","similarity_score":0.27439587453492986},{"class_name":"BreakingChangesGenerator","similarity_score":0.25393845960178424},{"class_name":"TagVersionsTask","similarity_score":0.27562912063427714},{"class_name":"MigrationIndexGenerator","similarity_score":0.3258452319850227},{"class_name":"MinorVersion","similarity_score":0.28884691392247847},{"class_name":"UpdateVersionsTaskTests","similarity_score":0.24131985281532464},{"class_name":"PruneChangelogsTask","similarity_score":0.16698191642534496},{"class_name":"QualifiedVersion","similarity_score":0.37046812996128275},{"class_name":"Qualifier","similarity_score":0.3630072665202689},{"class_name":"ReleaseHighlightsGenerator","similarity_score":0.26845109750386775},{"class_name":"ReleaseNotesGenerator","similarity_score":0.26927339207324996},{"class_name":"ReleaseNotesIndexGenerator","similarity_score":0.2753894841951425},{"class_name":"FileUtils","similarity_score":0.35599673951603167},{"class_name":"PermissionUtils","similarity_score":0.2867401930930616},{"class_name":"Descriptor","similarity_score":0.22741126155817273},{"class_name":"InjectHeaderTests","similarity_score":0.25403277435823785},{"class_name":"InMemoryJavaCompiler","similarity_score":0.26786437596643087},{"class_name":"JarScanner","similarity_score":0.35250943145240704}],"target_classes_sorted_by_llm":["QualifiedVersion","MinorVersion","ChangelogEntry","MigrationIndexGenerator","FileUtils","TestUtils","PermissionUtils","Qualifier","JarScanner","TestUtil"],"llm_response_time":7307,"similarity_computation_time":9,"similarity_metric":"voyage"},"toVersionField":{"target_classes":[{"class_name":"TemplateUtils","similarity_score":0.23570226039551584},{"class_name":"RestTestUtil","similarity_score":0.26905009606390734},{"class_name":"TestUtil","similarity_score":0.3892494720807615},{"class_name":"TestUtils","similarity_score":0.35478743759344955},{"class_name":"ParsingUtils","similarity_score":0.2523407064414136},{"class_name":"AstUtils","similarity_score":0.2631806779839076},{"class_name":"JarUtils","similarity_score":0.19630475588928234},{"class_name":"Util","similarity_score":0.4158492671520892},{"class_name":"DependenciesUtils","similarity_score":0.18953562637585883},{"class_name":"TagVersionsTask","similarity_score":0.31090114536848695},{"class_name":"ReleaseHighlightsGenerator","similarity_score":0.27804409408113695},{"class_name":"ReleaseNotesGenerator","similarity_score":0.26544027520861996},{"class_name":"ReleaseNotesIndexGenerator","similarity_score":0.26608300880432245},{"class_name":"PruneChangelogsTask","similarity_score":0.2040868792991277},{"class_name":"MigrationIndexGenerator","similarity_score":0.3148336618027138},{"class_name":"MinorVersion","similarity_score":0.39086797998528583},{"class_name":"QualifiedVersion","similarity_score":0.4022432198106058},{"class_name":"Qualifier","similarity_score":0.39570649463110713},{"class_name":"GenerateReleaseNotesTask","similarity_score":0.2932077470089829},{"class_name":"UpdateVersionsTaskTests","similarity_score":0.1886027093019471},{"class_name":"ExtractCurrentVersionsTask","similarity_score":0.33590241436966206},{"class_name":"ChangelogEntry","similarity_score":0.4698878108647613},{"class_name":"BreakingChangesGenerator","similarity_score":0.2180950197925595},{"class_name":"PermissionUtils","similarity_score":0.3836078769656734},{"class_name":"FileUtils","similarity_score":0.3858316463353162},{"class_name":"TestFixturesDeployPlugin","similarity_score":0.3584640895494324},{"class_name":"PublishPlugin","similarity_score":0.2350288290263898},{"class_name":"RepositoriesSetupPlugin","similarity_score":0.2884526489088942},{"class_name":"TestTaskConfigurer","similarity_score":0.4580104146506783}],"target_classes_sorted_by_llm":["QualifiedVersion","Util","MinorVersion","ChangelogEntry","TestUtil","FileUtils","PermissionUtils","TestTaskConfigurer","Qualifier","TestFixturesDeployPlugin"],"llm_response_time":8619,"similarity_computation_time":10,"similarity_metric":"voyage"}}}
{"id":"0d988572-6de5-4675-8c6f-9a237b6c99a5","methodCount":82,"hostFunctionTelemetryData":{"hostFunctionSize":795,"lineStart":99,"lineEnd":893,"bodyLineStart":99,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/io/stream/PlanNamedTypes.java","sourceCode":"/**\n * A utility class that consists solely of static methods that describe how to serialize and\n * deserialize QL and ESQL plan types.\n * \u003cP\u003e\n * All types that require to be serialized should have a pair of co-located `readFoo` and `writeFoo`\n * methods that deserialize and serialize respectively.\n * \u003cP\u003e\n * A type can be named or non-named. A named type has a name written to the stream before its\n * contents (similar to NamedWriteable), whereas a non-named type does not (similar to Writable).\n * Named types allow to determine specific deserialization implementations for more general types,\n * e.g. Literal, which is an Expression. Named types must have an entries in the namedTypeEntries\n * list.\n */\npublic final class PlanNamedTypes {\n\n    private PlanNamedTypes() {}\n\n    /**\n     * Determines the writeable name of the give class. The simple class name is commonly used for\n     * {@link NamedWriteable}s and is sufficient here too, but it could be almost anything else.\n     */\n    public static String name(Class\u003c?\u003e cls) {\n        return cls.getSimpleName();\n    }\n\n    /**\n     * List of named type entries that link concrete names to stream reader and writer implementations.\n     * Entries have the form:  category,  name,  serializer method,  deserializer method.\n     */\n    public static List\u003cPlanNameRegistry.Entry\u003e namedTypeEntries() {\n        List\u003cPlanNameRegistry.Entry\u003e declared \u003d List.of(\n            // Physical Plan Nodes\n            of(PhysicalPlan.class, AggregateExec.class, PlanNamedTypes::writeAggregateExec, PlanNamedTypes::readAggregateExec),\n            of(PhysicalPlan.class, DissectExec.class, PlanNamedTypes::writeDissectExec, PlanNamedTypes::readDissectExec),\n            of(PhysicalPlan.class, EsQueryExec.class, PlanNamedTypes::writeEsQueryExec, PlanNamedTypes::readEsQueryExec),\n            of(PhysicalPlan.class, EsSourceExec.class, PlanNamedTypes::writeEsSourceExec, PlanNamedTypes::readEsSourceExec),\n            of(PhysicalPlan.class, EvalExec.class, PlanNamedTypes::writeEvalExec, PlanNamedTypes::readEvalExec),\n            of(PhysicalPlan.class, EnrichExec.class, PlanNamedTypes::writeEnrichExec, PlanNamedTypes::readEnrichExec),\n            of(PhysicalPlan.class, ExchangeExec.class, PlanNamedTypes::writeExchangeExec, PlanNamedTypes::readExchangeExec),\n            of(PhysicalPlan.class, ExchangeSinkExec.class, PlanNamedTypes::writeExchangeSinkExec, PlanNamedTypes::readExchangeSinkExec),\n            of(\n                PhysicalPlan.class,\n                ExchangeSourceExec.class,\n                PlanNamedTypes::writeExchangeSourceExec,\n                PlanNamedTypes::readExchangeSourceExec\n            ),\n            of(PhysicalPlan.class, FieldExtractExec.class, PlanNamedTypes::writeFieldExtractExec, PlanNamedTypes::readFieldExtractExec),\n            of(PhysicalPlan.class, FilterExec.class, PlanNamedTypes::writeFilterExec, PlanNamedTypes::readFilterExec),\n            of(PhysicalPlan.class, FragmentExec.class, PlanNamedTypes::writeFragmentExec, PlanNamedTypes::readFragmentExec),\n            of(PhysicalPlan.class, GrokExec.class, PlanNamedTypes::writeGrokExec, PlanNamedTypes::readGrokExec),\n            of(PhysicalPlan.class, LimitExec.class, PlanNamedTypes::writeLimitExec, PlanNamedTypes::readLimitExec),\n            of(PhysicalPlan.class, LocalSourceExec.class, (out, v) -\u003e v.writeTo(out), LocalSourceExec::new),\n            of(PhysicalPlan.class, HashJoinExec.class, (out, v) -\u003e v.writeTo(out), HashJoinExec::new),\n            of(PhysicalPlan.class, MvExpandExec.class, PlanNamedTypes::writeMvExpandExec, PlanNamedTypes::readMvExpandExec),\n            of(PhysicalPlan.class, OrderExec.class, PlanNamedTypes::writeOrderExec, PlanNamedTypes::readOrderExec),\n            of(PhysicalPlan.class, ProjectExec.class, PlanNamedTypes::writeProjectExec, PlanNamedTypes::readProjectExec),\n            of(PhysicalPlan.class, RowExec.class, PlanNamedTypes::writeRowExec, PlanNamedTypes::readRowExec),\n            of(PhysicalPlan.class, ShowExec.class, PlanNamedTypes::writeShowExec, PlanNamedTypes::readShowExec),\n            of(PhysicalPlan.class, TopNExec.class, PlanNamedTypes::writeTopNExec, PlanNamedTypes::readTopNExec),\n            // Logical Plan Nodes - a subset of plans that end up being actually serialized\n            of(LogicalPlan.class, Aggregate.class, PlanNamedTypes::writeAggregate, PlanNamedTypes::readAggregate),\n            of(LogicalPlan.class, Dissect.class, PlanNamedTypes::writeDissect, PlanNamedTypes::readDissect),\n            of(LogicalPlan.class, EsRelation.class, PlanNamedTypes::writeEsRelation, PlanNamedTypes::readEsRelation),\n            of(LogicalPlan.class, Eval.class, PlanNamedTypes::writeEval, PlanNamedTypes::readEval),\n            of(LogicalPlan.class, Enrich.class, PlanNamedTypes::writeEnrich, PlanNamedTypes::readEnrich),\n            of(LogicalPlan.class, EsqlProject.class, PlanNamedTypes::writeEsqlProject, PlanNamedTypes::readEsqlProject),\n            of(LogicalPlan.class, Filter.class, PlanNamedTypes::writeFilter, PlanNamedTypes::readFilter),\n            of(LogicalPlan.class, Grok.class, PlanNamedTypes::writeGrok, PlanNamedTypes::readGrok),\n            of(LogicalPlan.class, Join.class, (out, p) -\u003e p.writeTo(out), Join::new),\n            of(LogicalPlan.class, Limit.class, PlanNamedTypes::writeLimit, PlanNamedTypes::readLimit),\n            of(LogicalPlan.class, LocalRelation.class, (out, p) -\u003e p.writeTo(out), LocalRelation::new),\n            of(LogicalPlan.class, Lookup.class, (out, p) -\u003e p.writeTo(out), Lookup::new),\n            of(LogicalPlan.class, MvExpand.class, PlanNamedTypes::writeMvExpand, PlanNamedTypes::readMvExpand),\n            of(LogicalPlan.class, OrderBy.class, PlanNamedTypes::writeOrderBy, PlanNamedTypes::readOrderBy),\n            of(LogicalPlan.class, Project.class, PlanNamedTypes::writeProject, PlanNamedTypes::readProject),\n            of(LogicalPlan.class, TopN.class, PlanNamedTypes::writeTopN, PlanNamedTypes::readTopN)\n        );\n        List\u003cPlanNameRegistry.Entry\u003e entries \u003d new ArrayList\u003c\u003e(declared);\n\n        // From NamedWriteables\n        for (List\u003cNamedWriteableRegistry.Entry\u003e ee : List.of(\n            AbstractMultivalueFunction.getNamedWriteables(),\n            AggregateFunction.getNamedWriteables(),\n            BinarySpatialFunction.getNamedWriteables(),\n            EsqlArithmeticOperation.getNamedWriteables(),\n            EsqlBinaryComparison.getNamedWriteables(),\n            EsqlScalarFunction.getNamedWriteables(),\n            FullTextPredicate.getNamedWriteables(),\n            NamedExpression.getNamedWriteables(),\n            UnaryScalarFunction.getNamedWriteables(),\n            List.of(UnsupportedAttribute.ENTRY, Literal.ENTRY, org.elasticsearch.xpack.esql.expression.Order.ENTRY)\n        )) {\n            for (NamedWriteableRegistry.Entry e : ee) {\n                entries.add(of(Expression.class, e));\n            }\n        }\n\n        return entries;\n    }\n\n    // -- physical plan nodes\n    static AggregateExec readAggregateExec(PlanStreamInput in) throws IOException {\n        return new AggregateExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression)),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class),\n            in.readEnum(AggregateExec.Mode.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(aggregateExec.child());\n        out.writeCollection(aggregateExec.groupings(), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n        out.writeNamedWriteableCollection(aggregateExec.aggregates());\n        out.writeEnum(aggregateExec.getMode());\n        out.writeOptionalVInt(aggregateExec.estimatedRowSize());\n    }\n\n    static DissectExec readDissectExec(PlanStreamInput in) throws IOException {\n        return new DissectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readExpression(),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissectExec(PlanStreamOutput out, DissectExec dissectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(dissectExec.child());\n        out.writeExpression(dissectExec.inputExpression());\n        writeDissectParser(out, dissectExec.parser());\n        out.writeNamedWriteableCollection(dissectExec.extractedFields());\n    }\n\n    static EsQueryExec readEsQueryExec(PlanStreamInput in) throws IOException {\n        return new EsQueryExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            readIndexMode(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalNamed(Expression.class),\n            in.readOptionalCollectionAsList(readerFromPlanReader(PlanNamedTypes::readFieldSort)),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec) throws IOException {\n        assert esQueryExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esQueryExec.index());\n        writeIndexMode(out, esQueryExec.indexMode());\n        out.writeNamedWriteableCollection(esQueryExec.output());\n        out.writeOptionalNamedWriteable(esQueryExec.query());\n        out.writeOptionalExpression(esQueryExec.limit());\n        out.writeOptionalCollection(esQueryExec.sorts(), writerFromPlanWriter(PlanNamedTypes::writeFieldSort));\n        out.writeOptionalInt(esQueryExec.estimatedRowSize());\n    }\n\n    static EsSourceExec readEsSourceExec(PlanStreamInput in) throws IOException {\n        return new EsSourceExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            readIndexMode(in)\n        );\n    }\n\n    static void writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esSourceExec.index());\n        out.writeNamedWriteableCollection(esSourceExec.output());\n        out.writeOptionalNamedWriteable(esSourceExec.query());\n        writeIndexMode(out, esSourceExec.indexMode());\n    }\n\n    static IndexMode readIndexMode(StreamInput in) throws IOException {\n        if (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            return IndexMode.fromString(in.readString());\n        } else {\n            return IndexMode.STANDARD;\n        }\n    }\n\n    static void writeIndexMode(StreamOutput out, IndexMode indexMode) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            out.writeString(indexMode.getName());\n        } else if (indexMode !\u003d IndexMode.STANDARD) {\n            throw new IllegalStateException(\"not ready to support index mode [\" + indexMode + \"]\");\n        }\n    }\n\n    static EvalExec readEvalExec(PlanStreamInput in) throws IOException {\n        return new EvalExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEvalExec(PlanStreamOutput out, EvalExec evalExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(evalExec.child());\n        out.writeCollection(evalExec.fields());\n    }\n\n    static EnrichExec readEnrichExec(PlanStreamInput in) throws IOException {\n        final Source source \u003d Source.readFrom(in);\n        final PhysicalPlan child \u003d in.readPhysicalPlanNode();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        final String policyName \u003d in.readString();\n        final String matchType \u003d (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_EXTENDED_ENRICH_TYPES))\n            ? in.readString()\n            : \"match\";\n        final String policyMatchField \u003d in.readString();\n        final Map\u003cString, String\u003e concreteIndices;\n        final Enrich.Mode mode;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            mode \u003d Enrich.Mode.ANY;\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() !\u003d 1) {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + esIndex.concreteIndices());\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new EnrichExec(\n            source,\n            child,\n            mode,\n            matchType,\n            matchField,\n            policyName,\n            policyMatchField,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrichExec(PlanStreamOutput out, EnrichExec enrich) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(enrich.child());\n        out.writeNamedWriteable(enrich.matchField());\n        out.writeString(enrich.policyName());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_EXTENDED_ENRICH_TYPES)) {\n            out.writeString(enrich.matchType());\n        }\n        out.writeString(enrich.policyMatchField());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            if (enrich.concreteIndices().keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String concreteIndex \u003d enrich.concreteIndices().get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                writeEsIndex(out, new EsIndex(concreteIndex, Map.of(), Set.of(concreteIndex)));\n            } else {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + enrich.concreteIndices());\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static ExchangeExec readExchangeExec(PlanStreamInput in) throws IOException {\n        return new ExchangeExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeExec.output());\n        out.writeBoolean(exchangeExec.isInBetweenAggs());\n        out.writePhysicalPlanNode(exchangeExec.child());\n    }\n\n    static ExchangeSinkExec readExchangeSinkExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSinkExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeSinkExec.output());\n        out.writeBoolean(exchangeSinkExec.isIntermediateAgg());\n        out.writePhysicalPlanNode(exchangeSinkExec.child());\n    }\n\n    static ExchangeSourceExec readExchangeSourceExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSourceExec(Source.readFrom(in), in.readNamedWriteableCollectionAsList(Attribute.class), in.readBoolean());\n    }\n\n    static void writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec) throws IOException {\n        out.writeNamedWriteableCollection(exchangeSourceExec.output());\n        out.writeBoolean(exchangeSourceExec.isIntermediateAgg());\n    }\n\n    static FieldExtractExec readFieldExtractExec(PlanStreamInput in) throws IOException {\n        return new FieldExtractExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteableCollectionAsList(Attribute.class));\n    }\n\n    static void writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(fieldExtractExec.child());\n        out.writeNamedWriteableCollection(fieldExtractExec.attributesToExtract());\n    }\n\n    static FilterExec readFilterExec(PlanStreamInput in) throws IOException {\n        return new FilterExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readExpression());\n    }\n\n    static void writeFilterExec(PlanStreamOutput out, FilterExec filterExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(filterExec.child());\n        out.writeExpression(filterExec.condition());\n    }\n\n    static FragmentExec readFragmentExec(PlanStreamInput in) throws IOException {\n        return new FragmentExec(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalVInt(),\n            in.getTransportVersion().onOrAfter(TransportVersions.ESQL_REDUCER_NODE_FRAGMENT) ? in.readOptionalPhysicalPlanNode() : null\n        );\n    }\n\n    static void writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(fragmentExec.fragment());\n        out.writeOptionalNamedWriteable(fragmentExec.esFilter());\n        out.writeOptionalVInt(fragmentExec.estimatedRowSize());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_REDUCER_NODE_FRAGMENT)) {\n            out.writeOptionalPhysicalPlanNode(fragmentExec.reducer());\n        }\n    }\n\n    static GrokExec readGrokExec(PlanStreamInput in) throws IOException {\n        Source source;\n        return new GrokExec(\n            source \u003d Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readExpression(),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrokExec(PlanStreamOutput out, GrokExec grokExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(grokExec.child());\n        out.writeExpression(grokExec.inputExpression());\n        out.writeString(grokExec.pattern().pattern());\n        out.writeNamedWriteableCollection(grokExec.extractedFields());\n    }\n\n    static LimitExec readLimitExec(PlanStreamInput in) throws IOException {\n        return new LimitExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamed(Expression.class));\n    }\n\n    static void writeLimitExec(PlanStreamOutput out, LimitExec limitExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(limitExec.child());\n        out.writeExpression(limitExec.limit());\n    }\n\n    static MvExpandExec readMvExpandExec(PlanStreamInput in) throws IOException {\n        return new MvExpandExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(mvExpandExec.child());\n        out.writeNamedWriteable(mvExpandExec.target());\n        out.writeNamedWriteable(mvExpandExec.expanded());\n    }\n\n    static OrderExec readOrderExec(PlanStreamInput in) throws IOException {\n        return new OrderExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new)\n        );\n    }\n\n    static void writeOrderExec(PlanStreamOutput out, OrderExec orderExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(orderExec.child());\n        out.writeCollection(orderExec.order());\n    }\n\n    static ProjectExec readProjectExec(PlanStreamInput in) throws IOException {\n        return new ProjectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeProjectExec(PlanStreamOutput out, ProjectExec projectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(projectExec.child());\n        out.writeNamedWriteableCollection(projectExec.projections());\n    }\n\n    static RowExec readRowExec(PlanStreamInput in) throws IOException {\n        return new RowExec(Source.readFrom(in), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeRowExec(PlanStreamOutput out, RowExec rowExec) throws IOException {\n        assert rowExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        out.writeCollection(rowExec.fields());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static ShowExec readShowExec(PlanStreamInput in) throws IOException {\n        return new ShowExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            (List\u003cList\u003cObject\u003e\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeShowExec(PlanStreamOutput out, ShowExec showExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(showExec.output());\n        out.writeGenericValue(showExec.values());\n    }\n\n    static TopNExec readTopNExec(PlanStreamInput in) throws IOException {\n        return new TopNExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new),\n            in.readNamed(Expression.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeTopNExec(PlanStreamOutput out, TopNExec topNExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(topNExec.child());\n        out.writeCollection(topNExec.order());\n        out.writeExpression(topNExec.limit());\n        out.writeOptionalVInt(topNExec.estimatedRowSize());\n    }\n\n    // -- Logical plan nodes\n    static Aggregate readAggregate(PlanStreamInput in) throws IOException {\n        return new Aggregate(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(readerFromPlanReader(PlanStreamInput::readExpression)),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeAggregate(PlanStreamOutput out, Aggregate aggregate) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(aggregate.child());\n        out.writeCollection(aggregate.groupings(), writerFromPlanWriter(PlanStreamOutput::writeExpression));\n        out.writeNamedWriteableCollection(aggregate.aggregates());\n    }\n\n    static Dissect readDissect(PlanStreamInput in) throws IOException {\n        return new Dissect(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readExpression(),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissect(PlanStreamOutput out, Dissect dissect) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(dissect.child());\n        out.writeExpression(dissect.input());\n        writeDissectParser(out, dissect.parser());\n        out.writeNamedWriteableCollection(dissect.extractedFields());\n    }\n\n    static EsRelation readEsRelation(PlanStreamInput in) throws IOException {\n        Source source \u003d Source.readFrom(in);\n        EsIndex esIndex \u003d readEsIndex(in);\n        List\u003cAttribute\u003e attributes \u003d in.readNamedWriteableCollectionAsList(Attribute.class);\n        if (supportingEsSourceOptions(in.getTransportVersion())) {\n            readEsSourceOptions(in); // consume optional strings sent by remote\n        }\n        final IndexMode indexMode \u003d readIndexMode(in);\n        boolean frozen \u003d in.readBoolean();\n        return new EsRelation(source, esIndex, attributes, indexMode, frozen);\n    }\n\n    static void writeEsRelation(PlanStreamOutput out, EsRelation relation) throws IOException {\n        assert relation.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, relation.index());\n        out.writeNamedWriteableCollection(relation.output());\n        if (supportingEsSourceOptions(out.getTransportVersion())) {\n            writeEsSourceOptions(out); // write (null) string fillers expected by remote\n        }\n        writeIndexMode(out, relation.indexMode());\n        out.writeBoolean(relation.frozen());\n    }\n\n    private static boolean supportingEsSourceOptions(TransportVersion version) {\n        return version.onOrAfter(TransportVersions.ESQL_ES_SOURCE_OPTIONS)\n            \u0026\u0026 version.before(TransportVersions.ESQL_REMOVE_ES_SOURCE_OPTIONS);\n    }\n\n    private static void readEsSourceOptions(PlanStreamInput in) throws IOException {\n        // allowNoIndices\n        in.readOptionalString();\n        // ignoreUnavailable\n        in.readOptionalString();\n        // preference\n        in.readOptionalString();\n    }\n\n    private static void writeEsSourceOptions(PlanStreamOutput out) throws IOException {\n        // allowNoIndices\n        out.writeOptionalString(null);\n        // ignoreUnavailable\n        out.writeOptionalString(null);\n        // preference\n        out.writeOptionalString(null);\n    }\n\n    static Eval readEval(PlanStreamInput in) throws IOException {\n        return new Eval(Source.readFrom(in), in.readLogicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEval(PlanStreamOutput out, Eval eval) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(eval.child());\n        out.writeCollection(eval.fields());\n    }\n\n    static Enrich readEnrich(PlanStreamInput in) throws IOException {\n        Enrich.Mode mode \u003d Enrich.Mode.ANY;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n        }\n        final Source source \u003d Source.readFrom(in);\n        final LogicalPlan child \u003d in.readLogicalPlanNode();\n        final Expression policyName \u003d in.readExpression();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        if (in.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            in.readString(); // discard the old policy name\n        }\n        final EnrichPolicy policy \u003d new EnrichPolicy(in);\n        final Map\u003cString, String\u003e concreteIndices;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() \u003e 1) {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + esIndex);\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new Enrich(\n            source,\n            child,\n            mode,\n            policyName,\n            matchField,\n            policy,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrich(PlanStreamOutput out, Enrich enrich) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n        }\n\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(enrich.child());\n        out.writeExpression(enrich.policyName());\n        out.writeNamedWriteable(enrich.matchField());\n        if (out.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            out.writeString(BytesRefs.toString(enrich.policyName().fold())); // old policy name\n        }\n        enrich.policy().writeTo(out);\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            Map\u003cString, String\u003e concreteIndices \u003d enrich.concreteIndices();\n            if (concreteIndices.keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String enrichIndex \u003d concreteIndices.get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                EsIndex esIndex \u003d new EsIndex(enrichIndex, Map.of(), Set.of(enrichIndex));\n                writeEsIndex(out, esIndex);\n            } else {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + concreteIndices);\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static EsqlProject readEsqlProject(PlanStreamInput in) throws IOException {\n        return new EsqlProject(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeEsqlProject(PlanStreamOutput out, EsqlProject project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    static Filter readFilter(PlanStreamInput in) throws IOException {\n        return new Filter(Source.readFrom(in), in.readLogicalPlanNode(), in.readExpression());\n    }\n\n    static void writeFilter(PlanStreamOutput out, Filter filter) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(filter.child());\n        out.writeExpression(filter.condition());\n    }\n\n    static Grok readGrok(PlanStreamInput in) throws IOException {\n        Source source;\n        return new Grok(\n            source \u003d Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readExpression(),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrok(PlanStreamOutput out, Grok grok) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(grok.child());\n        out.writeExpression(grok.input());\n        out.writeString(grok.parser().pattern());\n        out.writeNamedWriteableCollection(grok.extractedFields());\n    }\n\n    static Limit readLimit(PlanStreamInput in) throws IOException {\n        return new Limit(Source.readFrom(in), in.readNamed(Expression.class), in.readLogicalPlanNode());\n    }\n\n    static void writeLimit(PlanStreamOutput out, Limit limit) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeExpression(limit.limit());\n        out.writeLogicalPlanNode(limit.child());\n    }\n\n    static MvExpand readMvExpand(PlanStreamInput in) throws IOException {\n        return new MvExpand(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpand(PlanStreamOutput out, MvExpand mvExpand) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(mvExpand.child());\n        out.writeNamedWriteable(mvExpand.target());\n        out.writeNamedWriteable(mvExpand.expanded());\n    }\n\n    static OrderBy readOrderBy(PlanStreamInput in) throws IOException {\n        return new OrderBy(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new)\n        );\n    }\n\n    static void writeOrderBy(PlanStreamOutput out, OrderBy order) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(order.child());\n        out.writeCollection(order.order());\n    }\n\n    static Project readProject(PlanStreamInput in) throws IOException {\n        return new Project(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeProject(PlanStreamOutput out, Project project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    static TopN readTopN(PlanStreamInput in) throws IOException {\n        return new TopN(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new),\n            in.readExpression()\n        );\n    }\n\n    static void writeTopN(PlanStreamOutput out, TopN topN) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(topN.child());\n        out.writeCollection(topN.order());\n        out.writeExpression(topN.limit());\n    }\n\n    static final Map\u003c\n        String,\n        BiFunction\u003c\n            Source,\n            Expression,\n            org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction\u003e\u003e QL_UNARY_SCALAR_CTRS \u003d Map.ofEntries(\n                entry(name(IsNotNull.class), IsNotNull::new),\n                entry(name(IsNull.class), IsNull::new),\n                entry(name(Not.class), Not::new)\n            );\n\n    static org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction readQLUnaryScalar(\n        PlanStreamInput in,\n        String name\n    ) throws IOException {\n        var ctr \u003d QL_UNARY_SCALAR_CTRS.get(name);\n        if (ctr \u003d\u003d null) {\n            throw new IOException(\"Constructor for QLUnaryScalar not found for name:\" + name);\n        }\n        return ctr.apply(Source.readFrom(in), in.readExpression());\n    }\n\n    static void writeQLUnaryScalar(\n        PlanStreamOutput out,\n        org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction function\n    ) throws IOException {\n        function.source().writeTo(out);\n        out.writeExpression(function.field());\n    }\n\n    // -- ancillary supporting classes of plan nodes, etc\n\n    static EsQueryExec.FieldSort readFieldSort(PlanStreamInput in) throws IOException {\n        return new EsQueryExec.FieldSort(\n            new FieldAttribute(in),\n            in.readEnum(Order.OrderDirection.class),\n            in.readEnum(Order.NullsPosition.class)\n        );\n    }\n\n    static void writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort) throws IOException {\n        fieldSort.field().writeTo(out);\n        out.writeEnum(fieldSort.direction());\n        out.writeEnum(fieldSort.nulls());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static EsIndex readEsIndex(PlanStreamInput in) throws IOException {\n        return new EsIndex(\n            in.readString(),\n            in.readImmutableMap(StreamInput::readString, i -\u003e i.readNamedWriteable(EsField.class)),\n            (Set\u003cString\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeEsIndex(PlanStreamOutput out, EsIndex esIndex) throws IOException {\n        out.writeString(esIndex.name());\n        out.writeMap(esIndex.mapping(), StreamOutput::writeNamedWriteable);\n        out.writeGenericValue(esIndex.concreteIndices());\n    }\n\n    static Parser readDissectParser(PlanStreamInput in) throws IOException {\n        String pattern \u003d in.readString();\n        String appendSeparator \u003d in.readString();\n        return new Parser(pattern, appendSeparator, new DissectParser(pattern, appendSeparator));\n    }\n\n    static void writeDissectParser(PlanStreamOutput out, Parser dissectParser) throws IOException {\n        out.writeString(dissectParser.pattern());\n        out.writeString(dissectParser.appendSeparator());\n    }\n}","methodCount":82},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":123,"lineEnd":196,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanNameRegistry","description":"move method namedTypeEntries to PsiClass:PlanNameRegistry\nRationale: The namedTypeEntries() method is closely related to managing named type entries, which directly aligns with the responsibilities of PlanNameRegistry. Moving it here enhances cohesion as it centralizes the logic for managing registry entries. This adheres to the Single Responsibility Principle by ensuring that PlanNameRegistry handles all related operations. A potential drawback is that it may increase the complexity of PlanNameRegistry if it becomes too large.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":123,"lineEnd":196,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanStreamInput","description":"move method namedTypeEntries to PsiClass:PlanStreamInput\nRationale: The method deals with entries that are likely read from a stream, making PlanStreamInput a suitable target. This aligns with the Interface Segregation Principle by separating concerns related to input handling from other classes. However, this class may already be focused on reading logic, and adding this method could lead to a violation of the Single Responsibility Principle if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":123,"lineEnd":196,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanStreamOutput","description":"move method namedTypeEntries to PsiClass:PlanStreamOutput\nRationale: Similar to PlanStreamInput, PlanStreamOutput is concerned with writing operations, which could logically include the management of named type entries. This move would improve cohesion by grouping related functionality together. However, it could blur the lines between input and output responsibilities, necessitating careful consideration of how these classes interact.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":634,"lineEnd":641,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class PlanStreamInput","description":"move method writeEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The writeEsSourceOptions() method is responsible for writing options to a stream, which aligns closely with the responsibilities of PlanStreamInput, as it handles reading and writing data streams. This move adheres to the Single Responsibility Principle by ensuring that the method is located within a class that directly manages stream operations, improving cohesion. However, care must be taken to ensure that the method\u0027s dependencies are properly managed in the new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":634,"lineEnd":641,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class TestUtils","description":"move method writeEsSourceOptions to PsiClass:TestUtils\nRationale: The method seems to be used for preparing or configuring outputs, which is a common utility function in testing scenarios. Moving this method to TestUtils would enhance its reusability in various test cases. This aligns with the Open/Closed Principle, allowing the utility class to be extended with additional functionality without modifying existing code. However, it may lead to an overcrowded utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":634,"lineEnd":641,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class EsqlTestUtils","description":"move method writeEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils is focused on providing utility methods for testing Esql-related functionality. Since writeEsSourceOptions() appears to be related to the configuration of Esql sources, moving it here would improve cohesion and maintainability. This aligns with the Single Responsibility Principle, as it groups related functionalities. The drawback could be that it might not be directly related to Esql operations, leading to potential confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":625,"lineEnd":632,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class PlanStreamInput","description":"move method readEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The readEsSourceOptions() method directly interacts with the PlanStreamInput class for reading source options. Moving it here enhances cohesion, as it deals with the input stream\u0027s properties. This aligns with the Single Responsibility Principle, as PlanStreamInput is responsible for managing input operations. However, it may increase the complexity of PlanStreamInput if too many methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":625,"lineEnd":632,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class EsqlTestUtils","description":"move method readEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils provides utility methods for Esql-related operations, and since readEsSourceOptions seems to deal with options relevant to Esql, this class is a good candidate. It adheres to the Open/Closed Principle by allowing for extension without modifying existing code. However, it may dilute the purpose of EsqlTestUtils if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":625,"lineEnd":632,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class StringUtils","description":"move method readEsSourceOptions to PsiClass:StringUtils\nRationale: Given that readEsSourceOptions reads optional strings, StringUtils may be a reasonable target as it handles string operations. This aligns with the Single Responsibility Principle, focusing on string-related functionalities. However, this could lead to an inappropriate coupling of unrelated functionalities if StringUtils becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"name","method_signature":"public static name(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"readAggregateExec","method_signature":"static readAggregateExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},{"method_name":"readDissectExec","method_signature":"static readDissectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"readEsSourceExec","method_signature":"static readEsSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},{"method_name":"readIndexMode","method_signature":"static readIndexMode(StreamInput in)","target_class":"","rationale":""},{"method_name":"writeIndexMode","method_signature":"static writeIndexMode(StreamOutput out, IndexMode indexMode)","target_class":"","rationale":""},{"method_name":"readEvalExec","method_signature":"static readEvalExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEvalExec","method_signature":"static writeEvalExec(PlanStreamOutput out, EvalExec evalExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrichExec","method_signature":"static writeEnrichExec(PlanStreamOutput out, EnrichExec enrich)","target_class":"","rationale":""},{"method_name":"readExchangeExec","method_signature":"static readExchangeExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},{"method_name":"readExchangeSinkExec","method_signature":"static readExchangeSinkExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},{"method_name":"readExchangeSourceExec","method_signature":"static readExchangeSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},{"method_name":"readFieldExtractExec","method_signature":"static readFieldExtractExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldExtractExec","method_signature":"static writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec)","target_class":"","rationale":""},{"method_name":"readFilterExec","method_signature":"static readFilterExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilterExec","method_signature":"static writeFilterExec(PlanStreamOutput out, FilterExec filterExec)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFragmentExec","method_signature":"static writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec)","target_class":"","rationale":""},{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},{"method_name":"readLimitExec","method_signature":"static readLimitExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimitExec","method_signature":"static writeLimitExec(PlanStreamOutput out, LimitExec limitExec)","target_class":"","rationale":""},{"method_name":"readMvExpandExec","method_signature":"static readMvExpandExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},{"method_name":"readOrderExec","method_signature":"static readOrderExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderExec","method_signature":"static writeOrderExec(PlanStreamOutput out, OrderExec orderExec)","target_class":"","rationale":""},{"method_name":"readProjectExec","method_signature":"static readProjectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProjectExec","method_signature":"static writeProjectExec(PlanStreamOutput out, ProjectExec projectExec)","target_class":"","rationale":""},{"method_name":"readRowExec","method_signature":"static readRowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readShowExec","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readShowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeShowExec","method_signature":"static writeShowExec(PlanStreamOutput out, ShowExec showExec)","target_class":"","rationale":""},{"method_name":"readTopNExec","method_signature":"static readTopNExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},{"method_name":"readAggregate","method_signature":"static readAggregate(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAggregate","method_signature":"static writeAggregate(PlanStreamOutput out, Aggregate aggregate)","target_class":"","rationale":""},{"method_name":"readDissect","method_signature":"static readDissect(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsRelation","method_signature":"static writeEsRelation(PlanStreamOutput out, EsRelation relation)","target_class":"","rationale":""},{"method_name":"supportingEsSourceOptions","method_signature":"private static supportingEsSourceOptions(TransportVersion version)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEval","method_signature":"static readEval(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEval","method_signature":"static writeEval(PlanStreamOutput out, Eval eval)","target_class":"","rationale":""},{"method_name":"readEnrich","method_signature":"static readEnrich(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrich","method_signature":"static writeEnrich(PlanStreamOutput out, Enrich enrich)","target_class":"","rationale":""},{"method_name":"readEsqlProject","method_signature":"static readEsqlProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsqlProject","method_signature":"static writeEsqlProject(PlanStreamOutput out, EsqlProject project)","target_class":"","rationale":""},{"method_name":"readFilter","method_signature":"static readFilter(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilter","method_signature":"static writeFilter(PlanStreamOutput out, Filter filter)","target_class":"","rationale":""},{"method_name":"readGrok","method_signature":"static readGrok(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrok","method_signature":"static writeGrok(PlanStreamOutput out, Grok grok)","target_class":"","rationale":""},{"method_name":"readLimit","method_signature":"static readLimit(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimit","method_signature":"static writeLimit(PlanStreamOutput out, Limit limit)","target_class":"","rationale":""},{"method_name":"readMvExpand","method_signature":"static readMvExpand(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpand","method_signature":"static writeMvExpand(PlanStreamOutput out, MvExpand mvExpand)","target_class":"","rationale":""},{"method_name":"readOrderBy","method_signature":"static readOrderBy(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderBy","method_signature":"static writeOrderBy(PlanStreamOutput out, OrderBy order)","target_class":"","rationale":""},{"method_name":"readProject","method_signature":"static readProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProject","method_signature":"static writeProject(PlanStreamOutput out, Project project)","target_class":"","rationale":""},{"method_name":"readTopN","method_signature":"static readTopN(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopN","method_signature":"static writeTopN(PlanStreamOutput out, TopN topN)","target_class":"","rationale":""},{"method_name":"readQLUnaryScalar","method_signature":"static readQLUnaryScalar(\n        PlanStreamInput in,\n        String name\n    )","target_class":"","rationale":""},{"method_name":"writeQLUnaryScalar","method_signature":"static writeQLUnaryScalar(\n        PlanStreamOutput out,\n        org.elasticsearch.xpack.esql.core.expression.function.scalar.UnaryScalarFunction function\n    )","target_class":"","rationale":""},{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""},{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectParser","method_signature":"static writeDissectParser(PlanStreamOutput out, Parser dissectParser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static namedTypeEntries()":{"first":{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},"second":0.12283265182134905},"private static writeEsSourceOptions(PlanStreamOutput out)":{"first":{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},"second":0.22406227908928703},"private static readEsSourceOptions(PlanStreamInput in)":{"first":{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},"second":0.22420186414010013},"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)":{"first":{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},"second":0.26276228295594206},"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)":{"first":{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},"second":0.3446242665649821},"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)":{"first":{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},"second":0.35149163223632934},"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)":{"first":{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},"second":0.3655261575374215},"static writeDissect(PlanStreamOutput out, Dissect dissect)":{"first":{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},"second":0.3655261575374215},"static readDissectParser(PlanStreamInput in)":{"first":{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},"second":0.36778913790638146},"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)":{"first":{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},"second":0.36832169396828257},"static writeRowExec(PlanStreamOutput out, RowExec rowExec)":{"first":{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},"second":0.3742669603047504},"static readEnrichExec(PlanStreamInput in)":{"first":{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.37741693443172447},"static readEsRelation(PlanStreamInput in)":{"first":{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3824523114830342},"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)":{"first":{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3849748206314765},"static readFragmentExec(PlanStreamInput in)":{"first":{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3882090231764537}},"llmMethodPriority":{"priority_method_names":["namedTypeEntries","writeEsSourceOptions","readEsSourceOptions","writeEsQueryExec","writeAggregateExec","writeEsSourceExec","writeDissectExec","writeDissect","readDissectParser","writeEsIndex","writeRowExec","readEnrichExec","readEsRelation","readEsIndex","readFragmentExec"],"llm_response_time":3765},"targetClassMap":{"namedTypeEntries":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.10197177409089982},{"class_name":"AnalyzerTestUtils","similarity_score":0.12575955897571},{"class_name":"LoggingUtils","similarity_score":0.09988215309066698},{"class_name":"LuceneComponent2DUtils","similarity_score":0.14792660675851324},{"class_name":"Entry","similarity_score":0.12777018049328354},{"class_name":"SerializationTestUtils","similarity_score":0.13772835849735945},{"class_name":"EsqlTestUtils","similarity_score":0.17609761299538768},{"class_name":"ExceptionUtils","similarity_score":0.11083136831845164},{"class_name":"CsvTestUtils","similarity_score":0.1962959645745817},{"class_name":"TestUtils","similarity_score":0.17394001367413567},{"class_name":"SourceUtils","similarity_score":0.10653475153894172},{"class_name":"DateUtils","similarity_score":0.15386082777182256},{"class_name":"SpatialRelatesUtils","similarity_score":0.15927100507340128},{"class_name":"TransportActionUtils","similarity_score":0.15166928619795592},{"class_name":"StringContainsRegex","similarity_score":0.14045314062895045},{"class_name":"NumericUtilsTests","similarity_score":0.1238177032488542},{"class_name":"StringUtils","similarity_score":0.150819256156141},{"class_name":"ReflectionUtils","similarity_score":0.14964259744800779},{"class_name":"ParserUtils","similarity_score":0.13551233423324507},{"class_name":"PlanNamedTypesTests","similarity_score":0.19840155994076428},{"class_name":"PlanNameRegistry","similarity_score":0.18634642067054927},{"class_name":"PlannerUtils","similarity_score":0.210306975675615},{"class_name":"PlanStreamInput","similarity_score":0.18177066322696908},{"class_name":"PlanStreamOutput","similarity_score":0.15944656956040978},{"class_name":"ResponseValueUtils","similarity_score":0.21019777337565493},{"class_name":"ResponseXContentUtils","similarity_score":0.17932495005540075},{"class_name":"AuditUtil","similarity_score":0.14451988360814744},{"class_name":"JwkValidateUtil","similarity_score":0.14239196932324746},{"class_name":"JwkValidateUtilTests","similarity_score":0.14461760020202974}],"target_classes_sorted_by_llm":["PlanNameRegistry","PlanStreamInput","PlanStreamOutput","PlannerUtils","PlanNamedTypesTests","ResponseValueUtils","CsvTestUtils","EsqlTestUtils","ResponseXContentUtils","TestUtils"],"llm_response_time":8185,"similarity_computation_time":56,"similarity_metric":"voyage"},"writeEsSourceOptions":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.17712297710801905},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.2400396792595916},{"class_name":"LoggingUtils","similarity_score":0.17078251276599332},{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"EsqlTestUtils","similarity_score":0.2566640053653935},{"class_name":"CsvTestUtils","similarity_score":0.25552033264319435},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"PlanNamedTypesTests","similarity_score":0.28354650543062526},{"class_name":"PlanNameRegistry","similarity_score":0.2304929349447907},{"class_name":"PlannerUtils","similarity_score":0.22748444983666852},{"class_name":"PlanStreamInput","similarity_score":0.2596260935667953},{"class_name":"PlanStreamOutput","similarity_score":0.2397869506903664},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"SourceUtils","similarity_score":0.1561349078609147},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"ResponseValueUtils","similarity_score":0.1623887831995765},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"TransportActionUtils","similarity_score":0.22371713913234212},{"class_name":"TestUtils","similarity_score":0.311307259615},{"class_name":"AuditUtil","similarity_score":0.2615579179746265},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.1797866299901979},{"class_name":"AuthorizationUtils","similarity_score":0.1541174147700662}],"target_classes_sorted_by_llm":["PlanStreamInput","TestUtils","EsqlTestUtils","StringUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","AuditUtil","SerializationTestUtils"],"llm_response_time":0,"similarity_computation_time":8,"similarity_metric":"voyage"},"readEsSourceOptions":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"TestUtils","similarity_score":0.311307259615},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.2454951265154914},{"class_name":"TransportActionUtils","similarity_score":0.22371713913234212},{"class_name":"LoggingUtils","similarity_score":0.17078251276599332},{"class_name":"PlanNamedTypesTests","similarity_score":0.2821700660838746},{"class_name":"PlanNameRegistry","similarity_score":0.23630368120390308},{"class_name":"PlannerUtils","similarity_score":0.22748444983666852},{"class_name":"PlanStreamInput","similarity_score":0.2596260935667953},{"class_name":"PlanStreamOutput","similarity_score":0.2397869506903664},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"EsqlTestUtils","similarity_score":0.2566640053653935},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"CsvTestUtils","similarity_score":0.25552033264319435},{"class_name":"SourceUtils","similarity_score":0.16728740127955144},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"FunctionTestUtils","similarity_score":0.17712297710801905},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"ResponseValueUtils","similarity_score":0.1623887831995765},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"MatchersUtils","similarity_score":0.17819580931114817},{"class_name":"ResultUtils","similarity_score":0.17541160386140583},{"class_name":"JwkValidateUtil","similarity_score":0.18692158795056743}],"target_classes_sorted_by_llm":["PlanStreamInput","EsqlTestUtils","StringUtils","TestUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","SerializationTestUtils","PlanStreamOutput"],"llm_response_time":0,"similarity_computation_time":16,"similarity_metric":"voyage"}}}
{"id":"f2dcd7f2-91eb-40ca-b4ab-22c9d6477182","methodCount":31,"hostFunctionTelemetryData":{"hostFunctionSize":658,"lineStart":61,"lineEnd":718,"bodyLineStart":61,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql-core/src/test/java/org/elasticsearch/xpack/esql/core/tree/NodeSubclassTests.java","sourceCode":"/**\n * Looks for all subclasses of {@link Node} and verifies that they\n * implement {@link Node#info()} and\n * {@link Node#replaceChildren(List)} sanely. It\u0027d be better if\n * each subclass had its own test case that verified those methods\n * and any other interesting things that that they do but we\u0027re a\n * long way from that and this gets the job done for now.\n * \u003cp\u003e\n * This test attempts to use reflection to create believeable nodes\n * and manipulate them in believeable ways with as little knowledge\n * of the actual subclasses as possible. This is problematic because\n * it is possible, for example, for nodes to stackoverflow because\n * they \u003cstrong\u003ecan\u003c/strong\u003e contain themselves. So this class\n * \u003cstrong\u003edoes\u003c/strong\u003e have some {@link Node}-subclass-specific\n * knowledge. As little as I could get away with though.\n * \u003cp\u003e\n * When there are actual tests for a subclass of {@linkplain Node}\n * then this class will do two things:\n * \u003cul\u003e\n * \u003cli\u003eSkip running any tests for that subclass entirely.\n * \u003cli\u003eDelegate to that test to build nodes of that type when a\n * node of that type is called for.\n * \u003c/ul\u003e\n */\npublic class NodeSubclassTests\u003cT extends B, B extends Node\u003cB\u003e\u003e extends ESTestCase {\n\n    private static final List\u003cClass\u003c?\u003e\u003e CLASSES_WITH_MIN_TWO_CHILDREN \u003d asList(In.class);\n\n    private final Class\u003cT\u003e subclass;\n\n    public NodeSubclassTests(Class\u003cT\u003e subclass) {\n        this.subclass \u003d subclass;\n    }\n\n    public void testInfoParameters() throws Exception {\n        Constructor\u003cT\u003e ctor \u003d longestCtor(subclass);\n        Object[] nodeCtorArgs \u003d ctorArgs(ctor);\n        T node \u003d ctor.newInstance(nodeCtorArgs);\n        /*\n         * The count should be the same size as the longest constructor\n         * by convention. If it isn\u0027t then we\u0027re missing something.\n         */\n        int expectedCount \u003d ctor.getParameterCount();\n        /*\n         * Except the first `Location` argument of the ctor is implicit\n         * in the parameters and not included.\n         */\n        expectedCount -\u003d 1;\n        assertEquals(expectedCount, node.info().properties().size());\n    }\n\n    /**\n     * Test {@link Node#transformPropertiesOnly(Class, java.util.function.Function)}\n     * implementation on {@link #subclass} which tests the implementation of\n     * {@link Node#info()}. And tests the actual {@link NodeInfo} subclass\n     * implementations in the process.\n     */\n    public void testTransform() throws Exception {\n        Constructor\u003cT\u003e ctor \u003d longestCtor(subclass);\n        Object[] nodeCtorArgs \u003d ctorArgs(ctor);\n        T node \u003d ctor.newInstance(nodeCtorArgs);\n\n        Type[] argTypes \u003d ctor.getGenericParameterTypes();\n        // start at 1 because we can\u0027t change Location.\n        for (int changedArgOffset \u003d 1; changedArgOffset \u003c ctor.getParameterCount(); changedArgOffset++) {\n            Object originalArgValue \u003d nodeCtorArgs[changedArgOffset];\n\n            Type changedArgType \u003d argTypes[changedArgOffset];\n            Object changedArgValue \u003d randomValueOtherThanMaxTries(\n                nodeCtorArgs[changedArgOffset],\n                () -\u003e makeArg(changedArgType),\n                // JoinType has only 1 permitted enum element. Limit the number of retries.\n                3\n            );\n\n            B transformed \u003d node.transformNodeProps(Object.class, prop -\u003e Objects.equals(prop, originalArgValue) ? changedArgValue : prop);\n\n            if (node.children().contains(originalArgValue) || node.children().equals(originalArgValue)) {\n                if (node.children().equals(emptyList()) \u0026\u0026 originalArgValue.equals(emptyList())) {\n                    /*\n                     * If the children are an empty list and the value\n                     * we want to change is an empty list they\u0027ll be\n                     * equal to one another so they\u0027ll come on this branch.\n                     * This case is rare and hard to reason about so we\u0027re\n                     * just going to assert nothing here and hope to catch\n                     * it when we write non-reflection hack tests.\n                     */\n                    continue;\n                }\n                // Transformation shouldn\u0027t apply to children.\n                assertSame(node, transformed);\n            } else {\n                assertTransformedOrReplacedChildren(node, transformed, ctor, nodeCtorArgs, changedArgOffset, changedArgValue);\n            }\n        }\n    }\n\n    /**\n     * Test {@link Node#replaceChildren(List)} implementation on {@link #subclass}.\n     */\n    public void testReplaceChildren() throws Exception {\n        Constructor\u003cT\u003e ctor \u003d longestCtor(subclass);\n        Object[] nodeCtorArgs \u003d ctorArgs(ctor);\n        T node \u003d ctor.newInstance(nodeCtorArgs);\n\n        Type[] argTypes \u003d ctor.getGenericParameterTypes();\n        // start at 1 because we can\u0027t change Location.\n        for (int changedArgOffset \u003d 1; changedArgOffset \u003c ctor.getParameterCount(); changedArgOffset++) {\n            Object originalArgValue \u003d nodeCtorArgs[changedArgOffset];\n            Type changedArgType \u003d argTypes[changedArgOffset];\n\n            if (originalArgValue instanceof Collection\u003c?\u003e col) {\n\n                if (col.isEmpty() || col instanceof EnumSet) {\n                    /*\n                     * We skip empty lists here because they\u0027ll spuriously\n                     * pass the conditions below if statements even if they don\u0027t\n                     * have anything to do with children. This might cause us to\n                     * ignore the case where a parameter gets copied into the\n                     * children and just happens to be empty but I don\u0027t really\n                     * know another way.\n                     */\n\n                    continue;\n                }\n\n                if (col instanceof List\u003c?\u003e originalList \u0026\u0026 node.children().equals(originalList)) {\n                    // The arg we\u0027re looking at *is* the children\n                    @SuppressWarnings(\"unchecked\") // we pass a reasonable type so get reasonable results\n                    List\u003cB\u003e newChildren \u003d (List\u003cB\u003e) makeListOfSameSizeOtherThan(changedArgType, originalList);\n                    B transformed \u003d node.replaceChildren(newChildren);\n                    assertTransformedOrReplacedChildren(node, transformed, ctor, nodeCtorArgs, changedArgOffset, newChildren);\n                } else if (false \u003d\u003d col.isEmpty() \u0026\u0026 node.children().containsAll(col)) {\n                    // The arg we\u0027re looking at is a collection contained within the children\n                    List\u003c?\u003e originalList \u003d (List\u003c?\u003e) originalArgValue;\n\n                    // First make the new children\n                    @SuppressWarnings(\"unchecked\") // we pass a reasonable type so get reasonable results\n                    List\u003cB\u003e newCollection \u003d (List\u003cB\u003e) makeListOfSameSizeOtherThan(changedArgType, originalList);\n\n                    // Now merge that list of children into the original list of children\n                    List\u003cB\u003e originalChildren \u003d node.children();\n                    List\u003cB\u003e newChildren \u003d new ArrayList\u003c\u003e(originalChildren.size());\n                    int originalOffset \u003d 0;\n                    for (int i \u003d 0; i \u003c originalChildren.size(); i++) {\n                        if (originalOffset \u003c originalList.size() \u0026\u0026 originalChildren.get(i).equals(originalList.get(originalOffset))) {\n                            newChildren.add(newCollection.get(originalOffset));\n                            originalOffset++;\n                        } else {\n                            newChildren.add(originalChildren.get(i));\n                        }\n                    }\n\n                    // Finally! We can assert.....\n                    B transformed \u003d node.replaceChildren(newChildren);\n                    assertTransformedOrReplacedChildren(node, transformed, ctor, nodeCtorArgs, changedArgOffset, newCollection);\n                } else {\n                    // The arg we\u0027re looking at has nothing to do with the children\n                }\n            } else {\n                if (node.children().contains(originalArgValue)) {\n                    // The arg we\u0027re looking at is one of the children\n                    List\u003cB\u003e newChildren \u003d new ArrayList\u003c\u003e(node.children());\n                    @SuppressWarnings(\"unchecked\") // makeArg produced reasonable values\n                    B newChild \u003d (B) randomValueOtherThan(nodeCtorArgs[changedArgOffset], () -\u003e makeArg(changedArgType));\n                    newChildren.replaceAll(e -\u003e Objects.equals(originalArgValue, e) ? newChild : e);\n                    B transformed \u003d node.replaceChildren(newChildren);\n                    assertTransformedOrReplacedChildren(node, transformed, ctor, nodeCtorArgs, changedArgOffset, newChild);\n                } else {\n                    // The arg we\u0027re looking at has nothing to do with the children\n                }\n            }\n        }\n    }\n\n    private void assertTransformedOrReplacedChildren(\n        T node,\n        B transformed,\n        Constructor\u003cT\u003e ctor,\n        Object[] nodeCtorArgs,\n        int changedArgOffset,\n        Object changedArgValue\n    ) throws Exception {\n        if (node instanceof Function) {\n            /*\n             * Functions have a weaker definition of transform then other\n             * things:\n             *\n             * Transforming using the way we did above should only change\n             * the one property of the node that we intended to transform.\n             */\n            assertEquals(node.source(), transformed.source());\n            List\u003cObject\u003e op \u003d node.nodeProperties();\n            List\u003cObject\u003e tp \u003d transformed.nodeProperties();\n            for (int p \u003d 0; p \u003c op.size(); p++) {\n                if (p \u003d\u003d changedArgOffset - 1) { // -1 because location isn\u0027t in the list\n                    assertEquals(changedArgValue, tp.get(p));\n                } else {\n                    assertEquals(op.get(p), tp.get(p));\n                }\n            }\n        } else {\n            /*\n             * The stronger assertion for all non-Functions: transforming\n             * a node changes *only* the transformed value such that you\n             * can rebuild a copy of the node using its constructor changing\n             * only one argument and it\u0027ll be *equal* to the result of the\n             * transformation.\n             */\n            Type[] argTypes \u003d ctor.getGenericParameterTypes();\n            Object[] args \u003d new Object[argTypes.length];\n            for (int i \u003d 0; i \u003c argTypes.length; i++) {\n                args[i] \u003d nodeCtorArgs[i] \u003d\u003d nodeCtorArgs[changedArgOffset] ? changedArgValue : nodeCtorArgs[i];\n            }\n            T reflectionTransformed \u003d ctor.newInstance(args);\n            assertEquals(reflectionTransformed, transformed);\n        }\n    }\n\n    /**\n     * Find the longest constructor of the given class.\n     * By convention, for all subclasses of {@link Node},\n     * this constructor should have \"all\" of the state of\n     * the node. All other constructors should all delegate\n     * to this constructor.\n     */\n    static \u003cT\u003e Constructor\u003cT\u003e longestCtor(Class\u003cT\u003e clazz) {\n        Constructor\u003cT\u003e longest \u003d null;\n        for (Constructor\u003c?\u003e ctor : clazz.getConstructors()) {\n            if (longest \u003d\u003d null || longest.getParameterCount() \u003c ctor.getParameterCount()) {\n                @SuppressWarnings(\"unchecked\") // Safe because the ctor has to be a ctor for T\n                Constructor\u003cT\u003e castCtor \u003d (Constructor\u003cT\u003e) ctor;\n                longest \u003d castCtor;\n            }\n        }\n        if (longest \u003d\u003d null) {\n            throw new IllegalArgumentException(\"Couldn\u0027t find any constructors for [\" + clazz.getName() + \"]\");\n        }\n        return longest;\n    }\n\n    /**\n     * Scans the {@code .class} files to identify all classes and\n     * checks if they are subclasses of {@link Node}.\n     */\n    @ParametersFactory\n    @SuppressWarnings(\"rawtypes\")\n    public static List\u003cObject[]\u003e nodeSubclasses() throws IOException {\n        return subclassesOf(Node.class, CLASSNAME_FILTER).stream()\n            .filter(c -\u003e testClassFor(c) \u003d\u003d null)\n            .map(c -\u003e new Object[] { c })\n            .toList();\n    }\n\n    /**\n     * Build a list of arguments to use when calling\n     * {@code ctor} that make sense when {@code ctor}\n     * builds subclasses of {@link Node}.\n     */\n    private Object[] ctorArgs(Constructor\u003c? extends Node\u003c?\u003e\u003e ctor) throws Exception {\n        Type[] argTypes \u003d ctor.getGenericParameterTypes();\n        Object[] args \u003d new Object[argTypes.length];\n        for (int i \u003d 0; i \u003c argTypes.length; i++) {\n            final int currentArgIndex \u003d i;\n            args[i] \u003d randomValueOtherThanMany(candidate -\u003e {\n                for (int a \u003d 0; a \u003c currentArgIndex; a++) {\n                    if (Objects.equals(args[a], candidate)) {\n                        return true;\n                    }\n                }\n                return false;\n            }, () -\u003e {\n                try {\n                    return makeArg(ctor.getDeclaringClass(), argTypes[currentArgIndex]);\n                } catch (Exception e) {\n                    throw new RuntimeException(e);\n                }\n            });\n        }\n        return args;\n    }\n\n    /**\n     * Make an argument to feed the {@link #subclass}\u0027s ctor.\n     */\n    protected Object makeArg(Type argType) {\n        try {\n            return makeArg(subclass, argType);\n        } catch (Exception e) {\n            // Wrap to make `randomValueOtherThan` happy.\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Make an argument to feed to the constructor for {@code toBuildClass}.\n     */\n    @SuppressWarnings(\"unchecked\")\n    private Object makeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Type argType) throws Exception {\n\n        if (argType instanceof ParameterizedType pt) {\n            if (pt.getRawType() \u003d\u003d Map.class) {\n                return makeMap(toBuildClass, pt);\n            }\n            if (pt.getRawType() \u003d\u003d List.class) {\n                return makeList(toBuildClass, pt);\n            }\n            if (pt.getRawType() \u003d\u003d Set.class) {\n                return makeSet(toBuildClass, pt);\n            }\n            if (pt.getRawType() \u003d\u003d EnumSet.class) {\n                @SuppressWarnings(\"rawtypes\")\n                Enum enm \u003d (Enum) makeArg(toBuildClass, pt.getActualTypeArguments()[0]);\n                return EnumSet.of(enm);\n            }\n            Object obj \u003d pluggableMakeParameterizedArg(toBuildClass, pt);\n            if (obj !\u003d null) {\n                return obj;\n            }\n            throw new IllegalArgumentException(\"Unsupported parameterized type [\" + pt + \"], for \" + toBuildClass.getSimpleName());\n        }\n        if (argType instanceof WildcardType wt) {\n            if (wt.getLowerBounds().length \u003e 0 || wt.getUpperBounds().length \u003e 1) {\n                throw new IllegalArgumentException(\"Unsupported wildcard type [\" + wt + \"]\");\n            }\n            return makeArg(toBuildClass, wt.getUpperBounds()[0]);\n        }\n        Class\u003c?\u003e argClass \u003d (Class\u003c?\u003e) argType;\n\n        /*\n         * Sometimes all of the required type information isn\u0027t in the ctor\n         * so we have to hard code it here.\n         */\n        if (toBuildClass \u003d\u003d FieldAttribute.class) {\n            // `parent` is nullable.\n            if (argClass \u003d\u003d FieldAttribute.class \u0026\u0026 randomBoolean()) {\n                return null;\n            }\n        } else if (toBuildClass \u003d\u003d ChildrenAreAProperty.class) {\n            /*\n             * While any subclass of DummyFunction will do here we want to prevent\n             * stack overflow so we use the one without children.\n             */\n            if (argClass \u003d\u003d Dummy.class) {\n                return makeNode(NoChildren.class);\n            }\n        } else if (FullTextPredicate.class.isAssignableFrom(toBuildClass)) {\n            /*\n             * FullTextPredicate analyzes its string arguments on\n             * construction so they have to be valid.\n             */\n            if (argClass \u003d\u003d String.class) {\n                int size \u003d between(0, 5);\n                StringBuilder b \u003d new StringBuilder();\n                for (int i \u003d 0; i \u003c size; i++) {\n                    if (i !\u003d 0) {\n                        b.append(\u0027;\u0027);\n                    }\n                    b.append(randomAlphaOfLength(5)).append(\u0027\u003d\u0027).append(randomAlphaOfLength(5));\n                }\n                return b.toString();\n            }\n        } else if (toBuildClass \u003d\u003d Like.class) {\n\n            if (argClass \u003d\u003d LikePattern.class) {\n                return new LikePattern(randomAlphaOfLength(16), randomFrom(\u0027\\\\\u0027, \u0027|\u0027, \u0027/\u0027, \u0027`\u0027));\n            }\n\n        } else {\n            Object postProcess \u003d pluggableMakeArg(toBuildClass, argClass);\n            if (postProcess !\u003d null) {\n                return postProcess;\n            }\n        }\n        if (Expression.class \u003d\u003d argClass) {\n            /*\n             * Rather than use any old subclass of expression lets\n             * use a simple one. Without this we\u0027re very prone to\n             * stackoverflow errors while building the tree.\n             */\n            return UnresolvedAttributeTests.randomUnresolvedAttribute();\n        }\n        if (EnrichPolicy.class \u003d\u003d argClass) {\n            List\u003cString\u003e enrichFields \u003d randomSubsetOf(List.of(\"e1\", \"e2\", \"e3\"));\n            return new EnrichPolicy(randomFrom(\"match\", \"range\"), null, List.of(), randomFrom(\"m1\", \"m2\"), enrichFields);\n        }\n\n        if (Node.class.isAssignableFrom(argClass)) {\n            /*\n             * Rather than attempting to mock subclasses of node\n             * and emulate them we just try and instantiate an\n             * appropriate subclass\n             */\n            @SuppressWarnings(\"unchecked\") // safe because this is the lowest possible bounds for Node\n            Class\u003c? extends Node\u003c?\u003e\u003e asNodeSubclass \u003d (Class\u003c? extends Node\u003c?\u003e\u003e) argType;\n            return makeNode(asNodeSubclass);\n        }\n\n        if (argClass.isEnum()) {\n            // Can\u0027t mock enums but luckily we can just pick one\n            return randomFrom(argClass.getEnumConstants());\n        }\n        if (argClass \u003d\u003d boolean.class) {\n            // Can\u0027t mock primitives....\n            return randomBoolean();\n        }\n        if (argClass \u003d\u003d int.class) {\n            return randomInt();\n        }\n        if (argClass \u003d\u003d String.class) {\n            // Nor strings\n            return randomAlphaOfLength(5);\n        }\n        if (argClass \u003d\u003d Source.class) {\n            // Location is final and can\u0027t be mocked but we have a handy method to generate ones.\n            return SourceTests.randomSource();\n        }\n        if (argClass \u003d\u003d ZoneId.class) {\n            // ZoneId is a sealed class (cannot be mocked) starting with Java 19\n            return randomZone();\n        }\n        try {\n            return mock(argClass);\n        } catch (MockitoException e) {\n            throw new RuntimeException(\"failed to mock [\" + argClass.getName() + \"] for [\" + toBuildClass.getName() + \"]\", e);\n        }\n    }\n\n    protected Object pluggableMakeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Class\u003c?\u003e argClass) throws Exception {\n        return null;\n    }\n\n    protected Object pluggableMakeParameterizedArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt) {\n        return null;\n    }\n\n    private List\u003c?\u003e makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType) throws Exception {\n        return makeList(toBuildClass, listType, randomSizeForCollection(toBuildClass));\n    }\n\n    private List\u003c?\u003e makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size) throws Exception {\n        List\u003cObject\u003e list \u003d new ArrayList\u003c\u003e();\n        for (int i \u003d 0; i \u003c size; i++) {\n            list.add(makeArg(toBuildClass, listType.getActualTypeArguments()[0]));\n        }\n        return list;\n    }\n\n    private Set\u003c?\u003e makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType) throws Exception {\n        return makeSet(toBuildClass, listType, randomSizeForCollection(toBuildClass));\n    }\n\n    private Set\u003c?\u003e makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size) throws Exception {\n        Set\u003cObject\u003e list \u003d new HashSet\u003c\u003e();\n        for (int i \u003d 0; i \u003c size; i++) {\n            list.add(makeArg(toBuildClass, listType.getActualTypeArguments()[0]));\n        }\n        return list;\n    }\n\n    private Object makeMap(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt) throws Exception {\n        Map\u003cObject, Object\u003e map \u003d new HashMap\u003c\u003e();\n        int size \u003d randomSizeForCollection(toBuildClass);\n        while (map.size() \u003c size) {\n            Object key \u003d makeArg(toBuildClass, pt.getActualTypeArguments()[0]);\n            Object value \u003d makeArg(toBuildClass, pt.getActualTypeArguments()[1]);\n            map.put(key, value);\n        }\n        return map;\n    }\n\n    private int randomSizeForCollection(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass) {\n        int minCollectionLength \u003d 0;\n        int maxCollectionLength \u003d 10;\n\n        if (hasAtLeastTwoChildren(toBuildClass)) {\n            minCollectionLength \u003d 2;\n        }\n        return between(minCollectionLength, maxCollectionLength);\n    }\n\n    protected boolean hasAtLeastTwoChildren(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass) {\n        return CLASSES_WITH_MIN_TWO_CHILDREN.stream().anyMatch(toBuildClass::equals);\n    }\n\n    private List\u003c?\u003e makeListOfSameSizeOtherThan(Type listType, List\u003c?\u003e original) throws Exception {\n        if (original.isEmpty()) {\n            throw new IllegalArgumentException(\"Can\u0027t make a different empty list\");\n        }\n        return randomValueOtherThan(original, () -\u003e {\n            try {\n                return makeList(subclass, (ParameterizedType) listType, original.size());\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        });\n\n    }\n\n    public \u003cT extends Node\u003c?\u003e\u003e T makeNode(Class\u003c? extends T\u003e nodeClass) throws Exception {\n        if (Modifier.isAbstract(nodeClass.getModifiers())) {\n            nodeClass \u003d randomFrom(innerSubclassesOf(nodeClass));\n        }\n        Class\u003c?\u003e testSubclassFor \u003d testClassFor(nodeClass);\n        if (testSubclassFor !\u003d null) {\n            // Delegate to the test class for a node if there is one\n            Method m \u003d testSubclassFor.getMethod(\"random\" + Strings.capitalize(nodeClass.getSimpleName()));\n            assert Modifier.isStatic(m.getModifiers()) : \"Expected static method, got:\" + m;\n            return nodeClass.cast(m.invoke(null));\n        }\n        Constructor\u003c? extends T\u003e ctor \u003d longestCtor(nodeClass);\n        Object[] nodeCtorArgs \u003d ctorArgs(ctor);\n        return ctor.newInstance(nodeCtorArgs);\n    }\n\n    /**\n     * Cache of subclasses. We use a cache because it significantly speeds up\n     * the test.\n     */\n    private static final Map\u003cClass\u003c?\u003e, Set\u003c?\u003e\u003e subclassCache \u003d new HashMap\u003c\u003e();\n\n    private static final Predicate\u003cString\u003e CLASSNAME_FILTER \u003d className -\u003e {\n        // filter the class that are not interested\n        // (and IDE folders like eclipse)\n        if (className.startsWith(\"org.elasticsearch.xpack.esql.core\") \u003d\u003d false\n            \u0026\u0026 className.startsWith(\"org.elasticsearch.xpack.sql\") \u003d\u003d false\n            \u0026\u0026 className.startsWith(\"org.elasticsearch.xpack.eql\") \u003d\u003d false) {\n            return false;\n        }\n        return true;\n    };\n\n    protected Predicate\u003cString\u003e pluggableClassNameFilter() {\n        return CLASSNAME_FILTER;\n    }\n\n    private \u003cT\u003e Set\u003cClass\u003c? extends T\u003e\u003e innerSubclassesOf(Class\u003cT\u003e clazz) throws IOException {\n        return subclassesOf(clazz, pluggableClassNameFilter());\n    }\n\n    public static \u003cT\u003e Set\u003cClass\u003c? extends T\u003e\u003e subclassesOf(Class\u003cT\u003e clazz) throws IOException {\n        return subclassesOf(clazz, CLASSNAME_FILTER);\n    }\n\n    /**\n     * Find all subclasses of a particular class.\n     */\n    public static \u003cT\u003e Set\u003cClass\u003c? extends T\u003e\u003e subclassesOf(Class\u003cT\u003e clazz, Predicate\u003cString\u003e classNameFilter) throws IOException {\n        @SuppressWarnings(\"unchecked\") // The map is built this way\n        Set\u003cClass\u003c? extends T\u003e\u003e lookup \u003d (Set\u003cClass\u003c? extends T\u003e\u003e) subclassCache.get(clazz);\n        if (lookup !\u003d null) {\n            return lookup;\n        }\n        Set\u003cClass\u003c? extends T\u003e\u003e results \u003d new LinkedHashSet\u003c\u003e();\n        String[] paths \u003d System.getProperty(\"java.class.path\").split(System.getProperty(\"path.separator\"));\n        for (String path : paths) {\n            Path root \u003d PathUtils.get(path);\n            int rootLength \u003d root.toString().length() + 1;\n\n            // load classes from jar files\n            // NIO FileSystem API is not used since it trips the SecurityManager\n            // https://bugs.openjdk.java.net/browse/JDK-8160798\n            // so iterate the jar \"by hand\"\n            if (path.endsWith(\".jar\") \u0026\u0026 path.contains(\"x-pack-ql\")) {\n                try (JarInputStream jar \u003d jarStream(root)) {\n                    JarEntry je \u003d null;\n                    while ((je \u003d jar.getNextJarEntry()) !\u003d null) {\n                        String name \u003d je.getName();\n                        if (name.endsWith(\".class\")) {\n                            String className \u003d name.substring(0, name.length() - \".class\".length()).replace(\"/\", \".\");\n                            maybeLoadClass(clazz, className, root + \"!/\" + name, classNameFilter, results);\n                        }\n                    }\n                }\n            }\n            // for folders, just use the FileSystems API\n            else {\n                Files.walkFileTree(root, new SimpleFileVisitor\u003c\u003e() {\n                    @Override\n                    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\n                        if (Files.isRegularFile(file) \u0026\u0026 file.getFileName().toString().endsWith(\".class\")) {\n                            String fileName \u003d file.toString();\n                            // Chop off the root and file extension\n                            String className \u003d fileName.substring(rootLength, fileName.length() - \".class\".length());\n                            // Go from \"path\" style to class style\n                            className \u003d className.replace(PathUtils.getDefaultFileSystem().getSeparator(), \".\");\n                            maybeLoadClass(clazz, className, fileName, classNameFilter, results);\n                        }\n                        return FileVisitResult.CONTINUE;\n                    }\n                });\n            }\n        }\n        subclassCache.put(clazz, results);\n        return results;\n    }\n\n    @SuppressForbidden(reason \u003d \"test reads from jar\")\n    private static JarInputStream jarStream(Path path) throws IOException {\n        return new JarInputStream(path.toUri().toURL().openStream());\n    }\n\n    /**\n     * Load classes from predefined packages (hack to limit the scope) and if they match the hierarchy, add them to the cache\n     */\n    private static \u003cT\u003e void maybeLoadClass(\n        Class\u003cT\u003e clazz,\n        String className,\n        String location,\n        Predicate\u003cString\u003e classNameFilter,\n        Set\u003cClass\u003c? extends T\u003e\u003e results\n    ) throws IOException {\n        if (classNameFilter.test(className) \u003d\u003d false) {\n            return;\n        }\n\n        Class\u003c?\u003e c;\n        try {\n            c \u003d Class.forName(className);\n        } catch (ClassNotFoundException e) {\n            throw new IOException(\"Couldn\u0027t load \" + location, e);\n        }\n\n        if (false \u003d\u003d Modifier.isAbstract(c.getModifiers()) \u0026\u0026 false \u003d\u003d c.isAnonymousClass() \u0026\u0026 clazz.isAssignableFrom(c)) {\n            Class\u003c? extends T\u003e s \u003d c.asSubclass(clazz);\n            results.add(s);\n        }\n    }\n\n    /**\n     * The test class for some subclass of node or {@code null}\n     * if there isn\u0027t such a class or it doesn\u0027t extend\n     * {@link AbstractNodeTestCase}.\n     */\n    protected static Class\u003c?\u003e testClassFor(Class\u003c?\u003e nodeSubclass) {\n        String testClassName \u003d nodeSubclass.getName() + \"Tests\";\n        try {\n            Class\u003c?\u003e c \u003d Class.forName(testClassName);\n            if (AbstractNodeTestCase.class.isAssignableFrom(c)) {\n                return c;\n            }\n            return null;\n        } catch (ClassNotFoundException e) {\n            return null;\n        }\n    }\n\n    private static \u003cT\u003e T randomValueOtherThanManyMaxTries(Predicate\u003cT\u003e input, Supplier\u003cT\u003e randomSupplier, int maxTries) {\n        int[] maxTriesHolder \u003d { maxTries };\n        Predicate\u003cT\u003e inputWithMaxTries \u003d t -\u003e input.test(t) \u0026\u0026 maxTriesHolder[0]-- \u003e 0;\n\n        return ESTestCase.randomValueOtherThanMany(inputWithMaxTries, randomSupplier);\n    }\n\n    public static \u003cT\u003e T randomValueOtherThanMaxTries(T input, Supplier\u003cT\u003e randomSupplier, int maxTries) {\n        return randomValueOtherThanManyMaxTries(v -\u003e Objects.equals(input, v), randomSupplier, maxTries);\n    }\n}","methodCount":31},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":714,"lineEnd":716,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomValueOtherThanMaxTries to class TestUtils","description":"move method randomValueOtherThanMaxTries to PsiClass:TestUtils\nRationale: The randomValueOtherThanMaxTries() method is a utility function that generates random values based on certain conditions, which aligns well with the existing utility methods in TestUtils. Moving it here adheres to the Single Responsibility Principle by consolidating random generation logic in one place, enhancing code organization and reuse. However, care must be taken to ensure that the method\u0027s dependencies are adequately managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":714,"lineEnd":716,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomValueOtherThanMaxTries to class EsqlTestUtils","description":"move method randomValueOtherThanMaxTries to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils contains various utility methods related to testing and assertions, making it a suitable candidate for randomValueOtherThanMaxTries(). This relocation would enhance cohesion as both classes deal with test utilities. It also aligns with the Open/Closed Principle by allowing the class to be extended with more random value generation methods. A potential drawback is that it may introduce dependencies on the specific context of Esql testing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":714,"lineEnd":716,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomValueOtherThanMaxTries to class FunctionTestUtils","description":"move method randomValueOtherThanMaxTries to PsiClass:FunctionTestUtils\nRationale: FunctionTestUtils is focused on functions and utility methods related to testing. The randomValueOtherThanMaxTries() method fits well within this context, promoting reusability and organization of related functionality. This move supports the Single Responsibility Principle by keeping function-related utilities together. However, it may dilute the focus of FunctionTestUtils if it becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":301,"lineEnd":312,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method nodeSubclasses to class TestUtils","description":"move method nodeSubclasses to PsiClass:TestUtils\nRationale: The nodeSubclasses() method is utility-based and does not rely on instance state, making it suitable for a utility class. TestUtils already handles various utility methods for testing purposes, so this move enhances cohesion. It aligns with the Single Responsibility Principle by centralizing testing-related utilities. However, it may increase the size of TestUtils, which could affect maintainability if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":301,"lineEnd":312,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method nodeSubclasses to class EsqlTestUtils","description":"move method nodeSubclasses to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils is focused on testing-related functionalities, and the nodeSubclasses() method could support testing scenarios involving Node subclasses. This move would keep related functionalities together, adhering to the Open/Closed Principle by allowing for future enhancements without modifying existing code. The drawback could be that it may introduce unnecessary dependencies if EsqlTestUtils becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":301,"lineEnd":312,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method nodeSubclasses to class ResponseValueUtils","description":"move method nodeSubclasses to PsiClass:ResponseValueUtils\nRationale: ResponseValueUtils deals with data representation and manipulation, which can be relevant when working with Node subclasses in response contexts. Moving nodeSubclasses() here can improve cohesion by grouping related functionalities. This aligns with the Interface Segregation Principle by keeping utility methods focused on specific operations, although it may confuse the purpose of ResponseValueUtils if not clearly documented.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"testInfoParameters","method_signature":"public testInfoParameters()","target_class":"","rationale":""},{"method_name":"testTransform","method_signature":"public testTransform()","target_class":"","rationale":""},{"method_name":"testReplaceChildren","method_signature":"public testReplaceChildren()","target_class":"","rationale":""},{"method_name":"assertTransformedOrReplacedChildren","method_signature":"private assertTransformedOrReplacedChildren(\n        T node,\n        B transformed,\n        Constructor\u003cT\u003e ctor,\n        Object[] nodeCtorArgs,\n        int changedArgOffset,\n        Object changedArgValue\n    )","target_class":"","rationale":""},{"method_name":"longestCtor","method_signature":"static longestCtor(Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"nodeSubclasses","method_signature":"@ParametersFactory\n    @SuppressWarnings(\"rawtypes\")\n    public static nodeSubclasses()","target_class":"","rationale":""},{"method_name":"ctorArgs","method_signature":"private ctorArgs(Constructor\u003c? extends Node\u003c?\u003e\u003e ctor)","target_class":"","rationale":""},{"method_name":"makeArg","method_signature":"protected makeArg(Type argType)","target_class":"","rationale":""},{"method_name":"makeArg","method_signature":"@SuppressWarnings(\"unchecked\")\n    private makeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Type argType)","target_class":"","rationale":""},{"method_name":"pluggableMakeArg","method_signature":"protected pluggableMakeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Class\u003c?\u003e argClass)","target_class":"","rationale":""},{"method_name":"pluggableMakeParameterizedArg","method_signature":"protected pluggableMakeParameterizedArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},{"method_name":"makeList","method_signature":"private makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},{"method_name":"makeList","method_signature":"private makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size)","target_class":"","rationale":""},{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size)","target_class":"","rationale":""},{"method_name":"makeMap","method_signature":"private makeMap(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},{"method_name":"randomSizeForCollection","method_signature":"private randomSizeForCollection(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass)","target_class":"","rationale":""},{"method_name":"hasAtLeastTwoChildren","method_signature":"protected hasAtLeastTwoChildren(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass)","target_class":"","rationale":""},{"method_name":"makeListOfSameSizeOtherThan","method_signature":"private makeListOfSameSizeOtherThan(Type listType, List\u003c?\u003e original)","target_class":"","rationale":""},{"method_name":"makeNode","method_signature":"public makeNode(Class\u003c? extends T\u003e nodeClass)","target_class":"","rationale":""},{"method_name":"innerSubclassesOf","method_signature":"private innerSubclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"subclassesOf","method_signature":"public static subclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"jarStream","method_signature":"@SuppressForbidden(reason \u003d \"test reads from jar\")\n    private static jarStream(Path path)","target_class":"","rationale":""},{"method_name":"maybeLoadClass","method_signature":"private static maybeLoadClass(\n        Class\u003cT\u003e clazz,\n        String className,\n        String location,\n        Predicate\u003cString\u003e classNameFilter,\n        Set\u003cClass\u003c? extends T\u003e\u003e results\n    )","target_class":"","rationale":""},{"method_name":"testClassFor","method_signature":"protected static testClassFor(Class\u003c?\u003e nodeSubclass)","target_class":"","rationale":""},{"method_name":"randomValueOtherThanManyMaxTries","method_signature":"private static randomValueOtherThanManyMaxTries(Predicate\u003cT\u003e input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""},{"method_name":"randomValueOtherThanMaxTries","method_signature":"public static randomValueOtherThanMaxTries(T input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"randomValueOtherThanMaxTries","method_signature":"public static randomValueOtherThanMaxTries(T input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""},{"method_name":"nodeSubclasses","method_signature":"@ParametersFactory\n    @SuppressWarnings(\"rawtypes\")\n    public static nodeSubclasses()","target_class":"","rationale":""},{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},{"method_name":"makeList","method_signature":"private makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},{"method_name":"randomValueOtherThanManyMaxTries","method_signature":"private static randomValueOtherThanManyMaxTries(Predicate\u003cT\u003e input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""},{"method_name":"innerSubclassesOf","method_signature":"private innerSubclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"subclassesOf","method_signature":"public static subclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},{"method_name":"makeMap","method_signature":"private makeMap(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},{"method_name":"testInfoParameters","method_signature":"public testInfoParameters()","target_class":"","rationale":""},{"method_name":"jarStream","method_signature":"@SuppressForbidden(reason \u003d \"test reads from jar\")\n    private static jarStream(Path path)","target_class":"","rationale":""},{"method_name":"hasAtLeastTwoChildren","method_signature":"protected hasAtLeastTwoChildren(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass)","target_class":"","rationale":""},{"method_name":"pluggableMakeParameterizedArg","method_signature":"protected pluggableMakeParameterizedArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},{"method_name":"pluggableMakeArg","method_signature":"protected pluggableMakeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Class\u003c?\u003e argClass)","target_class":"","rationale":""},{"method_name":"makeArg","method_signature":"protected makeArg(Type argType)","target_class":"","rationale":""},{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static randomValueOtherThanMaxTries(T input, Supplier\u003cT\u003e randomSupplier, int maxTries)":{"first":{"method_name":"randomValueOtherThanMaxTries","method_signature":"public static randomValueOtherThanMaxTries(T input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""},"second":0.3782170569698577},"@ParametersFactory\n    @SuppressWarnings(\"rawtypes\")\n    public static nodeSubclasses()":{"first":{"method_name":"nodeSubclasses","method_signature":"@ParametersFactory\n    @SuppressWarnings(\"rawtypes\")\n    public static nodeSubclasses()","target_class":"","rationale":""},"second":0.4017808658212667},"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)":{"first":{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},"second":0.4560301968262259},"private makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)":{"first":{"method_name":"makeList","method_signature":"private makeList(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType)","target_class":"","rationale":""},"second":0.4560545067679686},"private static randomValueOtherThanManyMaxTries(Predicate\u003cT\u003e input, Supplier\u003cT\u003e randomSupplier, int maxTries)":{"first":{"method_name":"randomValueOtherThanManyMaxTries","method_signature":"private static randomValueOtherThanManyMaxTries(Predicate\u003cT\u003e input, Supplier\u003cT\u003e randomSupplier, int maxTries)","target_class":"","rationale":""},"second":0.48245928151666123},"private innerSubclassesOf(Class\u003cT\u003e clazz)":{"first":{"method_name":"innerSubclassesOf","method_signature":"private innerSubclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},"second":0.48960427406812634},"public static subclassesOf(Class\u003cT\u003e clazz)":{"first":{"method_name":"subclassesOf","method_signature":"public static subclassesOf(Class\u003cT\u003e clazz)","target_class":"","rationale":""},"second":0.48964666108451754},"private makeMap(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)":{"first":{"method_name":"makeMap","method_signature":"private makeMap(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},"second":0.5117298014088332},"public testInfoParameters()":{"first":{"method_name":"testInfoParameters","method_signature":"public testInfoParameters()","target_class":"","rationale":""},"second":0.5206921897529911},"@SuppressForbidden(reason \u003d \"test reads from jar\")\n    private static jarStream(Path path)":{"first":{"method_name":"jarStream","method_signature":"@SuppressForbidden(reason \u003d \"test reads from jar\")\n    private static jarStream(Path path)","target_class":"","rationale":""},"second":0.5278017344641012},"protected hasAtLeastTwoChildren(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass)":{"first":{"method_name":"hasAtLeastTwoChildren","method_signature":"protected hasAtLeastTwoChildren(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass)","target_class":"","rationale":""},"second":0.5452356638969771},"protected pluggableMakeParameterizedArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)":{"first":{"method_name":"pluggableMakeParameterizedArg","method_signature":"protected pluggableMakeParameterizedArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType pt)","target_class":"","rationale":""},"second":0.5564211340403337},"protected pluggableMakeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Class\u003c?\u003e argClass)":{"first":{"method_name":"pluggableMakeArg","method_signature":"protected pluggableMakeArg(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, Class\u003c?\u003e argClass)","target_class":"","rationale":""},"second":0.5566657424650009},"protected makeArg(Type argType)":{"first":{"method_name":"makeArg","method_signature":"protected makeArg(Type argType)","target_class":"","rationale":""},"second":0.5731271450579396},"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size)":{"first":{"method_name":"makeSet","method_signature":"private makeSet(Class\u003c? extends Node\u003c?\u003e\u003e toBuildClass, ParameterizedType listType, int size)","target_class":"","rationale":""},"second":0.5749837518709391}},"llmMethodPriority":{"priority_method_names":["randomValueOtherThanMaxTries","nodeSubclasses","makeSet","makeList","randomValueOtherThanManyMaxTries","innerSubclassesOf","subclassesOf","makeMap","jarStream","hasAtLeastTwoChildren","pluggableMakeParameterizedArg","pluggableMakeArg","makeArg","makeSet","testInfoParameters"],"llm_response_time":4994},"targetClassMap":{"randomValueOtherThanMaxTries":{"target_classes":[{"class_name":"DateUtils","similarity_score":0.27541984343975917},{"class_name":"LoggingUtils","similarity_score":0.23328473740792174},{"class_name":"NumericUtilsTests","similarity_score":0.22107854647338576},{"class_name":"ParserUtils","similarity_score":0.36050828811180363},{"class_name":"ReflectionUtils","similarity_score":0.2790404591875126},{"class_name":"SourceUtils","similarity_score":0.19994668799052295},{"class_name":"TestUtils","similarity_score":0.3518339093534824},{"class_name":"TransportActionUtils","similarity_score":0.19883078532290083},{"class_name":"StringUtils","similarity_score":0.30974008100736644},{"class_name":"StringContainsRegex","similarity_score":0.31746031746031744},{"class_name":"FunctionTestUtils","similarity_score":0.34401648061622603},{"class_name":"CsvTestUtils","similarity_score":0.30434470399251784},{"class_name":"AnalyzerTestUtils","similarity_score":0.3886194482438796},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2383931743197989},{"class_name":"SerializationTestUtils","similarity_score":0.38249645051039255},{"class_name":"EsqlTestUtils","similarity_score":0.4063882148688849},{"class_name":"ExceptionUtils","similarity_score":0.14447872876615397},{"class_name":"PlannerUtils","similarity_score":0.3239437764950118},{"class_name":"NodeTests","similarity_score":0.37796447300922725},{"class_name":"Source","similarity_score":0.36355567073161277},{"class_name":"SourceTests","similarity_score":0.33071891388307384},{"class_name":"SpatialRelatesUtils","similarity_score":0.24487330623215772},{"class_name":"ResponseValueUtils","similarity_score":0.3385775965840738},{"class_name":"ResponseXContentUtils","similarity_score":0.31526575618851205},{"class_name":"Comparisons","similarity_score":0.2881613249891835},{"class_name":"JwkValidateUtil","similarity_score":0.26626055584936703},{"class_name":"JwkValidateUtilTests","similarity_score":0.3014796249054253},{"class_name":"JwtUtil","similarity_score":0.292239618096528},{"class_name":"CredentialsRedaction","similarity_score":0.282317561583358}],"target_classes_sorted_by_llm":["TestUtils","EsqlTestUtils","FunctionTestUtils","AnalyzerTestUtils","ResponseValueUtils","SerializationTestUtils","ParserUtils","Source","NodeTests","SourceTests"],"llm_response_time":26059,"similarity_computation_time":22,"similarity_metric":"voyage"},"nodeSubclasses":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.2970442628930023},{"class_name":"TestUtils","similarity_score":0.3977738253647514},{"class_name":"TransportActionUtils","similarity_score":0.3719783383107478},{"class_name":"LoggingUtils","similarity_score":0.20003306604965967},{"class_name":"SourceUtils","similarity_score":0.36575342323946536},{"class_name":"DateUtils","similarity_score":0.3386016272631634},{"class_name":"StringContainsRegex","similarity_score":0.3365511935193492},{"class_name":"StringUtils","similarity_score":0.3181407386105177},{"class_name":"ReflectionUtils","similarity_score":0.2847473987257497},{"class_name":"NumericUtilsTests","similarity_score":0.2485778308077207},{"class_name":"ParserUtils","similarity_score":0.32297569699316747},{"class_name":"AnalyzerTestUtils","similarity_score":0.3297043740550191},{"class_name":"SerializationTestUtils","similarity_score":0.32342839987955335},{"class_name":"LuceneComponent2DUtils","similarity_score":0.3910516499263398},{"class_name":"EsqlTestUtils","similarity_score":0.4306151041308466},{"class_name":"ExceptionUtils","similarity_score":0.3491309788397344},{"class_name":"CsvTestUtils","similarity_score":0.40862748157804},{"class_name":"Source","similarity_score":0.342651517422791},{"class_name":"SourceTests","similarity_score":0.3339115355603141},{"class_name":"SpatialRelatesUtils","similarity_score":0.4531092752207737},{"class_name":"NodeTests","similarity_score":0.35735503995449175},{"class_name":"ResponseValueUtils","similarity_score":0.43301639885833626},{"class_name":"ResponseXContentUtils","similarity_score":0.44449315335405915},{"class_name":"PlannerUtils","similarity_score":0.4974982412851524},{"class_name":"InComparisons","similarity_score":0.37212791772689335},{"class_name":"FunctionRegistry","similarity_score":0.394150396781293},{"class_name":"FunctionRegistryTests","similarity_score":0.29736974442493835},{"class_name":"IndexerUtils","similarity_score":0.3635560026911103},{"class_name":"JwkValidateUtil","similarity_score":0.3339937945020229}],"target_classes_sorted_by_llm":["TestUtils","EsqlTestUtils","ResponseValueUtils","FunctionRegistry","PlannerUtils","SpatialRelatesUtils","LuceneComponent2DUtils","CsvTestUtils","ResponseXContentUtils","InComparisons"],"llm_response_time":11884,"similarity_computation_time":18,"similarity_metric":"voyage"},"makeSet":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":580,"similarity_computation_time":1,"similarity_metric":"voyage"}}}
{"id":"f49f9b08-2bca-491b-bbb6-66ffdf9a97db","methodCount":134,"hostFunctionTelemetryData":{"hostFunctionSize":1948,"lineStart":65,"lineEnd":2012,"bodyLineStart":65,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/server/src/main/java/org/elasticsearch/index/translog/Translog.java","sourceCode":"/**\n * A Translog is a per index shard component that records all non-committed index operations in a durable manner.\n * In Elasticsearch there is one Translog instance per {@link org.elasticsearch.index.engine.InternalEngine}.\n * Additionally, since Elasticsearch 2.0 the engine also records a {@link #TRANSLOG_UUID_KEY} with each commit to ensure a strong\n * association between the lucene index an the transaction log file. This UUID is used to prevent accidental recovery from a transaction\n * log that belongs to a\n * different engine.\n * \u003cp\u003e\n * Each Translog has only one translog file open for writes at any time referenced by a translog generation ID. This ID is written to a\n * {@code translog.ckp} file that is designed to fit in a single disk block such that a write of the file is atomic. The checkpoint file\n * is written on each fsync operation of the translog and records the number of operations written, the current translog\u0027s file generation,\n * its fsynced offset in bytes, and other important statistics.\n * \u003c/p\u003e\n * \u003cp\u003e\n * When the current translog file reaches a certain size ({@link IndexSettings#INDEX_TRANSLOG_GENERATION_THRESHOLD_SIZE_SETTING}, or when\n * a clear separation between old and new operations (upon change in primary term), the current file is reopened for read only and a new\n * write only file is created. Any non-current, read only translog file always has a {@code translog-${gen}.ckp} associated with it\n * which is an fsynced copy of its last {@code translog.ckp} such that in disaster recovery last fsynced offsets, number of\n * operation etc. are still preserved.\n * \u003c/p\u003e\n */\npublic class Translog extends AbstractIndexShardComponent implements IndexShardComponent, Closeable {\n\n    /*\n     * TODO\n     *  - we might need something like a deletion policy to hold on to more than one translog eventually (I think sequence IDs needs this)\n     *    but we can refactor as we go\n     *  - use a simple BufferedOutputStream to write stuff and fold BufferedTranslogWriter into it\u0027s super class... the tricky bit is we\n     *    need to be able to do random access reads even from the buffer\n     *  - we need random exception on the FileSystem API tests for all this.\n     *  - we need to page align the last write before we sync, we can take advantage of ensureSynced for this since we might have already\n     *    fsynced far enough\n     */\n    public static final String TRANSLOG_UUID_KEY \u003d \"translog_uuid\";\n    public static final String TRANSLOG_FILE_PREFIX \u003d \"translog-\";\n    public static final String TRANSLOG_FILE_SUFFIX \u003d \".tlog\";\n    public static final String CHECKPOINT_SUFFIX \u003d \".ckp\";\n    public static final String CHECKPOINT_FILE_NAME \u003d \"translog\" + CHECKPOINT_SUFFIX;\n\n    static final Pattern PARSE_STRICT_ID_PATTERN \u003d Pattern.compile(\"^\" + TRANSLOG_FILE_PREFIX + \"(\\\\d+)(\\\\.tlog)$\");\n    public static final int DEFAULT_HEADER_SIZE_IN_BYTES \u003d TranslogHeader.headerSizeInBytes(UUIDs.randomBase64UUID());\n\n    // the list of translog readers is guaranteed to be in order of translog generation\n    private final List\u003cTranslogReader\u003e readers \u003d new ArrayList\u003c\u003e();\n    private final BigArrays bigArrays;\n    private final DiskIoBufferPool diskIoBufferPool;\n    protected final Lock readLock;\n    protected final Lock writeLock;\n    private final Path location;\n    private TranslogWriter current;\n\n    protected final TragicExceptionHolder tragedy \u003d new TragicExceptionHolder();\n    private final AtomicBoolean closed \u003d new AtomicBoolean();\n    private final TranslogConfig config;\n    private final LongSupplier globalCheckpointSupplier;\n    private final LongSupplier primaryTermSupplier;\n    private final String translogUUID;\n    private final TranslogDeletionPolicy deletionPolicy;\n    private final LongConsumer persistedSequenceNumberConsumer;\n    private final OperationListener operationListener;\n\n    /**\n     * Creates a new Translog instance. This method will create a new transaction log unless the given {@link TranslogGeneration} is\n     * {@code null}. If the generation is {@code null} this method is destructive and will delete all files in the translog path given. If\n     * the generation is not {@code null}, this method tries to open the given translog generation. The generation is treated as the last\n     * generation referenced from already committed data. This means all operations that have not yet been committed should be in the\n     * translog file referenced by this generation. The translog creation will fail if this generation can\u0027t be opened.\n     *\n     * @param config                   the configuration of this translog\n     * @param translogUUID             the translog uuid to open, null for a new translog\n     * @param deletionPolicy           an instance of {@link TranslogDeletionPolicy} that controls when a translog file can be safely\n     *                                 deleted\n     * @param globalCheckpointSupplier a supplier for the global checkpoint\n     * @param primaryTermSupplier      a supplier for the latest value of primary term of the owning index shard. The latest term value is\n     *                                 examined and stored in the header whenever a new generation is rolled. It\u0027s guaranteed from outside\n     *                                 that a new generation is rolled when the term is increased. This guarantee allows to us to validate\n     *                                 and reject operation whose term is higher than the primary term stored in the translog header.\n     * @param persistedSequenceNumberConsumer a callback that\u0027s called whenever an operation with a given sequence number is successfully\n     *                                        persisted.\n     */\n    @SuppressWarnings(\"this-escape\")\n    public Translog(\n        final TranslogConfig config,\n        final String translogUUID,\n        TranslogDeletionPolicy deletionPolicy,\n        final LongSupplier globalCheckpointSupplier,\n        final LongSupplier primaryTermSupplier,\n        final LongConsumer persistedSequenceNumberConsumer\n    ) throws IOException {\n        super(config.getShardId(), config.getIndexSettings());\n        this.config \u003d config;\n        this.globalCheckpointSupplier \u003d globalCheckpointSupplier;\n        this.primaryTermSupplier \u003d primaryTermSupplier;\n        this.persistedSequenceNumberConsumer \u003d persistedSequenceNumberConsumer;\n        this.operationListener \u003d config.getOperationListener();\n        this.deletionPolicy \u003d deletionPolicy;\n        this.translogUUID \u003d translogUUID;\n        this.bigArrays \u003d config.getBigArrays();\n        this.diskIoBufferPool \u003d config.getDiskIoBufferPool();\n        var rwl \u003d new ReentrantReadWriteLock();\n        this.readLock \u003d rwl.readLock();\n        this.writeLock \u003d rwl.writeLock();\n        this.location \u003d config.getTranslogPath();\n        Files.createDirectories(this.location);\n\n        try {\n            final Checkpoint checkpoint \u003d readCheckpoint(location);\n            final Path nextTranslogFile \u003d location.resolve(getFilename(checkpoint.generation + 1));\n            final Path currentCheckpointFile \u003d location.resolve(getCommitCheckpointFileName(checkpoint.generation));\n            // this is special handling for error condition when we create a new writer but we fail to bake\n            // the newly written file (generation+1) into the checkpoint. This is still a valid state\n            // we just need to cleanup before we continue\n            // we hit this before and then blindly deleted the new generation even though we managed to bake it in and then hit this:\n            // https://discuss.elastic.co/t/cannot-recover-index-because-of-missing-tanslog-files/38336 as an example\n            //\n            // For this to happen we must have already copied the translog.ckp file into translog-gen.ckp so we first check if that\n            // file exists. If not we don\u0027t even try to clean it up and wait until we fail creating it\n            assert Files.exists(nextTranslogFile) \u003d\u003d false || Files.size(nextTranslogFile) \u003c\u003d TranslogHeader.headerSizeInBytes(translogUUID)\n                : \"unexpected translog file: [\" + nextTranslogFile + \"]\";\n            if (Files.exists(currentCheckpointFile) // current checkpoint is already copied\n                \u0026\u0026 Files.deleteIfExists(nextTranslogFile)) { // delete it and log a warning\n                logger.warn(\n                    \"deleted previously created, but not yet committed, next generation [{}]. This can happen due to a\"\n                        + \" tragic exception when creating a new generation\",\n                    nextTranslogFile.getFileName()\n                );\n            }\n            this.readers.addAll(recoverFromFiles(checkpoint));\n            if (readers.isEmpty()) {\n                throw new IllegalStateException(\"at least one reader must be recovered\");\n            }\n            boolean success \u003d false;\n            current \u003d null;\n            try {\n                current \u003d createWriter(\n                    checkpoint.generation + 1,\n                    getMinFileGeneration(),\n                    checkpoint.globalCheckpoint,\n                    persistedSequenceNumberConsumer\n                );\n                success \u003d true;\n            } finally {\n                // we have to close all the recovered ones otherwise we leak file handles here\n                // for instance if we have a lot of tlog and we can\u0027t create the writer we keep on holding\n                // on to all the uncommitted tlog files if we don\u0027t close\n                if (success \u003d\u003d false) {\n                    IOUtils.closeWhileHandlingException(readers);\n                }\n            }\n        } catch (Exception e) {\n            // close the opened translog files if we fail to create a new translog...\n            IOUtils.closeWhileHandlingException(current);\n            IOUtils.closeWhileHandlingException(readers);\n            throw e;\n        }\n    }\n\n    /** recover all translog files found on disk */\n    private ArrayList\u003cTranslogReader\u003e recoverFromFiles(Checkpoint checkpoint) throws IOException {\n        boolean success \u003d false;\n        ArrayList\u003cTranslogReader\u003e foundTranslogs \u003d new ArrayList\u003c\u003e();\n        writeLock.lock();\n        try {\n            logger.debug(\"open uncommitted translog checkpoint {}\", checkpoint);\n\n            final long minGenerationToRecoverFrom \u003d checkpoint.minTranslogGeneration;\n            assert minGenerationToRecoverFrom \u003e\u003d 0 : \"minTranslogGeneration should be non-negative\";\n\n            // we open files in reverse order in order to validate the translog uuid before we start traversing the translog based on\n            // the generation id we found in the lucene commit. This gives for better error messages if the wrong\n            // translog was found.\n            for (long i \u003d checkpoint.generation; i \u003e\u003d minGenerationToRecoverFrom; i--) {\n                Path committedTranslogFile \u003d location.resolve(getFilename(i));\n                final Checkpoint readerCheckpoint \u003d i \u003d\u003d checkpoint.generation\n                    ? checkpoint\n                    : Checkpoint.read(location.resolve(getCommitCheckpointFileName(i)));\n                final TranslogReader reader;\n                try {\n                    reader \u003d openReader(committedTranslogFile, readerCheckpoint);\n                } catch (NoSuchFileException fnfe) {\n                    throw new TranslogCorruptedException(\n                        committedTranslogFile.toString(),\n                        \"translog file doesn\u0027t exist with generation: \"\n                            + i\n                            + \" recovering from: \"\n                            + minGenerationToRecoverFrom\n                            + \" checkpoint: \"\n                            + checkpoint.generation\n                            + \" - translog ids must be consecutive\"\n                    );\n                }\n                assert reader.getPrimaryTerm() \u003c\u003d primaryTermSupplier.getAsLong()\n                    : \"Primary terms go backwards; current term [\"\n                        + primaryTermSupplier.getAsLong()\n                        + \"] translog path [ \"\n                        + committedTranslogFile\n                        + \", existing term [\"\n                        + reader.getPrimaryTerm()\n                        + \"]\";\n                foundTranslogs.add(reader);\n                logger.debug(\"recovered local translog from checkpoint {}\", checkpoint);\n            }\n            Collections.reverse(foundTranslogs);\n\n            // when we clean up files, we first update the checkpoint with a new minReferencedTranslog and then delete them;\n            // if we crash just at the wrong moment, it may be that we leave one unreferenced file behind so we delete it if there\n            IOUtils.deleteFilesIgnoringExceptions(\n                location.resolve(getFilename(minGenerationToRecoverFrom - 1)),\n                location.resolve(getCommitCheckpointFileName(minGenerationToRecoverFrom - 1))\n            );\n\n            Path commitCheckpoint \u003d location.resolve(getCommitCheckpointFileName(checkpoint.generation));\n            if (Files.exists(commitCheckpoint)) {\n                Checkpoint checkpointFromDisk \u003d Checkpoint.read(commitCheckpoint);\n                if (checkpoint.equals(checkpointFromDisk) \u003d\u003d false) {\n                    throw new TranslogCorruptedException(\n                        commitCheckpoint.toString(),\n                        \"checkpoint file \"\n                            + commitCheckpoint.getFileName()\n                            + \" already exists but has corrupted content: expected \"\n                            + checkpoint\n                            + \" but got \"\n                            + checkpointFromDisk\n                    );\n                }\n            } else {\n                copyCheckpointTo(commitCheckpoint);\n            }\n            success \u003d true;\n        } finally {\n            if (success \u003d\u003d false) {\n                IOUtils.closeWhileHandlingException(foundTranslogs);\n            }\n            writeLock.unlock();\n        }\n        return foundTranslogs;\n    }\n\n    private void copyCheckpointTo(Path targetPath) throws IOException {\n        // a temp file to copy checkpoint to - note it must be in on the same FS otherwise atomic move won\u0027t work\n        final Path tempFile \u003d Files.createTempFile(location, TRANSLOG_FILE_PREFIX, CHECKPOINT_SUFFIX);\n        boolean tempFileRenamed \u003d false;\n\n        try {\n            // we first copy this into the temp-file and then fsync it followed by an atomic move into the target file\n            // that way if we hit a disk-full here we are still in an consistent state.\n            Files.copy(location.resolve(CHECKPOINT_FILE_NAME), tempFile, StandardCopyOption.REPLACE_EXISTING);\n            IOUtils.fsync(tempFile, false);\n            Files.move(tempFile, targetPath, StandardCopyOption.ATOMIC_MOVE);\n            tempFileRenamed \u003d true;\n            // we only fsync the directory the tempFile was already fsynced\n            IOUtils.fsync(targetPath.getParent(), true);\n        } finally {\n            if (tempFileRenamed \u003d\u003d false) {\n                try {\n                    Files.delete(tempFile);\n                } catch (IOException ex) {\n                    logger.warn(() -\u003e format(\"failed to delete temp file %s\", tempFile), ex);\n                }\n            }\n        }\n    }\n\n    TranslogReader openReader(Path path, Checkpoint checkpoint) throws IOException {\n        FileChannel channel \u003d FileChannel.open(path, StandardOpenOption.READ);\n        try {\n            assert Translog.parseIdFromFileName(path) \u003d\u003d checkpoint.generation\n                : \"expected generation: \" + Translog.parseIdFromFileName(path) + \" but got: \" + checkpoint.generation;\n            TranslogReader reader \u003d TranslogReader.open(channel, path, checkpoint, translogUUID);\n            channel \u003d null;\n            return reader;\n        } finally {\n            IOUtils.close(channel);\n        }\n    }\n\n    /**\n     * Extracts the translog generation from a file name.\n     *\n     * @throws IllegalArgumentException if the path doesn\u0027t match the expected pattern.\n     */\n    public static long parseIdFromFileName(Path translogFile) {\n        final String fileName \u003d translogFile.getFileName().toString();\n        final Matcher matcher \u003d PARSE_STRICT_ID_PATTERN.matcher(fileName);\n        if (matcher.matches()) {\n            try {\n                return Long.parseLong(matcher.group(1));\n            } catch (NumberFormatException e) {\n                throw new IllegalStateException(\n                    \"number formatting issue in a file that passed PARSE_STRICT_ID_PATTERN: \" + fileName + \"]\",\n                    e\n                );\n            }\n        }\n        throw new IllegalArgumentException(\"can\u0027t parse id from file: \" + fileName);\n    }\n\n    /** Returns {@code true} if this {@code Translog} is still open. */\n    public boolean isOpen() {\n        return closed.get() \u003d\u003d false;\n    }\n\n    private static boolean calledFromOutsideOrViaTragedyClose() {\n        List\u003cStackTraceElement\u003e frames \u003d Stream.of(Thread.currentThread().getStackTrace()).skip(3). // skip getStackTrace, current method\n                                                                                                    // and close method frames\n            limit(10). // limit depth of analysis to 10 frames, it should be enough to catch closing with, e.g. IOUtils\n            filter(f -\u003e {\n                try {\n                    return Translog.class.isAssignableFrom(Class.forName(f.getClassName()));\n                } catch (Exception ignored) {\n                    return false;\n                }\n            }). // find all inner callers including Translog subclasses\n            toList();\n        // the list of inner callers should be either empty or should contain closeOnTragicEvent method\n        return frames.isEmpty() || frames.stream().anyMatch(f -\u003e f.getMethodName().equals(\"closeOnTragicEvent\"));\n    }\n\n    @Override\n    public void close() throws IOException {\n        assert calledFromOutsideOrViaTragedyClose()\n            : \"Translog.close method is called from inside Translog, but not via closeOnTragicEvent method\";\n        if (closed.compareAndSet(false, true)) {\n            writeLock.lock();\n            try {\n                try {\n                    current.sync();\n                } finally {\n                    closeFilesIfNoPendingRetentionLocks();\n                }\n            } finally {\n                writeLock.unlock();\n                logger.debug(\"translog closed\");\n            }\n        }\n    }\n\n    /**\n     * Returns all translog locations as absolute paths.\n     * These paths don\u0027t contain actual translog files they are\n     * directories holding the transaction logs.\n     */\n    public Path location() {\n        return location;\n    }\n\n    /**\n     * Returns the generation of the current transaction log.\n     */\n    public long currentFileGeneration() {\n        readLock.lock();\n        try {\n            return current.getGeneration();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the minimum file generation referenced by the translog\n     */\n    public long getMinFileGeneration() {\n        readLock.lock();\n        try {\n            if (readers.isEmpty()) {\n                return current.getGeneration();\n            } else {\n                assert readers.stream().map(TranslogReader::getGeneration).min(Long::compareTo).get().equals(readers.get(0).getGeneration())\n                    : \"the first translog isn\u0027t the one with the minimum generation:\" + readers;\n                return readers.get(0).getGeneration();\n            }\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the number of operations in the translog files\n     */\n    public int totalOperations() {\n        return totalOperationsByMinGen(-1);\n    }\n\n    /**\n     * Returns the size in bytes of the v files\n     */\n    public long sizeInBytes() {\n        return sizeInBytesByMinGen(-1);\n    }\n\n    long earliestLastModifiedAge() {\n        readLock.lock();\n        try {\n            ensureOpen();\n            return findEarliestLastModifiedAge(System.currentTimeMillis(), readers, current);\n        } catch (IOException e) {\n            throw new TranslogException(shardId, \"Unable to get the earliest last modified time for the transaction log\");\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the age of the oldest entry in the translog files in seconds\n     */\n    static long findEarliestLastModifiedAge(long currentTime, Iterable\u003cTranslogReader\u003e readers, TranslogWriter writer) throws IOException {\n        long earliestTime \u003d currentTime;\n        for (TranslogReader r : readers) {\n            earliestTime \u003d Math.min(r.getLastModifiedTime(), earliestTime);\n        }\n        return Math.max(0, currentTime - Math.min(earliestTime, writer.getLastModifiedTime()));\n    }\n\n    /**\n     * Returns the number of operations in the translog files at least the given generation\n     */\n    public int totalOperationsByMinGen(long minGeneration) {\n        readLock.lock();\n        try {\n            ensureOpen();\n            return Stream.concat(readers.stream(), Stream.of(current))\n                .filter(r -\u003e r.getGeneration() \u003e\u003d minGeneration)\n                .mapToInt(BaseTranslogReader::totalOperations)\n                .sum();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the number of operations in the transaction files that contain operations with seq# above the given number.\n     */\n    public int estimateTotalOperationsFromMinSeq(long minSeqNo) {\n        readLock.lock();\n        try {\n            ensureOpen();\n            return Stream.concat(readers.stream(), Stream.of(current))\n                .filter(reader -\u003e minSeqNo \u003c\u003d reader.getCheckpoint().maxEffectiveSeqNo())\n                .mapToInt(BaseTranslogReader::totalOperations)\n                .sum();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the size in bytes of the translog files at least the given generation\n     */\n    public long sizeInBytesByMinGen(long minGeneration) {\n        readLock.lock();\n        try {\n            ensureOpen();\n            return Stream.concat(readers.stream(), Stream.of(current))\n                .filter(r -\u003e r.getGeneration() \u003e\u003d minGeneration)\n                .mapToLong(BaseTranslogReader::sizeInBytes)\n                .sum();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Creates a new translog for the specified generation.\n     *\n     * @param fileGeneration the translog generation\n     * @return a writer for the new translog\n     * @throws IOException if creating the translog failed\n     */\n    TranslogWriter createWriter(long fileGeneration) throws IOException {\n        final TranslogWriter writer \u003d createWriter(\n            fileGeneration,\n            getMinFileGeneration(),\n            globalCheckpointSupplier.getAsLong(),\n            persistedSequenceNumberConsumer\n        );\n        assert writer.sizeInBytes() \u003d\u003d DEFAULT_HEADER_SIZE_IN_BYTES\n            : \"Mismatch translog header size; \"\n                + \"empty translog size [\"\n                + writer.sizeInBytes()\n                + \", header size [\"\n                + DEFAULT_HEADER_SIZE_IN_BYTES\n                + \"]\";\n        return writer;\n    }\n\n    /**\n     * creates a new writer\n     *\n     * @param fileGeneration          the generation of the write to be written\n     * @param initialMinTranslogGen   the minimum translog generation to be written in the first checkpoint. This is\n     *                                needed to solve and initialization problem while constructing an empty translog.\n     *                                With no readers and no current, a call to  {@link #getMinFileGeneration()} would not work.\n     * @param initialGlobalCheckpoint the global checkpoint to be written in the first checkpoint.\n     */\n    TranslogWriter createWriter(\n        long fileGeneration,\n        long initialMinTranslogGen,\n        long initialGlobalCheckpoint,\n        LongConsumer persistedSequenceNumberConsumer\n    ) throws IOException {\n        final TranslogWriter newWriter;\n        try {\n            newWriter \u003d TranslogWriter.create(\n                shardId,\n                translogUUID,\n                fileGeneration,\n                location.resolve(getFilename(fileGeneration)),\n                getChannelFactory(),\n                config.getBufferSize(),\n                initialMinTranslogGen,\n                initialGlobalCheckpoint,\n                globalCheckpointSupplier,\n                this::getMinFileGeneration,\n                primaryTermSupplier.getAsLong(),\n                tragedy,\n                persistedSequenceNumberConsumer,\n                bigArrays,\n                diskIoBufferPool,\n                operationListener,\n                config.fsync()\n            );\n        } catch (final IOException e) {\n            throw new TranslogException(shardId, \"failed to create new translog file\", e);\n        }\n        return newWriter;\n    }\n\n    /**\n     * Adds an operation to the transaction log.\n     *\n     * @param operation the operation to add\n     * @return the location of the operation in the translog\n     * @throws IOException if adding the operation to the translog resulted in an I/O exception\n     */\n    public Location add(final Operation operation) throws IOException {\n        try (ReleasableBytesStreamOutput out \u003d new ReleasableBytesStreamOutput(bigArrays)) {\n            writeOperationWithSize(out, operation);\n            final BytesReference bytes \u003d out.bytes();\n            readLock.lock();\n            try {\n                ensureOpen();\n                if (operation.primaryTerm() \u003e current.getPrimaryTerm()) {\n                    assert false\n                        : \"Operation term is newer than the current term; \"\n                            + \"current term[\"\n                            + current.getPrimaryTerm()\n                            + \"], operation term[\"\n                            + operation\n                            + \"]\";\n                    throw new IllegalArgumentException(\n                        \"Operation term is newer than the current term; \"\n                            + \"current term[\"\n                            + current.getPrimaryTerm()\n                            + \"], operation term[\"\n                            + operation\n                            + \"]\"\n                    );\n                }\n                return current.add(bytes, operation.seqNo());\n            } finally {\n                readLock.unlock();\n            }\n        } catch (final AlreadyClosedException | IOException ex) {\n            closeOnTragicEvent(ex);\n            throw ex;\n        } catch (final Exception ex) {\n            closeOnTragicEvent(ex);\n            throw new TranslogException(shardId, \"Failed to write operation [\" + operation + \"]\", ex);\n        }\n    }\n\n    /**\n     * Tests whether or not the translog generation should be rolled to a new generation. This test\n     * is based on the size of the current generation compared to the configured generation\n     * threshold size.\n     *\n     * @return {@code true} if the current generation should be rolled to a new generation\n     */\n    public boolean shouldRollGeneration() {\n        final long threshold \u003d this.indexSettings.getGenerationThresholdSize().getBytes();\n        readLock.lock();\n        try {\n            return this.current.sizeInBytes() \u003e threshold;\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * The a {@linkplain Location} that will sort after the {@linkplain Location} returned by the last write but before any locations which\n     * can be returned by the next write.\n     */\n    public Location getLastWriteLocation() {\n        readLock.lock();\n        try {\n            /*\n             * We use position \u003d current - 1 and size \u003d Integer.MAX_VALUE here instead of position current and size \u003d 0 for two reasons:\n             * 1. Translog.Location\u0027s compareTo doesn\u0027t actually pay attention to size even though it\u0027s equals method does.\n             * 2. It feels more right to return a *position* that is before the next write\u0027s position rather than rely on the size.\n             */\n            return new Location(current.generation, current.sizeInBytes() - 1, Integer.MAX_VALUE);\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * The last synced checkpoint for this translog.\n     *\n     * @return the last synced checkpoint\n     */\n    public long getLastSyncedGlobalCheckpoint() {\n        return getLastSyncedCheckpoint().globalCheckpoint;\n    }\n\n    final Checkpoint getLastSyncedCheckpoint() {\n        readLock.lock();\n        try {\n            return current.getLastSyncedCheckpoint();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    // for testing\n    public Snapshot newSnapshot() throws IOException {\n        return newSnapshot(0, Long.MAX_VALUE);\n    }\n\n    /**\n     * Creates a new translog snapshot containing operations from the given range.\n     *\n     * @param fromSeqNo the lower bound of the range (inclusive)\n     * @param toSeqNo   the upper bound of the range (inclusive)\n     * @return the new snapshot\n     */\n    public Snapshot newSnapshot(long fromSeqNo, long toSeqNo) throws IOException {\n        assert fromSeqNo \u003c\u003d toSeqNo : fromSeqNo + \" \u003e \" + toSeqNo;\n        assert fromSeqNo \u003e\u003d 0 : \"from_seq_no must be non-negative \" + fromSeqNo;\n        readLock.lock();\n        try {\n            ensureOpen();\n            TranslogSnapshot[] snapshots \u003d Stream.concat(readers.stream(), Stream.of(current))\n                .filter(reader -\u003e reader.getCheckpoint().minSeqNo \u003c\u003d toSeqNo \u0026\u0026 fromSeqNo \u003c\u003d reader.getCheckpoint().maxEffectiveSeqNo())\n                .map(BaseTranslogReader::newSnapshot)\n                .toArray(TranslogSnapshot[]::new);\n            final Snapshot snapshot \u003d newMultiSnapshot(snapshots);\n            return new SeqNoFilterSnapshot(snapshot, fromSeqNo, toSeqNo);\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /**\n     * Reads and returns the operation from the given location if the generation it references is still available. Otherwise\n     * this method will return \u003ccode\u003enull\u003c/code\u003e.\n     */\n    public Operation readOperation(Location location) throws IOException {\n        try {\n            readLock.lock();\n            try {\n                ensureOpen();\n                if (location.generation \u003c getMinFileGeneration()) {\n                    return null;\n                }\n                if (current.generation \u003d\u003d location.generation) {\n                    // no need to fsync here the read operation will ensure that buffers are written to disk\n                    // if they are still in RAM and we are reading onto that position\n                    return current.read(location);\n                } else {\n                    // read backwards - it\u0027s likely we need to read on that is recent\n                    for (int i \u003d readers.size() - 1; i \u003e\u003d 0; i--) {\n                        TranslogReader translogReader \u003d readers.get(i);\n                        if (translogReader.generation \u003d\u003d location.generation) {\n                            return translogReader.read(location);\n                        }\n                    }\n                }\n            } finally {\n                readLock.unlock();\n            }\n        } catch (final Exception ex) {\n            closeOnTragicEvent(ex);\n            throw ex;\n        }\n        return null;\n    }\n\n    private Snapshot newMultiSnapshot(TranslogSnapshot[] snapshots) throws IOException {\n        final Closeable onClose;\n        if (snapshots.length \u003d\u003d 0) {\n            onClose \u003d () -\u003e {};\n        } else {\n            assert Arrays.stream(snapshots).map(BaseTranslogReader::getGeneration).min(Long::compareTo).get() \u003d\u003d snapshots[0].generation\n                : \"first reader generation of \" + snapshots + \" is not the smallest\";\n            onClose \u003d acquireTranslogGenFromDeletionPolicy(snapshots[0].generation);\n        }\n        boolean success \u003d false;\n        try {\n            Snapshot result \u003d new MultiSnapshot(snapshots, onClose);\n            success \u003d true;\n            return result;\n        } finally {\n            if (success \u003d\u003d false) {\n                onClose.close();\n            }\n        }\n    }\n\n    /**\n     * Acquires a lock on the translog files, preventing them from being trimmed\n     */\n    public Closeable acquireRetentionLock() {\n        readLock.lock();\n        try {\n            ensureOpen();\n            final long viewGen \u003d getMinFileGeneration();\n            return acquireTranslogGenFromDeletionPolicy(viewGen);\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    private Closeable acquireTranslogGenFromDeletionPolicy(long viewGen) {\n        Releasable toClose \u003d deletionPolicy.acquireTranslogGen(viewGen);\n        return () -\u003e {\n            try {\n                toClose.close();\n            } finally {\n                trimUnreferencedReaders();\n                closeFilesIfNoPendingRetentionLocks();\n            }\n        };\n    }\n\n    /**\n     * Sync\u0027s the translog.\n     */\n    public void sync() throws IOException {\n        try {\n            readLock.lock();\n            try {\n                if (closed.get() \u003d\u003d false) {\n                    current.sync();\n                }\n            } finally {\n                readLock.unlock();\n            }\n        } catch (final Exception ex) {\n            closeOnTragicEvent(ex);\n            throw ex;\n        }\n    }\n\n    /**\n     *  Returns \u003ccode\u003etrue\u003c/code\u003e if an fsync is required to ensure durability of the translogs operations or it\u0027s metadata.\n     */\n    public boolean syncNeeded() {\n        readLock.lock();\n        try {\n            return current.syncNeeded();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    /** package private for testing */\n    public static String getFilename(long generation) {\n        return TRANSLOG_FILE_PREFIX + generation + TRANSLOG_FILE_SUFFIX;\n    }\n\n    static String getCommitCheckpointFileName(long generation) {\n        return TRANSLOG_FILE_PREFIX + generation + CHECKPOINT_SUFFIX;\n    }\n\n    /**\n     * Trims translog for terms of files below \u003ccode\u003ebelowTerm\u003c/code\u003e and seq# above \u003ccode\u003eaboveSeqNo\u003c/code\u003e.\n     * Effectively it moves max visible seq# {@link Checkpoint#trimmedAboveSeqNo} therefore {@link TranslogSnapshot} skips those operations.\n     */\n    public void trimOperations(long belowTerm, long aboveSeqNo) throws IOException {\n        assert aboveSeqNo \u003e\u003d SequenceNumbers.NO_OPS_PERFORMED : \"aboveSeqNo has to a valid sequence number\";\n\n        writeLock.lock();\n        try {\n            ensureOpen();\n            if (current.getPrimaryTerm() \u003c belowTerm) {\n                throw new IllegalArgumentException(\n                    \"Trimming the translog can only be done for terms lower than the current one. \"\n                        + \"Trim requested for term [ \"\n                        + belowTerm\n                        + \" ] , current is [ \"\n                        + current.getPrimaryTerm()\n                        + \" ]\"\n                );\n            }\n            // we assume that the current translog generation doesn\u0027t have trimmable ops. Verify that.\n            assert current.assertNoSeqAbove(belowTerm, aboveSeqNo);\n            // update all existed ones (if it is necessary) as checkpoint and reader are immutable\n            final List\u003cTranslogReader\u003e newReaders \u003d new ArrayList\u003c\u003e(readers.size());\n            try {\n                for (TranslogReader reader : readers) {\n                    final TranslogReader newReader \u003d reader.getPrimaryTerm() \u003c belowTerm\n                        ? reader.closeIntoTrimmedReader(aboveSeqNo, getChannelFactory())\n                        : reader;\n                    newReaders.add(newReader);\n                }\n            } catch (IOException e) {\n                IOUtils.closeWhileHandlingException(newReaders);\n                tragedy.setTragicException(e);\n                closeOnTragicEvent(e);\n                throw e;\n            }\n\n            this.readers.clear();\n            this.readers.addAll(newReaders);\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    /**\n     * Ensures that the given location and global checkpoint has be synced / written to the underlying storage.\n     *\n     * @return Returns \u003ccode\u003etrue\u003c/code\u003e iff this call caused an actual sync operation otherwise \u003ccode\u003efalse\u003c/code\u003e\n     */\n    public boolean ensureSynced(Location location, long globalCheckpoint) throws IOException {\n        try {\n            readLock.lock();\n            try {\n                // if we have a new generation and the persisted global checkpoint is greater than or equal to the sync global checkpoint\n                // it\u0027s\n                // already synced\n                long persistedGlobalCheckpoint \u003d current.getLastSyncedCheckpoint().globalCheckpoint;\n                if (location.generation \u003d\u003d current.getGeneration() || persistedGlobalCheckpoint \u003c globalCheckpoint) {\n                    ensureOpen();\n                    return current.syncUpTo(location.translogLocation + location.size, globalCheckpoint);\n                }\n            } finally {\n                readLock.unlock();\n            }\n        } catch (final Exception ex) {\n            closeOnTragicEvent(ex);\n            throw ex;\n        }\n        return false;\n    }\n\n    /**\n     * Closes the translog if the current translog writer experienced a tragic exception.\n     *\n     * Note that in case this thread closes the translog it must not already be holding a read lock on the translog as it will acquire a\n     * write lock in the course of closing the translog\n     *\n     * @param ex if an exception occurs closing the translog, it will be suppressed into the provided exception\n     */\n    protected void closeOnTragicEvent(final Exception ex) {\n        // we can not hold a read lock here because closing will attempt to obtain a write lock and that would result in self-deadlock\n        if (tragedy.get() !\u003d null) {\n            try {\n                close();\n            } catch (final AlreadyClosedException inner) {\n                /*\n                 * Don\u0027t do anything in this case. The AlreadyClosedException comes from TranslogWriter and we should not add it as\n                 * suppressed because it will contain the provided exception as its cause. See also\n                 * https://github.com/elastic/elasticsearch/issues/15941.\n                 */\n            } catch (final Exception inner) {\n                assert ex !\u003d inner.getCause();\n                ex.addSuppressed(inner);\n            }\n        }\n    }\n\n    /**\n     * return stats\n     */\n    public TranslogStats stats() {\n        // acquire lock to make the two numbers roughly consistent (no file change half way)\n        readLock.lock();\n        try {\n            final long uncommittedGen \u003d minGenerationForSeqNo(deletionPolicy.getLocalCheckpointOfSafeCommit() + 1, current, readers);\n            return new TranslogStats(\n                totalOperations(),\n                sizeInBytes(),\n                totalOperationsByMinGen(uncommittedGen),\n                sizeInBytesByMinGen(uncommittedGen),\n                earliestLastModifiedAge()\n            );\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    public TranslogConfig getConfig() {\n        return config;\n    }\n\n    // public for testing\n    public TranslogDeletionPolicy getDeletionPolicy() {\n        return deletionPolicy;\n    }\n\n    public static class Location implements Comparable\u003cLocation\u003e {\n\n        public static Location EMPTY \u003d new Location(0, 0, 0);\n\n        public final long generation;\n        public final long translogLocation;\n        public final int size;\n\n        public Location(long generation, long translogLocation, int size) {\n            this.generation \u003d generation;\n            this.translogLocation \u003d translogLocation;\n            this.size \u003d size;\n        }\n\n        @Override\n        public String toString() {\n            return \"[generation: \" + generation + \", location: \" + translogLocation + \", size: \" + size + \"]\";\n        }\n\n        @Override\n        public int compareTo(Location o) {\n            if (generation \u003d\u003d o.generation) {\n                return Long.compare(translogLocation, o.translogLocation);\n            }\n            return Long.compare(generation, o.generation);\n        }\n\n        @Override\n        public boolean equals(Object o) {\n            if (this \u003d\u003d o) {\n                return true;\n            }\n            if (o \u003d\u003d null || getClass() !\u003d o.getClass()) {\n                return false;\n            }\n\n            Location location \u003d (Location) o;\n\n            if (generation !\u003d location.generation) {\n                return false;\n            }\n            if (translogLocation !\u003d location.translogLocation) {\n                return false;\n            }\n            return size \u003d\u003d location.size;\n\n        }\n\n        @Override\n        public int hashCode() {\n            int result \u003d Long.hashCode(generation);\n            result \u003d 31 * result + Long.hashCode(translogLocation);\n            result \u003d 31 * result + size;\n            return result;\n        }\n    }\n\n    /**\n     * A snapshot of the transaction log, allows to iterate over all the transaction log operations.\n     */\n    public interface Snapshot extends Closeable {\n\n        Snapshot EMPTY \u003d new Snapshot() {\n            @Override\n            public void close() {}\n\n            @Override\n            public int totalOperations() {\n                return 0;\n            }\n\n            @Override\n            public Operation next() {\n                return null;\n            }\n        };\n\n        /**\n         * The total estimated number of operations in the snapshot.\n         */\n        int totalOperations();\n\n        /**\n         * The number of operations have been skipped (overridden or trimmed) in the snapshot so far.\n         * Unlike {@link #totalOperations()}, this value is updated each time after {@link #next()}) is called.\n         */\n        default int skippedOperations() {\n            return 0;\n        }\n\n        /**\n         * Returns the next operation in the snapshot or \u003ccode\u003enull\u003c/code\u003e if we reached the end.\n         */\n        Translog.Operation next() throws IOException;\n    }\n\n    /**\n     * A filtered snapshot consisting of only operations whose sequence numbers are in the given range\n     * between {@code fromSeqNo} (inclusive) and {@code toSeqNo} (inclusive). This filtered snapshot\n     * shares the same underlying resources with the {@code delegate} snapshot, therefore we should not\n     * use the {@code delegate} after passing it to this filtered snapshot.\n     */\n    private static final class SeqNoFilterSnapshot implements Snapshot {\n        private final Snapshot delegate;\n        private int filteredOpsCount;\n        private final long fromSeqNo; // inclusive\n        private final long toSeqNo;   // inclusive\n\n        SeqNoFilterSnapshot(Snapshot delegate, long fromSeqNo, long toSeqNo) {\n            assert fromSeqNo \u003c\u003d toSeqNo : \"from_seq_no[\" + fromSeqNo + \"] \u003e to_seq_no[\" + toSeqNo + \"]\";\n            this.delegate \u003d delegate;\n            this.fromSeqNo \u003d fromSeqNo;\n            this.toSeqNo \u003d toSeqNo;\n        }\n\n        @Override\n        public int totalOperations() {\n            return delegate.totalOperations();\n        }\n\n        @Override\n        public int skippedOperations() {\n            return filteredOpsCount + delegate.skippedOperations();\n        }\n\n        @Override\n        public Operation next() throws IOException {\n            Translog.Operation op;\n            while ((op \u003d delegate.next()) !\u003d null) {\n                if (fromSeqNo \u003c\u003d op.seqNo() \u0026\u0026 op.seqNo() \u003c\u003d toSeqNo) {\n                    return op;\n                } else {\n                    filteredOpsCount++;\n                }\n            }\n            return null;\n        }\n\n        @Override\n        public void close() throws IOException {\n            delegate.close();\n        }\n    }\n\n    /**\n     * A generic interface representing an operation performed on the transaction log.\n     * Each is associated with a type.\n     */\n    public abstract static sealed class Operation implements Writeable permits Delete, Index, NoOp {\n        public enum Type {\n            @Deprecated\n            CREATE((byte) 1),\n            INDEX((byte) 2),\n            DELETE((byte) 3),\n            NO_OP((byte) 4);\n\n            private final byte id;\n\n            Type(byte id) {\n                this.id \u003d id;\n            }\n\n            public byte id() {\n                return this.id;\n            }\n\n            public static Type fromId(byte id) {\n                return switch (id) {\n                    case 1 -\u003e CREATE;\n                    case 2 -\u003e INDEX;\n                    case 3 -\u003e DELETE;\n                    case 4 -\u003e NO_OP;\n                    default -\u003e throw new IllegalArgumentException(\"no type mapped for [\" + id + \"]\");\n                };\n            }\n        }\n\n        protected final long seqNo;\n\n        protected final long primaryTerm;\n\n        protected Operation(long seqNo, long primaryTerm) {\n            this.seqNo \u003d seqNo;\n            this.primaryTerm \u003d primaryTerm;\n        }\n\n        public abstract Type opType();\n\n        public abstract long estimateSize();\n\n        public final long seqNo() {\n            return seqNo;\n        }\n\n        public final long primaryTerm() {\n            return primaryTerm;\n        }\n\n        /**\n         * Reads the type and the operation from the given stream.\n         */\n        public static Operation readOperation(final StreamInput input) throws IOException {\n            final Translog.Operation.Type type \u003d Translog.Operation.Type.fromId(input.readByte());\n            return switch (type) {\n                // the de-serialization logic in Index was identical to that of Create when create was deprecated\n                case CREATE, INDEX -\u003e Index.readFrom(input);\n                case DELETE -\u003e Delete.readFrom(input);\n                case NO_OP -\u003e new NoOp(input);\n            };\n        }\n\n        @Override\n        public final void writeTo(StreamOutput out) throws IOException {\n            out.writeByte(opType().id());\n            writeBody(out);\n        }\n\n        protected abstract void writeBody(StreamOutput out) throws IOException;\n    }\n\n    public static final class Index extends Operation {\n\n        public static final int FORMAT_NO_PARENT \u003d 9; // since 7.0\n        public static final int FORMAT_NO_VERSION_TYPE \u003d FORMAT_NO_PARENT + 1;\n        public static final int FORMAT_NO_DOC_TYPE \u003d FORMAT_NO_VERSION_TYPE + 1;\n        public static final int SERIALIZATION_FORMAT \u003d FORMAT_NO_DOC_TYPE;\n\n        private final String id;\n        private final long autoGeneratedIdTimestamp;\n        private final long version;\n        private final BytesReference source;\n        private final String routing;\n\n        private static Index readFrom(StreamInput in) throws IOException {\n            final int format \u003d in.readVInt(); // SERIALIZATION_FORMAT\n            assert format \u003e\u003d FORMAT_NO_PARENT : \"format was: \" + format;\n            String id \u003d in.readString();\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                in.readString();\n                // can\u0027t assert that this is _doc because pre-8.0 indexes can have any name for a type\n            }\n            BytesReference source \u003d in.readBytesReference();\n            String routing \u003d in.readOptionalString();\n            long version \u003d in.readLong();\n            if (format \u003c FORMAT_NO_VERSION_TYPE) {\n                in.readByte(); // _version_type\n            }\n            long autoGeneratedIdTimestamp \u003d in.readLong();\n            long seqNo \u003d in.readLong();\n            long primaryTerm \u003d in.readLong();\n            return new Index(id, seqNo, primaryTerm, version, source, routing, autoGeneratedIdTimestamp);\n        }\n\n        public Index(Engine.Index index, Engine.IndexResult indexResult) {\n            this(\n                index.id(),\n                indexResult.getSeqNo(),\n                index.primaryTerm(),\n                indexResult.getVersion(),\n                index.source(),\n                index.routing(),\n                index.getAutoGeneratedIdTimestamp()\n            );\n        }\n\n        public Index(\n            String id,\n            long seqNo,\n            long primaryTerm,\n            long version,\n            BytesReference source,\n            String routing,\n            long autoGeneratedIdTimestamp\n        ) {\n            super(seqNo, primaryTerm);\n            this.id \u003d id;\n            this.source \u003d source;\n            this.version \u003d version;\n            this.routing \u003d routing;\n            this.autoGeneratedIdTimestamp \u003d autoGeneratedIdTimestamp;\n        }\n\n        @Override\n        public Type opType() {\n            return Type.INDEX;\n        }\n\n        @Override\n        public long estimateSize() {\n            return (2 * id.length()) + source.length() + (routing !\u003d null ? 2 * routing.length() : 0) + (4 * Long.BYTES); // timestamp,\n                                                                                                                          // seq_no,\n                                                                                                                          // primary_term,\n                                                                                                                          // and version\n        }\n\n        public String id() {\n            return this.id;\n        }\n\n        public String routing() {\n            return this.routing;\n        }\n\n        public BytesReference source() {\n            return this.source;\n        }\n\n        public long version() {\n            return this.version;\n        }\n\n        @Override\n        public void writeBody(final StreamOutput out) throws IOException {\n            final int format \u003d out.getTransportVersion().onOrAfter(TransportVersions.V_8_0_0)\n                ? SERIALIZATION_FORMAT\n                : FORMAT_NO_VERSION_TYPE;\n            out.writeVInt(format);\n            out.writeString(id);\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                out.writeString(MapperService.SINGLE_MAPPING_NAME);\n            }\n            out.writeBytesReference(source);\n            out.writeOptionalString(routing);\n            out.writeLong(version);\n            out.writeLong(autoGeneratedIdTimestamp);\n            out.writeLong(seqNo);\n            out.writeLong(primaryTerm);\n        }\n\n        @Override\n        public boolean equals(Object o) {\n            if (this \u003d\u003d o) {\n                return true;\n            }\n            if (o \u003d\u003d null || getClass() !\u003d o.getClass()) {\n                return false;\n            }\n\n            Index index \u003d (Index) o;\n\n            if (version !\u003d index.version\n                || seqNo !\u003d index.seqNo\n                || primaryTerm !\u003d index.primaryTerm\n                || id.equals(index.id) \u003d\u003d false\n                || autoGeneratedIdTimestamp !\u003d index.autoGeneratedIdTimestamp\n                || source.equals(index.source) \u003d\u003d false) {\n                return false;\n            }\n            return Objects.equals(routing, index.routing);\n        }\n\n        @Override\n        public int hashCode() {\n            int result \u003d id.hashCode();\n            result \u003d 31 * result + Long.hashCode(seqNo);\n            result \u003d 31 * result + Long.hashCode(primaryTerm);\n            result \u003d 31 * result + Long.hashCode(version);\n            result \u003d 31 * result + source.hashCode();\n            result \u003d 31 * result + (routing !\u003d null ? routing.hashCode() : 0);\n            result \u003d 31 * result + Long.hashCode(autoGeneratedIdTimestamp);\n            return result;\n        }\n\n        @Override\n        public String toString() {\n            return \"Index{\"\n                + \"id\u003d\u0027\"\n                + id\n                + \u0027\\\u0027\u0027\n                + \", seqNo\u003d\"\n                + seqNo\n                + \", primaryTerm\u003d\"\n                + primaryTerm\n                + \", version\u003d\"\n                + version\n                + \", autoGeneratedIdTimestamp\u003d\"\n                + autoGeneratedIdTimestamp\n                + \u0027}\u0027;\n        }\n\n        public long getAutoGeneratedIdTimestamp() {\n            return autoGeneratedIdTimestamp;\n        }\n\n    }\n\n    public static final class Delete extends Operation {\n\n        private static final int FORMAT_6_0 \u003d 4; // 6.0 - *\n        public static final int FORMAT_NO_PARENT \u003d FORMAT_6_0 + 1; // since 7.0\n        public static final int FORMAT_NO_VERSION_TYPE \u003d FORMAT_NO_PARENT + 1;\n        public static final int FORMAT_NO_DOC_TYPE \u003d FORMAT_NO_VERSION_TYPE + 1;    // since 8.0\n        public static final int SERIALIZATION_FORMAT \u003d FORMAT_NO_DOC_TYPE;\n\n        private final String id;\n        private final long version;\n\n        private static Delete readFrom(StreamInput in) throws IOException {\n            final int format \u003d in.readVInt();// SERIALIZATION_FORMAT\n            assert format \u003e\u003d FORMAT_6_0 : \"format was: \" + format;\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                in.readString();\n                // Can\u0027t assert that this is _doc because pre-8.0 indexes can have any name for a type\n            }\n            String id \u003d in.readString();\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                final String docType \u003d in.readString();\n                assert docType.equals(IdFieldMapper.NAME) : docType + \" !\u003d \" + IdFieldMapper.NAME;\n                in.readSlicedBytesReference(); // uid\n            }\n            long version \u003d in.readLong();\n            if (format \u003c FORMAT_NO_VERSION_TYPE) {\n                in.readByte(); // versionType\n            }\n            long seqNo \u003d in.readLong();\n            long primaryTerm \u003d in.readLong();\n            return new Delete(id, seqNo, primaryTerm, version);\n        }\n\n        public Delete(Engine.Delete delete, Engine.DeleteResult deleteResult) {\n            this(delete.id(), deleteResult.getSeqNo(), delete.primaryTerm(), deleteResult.getVersion());\n        }\n\n        /** utility for testing */\n        public Delete(String id, long seqNo, long primaryTerm) {\n            this(id, seqNo, primaryTerm, Versions.MATCH_ANY);\n        }\n\n        public Delete(String id, long seqNo, long primaryTerm, long version) {\n            super(seqNo, primaryTerm);\n            this.id \u003d Objects.requireNonNull(id);\n            this.version \u003d version;\n        }\n\n        @Override\n        public Type opType() {\n            return Type.DELETE;\n        }\n\n        @Override\n        public long estimateSize() {\n            return (2 * id.length()) + (3 * Long.BYTES); // seq_no, primary_term, and version;\n        }\n\n        public String id() {\n            return id;\n        }\n\n        public long version() {\n            return this.version;\n        }\n\n        @Override\n        public void writeBody(final StreamOutput out) throws IOException {\n            final int format \u003d out.getTransportVersion().onOrAfter(TransportVersions.V_8_0_0)\n                ? SERIALIZATION_FORMAT\n                : FORMAT_NO_VERSION_TYPE;\n            out.writeVInt(format);\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                out.writeString(MapperService.SINGLE_MAPPING_NAME);\n            }\n            out.writeString(id);\n            if (format \u003c FORMAT_NO_DOC_TYPE) {\n                out.writeString(IdFieldMapper.NAME);\n                out.writeBytesRef(Uid.encodeId(id));\n            }\n            out.writeLong(version);\n            out.writeLong(seqNo);\n            out.writeLong(primaryTerm);\n        }\n\n        @Override\n        public boolean equals(Object o) {\n            if (this \u003d\u003d o) {\n                return true;\n            }\n            if (o \u003d\u003d null || getClass() !\u003d o.getClass()) {\n                return false;\n            }\n\n            Delete delete \u003d (Delete) o;\n\n            return id.equals(delete.id) \u0026\u0026 seqNo \u003d\u003d delete.seqNo \u0026\u0026 primaryTerm \u003d\u003d delete.primaryTerm \u0026\u0026 version \u003d\u003d delete.version;\n        }\n\n        @Override\n        public int hashCode() {\n            int result \u003d id.hashCode();\n            result +\u003d 31 * Long.hashCode(seqNo);\n            result \u003d 31 * result + Long.hashCode(primaryTerm);\n            result \u003d 31 * result + Long.hashCode(version);\n            return result;\n        }\n\n        @Override\n        public String toString() {\n            return \"Delete{\" + \"id\u003d\u0027\" + id + \"\u0027, seqNo\u003d\" + seqNo + \", primaryTerm\u003d\" + primaryTerm + \", version\u003d\" + version + \u0027}\u0027;\n        }\n    }\n\n    public static final class NoOp extends Operation {\n        private final String reason;\n\n        public String reason() {\n            return reason;\n        }\n\n        private NoOp(final StreamInput in) throws IOException {\n            this(in.readLong(), in.readLong(), in.readString());\n        }\n\n        public NoOp(final long seqNo, final long primaryTerm, final String reason) {\n            super(seqNo, primaryTerm);\n            assert seqNo \u003e SequenceNumbers.NO_OPS_PERFORMED;\n            assert primaryTerm \u003e\u003d 0;\n            assert reason !\u003d null;\n            this.reason \u003d reason;\n        }\n\n        @Override\n        public void writeBody(final StreamOutput out) throws IOException {\n            out.writeLong(seqNo);\n            out.writeLong(primaryTerm);\n            out.writeString(reason);\n        }\n\n        @Override\n        public Type opType() {\n            return Type.NO_OP;\n        }\n\n        @Override\n        public long estimateSize() {\n            return 2 * reason.length() + 2 * Long.BYTES;\n        }\n\n        @Override\n        public boolean equals(Object obj) {\n            if (this \u003d\u003d obj) {\n                return true;\n            }\n            if (obj \u003d\u003d null || getClass() !\u003d obj.getClass()) {\n                return false;\n            }\n            final NoOp that \u003d (NoOp) obj;\n            return seqNo \u003d\u003d that.seqNo \u0026\u0026 primaryTerm \u003d\u003d that.primaryTerm \u0026\u0026 reason.equals(that.reason);\n        }\n\n        @Override\n        public int hashCode() {\n            return 31 * 31 * Long.hashCode(seqNo) + 31 * Long.hashCode(primaryTerm) + reason().hashCode();\n        }\n\n        @Override\n        public String toString() {\n            return \"NoOp{\" + \"seqNo\u003d\" + seqNo + \", primaryTerm\u003d\" + primaryTerm + \", reason\u003d\u0027\" + reason + \u0027\\\u0027\u0027 + \u0027}\u0027;\n        }\n    }\n\n    public enum Durability {\n\n        /**\n         * Async durability - translogs are synced based on a time interval.\n         */\n        ASYNC,\n        /**\n         * Request durability - translogs are synced for each high level request (bulk, index, delete)\n         */\n        REQUEST\n\n    }\n\n    static void verifyChecksum(BufferedChecksumStreamInput in) throws IOException {\n        // This absolutely must come first, or else reading the checksum becomes part of the checksum\n        long expectedChecksum \u003d in.getChecksum();\n        long readChecksum \u003d Integer.toUnsignedLong(in.readInt());\n        if (readChecksum !\u003d expectedChecksum) {\n            throw new TranslogCorruptedException(\n                in.getSource(),\n                \"checksum verification failed - expected: 0x\"\n                    + Long.toHexString(expectedChecksum)\n                    + \", got: 0x\"\n                    + Long.toHexString(readChecksum)\n            );\n        }\n    }\n\n    /**\n     * Reads a list of operations written with {@link #writeOperations(StreamOutput, List)}\n     */\n    public static List\u003cOperation\u003e readOperations(StreamInput input, String source) throws IOException {\n        ArrayList\u003cOperation\u003e operations \u003d new ArrayList\u003c\u003e();\n        int numOps \u003d input.readInt();\n        final BufferedChecksumStreamInput checksumStreamInput \u003d new BufferedChecksumStreamInput(input, source);\n        if (input.getTransportVersion().before(TransportVersions.V_8_8_0)) {\n            for (int i \u003d 0; i \u003c numOps; i++) {\n                operations.add(readOperation(checksumStreamInput));\n            }\n        } else {\n            for (int i \u003d 0; i \u003c numOps; i++) {\n                checksumStreamInput.resetDigest();\n                operations.add(Translog.Operation.readOperation(checksumStreamInput));\n                verifyChecksum(checksumStreamInput);\n            }\n        }\n        return operations;\n    }\n\n    public static Translog.Operation readOperation(BufferedChecksumStreamInput in) throws IOException {\n        final Translog.Operation operation;\n        try {\n            final int opSize \u003d in.readInt();\n            if (opSize \u003c 4) { // 4byte for the checksum\n                throw new TranslogCorruptedException(in.getSource(), \"operation size must be at least 4 but was: \" + opSize);\n            }\n            in.resetDigest(); // size is not part of the checksum!\n            if (in.markSupported()) { // if we can we validate the checksum first\n                // we are sometimes called when mark is not supported this is the case when\n                // we are sending translogs across the network with LZ4 compression enabled - currently there is no way s\n                // to prevent this unfortunately.\n                in.mark(opSize);\n\n                in.skip(opSize - 4);\n                verifyChecksum(in);\n                in.reset();\n            }\n            operation \u003d Translog.Operation.readOperation(in);\n            verifyChecksum(in);\n        } catch (EOFException e) {\n            throw new TruncatedTranslogException(in.getSource(), \"reached premature end of file, translog is truncated\", e);\n        }\n        return operation;\n    }\n\n    /**\n     * Writes all operations in the given iterable to the given output stream including the size of the array\n     * use {@link #readOperations(StreamInput, String)} to read it back.\n     */\n    public static void writeOperations(StreamOutput outStream, List\u003cOperation\u003e toWrite) throws IOException {\n        int size \u003d toWrite.size();\n        outStream.writeInt(size);\n        if (size \u003d\u003d 0) {\n            return;\n        }\n        if (outStream.getTransportVersion().onOrAfter(TransportVersions.V_8_8_0)) {\n            final BufferedChecksumStreamOutput checksumStreamOutput \u003d new BufferedChecksumStreamOutput(outStream);\n            for (Operation op : toWrite) {\n                writeOperationNoSize(checksumStreamOutput, op);\n            }\n        } else {\n            writeOperationsToStreamLegacyFormat(outStream, toWrite);\n        }\n    }\n\n    private static void writeOperationsToStreamLegacyFormat(StreamOutput outStream, List\u003cOperation\u003e toWrite) throws IOException {\n        final BytesStreamOutput out \u003d new BytesStreamOutput();\n        final BufferedChecksumStreamOutput checksumStreamOutput \u003d new BufferedChecksumStreamOutput(out);\n        for (Operation op : toWrite) {\n            out.reset();\n            writeOperationNoSize(checksumStreamOutput, op);\n            outStream.writeInt(Math.toIntExact(out.position()));\n            out.bytes().writeTo(outStream);\n        }\n    }\n\n    public static void writeOperationNoSize(BufferedChecksumStreamOutput out, Translog.Operation op) throws IOException {\n        // This BufferedChecksumStreamOutput remains unclosed on purpose,\n        // because closing it closes the underlying stream, which we don\u0027t\n        // want to do here.\n        out.resetDigest();\n        op.writeTo(out);\n        long checksum \u003d out.getChecksum();\n        out.writeInt((int) checksum);\n    }\n\n    public static void writeOperationWithSize(BytesStreamOutput out, Translog.Operation op) throws IOException {\n        final long start \u003d out.position();\n        out.skip(Integer.BYTES);\n        writeOperationNoSize(new BufferedChecksumStreamOutput(out), op);\n        final long end \u003d out.position();\n        final int operationSize \u003d (int) (end - Integer.BYTES - start);\n        out.seek(start);\n        out.writeInt(operationSize);\n        out.seek(end);\n    }\n\n    /**\n     * Gets the minimum generation that could contain any sequence number after the specified sequence number, or the current generation if\n     * there is no generation that could any such sequence number.\n     *\n     * @param seqNo the sequence number\n     * @return the minimum generation for the sequence number\n     */\n    public TranslogGeneration getMinGenerationForSeqNo(final long seqNo) {\n        readLock.lock();\n        try {\n            return new TranslogGeneration(translogUUID, minGenerationForSeqNo(seqNo, current, readers));\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    private static long minGenerationForSeqNo(long seqNo, TranslogWriter writer, List\u003cTranslogReader\u003e readers) {\n        long minGen \u003d writer.generation;\n        for (final TranslogReader reader : readers) {\n            if (seqNo \u003c\u003d reader.getCheckpoint().maxEffectiveSeqNo()) {\n                minGen \u003d Math.min(minGen, reader.getGeneration());\n            }\n        }\n        return minGen;\n    }\n\n    /**\n     * Roll the current translog generation into a new generation if it\u0027s not empty. This does not commit the translog.\n     *\n     * @throws IOException if an I/O exception occurred during any file operations\n     */\n    public void rollGeneration() throws IOException {\n        syncBeforeRollGeneration();\n        if (current.totalOperations() \u003d\u003d 0 \u0026\u0026 primaryTermSupplier.getAsLong() \u003d\u003d current.getPrimaryTerm()) {\n            return;\n        }\n        writeLock.lock();\n        try {\n            ensureOpen();\n            try {\n                final TranslogReader reader \u003d current.closeIntoReader();\n                readers.add(reader);\n                assert Checkpoint.read(location.resolve(CHECKPOINT_FILE_NAME)).generation \u003d\u003d current.getGeneration();\n                copyCheckpointTo(location.resolve(getCommitCheckpointFileName(current.getGeneration())));\n                // create a new translog file; this will sync it and update the checkpoint data;\n                current \u003d createWriter(current.getGeneration() + 1);\n                logger.trace(\"current translog set to [{}]\", current.getGeneration());\n            } catch (final Exception e) {\n                tragedy.setTragicException(e);\n                closeOnTragicEvent(e);\n                throw e;\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    void syncBeforeRollGeneration() throws IOException {\n        // make sure we move most of the data to disk outside of the writeLock\n        // in order to reduce the time the lock is held since it\u0027s blocking all threads\n        sync();\n    }\n\n    /**\n     * Trims unreferenced translog generations by asking {@link TranslogDeletionPolicy} for the minimum\n     * required generation\n     */\n    public void trimUnreferencedReaders() throws IOException {\n        // first check under read lock if any readers can be trimmed\n        readLock.lock();\n        try {\n            if (closed.get()) {\n                // we\u0027re shutdown potentially on some tragic event, don\u0027t delete anything\n                return;\n            }\n            if (getMinReferencedGen() \u003d\u003d getMinFileGeneration()) {\n                return;\n            }\n        } finally {\n            readLock.unlock();\n        }\n\n        // move most of the data to disk to reduce the time the write lock is held\n        sync();\n        writeLock.lock();\n        try {\n            if (closed.get()) {\n                // we\u0027re shutdown potentially on some tragic event, don\u0027t delete anything\n                return;\n            }\n            final long minReferencedGen \u003d getMinReferencedGen();\n            for (Iterator\u003cTranslogReader\u003e iterator \u003d readers.iterator(); iterator.hasNext();) {\n                TranslogReader reader \u003d iterator.next();\n                if (reader.getGeneration() \u003e\u003d minReferencedGen) {\n                    break;\n                }\n                iterator.remove();\n                IOUtils.closeWhileHandlingException(reader);\n                final Path translogPath \u003d reader.path();\n                logger.trace(\"delete translog file [{}], not referenced and not current anymore\", translogPath);\n                // The checkpoint is used when opening the translog to know which files should be recovered from.\n                // We now update the checkpoint to ignore the file we are going to remove.\n                // Note that there is a provision in recoverFromFiles to allow for the case where we synced the checkpoint\n                // but crashed before we could delete the file.\n                // sync at once to make sure that there\u0027s at most one unreferenced generation.\n                current.sync();\n                deleteReaderFiles(reader);\n            }\n            assert readers.isEmpty() \u003d\u003d false || current.generation \u003d\u003d minReferencedGen\n                : \"all readers were cleaned but the minReferenceGen [\"\n                    + minReferencedGen\n                    + \"] is not the current writer\u0027s gen [\"\n                    + current.generation\n                    + \"]\";\n        } catch (final Exception ex) {\n            closeOnTragicEvent(ex);\n            throw ex;\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    private long getMinReferencedGen() {\n        long minReferencedGen \u003d Math.min(\n            deletionPolicy.getMinTranslogGenRequiredByLocks(),\n            minGenerationForSeqNo(deletionPolicy.getLocalCheckpointOfSafeCommit() + 1, current, readers)\n        );\n        assert minReferencedGen \u003e\u003d getMinFileGeneration()\n            : \"deletion policy requires a minReferenceGen of [\"\n                + minReferencedGen\n                + \"] but the lowest gen available is [\"\n                + getMinFileGeneration()\n                + \"]\";\n        assert minReferencedGen \u003c\u003d currentFileGeneration()\n            : \"deletion policy requires a minReferenceGen of [\"\n                + minReferencedGen\n                + \"] which is higher than the current generation [\"\n                + currentFileGeneration()\n                + \"]\";\n        return minReferencedGen;\n    }\n\n    /**\n     * deletes all files associated with a reader. package-private to be able to simulate node failures at this point\n     */\n    void deleteReaderFiles(TranslogReader reader) {\n        IOUtils.deleteFilesIgnoringExceptions(\n            reader.path(),\n            reader.path().resolveSibling(getCommitCheckpointFileName(reader.getGeneration()))\n        );\n    }\n\n    void closeFilesIfNoPendingRetentionLocks() throws IOException {\n        writeLock.lock();\n        try {\n            if (closed.get() \u0026\u0026 deletionPolicy.pendingTranslogRefCount() \u003d\u003d 0) {\n                logger.trace(\"closing files. translog is closed and there are no pending retention locks\");\n                ArrayList\u003cCloseable\u003e toClose \u003d new ArrayList\u003c\u003e(readers);\n                toClose.add(current);\n                IOUtils.close(toClose);\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    /**\n     * References a transaction log generation\n     */\n    public static final class TranslogGeneration {\n        public final String translogUUID;\n        public final long translogFileGeneration;\n\n        public TranslogGeneration(String translogUUID, long translogFileGeneration) {\n            this.translogUUID \u003d translogUUID;\n            this.translogFileGeneration \u003d translogFileGeneration;\n        }\n\n    }\n\n    /**\n     * Returns the current generation of this translog. This corresponds to the latest uncommitted translog generation\n     */\n    public TranslogGeneration getGeneration() {\n        return new TranslogGeneration(translogUUID, currentFileGeneration());\n    }\n\n    long getFirstOperationPosition() { // for testing\n        return current.getFirstOperationOffset();\n    }\n\n    private void ensureOpen() {\n        if (closed.get()) {\n            throw new AlreadyClosedException(\"translog is already closed\", tragedy.get());\n        }\n    }\n\n    ChannelFactory getChannelFactory() {\n        return FileChannel::open;\n    }\n\n    /**\n     * If this {@code Translog} was closed as a side-effect of a tragic exception,\n     * e.g. disk full while flushing a new segment, this returns the root cause exception.\n     * Otherwise (no tragic exception has occurred) it returns null.\n     */\n    public Exception getTragicException() {\n        return tragedy.get();\n    }\n\n    /** Reads and returns the current checkpoint */\n    static Checkpoint readCheckpoint(final Path location) throws IOException {\n        return Checkpoint.read(location.resolve(CHECKPOINT_FILE_NAME));\n    }\n\n    /**\n     * Reads the sequence numbers global checkpoint from the translog checkpoint.\n     * This ensures that the translogUUID from this translog matches with the provided translogUUID.\n     *\n     * @param location the location of the translog\n     * @return the global checkpoint\n     * @throws IOException                if an I/O exception occurred reading the checkpoint\n     * @throws TranslogCorruptedException if the translog is corrupted or mismatched with the given uuid\n     */\n    public static long readGlobalCheckpoint(final Path location, final String expectedTranslogUUID) throws IOException {\n        final Checkpoint checkpoint \u003d readCheckpoint(location, expectedTranslogUUID);\n        return checkpoint.globalCheckpoint;\n    }\n\n    private static Checkpoint readCheckpoint(Path location, String expectedTranslogUUID) throws IOException {\n        final Checkpoint checkpoint \u003d readCheckpoint(location);\n        // We need to open at least one translog header to validate the translogUUID.\n        final Path translogFile \u003d location.resolve(getFilename(checkpoint.generation));\n        try (FileChannel channel \u003d FileChannel.open(translogFile, StandardOpenOption.READ)) {\n            TranslogHeader.read(expectedTranslogUUID, translogFile, channel);\n        } catch (TranslogCorruptedException ex) {\n            throw ex; // just bubble up.\n        } catch (Exception ex) {\n            throw new TranslogCorruptedException(location.toString(), ex);\n        }\n        return checkpoint;\n    }\n\n    /**\n     * Returns the translog uuid used to associate a lucene index with a translog.\n     */\n    public String getTranslogUUID() {\n        return translogUUID;\n    }\n\n    /**\n     * Returns the max seq_no of translog operations found in this translog. Since this value is calculated based on the current\n     * existing readers, this value is not necessary to be the max seq_no of all operations have been stored in this translog.\n     */\n    public long getMaxSeqNo() {\n        readLock.lock();\n        try {\n            ensureOpen();\n            final OptionalLong maxSeqNo \u003d Stream.concat(readers.stream(), Stream.of(current))\n                .mapToLong(reader -\u003e reader.getCheckpoint().maxSeqNo)\n                .max();\n            assert maxSeqNo.isPresent() : \"must have at least one translog generation\";\n            return maxSeqNo.getAsLong();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    TranslogWriter getCurrent() {\n        return current;\n    }\n\n    List\u003cTranslogReader\u003e getReaders() {\n        return readers;\n    }\n\n    public static String createEmptyTranslog(\n        final Path location,\n        final long initialGlobalCheckpoint,\n        final ShardId shardId,\n        final long primaryTerm\n    ) throws IOException {\n        final ChannelFactory channelFactory \u003d FileChannel::open;\n        return createEmptyTranslog(location, initialGlobalCheckpoint, shardId, channelFactory, primaryTerm);\n    }\n\n    static String createEmptyTranslog(\n        Path location,\n        long initialGlobalCheckpoint,\n        ShardId shardId,\n        ChannelFactory channelFactory,\n        long primaryTerm\n    ) throws IOException {\n        return createEmptyTranslog(location, shardId, initialGlobalCheckpoint, primaryTerm, null, channelFactory);\n    }\n\n    /**\n     * Creates a new empty translog within the specified {@code location} that contains the given {@code initialGlobalCheckpoint},\n     * {@code primaryTerm} and {@code translogUUID}.\n     *\n     * This method should be used directly under specific circumstances like for shards that will see no indexing. Specifying a non-unique\n     * translog UUID could cause a lot of issues and that\u0027s why in all (but one) cases the method\n     * {@link #createEmptyTranslog(Path, long, ShardId, long)} should be used instead.\n     *\n     * @param location                a {@link Path} to the directory that will contains the translog files (translog + translog checkpoint)\n     * @param shardId                 the {@link ShardId}\n     * @param initialGlobalCheckpoint the global checkpoint to initialize the translog with\n     * @param primaryTerm             the shard\u0027s primary term to initialize the translog with\n     * @param translogUUID            the unique identifier to initialize the translog with\n     * @param factory                 a {@link ChannelFactory} used to open translog files\n     * @return the translog\u0027s unique identifier\n     * @throws IOException if something went wrong during translog creation\n     */\n    public static String createEmptyTranslog(\n        final Path location,\n        final ShardId shardId,\n        final long initialGlobalCheckpoint,\n        final long primaryTerm,\n        @Nullable final String translogUUID,\n        @Nullable final ChannelFactory factory\n    ) throws IOException {\n        IOUtils.rm(location);\n        Files.createDirectories(location);\n\n        final long generation \u003d 1L;\n        final long minTranslogGeneration \u003d 1L;\n        final ChannelFactory channelFactory \u003d factory !\u003d null ? factory : FileChannel::open;\n        final String uuid \u003d Strings.hasLength(translogUUID) ? translogUUID : UUIDs.randomBase64UUID();\n        final Path checkpointFile \u003d location.resolve(CHECKPOINT_FILE_NAME);\n        final Path translogFile \u003d location.resolve(getFilename(generation));\n        final Checkpoint checkpoint \u003d Checkpoint.emptyTranslogCheckpoint(0, generation, initialGlobalCheckpoint, minTranslogGeneration);\n\n        Checkpoint.write(channelFactory, checkpointFile, checkpoint, StandardOpenOption.WRITE, StandardOpenOption.CREATE_NEW);\n        final TranslogWriter writer \u003d TranslogWriter.create(\n            shardId,\n            uuid,\n            generation,\n            translogFile,\n            channelFactory,\n            EMPTY_TRANSLOG_BUFFER_SIZE,\n            minTranslogGeneration,\n            initialGlobalCheckpoint,\n            () -\u003e {\n                throw new UnsupportedOperationException();\n            },\n            () -\u003e { throw new UnsupportedOperationException(); },\n            primaryTerm,\n            new TragicExceptionHolder(),\n            seqNo -\u003e {\n                throw new UnsupportedOperationException();\n            },\n            BigArrays.NON_RECYCLING_INSTANCE,\n            DiskIoBufferPool.INSTANCE,\n            TranslogConfig.NOOP_OPERATION_LISTENER,\n            true\n        );\n        writer.close();\n        return uuid;\n    }\n}","methodCount":134},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":1132,"lineEnd":1140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromId to class Operation","description":"move method fromId to PsiClass:Operation\nRationale: The fromId() method is responsible for mapping byte IDs to operation types, which directly relates to the operations defined in the Operation class. Moving it to this class adheres to the Single Responsibility Principle, as it consolidates operation-related logic. This enhances cohesion and makes it easier to manage operation types in one place. However, care must be taken to ensure that any static references to this method are updated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1132,"lineEnd":1140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromId to class Index","description":"move method fromId to PsiClass:Index\nRationale: As the fromId() method maps IDs to specific operations that may include indexing, it fits well within the Index class. This move would improve the logical grouping of related functionality, enhancing maintainability. Aligning with the Open/Closed Principle, it allows for easy extension of operation types without modifying existing classes. However, it may introduce confusion if the Index class becomes overloaded with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1132,"lineEnd":1140,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fromId to class Delete","description":"move method fromId to PsiClass:Delete\nRationale: The Delete class represents an operation type that is directly referenced in the fromId() method. Relocating the method here would enhance the cohesion of operation types, making the Delete class more self-sufficient. This aligns with the Interface Segregation Principle by keeping operation-related logic within the context of operations. However, it may lead to a proliferation of such methods across multiple classes if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1938,"lineEnd":1946,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createEmptyTranslog to class TranslogWriter","description":"move method createEmptyTranslog to PsiClass:TranslogWriter\nRationale: The createEmptyTranslog() method is closely related to the functionality of managing translog files, which is a core responsibility of the TranslogWriter class. Moving it here adheres to the Single Responsibility Principle, as it consolidates translog-related operations. This enhances cohesion and encapsulates translog logic within a dedicated class. However, care must be taken to ensure that the method\u0027s dependencies are properly managed in the new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1938,"lineEnd":1946,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createEmptyTranslog to class Checkpoint","description":"move method createEmptyTranslog to PsiClass:Checkpoint\nRationale: The createEmptyTranslog() method interacts with checkpointing logic, which is a significant aspect of the Checkpoint class. Relocating the method here aligns with the Interface Segregation Principle, as it keeps related functionality together. This can lead to better maintainability and clearer intent. However, the Checkpoint class may become overloaded if too many responsibilities are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1938,"lineEnd":1946,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method createEmptyTranslog to class TranslogOperationsUtils","description":"move method createEmptyTranslog to PsiClass:TranslogOperationsUtils\nRationale: As a utility class for translog operations, TranslogOperationsUtils is a suitable candidate for the createEmptyTranslog() method. This move adheres to the Single Responsibility Principle by keeping utility methods related to translog management in one place, improving code organization. The drawback is that utility classes can grow too large and lose focus if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1641,"lineEnd":1650,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeOperationWithSize to class TranslogWriter","description":"move method writeOperationWithSize to PsiClass:TranslogWriter\nRationale: The writeOperationWithSize() method deals directly with writing operations to a stream, which aligns closely with the responsibilities of the TranslogWriter class. Moving this method would adhere to the Single Responsibility Principle, as it encapsulates the logic for writing operations, improving cohesion within the TranslogWriter. This also enhances reusability, as the method can be directly utilized in the context of writing logs. However, care should be taken to ensure that the method\u0027s static nature does not conflict with instance-based operations in TranslogWriter.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1641,"lineEnd":1650,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeOperationWithSize to class Checkpoint","description":"move method writeOperationWithSize to PsiClass:Checkpoint\nRationale: The method involves writing operations and managing their sizes, which is relevant to checkpointing in translogs. Moving it to Checkpoint could improve the logical grouping of operations related to checkpoint management. This aligns with the Interface Segregation Principle, as it would allow the Checkpoint class to handle its own operation writing logic. However, the Checkpoint class may become too burdened with responsibilities if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1641,"lineEnd":1650,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeOperationWithSize to class Index","description":"move method writeOperationWithSize to PsiClass:Index\nRationale: The writeOperationWithSize() method could be relevant to indexing operations, as these operations often involve writing data. Moving it to the Index class could help streamline the process of managing indexed operations, adhering to the Single Responsibility Principle. However, this may dilute the focus of the Index class if it becomes too involved in writing logic rather than simply managing indexed data.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"recoverFromFiles","method_signature":"private recoverFromFiles(Checkpoint checkpoint)","target_class":"","rationale":""},{"method_name":"copyCheckpointTo","method_signature":"private copyCheckpointTo(Path targetPath)","target_class":"","rationale":""},{"method_name":"openReader","method_signature":" openReader(Path path, Checkpoint checkpoint)","target_class":"","rationale":""},{"method_name":"parseIdFromFileName","method_signature":"public static parseIdFromFileName(Path translogFile)","target_class":"","rationale":""},{"method_name":"isOpen","method_signature":"public isOpen()","target_class":"","rationale":""},{"method_name":"calledFromOutsideOrViaTragedyClose","method_signature":"private static calledFromOutsideOrViaTragedyClose()","target_class":"","rationale":""},{"method_name":"currentFileGeneration","method_signature":"public currentFileGeneration()","target_class":"","rationale":""},{"method_name":"totalOperations","method_signature":"public totalOperations()","target_class":"","rationale":""},{"method_name":"sizeInBytes","method_signature":"public sizeInBytes()","target_class":"","rationale":""},{"method_name":"earliestLastModifiedAge","method_signature":" earliestLastModifiedAge()","target_class":"","rationale":""},{"method_name":"findEarliestLastModifiedAge","method_signature":"static findEarliestLastModifiedAge(long currentTime, Iterable\u003cTranslogReader\u003e readers, TranslogWriter writer)","target_class":"","rationale":""},{"method_name":"totalOperationsByMinGen","method_signature":"public totalOperationsByMinGen(long minGeneration)","target_class":"","rationale":""},{"method_name":"estimateTotalOperationsFromMinSeq","method_signature":"public estimateTotalOperationsFromMinSeq(long minSeqNo)","target_class":"","rationale":""},{"method_name":"sizeInBytesByMinGen","method_signature":"public sizeInBytesByMinGen(long minGeneration)","target_class":"","rationale":""},{"method_name":"createWriter","method_signature":" createWriter(long fileGeneration)","target_class":"","rationale":""},{"method_name":"createWriter","method_signature":" createWriter(\n        long fileGeneration,\n        long initialMinTranslogGen,\n        long initialGlobalCheckpoint,\n        LongConsumer persistedSequenceNumberConsumer\n    )","target_class":"","rationale":""},{"method_name":"add","method_signature":"public add(final Operation operation)","target_class":"","rationale":""},{"method_name":"shouldRollGeneration","method_signature":"public shouldRollGeneration()","target_class":"","rationale":""},{"method_name":"newSnapshot","method_signature":"public newSnapshot()","target_class":"","rationale":""},{"method_name":"newSnapshot","method_signature":"public newSnapshot(long fromSeqNo, long toSeqNo)","target_class":"","rationale":""},{"method_name":"readOperation","method_signature":"public readOperation(Location location)","target_class":"","rationale":""},{"method_name":"newMultiSnapshot","method_signature":"private newMultiSnapshot(TranslogSnapshot[] snapshots)","target_class":"","rationale":""},{"method_name":"acquireRetentionLock","method_signature":"public acquireRetentionLock()","target_class":"","rationale":""},{"method_name":"acquireTranslogGenFromDeletionPolicy","method_signature":"private acquireTranslogGenFromDeletionPolicy(long viewGen)","target_class":"","rationale":""},{"method_name":"sync","method_signature":"public sync()","target_class":"","rationale":""},{"method_name":"syncNeeded","method_signature":"public syncNeeded()","target_class":"","rationale":""},{"method_name":"getFilename","method_signature":"public static getFilename(long generation)","target_class":"","rationale":""},{"method_name":"getCommitCheckpointFileName","method_signature":"static getCommitCheckpointFileName(long generation)","target_class":"","rationale":""},{"method_name":"trimOperations","method_signature":"public trimOperations(long belowTerm, long aboveSeqNo)","target_class":"","rationale":""},{"method_name":"ensureSynced","method_signature":"public ensureSynced(Location location, long globalCheckpoint)","target_class":"","rationale":""},{"method_name":"closeOnTragicEvent","method_signature":"protected closeOnTragicEvent(final Exception ex)","target_class":"","rationale":""},{"method_name":"stats","method_signature":"public stats()","target_class":"","rationale":""},{"method_name":"skippedOperations","method_signature":"default skippedOperations()","target_class":"","rationale":""},{"method_name":"fromId","method_signature":"public static fromId(byte id)","target_class":"","rationale":""},{"method_name":"readOperation","method_signature":"public static readOperation(final StreamInput input)","target_class":"","rationale":""},{"method_name":"readFrom","method_signature":"private static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"readFrom","method_signature":"private static readFrom(StreamInput in)","target_class":"","rationale":""},{"method_name":"verifyChecksum","method_signature":"static verifyChecksum(BufferedChecksumStreamInput in)","target_class":"","rationale":""},{"method_name":"readOperations","method_signature":"public static readOperations(StreamInput input, String source)","target_class":"","rationale":""},{"method_name":"readOperation","method_signature":"public static readOperation(BufferedChecksumStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOperations","method_signature":"public static writeOperations(StreamOutput outStream, List\u003cOperation\u003e toWrite)","target_class":"","rationale":""},{"method_name":"writeOperationsToStreamLegacyFormat","method_signature":"private static writeOperationsToStreamLegacyFormat(StreamOutput outStream, List\u003cOperation\u003e toWrite)","target_class":"","rationale":""},{"method_name":"writeOperationNoSize","method_signature":"public static writeOperationNoSize(BufferedChecksumStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},{"method_name":"writeOperationWithSize","method_signature":"public static writeOperationWithSize(BytesStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},{"method_name":"getMinGenerationForSeqNo","method_signature":"public getMinGenerationForSeqNo(final long seqNo)","target_class":"","rationale":""},{"method_name":"minGenerationForSeqNo","method_signature":"private static minGenerationForSeqNo(long seqNo, TranslogWriter writer, List\u003cTranslogReader\u003e readers)","target_class":"","rationale":""},{"method_name":"rollGeneration","method_signature":"public rollGeneration()","target_class":"","rationale":""},{"method_name":"syncBeforeRollGeneration","method_signature":" syncBeforeRollGeneration()","target_class":"","rationale":""},{"method_name":"trimUnreferencedReaders","method_signature":"public trimUnreferencedReaders()","target_class":"","rationale":""},{"method_name":"deleteReaderFiles","method_signature":" deleteReaderFiles(TranslogReader reader)","target_class":"","rationale":""},{"method_name":"closeFilesIfNoPendingRetentionLocks","method_signature":" closeFilesIfNoPendingRetentionLocks()","target_class":"","rationale":""},{"method_name":"ensureOpen","method_signature":"private ensureOpen()","target_class":"","rationale":""},{"method_name":"readCheckpoint","method_signature":"static readCheckpoint(final Path location)","target_class":"","rationale":""},{"method_name":"readGlobalCheckpoint","method_signature":"public static readGlobalCheckpoint(final Path location, final String expectedTranslogUUID)","target_class":"","rationale":""},{"method_name":"readCheckpoint","method_signature":"private static readCheckpoint(Path location, String expectedTranslogUUID)","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final long initialGlobalCheckpoint,\n        final ShardId shardId,\n        final long primaryTerm\n    )","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"static createEmptyTranslog(\n        Path location,\n        long initialGlobalCheckpoint,\n        ShardId shardId,\n        ChannelFactory channelFactory,\n        long primaryTerm\n    )","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final ShardId shardId,\n        final long initialGlobalCheckpoint,\n        final long primaryTerm,\n        @Nullable final String translogUUID,\n        @Nullable final ChannelFactory factory\n    )","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"fromId","method_signature":"public static fromId(byte id)","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"static createEmptyTranslog(\n        Path location,\n        long initialGlobalCheckpoint,\n        ShardId shardId,\n        ChannelFactory channelFactory,\n        long primaryTerm\n    )","target_class":"","rationale":""},{"method_name":"writeOperationWithSize","method_signature":"public static writeOperationWithSize(BytesStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},{"method_name":"writeOperationNoSize","method_signature":"public static writeOperationNoSize(BufferedChecksumStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},{"method_name":"createWriter","method_signature":" createWriter(long fileGeneration)","target_class":"","rationale":""},{"method_name":"deleteReaderFiles","method_signature":" deleteReaderFiles(TranslogReader reader)","target_class":"","rationale":""},{"method_name":"readOperation","method_signature":"public static readOperation(final StreamInput input)","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final long initialGlobalCheckpoint,\n        final ShardId shardId,\n        final long primaryTerm\n    )","target_class":"","rationale":""},{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final ShardId shardId,\n        final long initialGlobalCheckpoint,\n        final long primaryTerm,\n        @Nullable final String translogUUID,\n        @Nullable final ChannelFactory factory\n    )","target_class":"","rationale":""},{"method_name":"syncBeforeRollGeneration","method_signature":" syncBeforeRollGeneration()","target_class":"","rationale":""},{"method_name":"isOpen","method_signature":"public isOpen()","target_class":"","rationale":""},{"method_name":"readGlobalCheckpoint","method_signature":"public static readGlobalCheckpoint(final Path location, final String expectedTranslogUUID)","target_class":"","rationale":""},{"method_name":"calledFromOutsideOrViaTragedyClose","method_signature":"private static calledFromOutsideOrViaTragedyClose()","target_class":"","rationale":""},{"method_name":"newSnapshot","method_signature":"public newSnapshot(long fromSeqNo, long toSeqNo)","target_class":"","rationale":""},{"method_name":"newSnapshot","method_signature":"public newSnapshot()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static fromId(byte id)":{"first":{"method_name":"fromId","method_signature":"public static fromId(byte id)","target_class":"","rationale":""},"second":0.2688546719023155},"static createEmptyTranslog(\n        Path location,\n        long initialGlobalCheckpoint,\n        ShardId shardId,\n        ChannelFactory channelFactory,\n        long primaryTerm\n    )":{"first":{"method_name":"createEmptyTranslog","method_signature":"static createEmptyTranslog(\n        Path location,\n        long initialGlobalCheckpoint,\n        ShardId shardId,\n        ChannelFactory channelFactory,\n        long primaryTerm\n    )","target_class":"","rationale":""},"second":0.3549334111887789},"public static writeOperationWithSize(BytesStreamOutput out, Translog.Operation op)":{"first":{"method_name":"writeOperationWithSize","method_signature":"public static writeOperationWithSize(BytesStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},"second":0.36074376647907525},"public static writeOperationNoSize(BufferedChecksumStreamOutput out, Translog.Operation op)":{"first":{"method_name":"writeOperationNoSize","method_signature":"public static writeOperationNoSize(BufferedChecksumStreamOutput out, Translog.Operation op)","target_class":"","rationale":""},"second":0.36313361657502363}," createWriter(long fileGeneration)":{"first":{"method_name":"createWriter","method_signature":" createWriter(long fileGeneration)","target_class":"","rationale":""},"second":0.3636455679254227}," deleteReaderFiles(TranslogReader reader)":{"first":{"method_name":"deleteReaderFiles","method_signature":" deleteReaderFiles(TranslogReader reader)","target_class":"","rationale":""},"second":0.36559433561965815},"public static readOperation(final StreamInput input)":{"first":{"method_name":"readOperation","method_signature":"public static readOperation(final StreamInput input)","target_class":"","rationale":""},"second":0.37404301425333464},"public static createEmptyTranslog(\n        final Path location,\n        final long initialGlobalCheckpoint,\n        final ShardId shardId,\n        final long primaryTerm\n    )":{"first":{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final long initialGlobalCheckpoint,\n        final ShardId shardId,\n        final long primaryTerm\n    )","target_class":"","rationale":""},"second":0.38725401722770436},"public static createEmptyTranslog(\n        final Path location,\n        final ShardId shardId,\n        final long initialGlobalCheckpoint,\n        final long primaryTerm,\n        @Nullable final String translogUUID,\n        @Nullable final ChannelFactory factory\n    )":{"first":{"method_name":"createEmptyTranslog","method_signature":"public static createEmptyTranslog(\n        final Path location,\n        final ShardId shardId,\n        final long initialGlobalCheckpoint,\n        final long primaryTerm,\n        @Nullable final String translogUUID,\n        @Nullable final ChannelFactory factory\n    )","target_class":"","rationale":""},"second":0.4152667752553984}," syncBeforeRollGeneration()":{"first":{"method_name":"syncBeforeRollGeneration","method_signature":" syncBeforeRollGeneration()","target_class":"","rationale":""},"second":0.4287290159307189},"public isOpen()":{"first":{"method_name":"isOpen","method_signature":"public isOpen()","target_class":"","rationale":""},"second":0.45240282675018134},"public static readGlobalCheckpoint(final Path location, final String expectedTranslogUUID)":{"first":{"method_name":"readGlobalCheckpoint","method_signature":"public static readGlobalCheckpoint(final Path location, final String expectedTranslogUUID)","target_class":"","rationale":""},"second":0.4529888648172286},"private static calledFromOutsideOrViaTragedyClose()":{"first":{"method_name":"calledFromOutsideOrViaTragedyClose","method_signature":"private static calledFromOutsideOrViaTragedyClose()","target_class":"","rationale":""},"second":0.46137459920206364},"public newSnapshot(long fromSeqNo, long toSeqNo)":{"first":{"method_name":"newSnapshot","method_signature":"public newSnapshot(long fromSeqNo, long toSeqNo)","target_class":"","rationale":""},"second":0.4619042114762149},"public newSnapshot()":{"first":{"method_name":"newSnapshot","method_signature":"public newSnapshot()","target_class":"","rationale":""},"second":0.46245134709287977}},"llmMethodPriority":{"priority_method_names":["createEmptyTranslog","writeOperationWithSize","writeOperationNoSize","createEmptyTranslog","createEmptyTranslog","isOpen","readGlobalCheckpoint","newSnapshot","newSnapshot"],"llm_response_time":4442},"targetClassMap":{"fromId":{"target_classes":[{"class_name":"Operation","similarity_score":0.6085625841110339},{"class_name":"TranslogOperationsUtils","similarity_score":0.1531050707248751},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.41173765554744707},{"class_name":"ForUtil","similarity_score":0.19936496889091548},{"class_name":"GeoUtilsTests","similarity_score":0.23521265396277274},{"class_name":"DocValuesForUtil","similarity_score":0.2242492833845288},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.29522791626489425},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.21695387847626657},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.19496546221690478},{"class_name":"CloseUtils","similarity_score":0.24402147483471978},{"class_name":"MapperTestUtils","similarity_score":0.2318625417624076},{"class_name":"BinaryRangeUtilTests","similarity_score":0.15336724062524115},{"class_name":"RetentionLeaseUtils","similarity_score":0.2492797449740257},{"class_name":"StoreUtils","similarity_score":0.2721398158118084},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.20307692386166665},{"class_name":"ShardUtils","similarity_score":0.19395064779941648},{"class_name":"PForUtil","similarity_score":0.18144082104712492},{"class_name":"Index","similarity_score":0.27671092546793674},{"class_name":"Checkpoint","similarity_score":0.24129281627049443},{"class_name":"Delete","similarity_score":0.2898174910133899},{"class_name":"ContainingInAnyOrderMatcher","similarity_score":0.25938716083526364},{"class_name":"TestTranslog","similarity_score":0.21539931166099366},{"class_name":"TruncateTranslogAction","similarity_score":0.26943728230646186},{"class_name":"Translog","similarity_score":0.2964730073034937},{"class_name":"TranslogCorruptedException","similarity_score":0.25209230284843376},{"class_name":"TranslogHeader","similarity_score":0.24053734152899164},{"class_name":"TranslogReader","similarity_score":0.23024162556950767},{"class_name":"TranslogTests","similarity_score":0.2826276487238478},{"class_name":"TranslogWriter","similarity_score":0.2564633081542721},{"class_name":"SnapshotMatchers","similarity_score":0.32716456455897697}],"target_classes_sorted_by_llm":["Operation","Index","Delete","Translog","StoreUtils","TranslogTests","SnapshotMatchers","IndexLongFieldRangeTestUtils","LiveVersionMapTestUtils","TruncateTranslogAction"],"llm_response_time":8354,"similarity_computation_time":28,"similarity_metric":"voyage"},"createEmptyTranslog":{"target_classes":[{"class_name":"TranslogOperationsUtils","similarity_score":0.2810736371242605},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.2246414837169715},{"class_name":"RetentionLeaseUtils","similarity_score":0.11053942207134547},{"class_name":"GeoUtilsTests","similarity_score":0.1524845545639677},{"class_name":"DocValuesForUtil","similarity_score":0.22855909232914315},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.20189370282403482},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.1689569025168811},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.37635552720706883},{"class_name":"ShardUtils","similarity_score":0.20285211318707386},{"class_name":"MapperTestUtils","similarity_score":0.28247348786611565},{"class_name":"ForUtil","similarity_score":0.15129641852582187},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.1296741071158002},{"class_name":"CloseUtils","similarity_score":0.17880882226176978},{"class_name":"BinaryRangeUtilTests","similarity_score":0.12990999633328934},{"class_name":"StoreUtils","similarity_score":0.27927962907828247},{"class_name":"PForUtil","similarity_score":0.18938399542439188},{"class_name":"Index","similarity_score":0.29914771943541874},{"class_name":"TestTranslog","similarity_score":0.2524819126232335},{"class_name":"TranslogCorruptedException","similarity_score":0.2759532298909644},{"class_name":"TranslogHeader","similarity_score":0.22896049876523178},{"class_name":"TranslogReader","similarity_score":0.2558148674356526},{"class_name":"TranslogTests","similarity_score":0.22681367802375274},{"class_name":"TranslogWriter","similarity_score":0.2636597318659058},{"class_name":"TruncateTranslogAction","similarity_score":0.2572078819031261},{"class_name":"Checkpoint","similarity_score":0.2673098623237094},{"class_name":"SnapshotMatchers","similarity_score":0.26012123293350553},{"class_name":"Delete","similarity_score":0.31514183415128433},{"class_name":"ContainingInAnyOrderMatcher","similarity_score":0.22182699803788972},{"class_name":"ESVectorUtil","similarity_score":0.15401027590842437}],"target_classes_sorted_by_llm":["TranslogWriter","Checkpoint","TranslogOperationsUtils","StoreUtils","Index","Delete","TranslogCorruptedException","MapperTestUtils","LiveVersionMapTestUtils","SnapshotMatchers"],"llm_response_time":9596,"similarity_computation_time":18,"similarity_metric":"voyage"},"writeOperationWithSize":{"target_classes":[{"class_name":"TranslogOperationsUtils","similarity_score":0.17275582977016063},{"class_name":"RetentionLeaseUtils","similarity_score":0.09046835805696823},{"class_name":"GeoUtilsTests","similarity_score":0.39327085379490445},{"class_name":"ForUtil","similarity_score":0.34902783499133777},{"class_name":"DocValuesForUtil","similarity_score":0.39337655476964306},{"class_name":"LiveVersionMapTestUtils","similarity_score":0.32290303186400515},{"class_name":"PForUtil","similarity_score":0.40798331593589404},{"class_name":"CloseUtils","similarity_score":0.2945841894624274},{"class_name":"ShardUtils","similarity_score":0.23830547675703506},{"class_name":"MapperTestUtils","similarity_score":0.33336834550015787},{"class_name":"IndexLongFieldRangeTestUtils","similarity_score":0.2971353109450694},{"class_name":"SpanQueryBuilderUtil","similarity_score":0.09648062312349498},{"class_name":"IpPrefixAutomatonUtil","similarity_score":0.3773661791990358},{"class_name":"IpPrefixAutomatonUtilTests","similarity_score":0.30269153090868783},{"class_name":"StoreUtils","similarity_score":0.16161498378886355},{"class_name":"BinaryRangeUtilTests","similarity_score":0.41636486906054687},{"class_name":"Checkpoint","similarity_score":0.4484175119346302},{"class_name":"Index","similarity_score":0.45554666009954237},{"class_name":"Delete","similarity_score":0.4689460557310025},{"class_name":"SnapshotMatchers","similarity_score":0.36288073231147505},{"class_name":"ContainingInAnyOrderMatcher","similarity_score":0.3190861648983546},{"class_name":"TestTranslog","similarity_score":0.4043302598812539},{"class_name":"TranslogCorruptedException","similarity_score":0.2138705971341109},{"class_name":"TranslogHeader","similarity_score":0.411684150883504},{"class_name":"TranslogReader","similarity_score":0.3872278887650319},{"class_name":"TranslogTests","similarity_score":0.5125002939580847},{"class_name":"TranslogWriter","similarity_score":0.3978212238116627},{"class_name":"TruncateTranslogAction","similarity_score":0.45510392448689835},{"class_name":"ESVectorUtil","similarity_score":0.2329942013280037}],"target_classes_sorted_by_llm":["TranslogWriter","Checkpoint","Index","Delete","TranslogTests","TruncateTranslogAction","BinaryRangeUtilTests","TranslogHeader","PForUtil","TestTranslog"],"llm_response_time":15983,"similarity_computation_time":19,"similarity_metric":"voyage"}}}
{"id":"23fb42ad-d52b-4ca9-963c-a90160723dac","methodCount":8,"hostFunctionTelemetryData":{"hostFunctionSize":160,"lineStart":50,"lineEnd":209,"bodyLineStart":50,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/action/ResponseValueUtils.java","sourceCode":"/**\n * Collection of static utility methods for helping transform response data between pages and values.\n */\npublic final class ResponseValueUtils {\n\n    /**\n     * Returns an iterator of iterators over the values in the given pages. There is one iterator\n     * for each block.\n     */\n    public static Iterator\u003cIterator\u003cObject\u003e\u003e pagesToValues(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages) {\n        BytesRef scratch \u003d new BytesRef();\n        return Iterators.flatMap(\n            pages.iterator(),\n            page -\u003e Iterators.forRange(\n                0,\n                page.getPositionCount(),\n                pos -\u003e Iterators.forRange(0, page.getBlockCount(), b -\u003e valueAtPosition(page.getBlock(b), pos, dataTypes.get(b), scratch))\n            )\n        );\n    }\n\n    /** Returns an iterable of iterables over the values in the given pages. There is one iterables for each row. */\n    static Iterable\u003cIterable\u003cObject\u003e\u003e valuesForRowsInPages(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages) {\n        BytesRef scratch \u003d new BytesRef();\n        return () -\u003e Iterators.flatMap(pages.iterator(), page -\u003e valuesForRowsInPage(dataTypes, page, scratch));\n    }\n\n    /** Returns an iterable of iterables over the values in the given page. There is one iterables for each row. */\n    static Iterator\u003cIterable\u003cObject\u003e\u003e valuesForRowsInPage(List\u003cDataType\u003e dataTypes, Page page, BytesRef scratch) {\n        return Iterators.forRange(0, page.getPositionCount(), position -\u003e valuesForRow(dataTypes, page, position, scratch));\n    }\n\n    /** Returns an iterable over the values in the given row in a page. */\n    static Iterable\u003cObject\u003e valuesForRow(List\u003cDataType\u003e dataTypes, Page page, int position, BytesRef scratch) {\n        return () -\u003e Iterators.forRange(\n            0,\n            page.getBlockCount(),\n            blockIdx -\u003e valueAtPosition(page.getBlock(blockIdx), position, dataTypes.get(blockIdx), scratch)\n        );\n    }\n\n    /**  Returns an iterator of values for the given column. */\n    static Iterator\u003cObject\u003e valuesForColumn(int columnIndex, DataType dataType, List\u003cPage\u003e pages) {\n        BytesRef scratch \u003d new BytesRef();\n        return Iterators.flatMap(\n            pages.iterator(),\n            page -\u003e Iterators.forRange(\n                0,\n                page.getPositionCount(),\n                pos -\u003e valueAtPosition(page.getBlock(columnIndex), pos, dataType, scratch)\n            )\n        );\n    }\n\n    /** Returns the value that the position and with the given data type, in the block. */\n    static Object valueAtPosition(Block block, int position, DataType dataType, BytesRef scratch) {\n        if (block.isNull(position)) {\n            return null;\n        }\n        int count \u003d block.getValueCount(position);\n        int start \u003d block.getFirstValueIndex(position);\n        if (count \u003d\u003d 1) {\n            return valueAt(dataType, block, start, scratch);\n        }\n        List\u003cObject\u003e values \u003d new ArrayList\u003c\u003e(count);\n        int end \u003d count + start;\n        for (int i \u003d start; i \u003c end; i++) {\n            values.add(valueAt(dataType, block, i, scratch));\n        }\n        return values;\n    }\n\n    private static Object valueAt(DataType dataType, Block block, int offset, BytesRef scratch) {\n        return switch (dataType) {\n            case UNSIGNED_LONG -\u003e unsignedLongAsNumber(((LongBlock) block).getLong(offset));\n            case LONG, COUNTER_LONG -\u003e ((LongBlock) block).getLong(offset);\n            case INTEGER, COUNTER_INTEGER -\u003e ((IntBlock) block).getInt(offset);\n            case DOUBLE, COUNTER_DOUBLE -\u003e ((DoubleBlock) block).getDouble(offset);\n            case KEYWORD, TEXT -\u003e ((BytesRefBlock) block).getBytesRef(offset, scratch).utf8ToString();\n            case IP -\u003e {\n                BytesRef val \u003d ((BytesRefBlock) block).getBytesRef(offset, scratch);\n                yield ipToString(val);\n            }\n            case DATETIME -\u003e {\n                long longVal \u003d ((LongBlock) block).getLong(offset);\n                yield dateTimeToString(longVal);\n            }\n            case BOOLEAN -\u003e ((BooleanBlock) block).getBoolean(offset);\n            case VERSION -\u003e versionToString(((BytesRefBlock) block).getBytesRef(offset, scratch));\n            case GEO_POINT, GEO_SHAPE, CARTESIAN_POINT, CARTESIAN_SHAPE -\u003e spatialToString(\n                ((BytesRefBlock) block).getBytesRef(offset, scratch)\n            );\n            case UNSUPPORTED -\u003e UnsupportedValueSource.UNSUPPORTED_OUTPUT;\n            case SOURCE -\u003e {\n                BytesRef val \u003d ((BytesRefBlock) block).getBytesRef(offset, scratch);\n                try {\n                    try (XContentParser parser \u003d XContentHelper.createParser(XContentParserConfiguration.EMPTY, new BytesArray(val))) {\n                        parser.nextToken();\n                        yield parser.mapOrdered();\n                    }\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            }\n            case SHORT, BYTE, FLOAT, HALF_FLOAT, SCALED_FLOAT, OBJECT, NESTED, DATE_PERIOD, TIME_DURATION, DOC_DATA_TYPE, TSID_DATA_TYPE,\n                NULL, PARTIAL_AGG -\u003e throw EsqlIllegalArgumentException.illegalDataType(dataType);\n        };\n    }\n\n    /**\n     * Converts a list of values to Pages so that we can parse from xcontent. It\u0027s not\n     * super efficient, but it doesn\u0027t really have to be.\n     */\n    static Page valuesToPage(BlockFactory blockFactory, List\u003cColumnInfoImpl\u003e columns, List\u003cList\u003cObject\u003e\u003e values) {\n        List\u003cDataType\u003e dataTypes \u003d columns.stream().map(ColumnInfoImpl::type).toList();\n        List\u003cBlock.Builder\u003e results \u003d dataTypes.stream()\n            .map(c -\u003e PlannerUtils.toElementType(c).newBlockBuilder(values.size(), blockFactory))\n            .toList();\n\n        for (List\u003cObject\u003e row : values) {\n            for (int c \u003d 0; c \u003c row.size(); c++) {\n                var builder \u003d results.get(c);\n                var value \u003d row.get(c);\n                switch (dataTypes.get(c)) {\n                    case UNSIGNED_LONG -\u003e ((LongBlock.Builder) builder).appendLong(longToUnsignedLong(((Number) value).longValue(), true));\n                    case LONG, COUNTER_LONG -\u003e ((LongBlock.Builder) builder).appendLong(((Number) value).longValue());\n                    case INTEGER, COUNTER_INTEGER -\u003e ((IntBlock.Builder) builder).appendInt(((Number) value).intValue());\n                    case DOUBLE, COUNTER_DOUBLE -\u003e ((DoubleBlock.Builder) builder).appendDouble(((Number) value).doubleValue());\n                    case KEYWORD, TEXT, UNSUPPORTED -\u003e ((BytesRefBlock.Builder) builder).appendBytesRef(new BytesRef(value.toString()));\n                    case IP -\u003e ((BytesRefBlock.Builder) builder).appendBytesRef(stringToIP(value.toString()));\n                    case DATETIME -\u003e {\n                        long longVal \u003d dateTimeToLong(value.toString());\n                        ((LongBlock.Builder) builder).appendLong(longVal);\n                    }\n                    case BOOLEAN -\u003e ((BooleanBlock.Builder) builder).appendBoolean(((Boolean) value));\n                    case NULL -\u003e builder.appendNull();\n                    case VERSION -\u003e ((BytesRefBlock.Builder) builder).appendBytesRef(stringToVersion(new BytesRef(value.toString())));\n                    case SOURCE -\u003e {\n                        @SuppressWarnings(\"unchecked\")\n                        Map\u003cString, ?\u003e o \u003d (Map\u003cString, ?\u003e) value;\n                        try {\n                            try (XContentBuilder sourceBuilder \u003d JsonXContent.contentBuilder()) {\n                                sourceBuilder.map(o);\n                                ((BytesRefBlock.Builder) builder).appendBytesRef(BytesReference.bytes(sourceBuilder).toBytesRef());\n                            }\n                        } catch (IOException e) {\n                            throw new UncheckedIOException(e);\n                        }\n                    }\n                    case GEO_POINT, GEO_SHAPE, CARTESIAN_POINT, CARTESIAN_SHAPE -\u003e {\n                        // This just converts WKT to WKB, so does not need CRS knowledge, we could merge GEO and CARTESIAN here\n                        BytesRef wkb \u003d stringToSpatial(value.toString());\n                        ((BytesRefBlock.Builder) builder).appendBytesRef(wkb);\n                    }\n                }\n            }\n        }\n        return new Page(results.stream().map(Block.Builder::build).toArray(Block[]::new));\n    }\n}","methodCount":8},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":103,"lineEnd":119,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valueAtPosition to class EsqlTestUtils","description":"move method valueAtPosition to PsiClass:EsqlTestUtils\nRationale: The valueAtPosition() method is primarily concerned with retrieving values from a block based on a position and data type, which aligns well with the utility nature of EsqlTestUtils. Moving it here adheres to the Single Responsibility Principle, as it centralizes value retrieval operations related to ESQL testing. This enhances cohesion and reusability of utility methods. However, care must be taken to ensure that the method\u0027s dependencies are managed appropriately.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":103,"lineEnd":119,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valueAtPosition to class SqlTestUtils","description":"move method valueAtPosition to PsiClass:SqlTestUtils\nRationale: SqlTestUtils is dedicated to SQL-related testing utilities, and the valueAtPosition() method performs a fundamental operation that could be useful in various SQL test scenarios. Relocating it here would improve the organization of utility functions and ensure that SQL-related logic is encapsulated in a single class. This aligns with the Open/Closed Principle by allowing future enhancements to be made without modifying existing code. However, it may introduce dependencies on the SQL context that need careful management.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":103,"lineEnd":119,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valueAtPosition to class ResponseXContentUtils","description":"move method valueAtPosition to PsiClass:ResponseXContentUtils\nRationale: Given that ResponseXContentUtils deals with formatting and retrieving values for responses, the valueAtPosition() method could fit well in this context. It would streamline the retrieval of values for response formatting, enhancing the utility of this class. This move would promote better separation of concerns, aligning with the Interface Segregation Principle by ensuring that ResponseXContentUtils focuses on response-related logic. However, it may lead to a bloated utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":76,"lineEnd":79,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRowsInPage to class ResponseXContentUtils","description":"move method valuesForRowsInPage to PsiClass:ResponseXContentUtils\nRationale: The valuesForRowsInPage() method is focused on extracting values from a page structure, which aligns with the utility functions in ResponseXContentUtils that deal with columnar and row values. Moving it here enhances cohesion as the method complements existing methods handling data extraction. This adheres to the Single Responsibility Principle, making the utility class more focused. A drawback could be that it may increase the size of ResponseXContentUtils, which should be monitored.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":76,"lineEnd":79,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRowsInPage to class SqlTestUtils","description":"move method valuesForRowsInPage to PsiClass:SqlTestUtils\nRationale: The method primarily deals with data extraction which is relevant in SQL context, especially in testing scenarios. SqlTestUtils is designed to facilitate SQL operations, making it a suitable target. This move enhances cohesion and aligns with the Interface Segregation Principle by keeping SQL-related utilities together. However, the method may not directly relate to SQL operations, so this could cause confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":76,"lineEnd":79,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRowsInPage to class CsvTestUtils","description":"move method valuesForRowsInPage to PsiClass:CsvTestUtils\nRationale: The valuesForRowsInPage() method can be relevant in contexts where data is structured in rows and columns, similar to CSV formats. CsvTestUtils focuses on handling CSV data, making it a good fit. This move aligns with the Single Responsibility Principle and improves cohesion. A potential drawback is that the method might not be directly tied to CSV operations, which could lead to unclear utility purposes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":88,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRow to class ResponseXContentUtils","description":"move method valuesForRow to PsiClass:ResponseXContentUtils\nRationale: The valuesForRow() method is focused on retrieving values from a page, which aligns with the responsibilities of ResponseXContentUtils, particularly its rowValues method. Moving this method here would enhance cohesion and keep related functionalities together. This change adheres to the Single Responsibility Principle and the Open/Closed Principle, as it allows for easier extensions related to response content processing. However, care should be taken to ensure that it does not introduce circular dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":88,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRow to class CsvTestUtils","description":"move method valuesForRow to PsiClass:CsvTestUtils\nRationale: Given that CsvTestUtils handles data loading and manipulation, moving valuesForRow() here would be appropriate as it deals with data extraction from a page structure, which can be seen as a part of CSV data processing. This aligns with the Single Responsibility Principle by grouping data-related functionalities. However, it may lead to a bloated utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":81,"lineEnd":88,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method valuesForRow to class PlannerUtils","description":"move method valuesForRow to PsiClass:PlannerUtils\nRationale: PlannerUtils is responsible for planning and data manipulation, which could encompass the retrieval of values from a structured page. This move would keep data handling methods together and enhance the cohesion of the class. It aligns with the Interface Segregation Principle by allowing users to focus on relevant methods. However, the method\u0027s utility nature may not fit well with the broader planning responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"pagesToValues","method_signature":"public static pagesToValues(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valuesForRowsInPages","method_signature":"static valuesForRowsInPages(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valuesForRowsInPage","method_signature":"static valuesForRowsInPage(List\u003cDataType\u003e dataTypes, Page page, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesForRow","method_signature":"static valuesForRow(List\u003cDataType\u003e dataTypes, Page page, int position, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesForColumn","method_signature":"static valuesForColumn(int columnIndex, DataType dataType, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valueAtPosition","method_signature":"static valueAtPosition(Block block, int position, DataType dataType, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valueAt","method_signature":"private static valueAt(DataType dataType, Block block, int offset, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesToPage","method_signature":"static valuesToPage(BlockFactory blockFactory, List\u003cColumnInfoImpl\u003e columns, List\u003cList\u003cObject\u003e\u003e values)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"valueAtPosition","method_signature":"static valueAtPosition(Block block, int position, DataType dataType, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesForRowsInPage","method_signature":"static valuesForRowsInPage(List\u003cDataType\u003e dataTypes, Page page, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesForRow","method_signature":"static valuesForRow(List\u003cDataType\u003e dataTypes, Page page, int position, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"pagesToValues","method_signature":"public static pagesToValues(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valuesForColumn","method_signature":"static valuesForColumn(int columnIndex, DataType dataType, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valuesForRowsInPages","method_signature":"static valuesForRowsInPages(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},{"method_name":"valueAt","method_signature":"private static valueAt(DataType dataType, Block block, int offset, BytesRef scratch)","target_class":"","rationale":""},{"method_name":"valuesToPage","method_signature":"static valuesToPage(BlockFactory blockFactory, List\u003cColumnInfoImpl\u003e columns, List\u003cList\u003cObject\u003e\u003e values)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"static valueAtPosition(Block block, int position, DataType dataType, BytesRef scratch)":{"first":{"method_name":"valueAtPosition","method_signature":"static valueAtPosition(Block block, int position, DataType dataType, BytesRef scratch)","target_class":"","rationale":""},"second":0.42719163139205085},"static valuesForRowsInPage(List\u003cDataType\u003e dataTypes, Page page, BytesRef scratch)":{"first":{"method_name":"valuesForRowsInPage","method_signature":"static valuesForRowsInPage(List\u003cDataType\u003e dataTypes, Page page, BytesRef scratch)","target_class":"","rationale":""},"second":0.4527149618022815},"static valuesForRow(List\u003cDataType\u003e dataTypes, Page page, int position, BytesRef scratch)":{"first":{"method_name":"valuesForRow","method_signature":"static valuesForRow(List\u003cDataType\u003e dataTypes, Page page, int position, BytesRef scratch)","target_class":"","rationale":""},"second":0.4902034435298469},"public static pagesToValues(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)":{"first":{"method_name":"pagesToValues","method_signature":"public static pagesToValues(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},"second":0.5437600793067314},"static valuesForColumn(int columnIndex, DataType dataType, List\u003cPage\u003e pages)":{"first":{"method_name":"valuesForColumn","method_signature":"static valuesForColumn(int columnIndex, DataType dataType, List\u003cPage\u003e pages)","target_class":"","rationale":""},"second":0.5466951853839458},"static valuesForRowsInPages(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)":{"first":{"method_name":"valuesForRowsInPages","method_signature":"static valuesForRowsInPages(List\u003cDataType\u003e dataTypes, List\u003cPage\u003e pages)","target_class":"","rationale":""},"second":0.5973605933925844},"private static valueAt(DataType dataType, Block block, int offset, BytesRef scratch)":{"first":{"method_name":"valueAt","method_signature":"private static valueAt(DataType dataType, Block block, int offset, BytesRef scratch)","target_class":"","rationale":""},"second":0.6346984028066996},"static valuesToPage(BlockFactory blockFactory, List\u003cColumnInfoImpl\u003e columns, List\u003cList\u003cObject\u003e\u003e values)":{"first":{"method_name":"valuesToPage","method_signature":"static valuesToPage(BlockFactory blockFactory, List\u003cColumnInfoImpl\u003e columns, List\u003cList\u003cObject\u003e\u003e values)","target_class":"","rationale":""},"second":0.6692383660051431}},"llmMethodPriority":{"priority_method_names":["pagesToValues","valueAtPosition","valuesForRowsInPage","valuesForRow","valuesForColumn","valuesForRowsInPages","valueAt","valuesToPage"],"llm_response_time":3099},"targetClassMap":{"valueAtPosition":{"target_classes":[{"class_name":"ResponseXContentUtils","similarity_score":0.5973870949886628},{"class_name":"FunctionTestUtils","similarity_score":0.325528582664392},{"class_name":"ExceptionUtils","similarity_score":0.2729402386824312},{"class_name":"NumberUtils","similarity_score":0.5333987816348611},{"class_name":"NumericUtilsTests","similarity_score":0.15304924939172054},{"class_name":"ParserUtils","similarity_score":0.4925509643019602},{"class_name":"AnalyzerTestUtils","similarity_score":0.39546733145891577},{"class_name":"LuceneComponent2DUtils","similarity_score":0.5391540632739336},{"class_name":"PlannerUtils","similarity_score":0.5947686502511789},{"class_name":"SerializationTestUtils","similarity_score":0.40330522705898053},{"class_name":"EsqlTestUtils","similarity_score":0.5721247414871148},{"class_name":"CsvTestUtils","similarity_score":0.6447724499655011},{"class_name":"DateUtils","similarity_score":0.5061316070966988},{"class_name":"SourceUtils","similarity_score":0.40290865207135923},{"class_name":"ReflectionUtils","similarity_score":0.5587226454368354},{"class_name":"SpatialRelatesUtils","similarity_score":0.4641867020033118},{"class_name":"SqlTestUtils","similarity_score":0.5628207329685172},{"class_name":"StringContainsRegex","similarity_score":0.45188680072809034},{"class_name":"StringUtils","similarity_score":0.514433758916831},{"class_name":"TestUtils","similarity_score":0.6367868483523107},{"class_name":"ColumnInfoImpl","similarity_score":0.46127024215707657},{"class_name":"EnrichIT","similarity_score":0.5468533898959148},{"class_name":"EsqlAsyncActionIT","similarity_score":0.5951228605227378},{"class_name":"EsqlCapabilities","similarity_score":0.2833967633728305},{"class_name":"EsqlQueryRequest","similarity_score":0.5717010428959416},{"class_name":"EsqlQueryRequestBuilder","similarity_score":0.37427540574203544},{"class_name":"EsqlQueryRequestTests","similarity_score":0.5333554536362693},{"class_name":"EsqlQueryResponse","similarity_score":0.5564441450349475},{"class_name":"EsqlQueryResponseTests","similarity_score":0.5627376769460186}],"target_classes_sorted_by_llm":["EsqlTestUtils","SqlTestUtils","ResponseXContentUtils","PlannerUtils","EsqlQueryRequest","TestUtils","EsqlQueryResponseTests","EsqlAsyncActionIT","ReflectionUtils","CsvTestUtils"],"llm_response_time":10150,"similarity_computation_time":42,"similarity_metric":"voyage"},"valuesForRowsInPage":{"target_classes":[{"class_name":"ResponseXContentUtils","similarity_score":0.44455032656843846},{"class_name":"FunctionTestUtils","similarity_score":0.17879963496303788},{"class_name":"ExceptionUtils","similarity_score":0.268452428509859},{"class_name":"AnalyzerTestUtils","similarity_score":0.20761834453055122},{"class_name":"EsqlTestUtils","similarity_score":0.26616848456830483},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2556169075650897},{"class_name":"CsvTestUtils","similarity_score":0.2742482379668481},{"class_name":"DateUtils","similarity_score":0.2817953249971559},{"class_name":"TestUtils","similarity_score":0.24389115022770286},{"class_name":"StringUtils","similarity_score":0.18465899891286158},{"class_name":"StringContainsRegex","similarity_score":0.26812060503657786},{"class_name":"SqlTestUtils","similarity_score":0.29920427902117586},{"class_name":"SourceUtils","similarity_score":0.22516127322813123},{"class_name":"SerializationTestUtils","similarity_score":0.19273420896674337},{"class_name":"SpatialRelatesUtils","similarity_score":0.31463014525205873},{"class_name":"NumberUtils","similarity_score":0.20871177748418046},{"class_name":"NumericUtilsTests","similarity_score":0.13805852577124877},{"class_name":"ReflectionUtils","similarity_score":0.20567735105731827},{"class_name":"ParserUtils","similarity_score":0.247013183489252},{"class_name":"PlannerUtils","similarity_score":0.3528168556398848},{"class_name":"ColumnInfoImpl","similarity_score":0.20241022618818408},{"class_name":"EsqlAsyncActionIT","similarity_score":0.2454154095929775},{"class_name":"EsqlCapabilities","similarity_score":0.3083440322526134},{"class_name":"EnrichIT","similarity_score":0.18578092294923976},{"class_name":"EsqlQueryRequest","similarity_score":0.23448628916659345},{"class_name":"EsqlQueryRequestBuilder","similarity_score":0.20236218768597958},{"class_name":"EsqlQueryRequestTests","similarity_score":0.14193958556819963},{"class_name":"EsqlQueryResponse","similarity_score":0.22603264335344314},{"class_name":"EsqlQueryResponseTests","similarity_score":0.21888501487088058}],"target_classes_sorted_by_llm":["ResponseXContentUtils","SqlTestUtils","CsvTestUtils","EsqlCapabilities","PlannerUtils","DateUtils","SpatialRelatesUtils","StringContainsRegex","ExceptionUtils","EsqlTestUtils"],"llm_response_time":12066,"similarity_computation_time":11,"similarity_metric":"voyage"},"valuesForRow":{"target_classes":[{"class_name":"ResponseXContentUtils","similarity_score":0.4412031694562865},{"class_name":"FunctionTestUtils","similarity_score":0.17149858514250885},{"class_name":"NumberUtils","similarity_score":0.23500483554019205},{"class_name":"NumericUtilsTests","similarity_score":0.26701300945759954},{"class_name":"SourceUtils","similarity_score":0.259160527674408},{"class_name":"SpatialRelatesUtils","similarity_score":0.3173920803304871},{"class_name":"SqlTestUtils","similarity_score":0.3043797937175354},{"class_name":"TestUtils","similarity_score":0.24386751657153216},{"class_name":"ParserUtils","similarity_score":0.21060153103139265},{"class_name":"AnalyzerTestUtils","similarity_score":0.21085466855667218},{"class_name":"StringContainsRegex","similarity_score":0.2571722499368198},{"class_name":"StringUtils","similarity_score":0.2007345148912587},{"class_name":"SerializationTestUtils","similarity_score":0.22267728242783083},{"class_name":"PlannerUtils","similarity_score":0.3760111551630739},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2082343250354164},{"class_name":"EsqlTestUtils","similarity_score":0.26336966434541004},{"class_name":"ExceptionUtils","similarity_score":0.26919463855110026},{"class_name":"CsvTestUtils","similarity_score":0.29618978474673396},{"class_name":"ReflectionUtils","similarity_score":0.18083888603589302},{"class_name":"DateUtils","similarity_score":0.28558793416466693},{"class_name":"TimeSeriesIT","similarity_score":0.17641816308482927},{"class_name":"EnrichIT","similarity_score":0.1867310792506188},{"class_name":"EsqlAsyncActionIT","similarity_score":0.23539419152654087},{"class_name":"EsqlCapabilities","similarity_score":0.2794232743619329},{"class_name":"EsqlQueryRequest","similarity_score":0.22662822798902246},{"class_name":"EsqlQueryRequestBuilder","similarity_score":0.19409899176618914},{"class_name":"EsqlQueryRequestTests","similarity_score":0.16032708244530364},{"class_name":"EsqlQueryResponse","similarity_score":0.2294077147501979},{"class_name":"EsqlQueryResponseTests","similarity_score":0.27044037195487874}],"target_classes_sorted_by_llm":["ResponseXContentUtils","CsvTestUtils","PlannerUtils","EsqlCapabilities","DateUtils","SqlTestUtils","EsqlQueryResponseTests","SpatialRelatesUtils","NumericUtilsTests","ExceptionUtils"],"llm_response_time":9385,"similarity_computation_time":23,"similarity_metric":"voyage"}}}
{"id":"e693f92e-f84c-4a67-90d2-04e3eb24be5e","methodCount":7,"hostFunctionTelemetryData":{"hostFunctionSize":125,"lineStart":36,"lineEnd":160,"bodyLineStart":36,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/optimizer/rules/SubstituteSurrogates.java","sourceCode":"public final class SubstituteSurrogates extends OptimizerRules.OptimizerRule\u003cAggregate\u003e {\n    // TODO: currently this rule only works for aggregate functions (AVG)\n\n    public SubstituteSurrogates() {\n        super(OptimizerRules.TransformDirection.UP);\n    }\n\n    @Override\n    protected LogicalPlan rule(Aggregate aggregate) {\n        var aggs \u003d aggregate.aggregates();\n        List\u003cNamedExpression\u003e newAggs \u003d new ArrayList\u003c\u003e(aggs.size());\n        // existing aggregate and their respective attributes\n        Map\u003cAggregateFunction, Attribute\u003e aggFuncToAttr \u003d new HashMap\u003c\u003e();\n        // surrogate functions eval\n        List\u003cAlias\u003e transientEval \u003d new ArrayList\u003c\u003e();\n        boolean changed \u003d false;\n\n        // first pass to check existing aggregates (to avoid duplication and alias waste)\n        for (NamedExpression agg : aggs) {\n            if (Alias.unwrap(agg) instanceof AggregateFunction af) {\n                if ((af instanceof SurrogateExpression se \u0026\u0026 se.surrogate() !\u003d null) \u003d\u003d false) {\n                    aggFuncToAttr.put(af, agg.toAttribute());\n                }\n            }\n        }\n\n        int[] counter \u003d new int[] { 0 };\n        // 0. check list of surrogate expressions\n        for (NamedExpression agg : aggs) {\n            Expression e \u003d Alias.unwrap(agg);\n            if (e instanceof SurrogateExpression sf \u0026\u0026 sf.surrogate() !\u003d null) {\n                changed \u003d true;\n                Expression s \u003d sf.surrogate();\n\n                // if the expression is NOT a 1:1 replacement need to add an eval\n                if (s instanceof AggregateFunction \u003d\u003d false) {\n                    // 1. collect all aggregate functions from the expression\n                    var surrogateWithRefs \u003d s.transformUp(AggregateFunction.class, af -\u003e {\n                        // TODO: more generic than this?\n                        if (af instanceof Rate) {\n                            return af;\n                        }\n                        // 2. check if they are already use otherwise add them to the Aggregate with some made-up aliases\n                        // 3. replace them inside the expression using the given alias\n                        var attr \u003d aggFuncToAttr.get(af);\n                        // the agg doesn\u0027t exist in the Aggregate, create an alias for it and save its attribute\n                        if (attr \u003d\u003d null) {\n                            var temporaryName \u003d temporaryName(af, agg, counter[0]++);\n                            // create a synthetic alias (so it doesn\u0027t clash with a user defined name)\n                            var newAlias \u003d new Alias(agg.source(), temporaryName, null, af, null, true);\n                            attr \u003d newAlias.toAttribute();\n                            aggFuncToAttr.put(af, attr);\n                            newAggs.add(newAlias);\n                        }\n                        return attr;\n                    });\n                    // 4. move the expression as an eval using the original alias\n                    // copy the original alias id so that other nodes using it down stream (e.g. eval referring to the original agg)\n                    // don\u0027t have to updated\n                    var aliased \u003d new Alias(agg.source(), agg.name(), null, surrogateWithRefs, agg.toAttribute().id());\n                    transientEval.add(aliased);\n                }\n                // the replacement is another aggregate function, so replace it in place\n                else {\n                    newAggs.add((NamedExpression) agg.replaceChildren(Collections.singletonList(s)));\n                }\n            } else {\n                newAggs.add(agg);\n            }\n        }\n\n        LogicalPlan plan \u003d aggregate;\n        if (changed) {\n            var source \u003d aggregate.source();\n            if (newAggs.isEmpty() \u003d\u003d false) {\n                plan \u003d new Aggregate(source, aggregate.child(), aggregate.aggregateType(), aggregate.groupings(), newAggs);\n            } else {\n                // All aggs actually have been surrogates for (foldable) expressions, e.g.\n                // \\_Aggregate[[],[AVG([1, 2][INTEGER]) AS s]]\n                // Replace by a local relation with one row, followed by an eval, e.g.\n                // \\_Eval[[MVAVG([1, 2][INTEGER]) AS s]]\n                // \\_LocalRelation[[{e}#21],[ConstantNullBlock[positions\u003d1]]]\n                plan \u003d new LocalRelation(\n                    source,\n                    List.of(new EmptyAttribute(source)),\n                    LocalSupplier.of(new Block[] { BlockUtils.constantBlock(PlannerUtils.NON_BREAKING_BLOCK_FACTORY, null, 1) })\n                );\n            }\n            // 5. force the initial projection in place\n            if (transientEval.isEmpty() \u003d\u003d false) {\n                plan \u003d new Eval(source, plan, transientEval);\n                // project away transient fields and re-enforce the original order using references (not copies) to the original aggs\n                // this works since the replaced aliases have their nameId copied to avoid having to update all references (which has\n                // a cascading effect)\n                plan \u003d new Project(source, plan, Expressions.asAttributes(aggs));\n            }\n        }\n\n        return plan;\n    }\n\n    public static String temporaryName(Expression inner, Expression outer, int suffix) {\n        String in \u003d toString(inner);\n        String out \u003d toString(outer);\n        return rawTemporaryName(in, out, String.valueOf(suffix));\n    }\n\n    public static String rawTemporaryName(String inner, String outer, String suffix) {\n        return FieldAttribute.SYNTHETIC_ATTRIBUTE_NAME_PREFIX + inner + \"$\" + outer + \"$\" + suffix;\n    }\n\n    static int TO_STRING_LIMIT \u003d 16;\n\n    static String toString(Expression ex) {\n        return ex instanceof AggregateFunction af ? af.functionName() : extractString(ex);\n    }\n\n    static String extractString(Expression ex) {\n        return ex instanceof NamedExpression ne ? ne.name() : limitToString(ex.sourceText()).replace(\u0027 \u0027, \u0027_\u0027);\n    }\n\n    static String limitToString(String string) {\n        return string.length() \u003e 16 ? string.substring(0, TO_STRING_LIMIT - 1) + \"\u003e\" : string;\n    }\n}","methodCount":7},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":142,"lineEnd":144,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class TestUtils","description":"move method rawTemporaryName to PsiClass:TestUtils\nRationale: The rawTemporaryName() method is a utility function that generates a specific formatted name, which aligns well with the purpose of TestUtils. This class is designed for various utility methods used in testing scenarios, making it a suitable home for this method. Moving it here adheres to the Single Responsibility Principle, as TestUtils can encapsulate all test-related utilities. However, it may lead to a bloated utility class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":142,"lineEnd":144,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class EsqlTestUtils","description":"move method rawTemporaryName to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils contains methods related to testing SQL-like structures, and the rawTemporaryName() method can be useful in generating names for temporary SQL constructs. This move would enhance cohesion within the class by grouping related functionalities. It aligns with the Open/Closed Principle, allowing for extension without modifying existing code. However, it may introduce confusion if the method is not directly related to SQL operations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":142,"lineEnd":144,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class AnalyzerTestUtils","description":"move method rawTemporaryName to PsiClass:AnalyzerTestUtils\nRationale: The rawTemporaryName() method could be relevant in the context of analyzing data structures, potentially serving as a naming convention for temporary analysis results. This aligns with the Interface Segregation Principle, as it allows the AnalyzerTestUtils to provide specific utilities for analysis without burdening other classes. A drawback could be that it might not directly relate to the core responsibilities of this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":156,"lineEnd":158,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class StringUtils","description":"move method limitToString to PsiClass:StringUtils\nRationale: The limitToString() method is primarily concerned with string manipulation, specifically limiting the length of a string. Moving it to StringUtils aligns with the class\u0027s focus on utility methods for string operations, enhancing cohesion. This adheres to the Single Responsibility Principle, as StringUtils can handle various string-related functionalities. A potential drawback is that if StringUtils becomes too large, it might violate the Interface Segregation Principle by containing unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":156,"lineEnd":158,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class TestUtils","description":"move method limitToString to PsiClass:TestUtils\nRationale: TestUtils is designed for various utility functions in testing scenarios. Since limitToString() could be used in test setups to ensure string representations are within limits, this move would promote reusability across tests. This aligns with the Open/Closed Principle, allowing the test utilities to be extended without modifying existing code. However, it may dilute the purpose of TestUtils if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":156,"lineEnd":158,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class CsvTestUtils","description":"move method limitToString to PsiClass:CsvTestUtils\nRationale: CsvTestUtils deals with CSV-related functionalities, and limiting string lengths could be relevant when processing CSV fields. This move would make sense if the method is specifically used for CSV data handling, enhancing cohesion. However, if the method is not frequently used in this context, it may lead to confusion about the class\u0027s responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":152,"lineEnd":154,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class StringUtils","description":"move method extractString to PsiClass:StringUtils\nRationale: The extractString() method is primarily concerned with string manipulation, specifically formatting strings based on the type of Expression. Moving it to StringUtils aligns with the Single Responsibility Principle, as StringUtils is focused on string operations. This enhances cohesion within StringUtils and makes the method more reusable in various contexts. However, we should ensure that the method\u0027s dependencies on Expression types are well-documented to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":152,"lineEnd":154,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class EsqlTestUtils","description":"move method extractString to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils deals with various Expression types and their attributes, making it a fitting candidate for extractString(). This relocation would enhance the relevance of utility methods related to expression handling. It adheres to the Open/Closed Principle, allowing for future extensions related to expression manipulation without altering existing code. However, care must be taken to avoid bloating the EsqlTestUtils class with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":152,"lineEnd":154,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class TestUtils","description":"move method extractString to PsiClass:TestUtils\nRationale: TestUtils serves as a general-purpose utility class for testing, and extractString() could be beneficial for various test cases involving Expressions. This move supports the Interface Segregation Principle, as it allows for more focused testing utilities. However, it may lead to a less cohesive utility class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""},{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""},{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static rawTemporaryName(String inner, String outer, String suffix)":{"first":{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},"second":0.15282874487084935},"static limitToString(String string)":{"first":{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""},"second":0.26832942750145455},"static extractString(Expression ex)":{"first":{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},"second":0.2882320412644159},"static toString(Expression ex)":{"first":{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},"second":0.32797088564851257},"public static temporaryName(Expression inner, Expression outer, int suffix)":{"first":{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""},"second":0.42520309929152794}},"llmMethodPriority":{"priority_method_names":["rawTemporaryName","limitToString","extractString","toString","temporaryName"],"llm_response_time":1243},"targetClassMap":{"rawTemporaryName":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.2207515735136804},{"class_name":"ExceptionUtils","similarity_score":0.09271040345873596},{"class_name":"NumericUtilsTests","similarity_score":0.12681751414778644},{"class_name":"TestUtils","similarity_score":0.3917096006932044},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.1500919393940964},{"class_name":"ParserUtils","similarity_score":0.2606582356223241},{"class_name":"AnalyzerTestUtils","similarity_score":0.36246047221623257},{"class_name":"PlannerUtils","similarity_score":0.19390964657111387},{"class_name":"LuceneComponent2DUtils","similarity_score":0.21948481531639943},{"class_name":"SerializationTestUtils","similarity_score":0.203843110180365},{"class_name":"SetAsOptimized","similarity_score":0.21514499158934372},{"class_name":"EsqlTestUtils","similarity_score":0.37336562837812354},{"class_name":"TranslateMetricsAggregate","similarity_score":0.09126825547682564},{"class_name":"PropagateEquals","similarity_score":0.1139035759698438},{"class_name":"PropagateNullable","similarity_score":0.15405696418470044},{"class_name":"PruneColumns","similarity_score":0.1450237099157442},{"class_name":"PruneFilters","similarity_score":0.20740744481552964},{"class_name":"PruneOrderByBeforeStats","similarity_score":0.1355980896482457},{"class_name":"PushDownAndCombineFilters","similarity_score":0.11379180839004961},{"class_name":"PushDownAndCombineLimits","similarity_score":0.15505390087187876},{"class_name":"CsvTestUtils","similarity_score":0.3117292399895723},{"class_name":"SimplifyComparisonsArithmetics","similarity_score":0.21009802467696245},{"class_name":"CombineProjections","similarity_score":0.13529198131278436},{"class_name":"MulDivSimplifier","similarity_score":0.1513131554975057},{"class_name":"BooleanSimplification","similarity_score":0.14861213870890636},{"class_name":"SourceUtils","similarity_score":0.12830357985667673},{"class_name":"SpatialRelatesUtils","similarity_score":0.20092351723737698},{"class_name":"DateUtils","similarity_score":0.2524769565329725},{"class_name":"ReflectionUtils","similarity_score":0.22789095468755416},{"class_name":"ConstantFoldingTests","similarity_score":0.08046927922251906}],"target_classes_sorted_by_llm":["TestUtils","EsqlTestUtils","AnalyzerTestUtils","CsvTestUtils","ParserUtils","DateUtils","ReflectionUtils","FunctionTestUtils","LuceneComponent2DUtils","SetAsOptimized"],"llm_response_time":10565,"similarity_computation_time":21,"similarity_metric":"voyage"},"limitToString":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.14086253611256433},{"class_name":"SourceUtils","similarity_score":0.15415176003458286},{"class_name":"SpatialRelatesUtils","similarity_score":0.24477803860310854},{"class_name":"TestUtils","similarity_score":0.3853489160311911},{"class_name":"ParserUtils","similarity_score":0.3896840335788381},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.25014376079393974},{"class_name":"AnalyzerTestUtils","similarity_score":0.3848078698348418},{"class_name":"StringContainsRegex","similarity_score":0.3170632437371139},{"class_name":"StringUtils","similarity_score":0.31924939485935494},{"class_name":"SerializationTestUtils","similarity_score":0.2589952750832449},{"class_name":"TranslateMetricsAggregate","similarity_score":0.14543318843580252},{"class_name":"SetAsOptimized","similarity_score":0.29373674772302333},{"class_name":"PlannerUtils","similarity_score":0.2770283321133963},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2615231081454222},{"class_name":"EsqlTestUtils","similarity_score":0.4034402289118169},{"class_name":"MulDivSimplifier","similarity_score":0.27989254189191043},{"class_name":"ExceptionUtils","similarity_score":0.11391948737358636},{"class_name":"SimplifyComparisonsArithmetics","similarity_score":0.3539115760878274},{"class_name":"PropagateEquals","similarity_score":0.22351580658629053},{"class_name":"PropagateNullable","similarity_score":0.26851080677052735},{"class_name":"PruneColumns","similarity_score":0.26235052076630055},{"class_name":"PruneFilters","similarity_score":0.33062326126679026},{"class_name":"PruneOrderByBeforeStats","similarity_score":0.23604282156200063},{"class_name":"PushDownAndCombineFilters","similarity_score":0.2077379538143142},{"class_name":"PushDownAndCombineLimits","similarity_score":0.24221798418726928},{"class_name":"CsvTestUtils","similarity_score":0.38864265148467025},{"class_name":"DateUtils","similarity_score":0.2812800604092306},{"class_name":"BooleanSimplification","similarity_score":0.23434911080204943},{"class_name":"ConstantFoldingTests","similarity_score":0.09356197609774433}],"target_classes_sorted_by_llm":["StringUtils","TestUtils","CsvTestUtils","ParserUtils","AnalyzerTestUtils","StringContainsRegex","EsqlTestUtils","SimplifyComparisonsArithmetics","PruneFilters","SetAsOptimized"],"llm_response_time":10708,"similarity_computation_time":8,"similarity_metric":"voyage"},"extractString":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.29411764705882354},{"class_name":"ExceptionUtils","similarity_score":0.12043434688555504},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.3271996747087936},{"class_name":"TestUtils","similarity_score":0.35162244556708766},{"class_name":"EsqlTestUtils","similarity_score":0.38876783188442454},{"class_name":"CsvTestUtils","similarity_score":0.36705827495328736},{"class_name":"AnalyzerTestUtils","similarity_score":0.40681436994182163},{"class_name":"SerializationTestUtils","similarity_score":0.2738067693265226},{"class_name":"TranslateMetricsAggregate","similarity_score":0.1645777455603688},{"class_name":"SetAsOptimized","similarity_score":0.3105350470222685},{"class_name":"LuceneComponent2DUtils","similarity_score":0.253439234411917},{"class_name":"DateUtils","similarity_score":0.2623817498732804},{"class_name":"CombineProjections","similarity_score":0.291486874634402},{"class_name":"ConstantFoldingTests","similarity_score":0.10340865294911424},{"class_name":"SimplifyComparisonsArithmetics","similarity_score":0.3562124155643652},{"class_name":"BooleanSimplification","similarity_score":0.267056416422748},{"class_name":"SourceUtils","similarity_score":0.14815221273648993},{"class_name":"SpatialRelatesUtils","similarity_score":0.2364681568641107},{"class_name":"MulDivSimplifier","similarity_score":0.31280763572529824},{"class_name":"StringContainsRegex","similarity_score":0.33519554521581},{"class_name":"NumericUtilsTests","similarity_score":0.15264117778873884},{"class_name":"StringUtils","similarity_score":0.35100698730238716},{"class_name":"ReflectionUtils","similarity_score":0.3383303246607606},{"class_name":"RemoveStatsOverride","similarity_score":0.19402850002906638},{"class_name":"PropagateEquals","similarity_score":0.26081981183045716},{"class_name":"PropagateNullable","similarity_score":0.2952211370179029},{"class_name":"ReplaceStatsAggExpressionWithEval","similarity_score":0.1413981171678506},{"class_name":"ReplaceStatsNestedExpressionWithEval","similarity_score":0.23963259805187934},{"class_name":"PushDownAndCombineFilters","similarity_score":0.25903676875338816}],"target_classes_sorted_by_llm":["StringUtils","EsqlTestUtils","TestUtils","CsvTestUtils","ReflectionUtils","AnalyzerTestUtils","MulDivSimplifier","SimplifyComparisonsArithmetics","StringContainsRegex","DuplicateLimitAfterMvExpand"],"llm_response_time":12131,"similarity_computation_time":10,"similarity_metric":"voyage"}}}
{"id":"4e091fb6-dccb-49ab-9271-b88da7d05ccc","methodCount":21,"hostFunctionTelemetryData":{"hostFunctionSize":105,"lineStart":28,"lineEnd":132,"bodyLineStart":28,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/parser/AbstractStatementParserTests.java","sourceCode":"abstract class AbstractStatementParserTests extends ESTestCase {\n\n    EsqlParser parser \u003d new EsqlParser();\n\n    void assertStatement(String statement, LogicalPlan expected) {\n        final LogicalPlan actual;\n        try {\n            actual \u003d statement(statement);\n        } catch (Exception e) {\n            throw new AssertionError(\"parsing error for [\" + statement + \"]\", e);\n        }\n        assertThat(statement, actual, equalTo(expected));\n    }\n\n    LogicalPlan statement(String e) {\n        return statement(e, new QueryParams());\n    }\n\n    LogicalPlan statement(String e, QueryParams params) {\n        return parser.createStatement(e, params);\n    }\n\n    LogicalPlan processingCommand(String e) {\n        return parser.createStatement(\"row a \u003d 1 | \" + e);\n    }\n\n    static UnresolvedAttribute attribute(String name) {\n        return new UnresolvedAttribute(EMPTY, name);\n    }\n\n    static ReferenceAttribute referenceAttribute(String name, DataType type) {\n        return new ReferenceAttribute(EMPTY, name, type);\n    }\n\n    static Literal integer(int i) {\n        return new Literal(EMPTY, i, DataType.INTEGER);\n    }\n\n    static Literal integers(int... ints) {\n        return new Literal(EMPTY, Arrays.stream(ints).boxed().toList(), DataType.INTEGER);\n    }\n\n    static Literal literalLong(long i) {\n        return new Literal(EMPTY, i, DataType.LONG);\n    }\n\n    static Literal literalLongs(long... longs) {\n        return new Literal(EMPTY, Arrays.stream(longs).boxed().toList(), DataType.LONG);\n    }\n\n    static Literal literalDouble(double d) {\n        return new Literal(EMPTY, d, DataType.DOUBLE);\n    }\n\n    static Literal literalDoubles(double... doubles) {\n        return new Literal(EMPTY, Arrays.stream(doubles).boxed().toList(), DataType.DOUBLE);\n    }\n\n    static Literal literalUnsignedLong(String ulong) {\n        return new Literal(EMPTY, asLongUnsigned(new BigInteger(ulong)), DataType.UNSIGNED_LONG);\n    }\n\n    static Literal literalUnsignedLongs(String... ulongs) {\n        return new Literal(EMPTY, Arrays.stream(ulongs).map(s -\u003e asLongUnsigned(new BigInteger(s))).toList(), DataType.UNSIGNED_LONG);\n    }\n\n    static Literal literalBoolean(boolean b) {\n        return new Literal(EMPTY, b, DataType.BOOLEAN);\n    }\n\n    static Literal literalBooleans(boolean... booleans) {\n        List\u003cBoolean\u003e v \u003d new ArrayList\u003c\u003e(booleans.length);\n        for (boolean b : booleans) {\n            v.add(b);\n        }\n        return new Literal(EMPTY, v, DataType.BOOLEAN);\n    }\n\n    static Literal literalString(String s) {\n        return new Literal(EMPTY, s, DataType.KEYWORD);\n    }\n\n    static Literal literalStrings(String... strings) {\n        return new Literal(EMPTY, Arrays.asList(strings), DataType.KEYWORD);\n    }\n\n    void expectError(String query, String errorMessage) {\n        ParsingException e \u003d expectThrows(ParsingException.class, \"Expected syntax error for \" + query, () -\u003e statement(query));\n        assertThat(e.getMessage(), containsString(errorMessage));\n    }\n\n    void expectVerificationError(String query, String errorMessage) {\n        VerificationException e \u003d expectThrows(VerificationException.class, \"Expected syntax error for \" + query, () -\u003e statement(query));\n        assertThat(e.getMessage(), containsString(errorMessage));\n    }\n\n    void expectError(String query, List\u003cQueryParam\u003e params, String errorMessage) {\n        ParsingException e \u003d expectThrows(\n            ParsingException.class,\n            \"Expected syntax error for \" + query,\n            () -\u003e statement(query, new QueryParams(params))\n        );\n        assertThat(e.getMessage(), containsString(errorMessage));\n    }\n}","methodCount":21},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":118,"lineEnd":121,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method expectVerificationError to class EsqlParser","description":"Move method expectVerificationError to org.elasticsearch.xpack.esql.parser.EsqlParser\nRationale: The expectVerificationError() method is designed to verify the correctness of SQL-like queries, which aligns closely with the responsibilities of the EsqlParser class, which is likely involved in parsing and validating such queries. Moving this method to EsqlParser adheres to the Single Responsibility Principle, as it centralizes error verification related to SQL parsing within the parser itself, thereby improving cohesion. Additionally, it enhances the overall design by making the method more reusable and contextually relevant to the EsqlParser, which is responsible for handling SQL syntax. However, care should be taken to ensure that the method\u0027s dependencies, such as the statement() function, are accessible within EsqlParser, and that the move does not disrupt existing functionalities or introduce tight coupling with other components.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":113,"lineEnd":116,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method expectError to class EsqlParser","description":"Move method expectError to org.elasticsearch.xpack.esql.parser.EsqlParser\nRationale: The expectError() method is primarily concerned with validating the error handling of SQL-like queries, which directly relates to the parsing functionality of the EsqlParser class. Moving this method to EsqlParser adheres to the Single Responsibility Principle, as it encapsulates error expectations within the context of parsing operations. This enhances cohesion, making it clearer that error expectations are part of the parsing process. Additionally, it aligns with the Open/Closed Principle, as the EsqlParser can be extended with more parsing-related error checks without modifying the existing classes. A potential drawback is that if expectError() is heavily used in its current context, refactoring could lead to a significant number of changes in call sites, necessitating thorough testing to ensure no unintended side effects occur.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":123,"lineEnd":130,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method expectError to class EsqlParser","description":"Move method expectError to org.elasticsearch.xpack.esql.parser.EsqlParser\nRationale: The expectError() method is primarily concerned with testing the parsing of SQL-like queries and handling exceptions, which directly relates to the functionality of the EsqlParser class. Moving this method to EsqlParser adheres to the Single Responsibility Principle, as it centralizes error handling and parsing logic within the parser itself, improving cohesion. Additionally, this move enhances the overall design by aligning the method with the class that directly deals with query parsing, making it more intuitive for future developers. However, one potential drawback is that this method is currently structured for testing purposes; careful consideration must be given to ensure that the method is appropriately adapted for its new context within the EsqlParser class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"assertStatement","method_signature":" assertStatement(String statement, LogicalPlan expected)","target_class":"","rationale":""},{"method_name":"statement","method_signature":" statement(String e)","target_class":"","rationale":""},{"method_name":"statement","method_signature":" statement(String e, QueryParams params)","target_class":"","rationale":""},{"method_name":"processingCommand","method_signature":" processingCommand(String e)","target_class":"","rationale":""},{"method_name":"attribute","method_signature":"static attribute(String name)","target_class":"","rationale":""},{"method_name":"referenceAttribute","method_signature":"static referenceAttribute(String name, DataType type)","target_class":"","rationale":""},{"method_name":"integer","method_signature":"static integer(int i)","target_class":"","rationale":""},{"method_name":"integers","method_signature":"static integers(int... ints)","target_class":"","rationale":""},{"method_name":"literalLong","method_signature":"static literalLong(long i)","target_class":"","rationale":""},{"method_name":"literalLongs","method_signature":"static literalLongs(long... longs)","target_class":"","rationale":""},{"method_name":"literalDouble","method_signature":"static literalDouble(double d)","target_class":"","rationale":""},{"method_name":"literalDoubles","method_signature":"static literalDoubles(double... doubles)","target_class":"","rationale":""},{"method_name":"literalUnsignedLong","method_signature":"static literalUnsignedLong(String ulong)","target_class":"","rationale":""},{"method_name":"literalUnsignedLongs","method_signature":"static literalUnsignedLongs(String... ulongs)","target_class":"","rationale":""},{"method_name":"literalBoolean","method_signature":"static literalBoolean(boolean b)","target_class":"","rationale":""},{"method_name":"literalBooleans","method_signature":"static literalBooleans(boolean... booleans)","target_class":"","rationale":""},{"method_name":"literalString","method_signature":"static literalString(String s)","target_class":"","rationale":""},{"method_name":"literalStrings","method_signature":"static literalStrings(String... strings)","target_class":"","rationale":""},{"method_name":"expectError","method_signature":" expectError(String query, String errorMessage)","target_class":"","rationale":""},{"method_name":"expectVerificationError","method_signature":" expectVerificationError(String query, String errorMessage)","target_class":"","rationale":""},{"method_name":"expectError","method_signature":" expectError(String query, List\u003cQueryParam\u003e params, String errorMessage)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"expectVerificationError","method_signature":" expectVerificationError(String query, String errorMessage)","target_class":"","rationale":""},{"method_name":"expectError","method_signature":" expectError(String query, String errorMessage)","target_class":"","rationale":""},{"method_name":"expectError","method_signature":" expectError(String query, List\u003cQueryParam\u003e params, String errorMessage)","target_class":"","rationale":""},{"method_name":"processingCommand","method_signature":" processingCommand(String e)","target_class":"","rationale":""},{"method_name":"assertStatement","method_signature":" assertStatement(String statement, LogicalPlan expected)","target_class":"","rationale":""},{"method_name":"statement","method_signature":" statement(String e, QueryParams params)","target_class":"","rationale":""},{"method_name":"referenceAttribute","method_signature":"static referenceAttribute(String name, DataType type)","target_class":"","rationale":""},{"method_name":"literalUnsignedLongs","method_signature":"static literalUnsignedLongs(String... ulongs)","target_class":"","rationale":""},{"method_name":"statement","method_signature":" statement(String e)","target_class":"","rationale":""},{"method_name":"attribute","method_signature":"static attribute(String name)","target_class":"","rationale":""},{"method_name":"literalBooleans","method_signature":"static literalBooleans(boolean... booleans)","target_class":"","rationale":""},{"method_name":"literalUnsignedLong","method_signature":"static literalUnsignedLong(String ulong)","target_class":"","rationale":""},{"method_name":"integers","method_signature":"static integers(int... ints)","target_class":"","rationale":""},{"method_name":"literalLongs","method_signature":"static literalLongs(long... longs)","target_class":"","rationale":""},{"method_name":"literalDouble","method_signature":"static literalDouble(double d)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{" expectVerificationError(String query, String errorMessage)":{"first":{"method_name":"expectVerificationError","method_signature":" expectVerificationError(String query, String errorMessage)","target_class":"","rationale":""},"second":0.4084288000916867}," expectError(String query, String errorMessage)":{"first":{"method_name":"expectError","method_signature":" expectError(String query, String errorMessage)","target_class":"","rationale":""},"second":0.41333137384109475}," expectError(String query, List\u003cQueryParam\u003e params, String errorMessage)":{"first":{"method_name":"expectError","method_signature":" expectError(String query, List\u003cQueryParam\u003e params, String errorMessage)","target_class":"","rationale":""},"second":0.4479065891561749}," processingCommand(String e)":{"first":{"method_name":"processingCommand","method_signature":" processingCommand(String e)","target_class":"","rationale":""},"second":0.46019764501370647}," assertStatement(String statement, LogicalPlan expected)":{"first":{"method_name":"assertStatement","method_signature":" assertStatement(String statement, LogicalPlan expected)","target_class":"","rationale":""},"second":0.5395338556448994}," statement(String e, QueryParams params)":{"first":{"method_name":"statement","method_signature":" statement(String e, QueryParams params)","target_class":"","rationale":""},"second":0.5493005765412794},"static referenceAttribute(String name, DataType type)":{"first":{"method_name":"referenceAttribute","method_signature":"static referenceAttribute(String name, DataType type)","target_class":"","rationale":""},"second":0.6011562187252576},"static literalUnsignedLongs(String... ulongs)":{"first":{"method_name":"literalUnsignedLongs","method_signature":"static literalUnsignedLongs(String... ulongs)","target_class":"","rationale":""},"second":0.6071866465926138}," statement(String e)":{"first":{"method_name":"statement","method_signature":" statement(String e)","target_class":"","rationale":""},"second":0.6471354225408505},"static attribute(String name)":{"first":{"method_name":"attribute","method_signature":"static attribute(String name)","target_class":"","rationale":""},"second":0.6487130639806373},"static literalBooleans(boolean... booleans)":{"first":{"method_name":"literalBooleans","method_signature":"static literalBooleans(boolean... booleans)","target_class":"","rationale":""},"second":0.6491296188762763},"static literalUnsignedLong(String ulong)":{"first":{"method_name":"literalUnsignedLong","method_signature":"static literalUnsignedLong(String ulong)","target_class":"","rationale":""},"second":0.6570658665645399},"static integers(int... ints)":{"first":{"method_name":"integers","method_signature":"static integers(int... ints)","target_class":"","rationale":""},"second":0.694640281109438},"static literalLongs(long... longs)":{"first":{"method_name":"literalLongs","method_signature":"static literalLongs(long... longs)","target_class":"","rationale":""},"second":0.694640281109438},"static literalDouble(double d)":{"first":{"method_name":"literalDouble","method_signature":"static literalDouble(double d)","target_class":"","rationale":""},"second":0.694640281109438}},"llmMethodPriority":{"priority_method_names":["expectVerificationError","expectError","expectError","processingCommand","assertStatement","statement","referenceAttribute","literalUnsignedLongs","statement","attribute","literalBooleans","literalUnsignedLong","integers","literalLongs","literalDouble"],"llm_response_time":2384},"targetClassMap":{"expectVerificationError":{"target_classes":[{"class_name":"EsqlParser","similarity_score":0.3401283629056619}],"target_classes_sorted_by_llm":["EsqlParser"],"llm_response_time":3447,"similarity_computation_time":2,"similarity_metric":"voyage"},"expectError":{"target_classes":[{"class_name":"EsqlParser","similarity_score":0.35489717125715986}],"target_classes_sorted_by_llm":["EsqlParser"],"llm_response_time":2014,"similarity_computation_time":0,"similarity_metric":"voyage"}}}
{"id":"b8d8ce74-75ce-4d1e-a7a1-6161577e8f29","methodCount":76,"hostFunctionTelemetryData":{"hostFunctionSize":710,"lineStart":83,"lineEnd":792,"bodyLineStart":83,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/io/stream/PlanNamedTypes.java","sourceCode":"/**\n * A utility class that consists solely of static methods that describe how to serialize and\n * deserialize QL and ESQL plan types.\n * \u003cP\u003e\n * All types that require to be serialized should have a pair of co-located `readFoo` and `writeFoo`\n * methods that deserialize and serialize respectively.\n * \u003cP\u003e\n * A type can be named or non-named. A named type has a name written to the stream before its\n * contents (similar to NamedWriteable), whereas a non-named type does not (similar to Writable).\n * Named types allow to determine specific deserialization implementations for more general types,\n * e.g. Literal, which is an Expression. Named types must have an entries in the namedTypeEntries\n * list.\n */\npublic final class PlanNamedTypes {\n\n    private PlanNamedTypes() {}\n\n    /**\n     * Determines the writeable name of the give class. The simple class name is commonly used for\n     * {@link NamedWriteable}s and is sufficient here too, but it could be almost anything else.\n     */\n    public static String name(Class\u003c?\u003e cls) {\n        return cls.getSimpleName();\n    }\n\n    /**\n     * List of named type entries that link concrete names to stream reader and writer implementations.\n     * Entries have the form:  category,  name,  serializer method,  deserializer method.\n     */\n    public static List\u003cPlanNameRegistry.Entry\u003e namedTypeEntries() {\n        List\u003cPlanNameRegistry.Entry\u003e declared \u003d List.of(\n            // Physical Plan Nodes\n            of(PhysicalPlan.class, AggregateExec.class, PlanNamedTypes::writeAggregateExec, PlanNamedTypes::readAggregateExec),\n            of(PhysicalPlan.class, DissectExec.class, PlanNamedTypes::writeDissectExec, PlanNamedTypes::readDissectExec),\n            of(PhysicalPlan.class, EsQueryExec.class, PlanNamedTypes::writeEsQueryExec, PlanNamedTypes::readEsQueryExec),\n            of(PhysicalPlan.class, EsSourceExec.class, PlanNamedTypes::writeEsSourceExec, PlanNamedTypes::readEsSourceExec),\n            of(PhysicalPlan.class, EvalExec.class, PlanNamedTypes::writeEvalExec, PlanNamedTypes::readEvalExec),\n            of(PhysicalPlan.class, EnrichExec.class, PlanNamedTypes::writeEnrichExec, PlanNamedTypes::readEnrichExec),\n            of(PhysicalPlan.class, ExchangeExec.class, PlanNamedTypes::writeExchangeExec, PlanNamedTypes::readExchangeExec),\n            of(PhysicalPlan.class, ExchangeSinkExec.class, PlanNamedTypes::writeExchangeSinkExec, PlanNamedTypes::readExchangeSinkExec),\n            of(\n                PhysicalPlan.class,\n                ExchangeSourceExec.class,\n                PlanNamedTypes::writeExchangeSourceExec,\n                PlanNamedTypes::readExchangeSourceExec\n            ),\n            of(PhysicalPlan.class, FieldExtractExec.class, PlanNamedTypes::writeFieldExtractExec, PlanNamedTypes::readFieldExtractExec),\n            of(PhysicalPlan.class, FilterExec.class, PlanNamedTypes::writeFilterExec, PlanNamedTypes::readFilterExec),\n            of(PhysicalPlan.class, FragmentExec.class, PlanNamedTypes::writeFragmentExec, PlanNamedTypes::readFragmentExec),\n            of(PhysicalPlan.class, GrokExec.class, PlanNamedTypes::writeGrokExec, PlanNamedTypes::readGrokExec),\n            of(PhysicalPlan.class, LimitExec.class, PlanNamedTypes::writeLimitExec, PlanNamedTypes::readLimitExec),\n            of(PhysicalPlan.class, LocalSourceExec.class, (out, v) -\u003e v.writeTo(out), LocalSourceExec::new),\n            of(PhysicalPlan.class, HashJoinExec.class, (out, v) -\u003e v.writeTo(out), HashJoinExec::new),\n            of(PhysicalPlan.class, MvExpandExec.class, PlanNamedTypes::writeMvExpandExec, PlanNamedTypes::readMvExpandExec),\n            of(PhysicalPlan.class, OrderExec.class, PlanNamedTypes::writeOrderExec, PlanNamedTypes::readOrderExec),\n            of(PhysicalPlan.class, ProjectExec.class, PlanNamedTypes::writeProjectExec, PlanNamedTypes::readProjectExec),\n            of(PhysicalPlan.class, RowExec.class, PlanNamedTypes::writeRowExec, PlanNamedTypes::readRowExec),\n            of(PhysicalPlan.class, ShowExec.class, PlanNamedTypes::writeShowExec, PlanNamedTypes::readShowExec),\n            of(PhysicalPlan.class, TopNExec.class, PlanNamedTypes::writeTopNExec, PlanNamedTypes::readTopNExec),\n            // Logical Plan Nodes - a subset of plans that end up being actually serialized\n            of(LogicalPlan.class, Aggregate.class, Aggregate::writeAggregate, Aggregate::new),\n            of(LogicalPlan.class, Dissect.class, PlanNamedTypes::writeDissect, PlanNamedTypes::readDissect),\n            of(LogicalPlan.class, EsRelation.class, PlanNamedTypes::writeEsRelation, PlanNamedTypes::readEsRelation),\n            of(LogicalPlan.class, Eval.class, PlanNamedTypes::writeEval, PlanNamedTypes::readEval),\n            of(LogicalPlan.class, Enrich.class, PlanNamedTypes::writeEnrich, PlanNamedTypes::readEnrich),\n            of(LogicalPlan.class, EsqlProject.class, PlanNamedTypes::writeEsqlProject, PlanNamedTypes::readEsqlProject),\n            of(LogicalPlan.class, Filter.class, PlanNamedTypes::writeFilter, PlanNamedTypes::readFilter),\n            of(LogicalPlan.class, Grok.class, PlanNamedTypes::writeGrok, PlanNamedTypes::readGrok),\n            of(LogicalPlan.class, InlineStats.class, (PlanStreamOutput out, InlineStats v) -\u003e v.writeTo(out), InlineStats::new),\n            of(LogicalPlan.class, Join.ENTRY),\n            of(LogicalPlan.class, Limit.class, PlanNamedTypes::writeLimit, PlanNamedTypes::readLimit),\n            of(LogicalPlan.class, LocalRelation.ENTRY),\n            of(LogicalPlan.class, Lookup.ENTRY),\n            of(LogicalPlan.class, MvExpand.class, PlanNamedTypes::writeMvExpand, PlanNamedTypes::readMvExpand),\n            of(LogicalPlan.class, OrderBy.class, PlanNamedTypes::writeOrderBy, PlanNamedTypes::readOrderBy),\n            of(LogicalPlan.class, Project.class, PlanNamedTypes::writeProject, PlanNamedTypes::readProject),\n            of(LogicalPlan.class, TopN.ENTRY)\n        );\n        return declared;\n    }\n\n    // -- physical plan nodes\n    static AggregateExec readAggregateExec(PlanStreamInput in) throws IOException {\n        return new AggregateExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteableCollectionAsList(Expression.class),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class),\n            in.readEnum(AggregateExec.Mode.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(aggregateExec.child());\n        out.writeNamedWriteableCollection(aggregateExec.groupings());\n        out.writeNamedWriteableCollection(aggregateExec.aggregates());\n        out.writeEnum(aggregateExec.getMode());\n        out.writeOptionalVInt(aggregateExec.estimatedRowSize());\n    }\n\n    static DissectExec readDissectExec(PlanStreamInput in) throws IOException {\n        return new DissectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(Expression.class),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissectExec(PlanStreamOutput out, DissectExec dissectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(dissectExec.child());\n        out.writeNamedWriteable(dissectExec.inputExpression());\n        writeDissectParser(out, dissectExec.parser());\n        out.writeNamedWriteableCollection(dissectExec.extractedFields());\n    }\n\n    static EsQueryExec readEsQueryExec(PlanStreamInput in) throws IOException {\n        return new EsQueryExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            readIndexMode(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalNamed(Expression.class),\n            in.readOptionalCollectionAsList(readerFromPlanReader(PlanNamedTypes::readFieldSort)),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec) throws IOException {\n        assert esQueryExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esQueryExec.index());\n        writeIndexMode(out, esQueryExec.indexMode());\n        out.writeNamedWriteableCollection(esQueryExec.output());\n        out.writeOptionalNamedWriteable(esQueryExec.query());\n        out.writeOptionalNamedWriteable(esQueryExec.limit());\n        out.writeOptionalCollection(esQueryExec.sorts(), writerFromPlanWriter(PlanNamedTypes::writeFieldSort));\n        out.writeOptionalInt(esQueryExec.estimatedRowSize());\n    }\n\n    static EsSourceExec readEsSourceExec(PlanStreamInput in) throws IOException {\n        return new EsSourceExec(\n            Source.readFrom(in),\n            readEsIndex(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            readIndexMode(in)\n        );\n    }\n\n    static void writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, esSourceExec.index());\n        out.writeNamedWriteableCollection(esSourceExec.output());\n        out.writeOptionalNamedWriteable(esSourceExec.query());\n        writeIndexMode(out, esSourceExec.indexMode());\n    }\n\n    static IndexMode readIndexMode(StreamInput in) throws IOException {\n        if (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            return IndexMode.fromString(in.readString());\n        } else {\n            return IndexMode.STANDARD;\n        }\n    }\n\n    static void writeIndexMode(StreamOutput out, IndexMode indexMode) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            out.writeString(indexMode.getName());\n        } else if (indexMode !\u003d IndexMode.STANDARD) {\n            throw new IllegalStateException(\"not ready to support index mode [\" + indexMode + \"]\");\n        }\n    }\n\n    static EvalExec readEvalExec(PlanStreamInput in) throws IOException {\n        return new EvalExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEvalExec(PlanStreamOutput out, EvalExec evalExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(evalExec.child());\n        out.writeCollection(evalExec.fields());\n    }\n\n    static EnrichExec readEnrichExec(PlanStreamInput in) throws IOException {\n        final Source source \u003d Source.readFrom(in);\n        final PhysicalPlan child \u003d in.readPhysicalPlanNode();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        final String policyName \u003d in.readString();\n        final String matchType \u003d (in.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) ? in.readString() : \"match\";\n        final String policyMatchField \u003d in.readString();\n        final Map\u003cString, String\u003e concreteIndices;\n        final Enrich.Mode mode;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            mode \u003d Enrich.Mode.ANY;\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() !\u003d 1) {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + esIndex.concreteIndices());\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new EnrichExec(\n            source,\n            child,\n            mode,\n            matchType,\n            matchField,\n            policyName,\n            policyMatchField,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrichExec(PlanStreamOutput out, EnrichExec enrich) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(enrich.child());\n        out.writeNamedWriteable(enrich.matchField());\n        out.writeString(enrich.policyName());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) {\n            out.writeString(enrich.matchType());\n        }\n        out.writeString(enrich.policyMatchField());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            if (enrich.concreteIndices().keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String concreteIndex \u003d enrich.concreteIndices().get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                writeEsIndex(out, new EsIndex(concreteIndex, Map.of(), Set.of(concreteIndex)));\n            } else {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + enrich.concreteIndices());\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static ExchangeExec readExchangeExec(PlanStreamInput in) throws IOException {\n        return new ExchangeExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeExec.output());\n        out.writeBoolean(exchangeExec.isInBetweenAggs());\n        out.writePhysicalPlanNode(exchangeExec.child());\n    }\n\n    static ExchangeSinkExec readExchangeSinkExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSinkExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeSinkExec.output());\n        out.writeBoolean(exchangeSinkExec.isIntermediateAgg());\n        out.writePhysicalPlanNode(exchangeSinkExec.child());\n    }\n\n    static ExchangeSourceExec readExchangeSourceExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSourceExec(Source.readFrom(in), in.readNamedWriteableCollectionAsList(Attribute.class), in.readBoolean());\n    }\n\n    static void writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec) throws IOException {\n        out.writeNamedWriteableCollection(exchangeSourceExec.output());\n        out.writeBoolean(exchangeSourceExec.isIntermediateAgg());\n    }\n\n    static FieldExtractExec readFieldExtractExec(PlanStreamInput in) throws IOException {\n        return new FieldExtractExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteableCollectionAsList(Attribute.class));\n    }\n\n    static void writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(fieldExtractExec.child());\n        out.writeNamedWriteableCollection(fieldExtractExec.attributesToExtract());\n    }\n\n    static FilterExec readFilterExec(PlanStreamInput in) throws IOException {\n        return new FilterExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteable(Expression.class));\n    }\n\n    static void writeFilterExec(PlanStreamOutput out, FilterExec filterExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(filterExec.child());\n        out.writeNamedWriteable(filterExec.condition());\n    }\n\n    static FragmentExec readFragmentExec(PlanStreamInput in) throws IOException {\n        return new FragmentExec(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalVInt(),\n            in.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0) ? in.readOptionalPhysicalPlanNode() : null\n        );\n    }\n\n    static void writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(fragmentExec.fragment());\n        out.writeOptionalNamedWriteable(fragmentExec.esFilter());\n        out.writeOptionalVInt(fragmentExec.estimatedRowSize());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) {\n            out.writeOptionalPhysicalPlanNode(fragmentExec.reducer());\n        }\n    }\n\n    static GrokExec readGrokExec(PlanStreamInput in) throws IOException {\n        Source source;\n        return new GrokExec(\n            source \u003d Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(Expression.class),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrokExec(PlanStreamOutput out, GrokExec grokExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(grokExec.child());\n        out.writeNamedWriteable(grokExec.inputExpression());\n        out.writeString(grokExec.pattern().pattern());\n        out.writeNamedWriteableCollection(grokExec.extractedFields());\n    }\n\n    static LimitExec readLimitExec(PlanStreamInput in) throws IOException {\n        return new LimitExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteable(Expression.class));\n    }\n\n    static void writeLimitExec(PlanStreamOutput out, LimitExec limitExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(limitExec.child());\n        out.writeNamedWriteable(limitExec.limit());\n    }\n\n    static MvExpandExec readMvExpandExec(PlanStreamInput in) throws IOException {\n        return new MvExpandExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(mvExpandExec.child());\n        out.writeNamedWriteable(mvExpandExec.target());\n        out.writeNamedWriteable(mvExpandExec.expanded());\n    }\n\n    static OrderExec readOrderExec(PlanStreamInput in) throws IOException {\n        return new OrderExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new)\n        );\n    }\n\n    static void writeOrderExec(PlanStreamOutput out, OrderExec orderExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(orderExec.child());\n        out.writeCollection(orderExec.order());\n    }\n\n    static ProjectExec readProjectExec(PlanStreamInput in) throws IOException {\n        return new ProjectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeProjectExec(PlanStreamOutput out, ProjectExec projectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(projectExec.child());\n        out.writeNamedWriteableCollection(projectExec.projections());\n    }\n\n    static RowExec readRowExec(PlanStreamInput in) throws IOException {\n        return new RowExec(Source.readFrom(in), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeRowExec(PlanStreamOutput out, RowExec rowExec) throws IOException {\n        assert rowExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        out.writeCollection(rowExec.fields());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static ShowExec readShowExec(PlanStreamInput in) throws IOException {\n        return new ShowExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            (List\u003cList\u003cObject\u003e\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeShowExec(PlanStreamOutput out, ShowExec showExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(showExec.output());\n        out.writeGenericValue(showExec.values());\n    }\n\n    static TopNExec readTopNExec(PlanStreamInput in) throws IOException {\n        return new TopNExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new),\n            in.readNamedWriteable(Expression.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeTopNExec(PlanStreamOutput out, TopNExec topNExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(topNExec.child());\n        out.writeCollection(topNExec.order());\n        out.writeNamedWriteable(topNExec.limit());\n        out.writeOptionalVInt(topNExec.estimatedRowSize());\n    }\n\n    static Dissect readDissect(PlanStreamInput in) throws IOException {\n        return new Dissect(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readNamedWriteable(Expression.class),\n            readDissectParser(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeDissect(PlanStreamOutput out, Dissect dissect) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(dissect.child());\n        out.writeNamedWriteable(dissect.input());\n        writeDissectParser(out, dissect.parser());\n        out.writeNamedWriteableCollection(dissect.extractedFields());\n    }\n\n    static EsRelation readEsRelation(PlanStreamInput in) throws IOException {\n        Source source \u003d Source.readFrom(in);\n        EsIndex esIndex \u003d readEsIndex(in);\n        List\u003cAttribute\u003e attributes \u003d in.readNamedWriteableCollectionAsList(Attribute.class);\n        if (supportingEsSourceOptions(in.getTransportVersion())) {\n            readEsSourceOptions(in); // consume optional strings sent by remote\n        }\n        final IndexMode indexMode \u003d readIndexMode(in);\n        boolean frozen \u003d in.readBoolean();\n        return new EsRelation(source, esIndex, attributes, indexMode, frozen);\n    }\n\n    static void writeEsRelation(PlanStreamOutput out, EsRelation relation) throws IOException {\n        assert relation.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        writeEsIndex(out, relation.index());\n        out.writeNamedWriteableCollection(relation.output());\n        if (supportingEsSourceOptions(out.getTransportVersion())) {\n            writeEsSourceOptions(out); // write (null) string fillers expected by remote\n        }\n        writeIndexMode(out, relation.indexMode());\n        out.writeBoolean(relation.frozen());\n    }\n\n    private static boolean supportingEsSourceOptions(TransportVersion version) {\n        return version.onOrAfter(TransportVersions.V_8_14_0) \u0026\u0026 version.before(TransportVersions.ESQL_REMOVE_ES_SOURCE_OPTIONS);\n    }\n\n    private static void readEsSourceOptions(PlanStreamInput in) throws IOException {\n        // allowNoIndices\n        in.readOptionalString();\n        // ignoreUnavailable\n        in.readOptionalString();\n        // preference\n        in.readOptionalString();\n    }\n\n    private static void writeEsSourceOptions(PlanStreamOutput out) throws IOException {\n        // allowNoIndices\n        out.writeOptionalString(null);\n        // ignoreUnavailable\n        out.writeOptionalString(null);\n        // preference\n        out.writeOptionalString(null);\n    }\n\n    static Eval readEval(PlanStreamInput in) throws IOException {\n        return new Eval(Source.readFrom(in), in.readLogicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEval(PlanStreamOutput out, Eval eval) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(eval.child());\n        out.writeCollection(eval.fields());\n    }\n\n    static Enrich readEnrich(PlanStreamInput in) throws IOException {\n        Enrich.Mode mode \u003d Enrich.Mode.ANY;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n        }\n        final Source source \u003d Source.readFrom(in);\n        final LogicalPlan child \u003d in.readLogicalPlanNode();\n        final Expression policyName \u003d in.readNamedWriteable(Expression.class);\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        if (in.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            in.readString(); // discard the old policy name\n        }\n        final EnrichPolicy policy \u003d new EnrichPolicy(in);\n        final Map\u003cString, String\u003e concreteIndices;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            EsIndex esIndex \u003d readEsIndex(in);\n            if (esIndex.concreteIndices().size() \u003e 1) {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + esIndex);\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new Enrich(\n            source,\n            child,\n            mode,\n            policyName,\n            matchField,\n            policy,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrich(PlanStreamOutput out, Enrich enrich) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n        }\n\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(enrich.child());\n        out.writeNamedWriteable(enrich.policyName());\n        out.writeNamedWriteable(enrich.matchField());\n        if (out.getTransportVersion().before(TransportVersions.V_8_13_0)) {\n            out.writeString(BytesRefs.toString(enrich.policyName().fold())); // old policy name\n        }\n        enrich.policy().writeTo(out);\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            Map\u003cString, String\u003e concreteIndices \u003d enrich.concreteIndices();\n            if (concreteIndices.keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String enrichIndex \u003d concreteIndices.get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                EsIndex esIndex \u003d new EsIndex(enrichIndex, Map.of(), Set.of(enrichIndex));\n                writeEsIndex(out, esIndex);\n            } else {\n                throw new IllegalStateException(\"expected a single enrich index; got \" + concreteIndices);\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static EsqlProject readEsqlProject(PlanStreamInput in) throws IOException {\n        return new EsqlProject(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeEsqlProject(PlanStreamOutput out, EsqlProject project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    static Filter readFilter(PlanStreamInput in) throws IOException {\n        return new Filter(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteable(Expression.class));\n    }\n\n    static void writeFilter(PlanStreamOutput out, Filter filter) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(filter.child());\n        out.writeNamedWriteable(filter.condition());\n    }\n\n    static Grok readGrok(PlanStreamInput in) throws IOException {\n        Source source;\n        return new Grok(\n            source \u003d Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readNamedWriteable(Expression.class),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrok(PlanStreamOutput out, Grok grok) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(grok.child());\n        out.writeNamedWriteable(grok.input());\n        out.writeString(grok.parser().pattern());\n        out.writeNamedWriteableCollection(grok.extractedFields());\n    }\n\n    static Limit readLimit(PlanStreamInput in) throws IOException {\n        return new Limit(Source.readFrom(in), in.readNamedWriteable(Expression.class), in.readLogicalPlanNode());\n    }\n\n    static void writeLimit(PlanStreamOutput out, Limit limit) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteable(limit.limit());\n        out.writeLogicalPlanNode(limit.child());\n    }\n\n    static MvExpand readMvExpand(PlanStreamInput in) throws IOException {\n        return new MvExpand(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpand(PlanStreamOutput out, MvExpand mvExpand) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(mvExpand.child());\n        out.writeNamedWriteable(mvExpand.target());\n        out.writeNamedWriteable(mvExpand.expanded());\n    }\n\n    static OrderBy readOrderBy(PlanStreamInput in) throws IOException {\n        return new OrderBy(\n            Source.readFrom(in),\n            in.readLogicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new)\n        );\n    }\n\n    static void writeOrderBy(PlanStreamOutput out, OrderBy order) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(order.child());\n        out.writeCollection(order.order());\n    }\n\n    static Project readProject(PlanStreamInput in) throws IOException {\n        return new Project(Source.readFrom(in), in.readLogicalPlanNode(), in.readNamedWriteableCollectionAsList(NamedExpression.class));\n    }\n\n    static void writeProject(PlanStreamOutput out, Project project) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeLogicalPlanNode(project.child());\n        out.writeNamedWriteableCollection(project.projections());\n    }\n\n    // -- ancillary supporting classes of plan nodes, etc\n\n    static EsQueryExec.FieldSort readFieldSort(PlanStreamInput in) throws IOException {\n        return new EsQueryExec.FieldSort(\n            FieldAttribute.readFrom(in),\n            in.readEnum(Order.OrderDirection.class),\n            in.readEnum(Order.NullsPosition.class)\n        );\n    }\n\n    static void writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort) throws IOException {\n        fieldSort.field().writeTo(out);\n        out.writeEnum(fieldSort.direction());\n        out.writeEnum(fieldSort.nulls());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static EsIndex readEsIndex(PlanStreamInput in) throws IOException {\n        return new EsIndex(\n            in.readString(),\n            in.readImmutableMap(StreamInput::readString, i -\u003e i.readNamedWriteable(EsField.class)),\n            (Set\u003cString\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeEsIndex(PlanStreamOutput out, EsIndex esIndex) throws IOException {\n        out.writeString(esIndex.name());\n        out.writeMap(esIndex.mapping(), StreamOutput::writeNamedWriteable);\n        out.writeGenericValue(esIndex.concreteIndices());\n    }\n\n    static Parser readDissectParser(PlanStreamInput in) throws IOException {\n        String pattern \u003d in.readString();\n        String appendSeparator \u003d in.readString();\n        return new Parser(pattern, appendSeparator, new DissectParser(pattern, appendSeparator));\n    }\n\n    static void writeDissectParser(PlanStreamOutput out, Parser dissectParser) throws IOException {\n        out.writeString(dissectParser.pattern());\n        out.writeString(dissectParser.appendSeparator());\n    }\n}","methodCount":76},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":107,"lineEnd":161,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanNameRegistry","description":"move method namedTypeEntries to PsiClass:PlanNameRegistry\nRationale: The namedTypeEntries() method is heavily tied to the registration of plan names and their associated serialization methods. Moving it to PlanNameRegistry aligns with the Single Responsibility Principle, as this class is responsible for managing the registry of plan names and their serializers/deserializers. This relocation would enhance the cohesion of the PlanNameRegistry class, making it clearer that it is responsible for the registration process. However, care should be taken to ensure that the method\u0027s static nature doesn\u0027t create confusion regarding instance versus class-level responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":107,"lineEnd":161,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanStreamOutput","description":"move method namedTypeEntries to PsiClass:PlanStreamOutput\nRationale: The namedTypeEntries() method involves writing and reading plan nodes, which is directly related to stream output operations. Moving it to PlanStreamOutput would make sense as this class handles the serialization of plan nodes. This aligns with the Open/Closed Principle by allowing PlanStreamOutput to be extended with new plan types without modifying existing code. However, this might introduce a tighter coupling between serialization logic and the output stream, which should be managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":107,"lineEnd":161,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlannerUtils","description":"move method namedTypeEntries to PsiClass:PlannerUtils\nRationale: The namedTypeEntries() method could be seen as a utility for planning operations, as it provides necessary entries for various plan types. Moving it to PlannerUtils would centralize utility functions related to planning, adhering to the Single Responsibility Principle. This would improve the organization of planning-related utilities, but it could blur the lines between utility functions and core domain logic, which might lead to maintenance challenges.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":579,"lineEnd":586,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class PlanStreamInput","description":"move method writeEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The writeEsSourceOptions() method is responsible for writing options to a stream, which aligns closely with the responsibilities of PlanStreamInput, as it handles reading and writing data streams. This move adheres to the Single Responsibility Principle by ensuring that the method is located within a class that directly manages stream operations, improving cohesion. However, care must be taken to ensure that the method\u0027s dependencies are properly managed in the new context.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":579,"lineEnd":586,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class TestUtils","description":"move method writeEsSourceOptions to PsiClass:TestUtils\nRationale: The method seems to be used for preparing or configuring outputs, which is a common utility function in testing scenarios. Moving this method to TestUtils would enhance its reusability in various test cases. This aligns with the Open/Closed Principle, allowing the utility class to be extended with additional functionality without modifying existing code. However, it may lead to an overcrowded utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":579,"lineEnd":586,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsSourceOptions to class EsqlTestUtils","description":"move method writeEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils is focused on providing utility methods for testing Esql-related functionality. Since writeEsSourceOptions() appears to be related to the configuration of Esql sources, moving it here would improve cohesion and maintainability. This aligns with the Single Responsibility Principle, as it groups related functionalities. The drawback could be that it might not be directly related to Esql operations, leading to potential confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":570,"lineEnd":577,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class PlanStreamInput","description":"move method readEsSourceOptions to PsiClass:PlanStreamInput\nRationale: The readEsSourceOptions() method directly interacts with the PlanStreamInput class for reading source options. Moving it here enhances cohesion, as it deals with the input stream\u0027s properties. This aligns with the Single Responsibility Principle, as PlanStreamInput is responsible for managing input operations. However, it may increase the complexity of PlanStreamInput if too many methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":570,"lineEnd":577,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class EsqlTestUtils","description":"move method readEsSourceOptions to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils provides utility methods for Esql-related operations, and since readEsSourceOptions seems to deal with options relevant to Esql, this class is a good candidate. It adheres to the Open/Closed Principle by allowing for extension without modifying existing code. However, it may dilute the purpose of EsqlTestUtils if it becomes overloaded with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":570,"lineEnd":577,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEsSourceOptions to class StringUtils","description":"move method readEsSourceOptions to PsiClass:StringUtils\nRationale: Given that readEsSourceOptions reads optional strings, StringUtils may be a reasonable target as it handles string operations. This aligns with the Single Responsibility Principle, focusing on string-related functionalities. However, this could lead to an inappropriate coupling of unrelated functionalities if StringUtils becomes too broad.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"name","method_signature":"public static name(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"readAggregateExec","method_signature":"static readAggregateExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},{"method_name":"readDissectExec","method_signature":"static readDissectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"readEsSourceExec","method_signature":"static readEsSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},{"method_name":"readIndexMode","method_signature":"static readIndexMode(StreamInput in)","target_class":"","rationale":""},{"method_name":"writeIndexMode","method_signature":"static writeIndexMode(StreamOutput out, IndexMode indexMode)","target_class":"","rationale":""},{"method_name":"readEvalExec","method_signature":"static readEvalExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEvalExec","method_signature":"static writeEvalExec(PlanStreamOutput out, EvalExec evalExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrichExec","method_signature":"static writeEnrichExec(PlanStreamOutput out, EnrichExec enrich)","target_class":"","rationale":""},{"method_name":"readExchangeExec","method_signature":"static readExchangeExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},{"method_name":"readExchangeSinkExec","method_signature":"static readExchangeSinkExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},{"method_name":"readExchangeSourceExec","method_signature":"static readExchangeSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},{"method_name":"readFieldExtractExec","method_signature":"static readFieldExtractExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldExtractExec","method_signature":"static writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec)","target_class":"","rationale":""},{"method_name":"readFilterExec","method_signature":"static readFilterExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilterExec","method_signature":"static writeFilterExec(PlanStreamOutput out, FilterExec filterExec)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFragmentExec","method_signature":"static writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec)","target_class":"","rationale":""},{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},{"method_name":"readLimitExec","method_signature":"static readLimitExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimitExec","method_signature":"static writeLimitExec(PlanStreamOutput out, LimitExec limitExec)","target_class":"","rationale":""},{"method_name":"readMvExpandExec","method_signature":"static readMvExpandExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},{"method_name":"readOrderExec","method_signature":"static readOrderExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderExec","method_signature":"static writeOrderExec(PlanStreamOutput out, OrderExec orderExec)","target_class":"","rationale":""},{"method_name":"readProjectExec","method_signature":"static readProjectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProjectExec","method_signature":"static writeProjectExec(PlanStreamOutput out, ProjectExec projectExec)","target_class":"","rationale":""},{"method_name":"readRowExec","method_signature":"static readRowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readShowExec","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readShowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeShowExec","method_signature":"static writeShowExec(PlanStreamOutput out, ShowExec showExec)","target_class":"","rationale":""},{"method_name":"readTopNExec","method_signature":"static readTopNExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},{"method_name":"readDissect","method_signature":"static readDissect(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsRelation","method_signature":"static writeEsRelation(PlanStreamOutput out, EsRelation relation)","target_class":"","rationale":""},{"method_name":"supportingEsSourceOptions","method_signature":"private static supportingEsSourceOptions(TransportVersion version)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEval","method_signature":"static readEval(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEval","method_signature":"static writeEval(PlanStreamOutput out, Eval eval)","target_class":"","rationale":""},{"method_name":"readEnrich","method_signature":"static readEnrich(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrich","method_signature":"static writeEnrich(PlanStreamOutput out, Enrich enrich)","target_class":"","rationale":""},{"method_name":"readEsqlProject","method_signature":"static readEsqlProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsqlProject","method_signature":"static writeEsqlProject(PlanStreamOutput out, EsqlProject project)","target_class":"","rationale":""},{"method_name":"readFilter","method_signature":"static readFilter(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilter","method_signature":"static writeFilter(PlanStreamOutput out, Filter filter)","target_class":"","rationale":""},{"method_name":"readGrok","method_signature":"static readGrok(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrok","method_signature":"static writeGrok(PlanStreamOutput out, Grok grok)","target_class":"","rationale":""},{"method_name":"readLimit","method_signature":"static readLimit(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimit","method_signature":"static writeLimit(PlanStreamOutput out, Limit limit)","target_class":"","rationale":""},{"method_name":"readMvExpand","method_signature":"static readMvExpand(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpand","method_signature":"static writeMvExpand(PlanStreamOutput out, MvExpand mvExpand)","target_class":"","rationale":""},{"method_name":"readOrderBy","method_signature":"static readOrderBy(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderBy","method_signature":"static writeOrderBy(PlanStreamOutput out, OrderBy order)","target_class":"","rationale":""},{"method_name":"readProject","method_signature":"static readProject(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProject","method_signature":"static writeProject(PlanStreamOutput out, Project project)","target_class":"","rationale":""},{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""},{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectParser","method_signature":"static writeDissectParser(PlanStreamOutput out, Parser dissectParser)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static namedTypeEntries()":{"first":{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},"second":0.05740809937237475},"private static writeEsSourceOptions(PlanStreamOutput out)":{"first":{"method_name":"writeEsSourceOptions","method_signature":"private static writeEsSourceOptions(PlanStreamOutput out)","target_class":"","rationale":""},"second":0.22065346285320614},"private static readEsSourceOptions(PlanStreamInput in)":{"first":{"method_name":"readEsSourceOptions","method_signature":"private static readEsSourceOptions(PlanStreamInput in)","target_class":"","rationale":""},"second":0.22080629870731075},"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)":{"first":{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},"second":0.26223130161728486},"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)":{"first":{"method_name":"writeEsSourceExec","method_signature":"static writeEsSourceExec(PlanStreamOutput out, EsSourceExec esSourceExec)","target_class":"","rationale":""},"second":0.3514340581862061},"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)":{"first":{"method_name":"writeAggregateExec","method_signature":"static writeAggregateExec(PlanStreamOutput out, AggregateExec aggregateExec)","target_class":"","rationale":""},"second":0.36326862155118717},"static readDissectParser(PlanStreamInput in)":{"first":{"method_name":"readDissectParser","method_signature":"static readDissectParser(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3640246295276221},"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)":{"first":{"method_name":"writeDissectExec","method_signature":"static writeDissectExec(PlanStreamOutput out, DissectExec dissectExec)","target_class":"","rationale":""},"second":0.36484843134715356},"static writeDissect(PlanStreamOutput out, Dissect dissect)":{"first":{"method_name":"writeDissect","method_signature":"static writeDissect(PlanStreamOutput out, Dissect dissect)","target_class":"","rationale":""},"second":0.36484843134715356},"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)":{"first":{"method_name":"writeEsIndex","method_signature":"static writeEsIndex(PlanStreamOutput out, EsIndex esIndex)","target_class":"","rationale":""},"second":0.3666466294241733},"static writeRowExec(PlanStreamOutput out, RowExec rowExec)":{"first":{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},"second":0.37274842030199246},"static readEnrichExec(PlanStreamInput in)":{"first":{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.37369597644756175},"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)":{"first":{"method_name":"readEsIndex","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readEsIndex(PlanStreamInput in)","target_class":"","rationale":""},"second":0.37911087761861534},"static readFragmentExec(PlanStreamInput in)":{"first":{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3806408552133039},"static readEsRelation(PlanStreamInput in)":{"first":{"method_name":"readEsRelation","method_signature":"static readEsRelation(PlanStreamInput in)","target_class":"","rationale":""},"second":0.38162573615915824}},"llmMethodPriority":{"priority_method_names":["namedTypeEntries","writeEsSourceOptions","readEsSourceOptions","writeEsQueryExec","writeEsSourceExec","writeAggregateExec","readDissectParser","writeDissectExec","writeDissect","writeEsIndex","writeRowExec","readEsIndex","readFragmentExec","readEsRelation"],"llm_response_time":9271},"targetClassMap":{"namedTypeEntries":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.0737075923302436},{"class_name":"LuceneComponent2DUtils","similarity_score":0.0701173060491733},{"class_name":"TestUtils","similarity_score":0.09096575140206038},{"class_name":"ParserUtils","similarity_score":0.06869832400657197},{"class_name":"FunctionTestUtils","similarity_score":0.05114781589870119},{"class_name":"AnalyzerTestUtils","similarity_score":0.0685289529131976},{"class_name":"ReflectionUtils","similarity_score":0.06663109529908308},{"class_name":"PlanNamedTypesTests","similarity_score":0.11688814692542927},{"class_name":"PlanNameRegistry","similarity_score":0.1091110521092394},{"class_name":"PlannerUtils","similarity_score":0.13047259859669708},{"class_name":"PlanStreamInput","similarity_score":0.10781374600555904},{"class_name":"PlanStreamOutput","similarity_score":0.11187726063650029},{"class_name":"PlanStreamOutputTests","similarity_score":0.058201298118118944},{"class_name":"SerializationTestUtils","similarity_score":0.07322261964870347},{"class_name":"ExceptionUtils","similarity_score":0.08592345816656875},{"class_name":"Entry","similarity_score":0.0877620777157238},{"class_name":"ResponseValueUtils","similarity_score":0.1134415105456517},{"class_name":"ResponseXContentUtils","similarity_score":0.09850166168785644},{"class_name":"EsqlTestUtils","similarity_score":0.09239852254289015},{"class_name":"CsvTestUtils","similarity_score":0.09994598275383013},{"class_name":"SourceUtils","similarity_score":0.0792740035289418},{"class_name":"SpatialRelatesUtils","similarity_score":0.10683473712324931},{"class_name":"DateUtils","similarity_score":0.09944751906396435},{"class_name":"StringContainsRegex","similarity_score":0.07787915579452676},{"class_name":"StringUtils","similarity_score":0.07946168102215256},{"class_name":"JwkValidateUtil","similarity_score":0.07234900300020457},{"class_name":"JwkValidateUtilTests","similarity_score":0.0647450624120165},{"class_name":"ProcessBuilderUtils","similarity_score":0.07965654548546586},{"class_name":"JwtUtil","similarity_score":0.08945529646576626}],"target_classes_sorted_by_llm":["PlanNameRegistry","PlanStreamOutput","PlannerUtils","PlanNamedTypesTests","PlanStreamInput","ResponseValueUtils","SpatialRelatesUtils","CsvTestUtils","DateUtils","ResponseXContentUtils"],"llm_response_time":15571,"similarity_computation_time":22,"similarity_metric":"voyage"},"writeEsSourceOptions":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.17712297710801905},{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.23855335116519702},{"class_name":"PlanNamedTypesTests","similarity_score":0.29181480543283217},{"class_name":"PlanNameRegistry","similarity_score":0.2304929349447907},{"class_name":"PlannerUtils","similarity_score":0.2265332131898575},{"class_name":"PlanStreamInput","similarity_score":0.2516087893381315},{"class_name":"PlanStreamOutput","similarity_score":0.21814836011224983},{"class_name":"PlanStreamOutputTests","similarity_score":0.20064104469690114},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"EsqlTestUtils","similarity_score":0.2553019063009157},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"CsvTestUtils","similarity_score":0.26026754177399475},{"class_name":"SourceUtils","similarity_score":0.1561349078609147},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"ResponseValueUtils","similarity_score":0.14940598782733747},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"TestUtils","similarity_score":0.31483161012083516},{"class_name":"CertParsingUtils","similarity_score":0.20685516016575112},{"class_name":"IndexerUtils","similarity_score":0.19570679932204535},{"class_name":"JwkValidateUtil","similarity_score":0.18692158795056743},{"class_name":"JwkValidateUtilTests","similarity_score":0.3223014929097608}],"target_classes_sorted_by_llm":["PlanStreamInput","TestUtils","EsqlTestUtils","StringUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","JwkValidateUtilTests","SerializationTestUtils"],"llm_response_time":0,"similarity_computation_time":7,"similarity_metric":"voyage"},"readEsSourceOptions":{"target_classes":[{"class_name":"NumericUtilsTests","similarity_score":0.10369394779796814},{"class_name":"TestUtils","similarity_score":0.31483161012083516},{"class_name":"ParserUtils","similarity_score":0.18692121762654273},{"class_name":"AnalyzerTestUtils","similarity_score":0.2344049556804848},{"class_name":"SerializationTestUtils","similarity_score":0.2439750182371333},{"class_name":"PlanNamedTypesTests","similarity_score":0.2902374281061682},{"class_name":"PlanNameRegistry","similarity_score":0.23630368120390308},{"class_name":"PlannerUtils","similarity_score":0.2265332131898575},{"class_name":"PlanStreamInput","similarity_score":0.2516087893381315},{"class_name":"PlanStreamOutput","similarity_score":0.21814836011224983},{"class_name":"PlanStreamOutputTests","similarity_score":0.20064104469690114},{"class_name":"Entry","similarity_score":0.10700403963703886},{"class_name":"LuceneComponent2DUtils","similarity_score":0.18644616740725337},{"class_name":"EsqlTestUtils","similarity_score":0.2553019063009157},{"class_name":"ExceptionUtils","similarity_score":0.07554973565193743},{"class_name":"CsvTestUtils","similarity_score":0.26026754177399475},{"class_name":"SourceUtils","similarity_score":0.16728740127955144},{"class_name":"SpatialRelatesUtils","similarity_score":0.16121367099516107},{"class_name":"DateUtils","similarity_score":0.3291896764575998},{"class_name":"ReflectionUtils","similarity_score":0.191014361990104},{"class_name":"ResponseValueUtils","similarity_score":0.14940598782733747},{"class_name":"ResponseXContentUtils","similarity_score":0.16820132262710866},{"class_name":"StringContainsRegex","similarity_score":0.3320079470373316},{"class_name":"StringUtils","similarity_score":0.2896350437347946},{"class_name":"FunctionTestUtils","similarity_score":0.17712297710801905},{"class_name":"CertParsingUtils","similarity_score":0.20685516016575112},{"class_name":"AuditUtil","similarity_score":0.2615579179746265},{"class_name":"ResultUtils","similarity_score":0.17541160386140583},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.1797866299901979}],"target_classes_sorted_by_llm":["PlanStreamInput","EsqlTestUtils","StringUtils","TestUtils","CsvTestUtils","StringContainsRegex","DateUtils","PlanNamedTypesTests","AuditUtil","SerializationTestUtils"],"llm_response_time":0,"similarity_computation_time":9,"similarity_metric":"voyage"}}}
{"id":"78c1a2ee-7f52-474e-a8c4-f1f32086fda8","methodCount":65,"hostFunctionTelemetryData":{"hostFunctionSize":1218,"lineStart":117,"lineEnd":1334,"bodyLineStart":117,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/test/java/org/elasticsearch/xpack/esql/expression/function/AbstractFunctionTestCase.java","sourceCode":"/**\n * Base class for function tests.\n */\npublic abstract class AbstractFunctionTestCase extends ESTestCase {\n    /**\n     * Operators are unregistered functions.\n     */\n    private static final Map\u003cString, Class\u003c?\u003e\u003e OPERATORS \u003d Map.ofEntries(\n        entry(\"in\", In.class),\n        entry(\"like\", WildcardLike.class),\n        entry(\"rlike\", RLike.class),\n        entry(\"equals\", Equals.class),\n        entry(\"not_equals\", NotEquals.class),\n        entry(\"greater_than\", GreaterThan.class),\n        entry(\"greater_than_or_equal\", GreaterThanOrEqual.class),\n        entry(\"less_than\", LessThan.class),\n        entry(\"less_than_or_equal\", LessThanOrEqual.class),\n        entry(\"add\", Add.class),\n        entry(\"sub\", Sub.class),\n        entry(\"mul\", Mul.class),\n        entry(\"div\", Div.class),\n        entry(\"mod\", Mod.class),\n        entry(\"neg\", Neg.class),\n        entry(\"is_null\", IsNull.class),\n        entry(\"is_not_null\", IsNotNull.class)\n    );\n\n    /**\n     * Generate a random value of the appropriate type to fit into blocks of {@code e}.\n     */\n    public static Literal randomLiteral(DataType type) {\n        return new Literal(Source.EMPTY, switch (type) {\n            case BOOLEAN -\u003e randomBoolean();\n            case BYTE -\u003e randomByte();\n            case SHORT -\u003e randomShort();\n            case INTEGER, COUNTER_INTEGER -\u003e randomInt();\n            case UNSIGNED_LONG, LONG, COUNTER_LONG -\u003e randomLong();\n            case DATE_PERIOD -\u003e Period.of(randomIntBetween(-1000, 1000), randomIntBetween(-13, 13), randomIntBetween(-32, 32));\n            case DATETIME -\u003e randomMillisUpToYear9999();\n            case DOUBLE, SCALED_FLOAT, COUNTER_DOUBLE -\u003e randomDouble();\n            case FLOAT -\u003e randomFloat();\n            case HALF_FLOAT -\u003e HalfFloatPoint.sortableShortToHalfFloat(HalfFloatPoint.halfFloatToSortableShort(randomFloat()));\n            case KEYWORD -\u003e new BytesRef(randomAlphaOfLength(5));\n            case IP -\u003e new BytesRef(InetAddressPoint.encode(randomIp(randomBoolean())));\n            case TIME_DURATION -\u003e Duration.ofMillis(randomLongBetween(-604800000L, 604800000L)); // plus/minus 7 days\n            case TEXT -\u003e new BytesRef(randomAlphaOfLength(50));\n            case VERSION -\u003e randomVersion().toBytesRef();\n            case GEO_POINT -\u003e GEO.asWkb(GeometryTestUtils.randomPoint());\n            case CARTESIAN_POINT -\u003e CARTESIAN.asWkb(ShapeTestUtils.randomPoint());\n            case GEO_SHAPE -\u003e GEO.asWkb(GeometryTestUtils.randomGeometry(randomBoolean()));\n            case CARTESIAN_SHAPE -\u003e CARTESIAN.asWkb(ShapeTestUtils.randomGeometry(randomBoolean()));\n            case NULL -\u003e null;\n            case SOURCE -\u003e {\n                try {\n                    yield BytesReference.bytes(\n                        JsonXContent.contentBuilder().startObject().field(randomAlphaOfLength(3), randomAlphaOfLength(10)).endObject()\n                    ).toBytesRef();\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            }\n            case UNSUPPORTED, OBJECT, DOC_DATA_TYPE, TSID_DATA_TYPE, PARTIAL_AGG -\u003e throw new IllegalArgumentException(\n                \"can\u0027t make random values for [\" + type.typeName() + \"]\"\n            );\n        }, type);\n    }\n\n    protected TestCaseSupplier.TestCase testCase;\n\n    /**\n     * Converts typed test suppliers to parameterized test parameters.\n     * \u003cp\u003e\n     *     Use {@code parameterSuppliersFromTypedDataWithDefaultChecks()} instead if possible, as it automatically add default checks.\n     * \u003c/p\u003e\n     */\n    protected static Iterable\u003cObject[]\u003e parameterSuppliersFromTypedData(List\u003cTestCaseSupplier\u003e suppliers) {\n        // TODO rename this method to something more descriptive. Javadoc. And make sure all parameters are \"representable\" types.\n        List\u003cObject[]\u003e parameters \u003d new ArrayList\u003c\u003e(suppliers.size());\n        for (TestCaseSupplier supplier : suppliers) {\n            parameters.add(new Object[] { supplier });\n        }\n        return parameters;\n    }\n\n    /**\n     * Adds cases with {@code null} and asserts that the result is {@code null}.\n     * \u003cp\u003e\n     * Note: This won\u0027t add more than a single null to any existing test case,\n     * just to keep the number of test cases from exploding totally.\n     * \u003c/p\u003e\n     *\n     * @param entirelyNullPreservesType should a test case that only contains parameters\n     *                                  with the {@code null} type keep it\u0027s expected type?\n     *                                  This is \u003cstrong\u003emostly\u003c/strong\u003e going to be {@code true}\n     *                                  except for functions that base their type entirely\n     *                                  on input types like {@link Greatest} or {@link Coalesce}.\n     */\n    protected static List\u003cTestCaseSupplier\u003e anyNullIsNull(boolean entirelyNullPreservesType, List\u003cTestCaseSupplier\u003e testCaseSuppliers) {\n        return anyNullIsNull(\n            testCaseSuppliers,\n            (nullPosition, nullValueDataType, original) -\u003e entirelyNullPreservesType \u003d\u003d false\n                \u0026\u0026 nullValueDataType \u003d\u003d DataType.NULL\n                \u0026\u0026 original.getData().size() \u003d\u003d 1 ? DataType.NULL : original.expectedType(),\n            (nullPosition, nullData, original) -\u003e original\n        );\n    }\n\n    public interface ExpectedType {\n        DataType expectedType(int nullPosition, DataType nullValueDataType, TestCaseSupplier.TestCase original);\n    }\n\n    public interface ExpectedEvaluatorToString {\n        Matcher\u003cString\u003e evaluatorToString(int nullPosition, TestCaseSupplier.TypedData nullData, Matcher\u003cString\u003e original);\n    }\n\n    protected static List\u003cTestCaseSupplier\u003e anyNullIsNull(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        ExpectedType expectedType,\n        ExpectedEvaluatorToString evaluatorToString\n    ) {\n        typesRequired(testCaseSuppliers);\n        List\u003cTestCaseSupplier\u003e suppliers \u003d new ArrayList\u003c\u003e(testCaseSuppliers.size());\n        suppliers.addAll(testCaseSuppliers);\n\n        /*\n         * For each original test case, add as many copies as there were\n         * arguments, replacing one of the arguments with null and keeping\n         * the others.\n         *\n         * Also, if this was the first time we saw the signature we copy it\n         * *again*, replacing the argument with null, but annotating the\n         * argument\u0027s type as `null` explicitly.\n         */\n        Set\u003cList\u003cDataType\u003e\u003e uniqueSignatures \u003d new HashSet\u003c\u003e();\n        for (TestCaseSupplier original : testCaseSuppliers) {\n            boolean firstTimeSeenSignature \u003d uniqueSignatures.add(original.types());\n            for (int nullPosition \u003d 0; nullPosition \u003c original.types().size(); nullPosition++) {\n                int finalNullPosition \u003d nullPosition;\n                suppliers.add(new TestCaseSupplier(original.name() + \" null in \" + nullPosition, original.types(), () -\u003e {\n                    TestCaseSupplier.TestCase oc \u003d original.get();\n                    List\u003cTestCaseSupplier.TypedData\u003e data \u003d IntStream.range(0, oc.getData().size()).mapToObj(i -\u003e {\n                        TestCaseSupplier.TypedData od \u003d oc.getData().get(i);\n                        if (i !\u003d finalNullPosition) {\n                            return od;\n                        }\n                        return od.withData(od.isMultiRow() ? Collections.singletonList(null) : null);\n                    }).toList();\n                    TestCaseSupplier.TypedData nulledData \u003d oc.getData().get(finalNullPosition);\n                    return new TestCaseSupplier.TestCase(\n                        data,\n                        evaluatorToString.evaluatorToString(finalNullPosition, nulledData, oc.evaluatorToString()),\n                        expectedType.expectedType(finalNullPosition, nulledData.type(), oc),\n                        nullValue(),\n                        null,\n                        oc.getExpectedTypeError(),\n                        null,\n                        null\n                    );\n                }));\n\n                if (firstTimeSeenSignature) {\n                    List\u003cDataType\u003e typesWithNull \u003d IntStream.range(0, original.types().size())\n                        .mapToObj(i -\u003e i \u003d\u003d finalNullPosition ? DataType.NULL : original.types().get(i))\n                        .toList();\n                    boolean newSignature \u003d uniqueSignatures.add(typesWithNull);\n                    if (newSignature) {\n                        suppliers.add(new TestCaseSupplier(typesWithNull, () -\u003e {\n                            TestCaseSupplier.TestCase oc \u003d original.get();\n                            List\u003cTestCaseSupplier.TypedData\u003e data \u003d IntStream.range(0, oc.getData().size())\n                                .mapToObj(\n                                    i -\u003e i \u003d\u003d finalNullPosition\n                                        ? (oc.getData().get(i).isMultiRow()\n                                            ? TestCaseSupplier.TypedData.MULTI_ROW_NULL\n                                            : TestCaseSupplier.TypedData.NULL)\n                                        : oc.getData().get(i)\n                                )\n                                .toList();\n                            return new TestCaseSupplier.TestCase(\n                                data,\n                                equalTo(\"LiteralsEvaluator[lit\u003dnull]\"),\n                                expectedType.expectedType(finalNullPosition, DataType.NULL, oc),\n                                nullValue(),\n                                null,\n                                oc.getExpectedTypeError(),\n                                null,\n                                null\n                            );\n                        }));\n                    }\n                }\n            }\n        }\n\n        return suppliers;\n    }\n\n    @FunctionalInterface\n    protected interface PositionalErrorMessageSupplier {\n        /**\n         * This interface defines functions to supply error messages for incorrect types in specific positions. Functions which have\n         * the same type requirements for all positions can simplify this with a lambda returning a string constant.\n         *\n         * @param validForPosition - the set of {@link DataType}s that the test infrastructure believes to be allowable in the\n         *                         given position.\n         * @param position - the zero-index position in the list of parameters the function has detected the bad argument to be.\n         * @return The string describing the acceptable parameters for that position.  Note that this function should not return\n         *         the full error string; that will be constructed by the test.  Just return the type string for that position.\n         */\n        String apply(Set\u003cDataType\u003e validForPosition, int position);\n    }\n\n    /**\n     * Adds test cases containing unsupported parameter types that assert\n     * that they throw type errors.\n     */\n    protected static List\u003cTestCaseSupplier\u003e errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        PositionalErrorMessageSupplier positionalErrorMessageSupplier\n    ) {\n        return errorsForCasesWithoutExamples(testCaseSuppliers, (i, v, t) -\u003e typeErrorMessage(i, v, t, positionalErrorMessageSupplier));\n    }\n\n    /**\n     * Build the expected error message for an invalid type signature.\n     */\n    protected static String typeErrorMessage(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier expectedTypeSupplier\n    ) {\n        int badArgPosition \u003d -1;\n        for (int i \u003d 0; i \u003c types.size(); i++) {\n            if (validPerPosition.get(i).contains(types.get(i)) \u003d\u003d false) {\n                badArgPosition \u003d i;\n                break;\n            }\n        }\n        if (badArgPosition \u003d\u003d -1) {\n            throw new IllegalStateException(\n                \"Can\u0027t generate error message for these types, you probably need a custom error message function\"\n            );\n        }\n        String ordinal \u003d includeOrdinal ? TypeResolutions.ParamOrdinal.fromIndex(badArgPosition).name().toLowerCase(Locale.ROOT) + \" \" : \"\";\n        String expectedTypeString \u003d expectedTypeSupplier.apply(validPerPosition.get(badArgPosition), badArgPosition);\n        String name \u003d types.get(badArgPosition).typeName();\n        return ordinal + \"argument of [] must be [\" + expectedTypeString + \"], found value [\" + name + \"] type [\" + name + \"]\";\n    }\n\n    @FunctionalInterface\n    protected interface TypeErrorMessageSupplier {\n        String apply(boolean includeOrdinal, List\u003cSet\u003cDataType\u003e\u003e validPerPosition, List\u003cDataType\u003e types);\n    }\n\n    protected static List\u003cTestCaseSupplier\u003e errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        TypeErrorMessageSupplier typeErrorMessageSupplier\n    ) {\n        typesRequired(testCaseSuppliers);\n        List\u003cTestCaseSupplier\u003e suppliers \u003d new ArrayList\u003c\u003e(testCaseSuppliers.size());\n        suppliers.addAll(testCaseSuppliers);\n\n        Set\u003cList\u003cDataType\u003e\u003e valid \u003d testCaseSuppliers.stream().map(TestCaseSupplier::types).collect(Collectors.toSet());\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition \u003d validPerPosition(valid);\n\n        testCaseSuppliers.stream()\n            .map(s -\u003e s.types().size())\n            .collect(Collectors.toSet())\n            .stream()\n            .flatMap(count -\u003e allPermutations(count))\n            .filter(types -\u003e valid.contains(types) \u003d\u003d false)\n            /*\n             * Skip any cases with more than one null. Our tests don\u0027t generate\n             * the full combinatorial explosions of all nulls - just a single null.\n             * Hopefully \u003cnull\u003e, \u003cnull\u003e cases will function the same as \u003cnull\u003e, \u003cvalid\u003e\n             * cases.\n             */.filter(types -\u003e types.stream().filter(t -\u003e t \u003d\u003d DataType.NULL).count() \u003c\u003d 1)\n            .map(types -\u003e typeErrorSupplier(validPerPosition.size() !\u003d 1, validPerPosition, types, typeErrorMessageSupplier))\n            .forEach(suppliers::add);\n        return suppliers;\n    }\n\n    private static List\u003cDataType\u003e append(List\u003cDataType\u003e orig, DataType extra) {\n        List\u003cDataType\u003e longer \u003d new ArrayList\u003c\u003e(orig.size() + 1);\n        longer.addAll(orig);\n        longer.add(extra);\n        return longer;\n    }\n\n    protected static Stream\u003cDataType\u003e representable() {\n        return DataType.types().stream().filter(DataType::isRepresentable);\n    }\n\n    protected static TestCaseSupplier typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier errorMessageSupplier\n    ) {\n        return typeErrorSupplier(includeOrdinal, validPerPosition, types, (o, v, t) -\u003e typeErrorMessage(o, v, t, errorMessageSupplier));\n    }\n\n    /**\n     * Build a test case that asserts that the combination of parameter types is an error.\n     */\n    protected static TestCaseSupplier typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        TypeErrorMessageSupplier errorMessageSupplier\n    ) {\n        return new TestCaseSupplier(\n            \"type error for \" + TestCaseSupplier.nameFromTypes(types),\n            types,\n            () -\u003e TestCaseSupplier.TestCase.typeError(\n                types.stream().map(type -\u003e new TestCaseSupplier.TypedData(randomLiteral(type).value(), type, type.typeName())).toList(),\n                errorMessageSupplier.apply(includeOrdinal, validPerPosition, types)\n            )\n        );\n    }\n\n    private static List\u003cSet\u003cDataType\u003e\u003e validPerPosition(Set\u003cList\u003cDataType\u003e\u003e valid) {\n        int max \u003d valid.stream().mapToInt(List::size).max().getAsInt();\n        List\u003cSet\u003cDataType\u003e\u003e result \u003d new ArrayList\u003c\u003e(max);\n        for (int i \u003d 0; i \u003c max; i++) {\n            result.add(new HashSet\u003c\u003e());\n        }\n        for (List\u003cDataType\u003e signature : valid) {\n            for (int i \u003d 0; i \u003c signature.size(); i++) {\n                result.get(i).add(signature.get(i));\n            }\n        }\n        return result;\n    }\n\n    protected static Stream\u003cList\u003cDataType\u003e\u003e allPermutations(int argumentCount) {\n        if (argumentCount \u003d\u003d 0) {\n            return Stream.of(List.of());\n        }\n        if (argumentCount \u003e 3) {\n            throw new IllegalArgumentException(\"would generate too many combinations\");\n        }\n        Stream\u003cList\u003cDataType\u003e\u003e stream \u003d validFunctionParameters().map(List::of);\n        for (int i \u003d 1; i \u003c argumentCount; i++) {\n            stream \u003d stream.flatMap(types -\u003e validFunctionParameters().map(t -\u003e append(types, t)));\n        }\n        return stream;\n    }\n\n    /**\n     * The types that are valid in function parameters. This is used by the\n     * function tests to enumerate all possible parameters to test error messages\n     * for invalid combinations.\n     */\n    public static Stream\u003cDataType\u003e validFunctionParameters() {\n        return Arrays.stream(DataType.values()).filter(t -\u003e {\n            if (t \u003d\u003d DataType.UNSUPPORTED) {\n                // By definition, functions never support UNSUPPORTED\n                return false;\n            }\n            if (t \u003d\u003d DataType.DOC_DATA_TYPE || t \u003d\u003d DataType.PARTIAL_AGG) {\n                /*\n                 * Doc and partial_agg are special and functions aren\u0027t\n                 * defined to take these. They\u0027ll use them implicitly if needed.\n                 */\n                return false;\n            }\n            if (t \u003d\u003d DataType.OBJECT) {\n                // Object and nested fields aren\u0027t supported by any functions yet\n                return false;\n            }\n            if (t \u003d\u003d DataType.SOURCE || t \u003d\u003d DataType.TSID_DATA_TYPE) {\n                // No functions take source or tsid fields yet. We\u0027ll make some eventually and remove this.\n                return false;\n            }\n            if (t \u003d\u003d DataType.DATE_PERIOD || t \u003d\u003d DataType.TIME_DURATION) {\n                // We don\u0027t test that functions don\u0027t take date_period or time_duration. We should.\n                return false;\n            }\n            if (t.isCounter()) {\n                /*\n                 * For now, we\u0027re assuming no functions take counters\n                 * as parameters. That\u0027s not true - some do. But we\u0027ll\n                 * need to update the tests to handle that.\n                 */\n                return false;\n            }\n            if (t.widenSmallNumeric() !\u003d t) {\n                // Small numeric types are widened long before they arrive at functions.\n                return false;\n            }\n\n            return true;\n        }).sorted();\n    }\n\n    /**\n     * Build an {@link Attribute} that loads a field.\n     */\n    public static FieldAttribute field(String name, DataType type) {\n        return new FieldAttribute(Source.synthetic(name), name, new EsField(name, type, Map.of(), true));\n    }\n\n    /**\n     * Build an {@link Attribute} that loads a field and then creates a deep copy of its data.\n     */\n    public static Expression deepCopyOfField(String name, DataType type) {\n        return new DeepCopy(\n            Source.synthetic(name),\n            new FieldAttribute(Source.synthetic(name), name, new EsField(name, type, Map.of(), true))\n        );\n    }\n\n    /**\n     * Build the expression being tested, for the given source and list of arguments.  Test classes need to implement this\n     * to have something to test.\n     *\n     * @param source the source\n     * @param args   arg list from the test case, should match the length expected\n     * @return an expression for evaluating the function being tested on the given arguments\n     */\n    protected abstract Expression build(Source source, List\u003cExpression\u003e args);\n\n    /**\n     * Build an {@link Expression} where all inputs are field references,\n     * \u003cstrong\u003eexcept\u003c/strong\u003e those that have been marked with {@link TestCaseSupplier.TypedData#forceLiteral()}.\n     */\n    protected final Expression buildFieldExpression(TestCaseSupplier.TestCase testCase) {\n        return build(testCase.getSource(), testCase.getDataAsFields());\n    }\n\n    /**\n     * Build an {@link Expression} where all inputs are anonymous functions\n     * that make a copy of the values from a field \u003cstrong\u003eexcept\u003c/strong\u003e\n     * those that have been marked with {@link TestCaseSupplier.TypedData#forceLiteral()}.\n     */\n    protected final Expression buildDeepCopyOfFieldExpression(TestCaseSupplier.TestCase testCase) {\n        return build(testCase.getSource(), testCase.getDataAsDeepCopiedFields());\n    }\n\n    protected final Expression buildLiteralExpression(TestCaseSupplier.TestCase testCase) {\n        assumeTrue(\"Data can\u0027t be converted to literals\", testCase.canGetDataAsLiterals());\n        return build(testCase.getSource(), testCase.getDataAsLiterals());\n    }\n\n    /**\n     * Convert an {@link Expression} tree into a {@link ExpressionEvaluator.Factory}\n     * for {@link ExpressionEvaluator}s in the same way as our planner.\n     */\n    public static ExpressionEvaluator.Factory evaluator(Expression e) {\n        e \u003d new FoldNull().rule(e);\n        if (e.foldable()) {\n            e \u003d new Literal(e.source(), e.fold(), e.dataType());\n        }\n        Layout.Builder builder \u003d new Layout.Builder();\n        buildLayout(builder, e);\n        Expression.TypeResolution resolution \u003d e.typeResolved();\n        if (resolution.unresolved()) {\n            throw new AssertionError(\"expected resolved \" + resolution.message());\n        }\n        return EvalMapper.toEvaluator(e, builder.build());\n    }\n\n    protected final Page row(List\u003cObject\u003e values) {\n        return new Page(1, BlockUtils.fromListRow(TestBlockFactory.getNonBreakingInstance(), values));\n    }\n\n    /**\n     * Creates a list of pages based on a list of multi-row fields.\n     */\n    protected final List\u003cPage\u003e rows(List\u003cTestCaseSupplier.TypedData\u003e multirowFields) {\n        if (multirowFields.isEmpty()) {\n            return List.of();\n        }\n\n        var rowsCount \u003d multirowFields.get(0).multiRowData().size();\n\n        multirowFields.stream()\n            .skip(1)\n            .forEach(\n                field -\u003e assertThat(\"All multi-row fields must have the same number of rows\", field.multiRowData(), hasSize(rowsCount))\n            );\n\n        List\u003cPage\u003e pages \u003d new ArrayList\u003c\u003e();\n\n        int pageSize \u003d randomIntBetween(1, 100);\n        for (int initialRow \u003d 0; initialRow \u003c rowsCount;) {\n            if (pageSize \u003e rowsCount - initialRow) {\n                pageSize \u003d rowsCount - initialRow;\n            }\n\n            var blocks \u003d new Block[multirowFields.size()];\n\n            for (int i \u003d 0; i \u003c multirowFields.size(); i++) {\n                var field \u003d multirowFields.get(i);\n                try (\n                    var wrapper \u003d BlockUtils.wrapperFor(\n                        TestBlockFactory.getNonBreakingInstance(),\n                        PlannerUtils.toElementType(field.type()),\n                        pageSize\n                    )\n                ) {\n                    var multiRowData \u003d field.multiRowData();\n                    for (int row \u003d initialRow; row \u003c initialRow + pageSize; row++) {\n                        var data \u003d multiRowData.get(row);\n                        if (data instanceof BigInteger bigIntegerData) {\n                            wrapper.accept(NumericUtils.asLongUnsigned(bigIntegerData));\n                        } else {\n                            wrapper.accept(data);\n                        }\n                    }\n\n                    blocks[i] \u003d wrapper.builder().build();\n                }\n            }\n\n            pages.add(new Page(pageSize, blocks));\n            initialRow +\u003d pageSize;\n            pageSize \u003d randomIntBetween(1, 100);\n        }\n\n        return pages;\n    }\n\n    /**\n     * Hack together a layout by scanning for Fields.\n     * Those will show up in the layout in whatever order a depth first traversal finds them.\n     */\n    protected static void buildLayout(Layout.Builder builder, Expression e) {\n        if (e instanceof FieldAttribute f) {\n            builder.append(f);\n            return;\n        }\n        for (Expression c : e.children()) {\n            buildLayout(builder, c);\n        }\n    }\n\n    protected Object toJavaObjectUnsignedLongAware(Block block, int position) {\n        Object result;\n        result \u003d toJavaObject(block, position);\n        if (result !\u003d null \u0026\u0026 testCase.expectedType() \u003d\u003d DataType.UNSIGNED_LONG) {\n            assertThat(result, instanceOf(Long.class));\n            result \u003d NumericUtils.unsignedLongAsBigInteger((Long) result);\n        }\n        return result;\n    }\n\n    /**\n     * Modifies suppliers to generate BytesRefs with random offsets.\n     */\n    protected static List\u003cTestCaseSupplier\u003e randomizeBytesRefsOffset(List\u003cTestCaseSupplier\u003e testCaseSuppliers) {\n        return testCaseSuppliers.stream().map(supplier -\u003e new TestCaseSupplier(supplier.name(), supplier.types(), () -\u003e {\n            var testCase \u003d supplier.supplier().get();\n\n            var newData \u003d testCase.getData().stream().map(typedData -\u003e {\n                if (typedData.isMultiRow()) {\n                    return typedData.withData(\n                        typedData.multiRowData().stream().map(AbstractFunctionTestCase::tryRandomizeBytesRefOffset).toList()\n                    );\n                }\n\n                return typedData.withData(tryRandomizeBytesRefOffset(typedData.data()));\n            }).toList();\n\n            return new TestCaseSupplier.TestCase(\n                newData,\n                testCase.evaluatorToString(),\n                testCase.expectedType(),\n                testCase.getMatcher(),\n                testCase.getExpectedWarnings(),\n                testCase.getExpectedTypeError(),\n                testCase.foldingExceptionClass(),\n                testCase.foldingExceptionMessage()\n            );\n        })).toList();\n    }\n\n    private static Object tryRandomizeBytesRefOffset(Object value) {\n        if (value instanceof BytesRef bytesRef) {\n            return randomizeBytesRefOffset(bytesRef);\n        }\n\n        if (value instanceof List\u003c?\u003e list) {\n            return list.stream().map(element -\u003e {\n                if (element instanceof BytesRef bytesRef) {\n                    return randomizeBytesRefOffset(bytesRef);\n                }\n                return element;\n            }).toList();\n        }\n\n        return value;\n    }\n\n    private static BytesRef randomizeBytesRefOffset(BytesRef bytesRef) {\n        var offset \u003d randomIntBetween(0, 10);\n        var extraLength \u003d randomIntBetween(0, 10);\n        var newBytesArray \u003d randomByteArrayOfLength(bytesRef.length + offset + extraLength);\n\n        System.arraycopy(bytesRef.bytes, bytesRef.offset, newBytesArray, offset, bytesRef.length);\n\n        return new BytesRef(newBytesArray, offset, bytesRef.length);\n    }\n\n    public void testSerializationOfSimple() {\n        assertSerialization(buildFieldExpression(testCase));\n    }\n\n    @AfterClass\n    public static void testFunctionInfo() {\n        Logger log \u003d LogManager.getLogger(getTestClass());\n        FunctionDefinition definition \u003d definition(functionName());\n        if (definition \u003d\u003d null) {\n            log.info(\"Skipping function info checks because the function isn\u0027t registered\");\n            return;\n        }\n        // TODO fix case tests to include all supported types\n        assumeFalse(\"CASE test incomplete\", definition.name().equals(\"case\"));\n        log.info(\"Running function info checks\");\n        EsqlFunctionRegistry.FunctionDescription description \u003d EsqlFunctionRegistry.description(definition);\n        List\u003cEsqlFunctionRegistry.ArgSignature\u003e args \u003d description.args();\n\n        assertTrue(\"expect description to be defined\", description.description() !\u003d null \u0026\u0026 false \u003d\u003d description.description().isEmpty());\n        assertThat(\n            \"descriptions should be complete sentences\",\n            description.description(),\n            either(endsWith(\".\")) // A full sentence\n                .or(endsWith(\"\")) // Math\n        );\n\n        List\u003cSet\u003cString\u003e\u003e typesFromSignature \u003d new ArrayList\u003c\u003e();\n        Set\u003cString\u003e returnFromSignature \u003d new HashSet\u003c\u003e();\n        for (int i \u003d 0; i \u003c args.size(); i++) {\n            typesFromSignature.add(new HashSet\u003c\u003e());\n        }\n        Function\u003cDataType, String\u003e typeName \u003d dt -\u003e dt.esType() !\u003d null ? dt.esType() : dt.typeName();\n        for (Map.Entry\u003cList\u003cDataType\u003e, DataType\u003e entry : signatures().entrySet()) {\n            List\u003cDataType\u003e types \u003d entry.getKey();\n            for (int i \u003d 0; i \u003c args.size() \u0026\u0026 i \u003c types.size(); i++) {\n                typesFromSignature.get(i).add(typeName.apply(types.get(i)));\n            }\n            returnFromSignature.add(typeName.apply(entry.getValue()));\n        }\n\n        for (int i \u003d 0; i \u003c args.size(); i++) {\n            EsqlFunctionRegistry.ArgSignature arg \u003d args.get(i);\n            Set\u003cString\u003e annotationTypes \u003d Arrays.stream(arg.type()).collect(Collectors.toCollection(TreeSet::new));\n            Set\u003cString\u003e signatureTypes \u003d typesFromSignature.get(i);\n            if (signatureTypes.isEmpty()) {\n                log.info(\"{}: skipping\", arg.name());\n                continue;\n            }\n            log.info(\"{}: tested {} vs annotated {}\", arg.name(), signatureTypes, annotationTypes);\n            assertEquals(signatureTypes, annotationTypes);\n        }\n\n        Set\u003cString\u003e returnTypes \u003d Arrays.stream(description.returnType()).collect(Collectors.toCollection(TreeSet::new));\n        assertEquals(returnFromSignature, returnTypes);\n    }\n\n    protected final void assertTypeResolutionFailure(Expression expression) {\n        assertTrue(\"expected unresolved\", expression.typeResolved().unresolved());\n        assertThat(expression.typeResolved().message(), equalTo(testCase.getExpectedTypeError()));\n    }\n\n    @AfterClass\n    public static void renderSignature() throws IOException {\n        if (System.getProperty(\"generateDocs\") \u003d\u003d null) {\n            return;\n        }\n        String rendered \u003d buildSignatureSvg(functionName());\n        if (rendered \u003d\u003d null) {\n            LogManager.getLogger(getTestClass()).info(\"Skipping rendering signature because the function isn\u0027t registered\");\n        } else {\n            LogManager.getLogger(getTestClass()).info(\"Writing function signature\");\n            writeToTempDir(\"signature\", rendered, \"svg\");\n        }\n    }\n\n    private static String buildSignatureSvg(String name) throws IOException {\n        String binaryOperator \u003d binaryOperator(name);\n        if (binaryOperator !\u003d null) {\n            return RailRoadDiagram.binaryOperator(binaryOperator);\n        }\n        String unaryOperator \u003d unaryOperator(name);\n        if (unaryOperator !\u003d null) {\n            return RailRoadDiagram.unaryOperator(unaryOperator);\n        }\n        FunctionDefinition definition \u003d definition(name);\n        if (definition !\u003d null) {\n            return RailRoadDiagram.functionSignature(definition);\n        }\n        return null;\n    }\n\n    private static Class\u003c?\u003e classGeneratingSignatures \u003d null;\n    /**\n     * Unique signatures in this test\u0027s parameters.\n     */\n    private static Map\u003cList\u003cDataType\u003e, DataType\u003e signatures;\n\n    private static Map\u003cList\u003cDataType\u003e, DataType\u003e signatures() {\n        Class\u003c?\u003e testClass \u003d getTestClass();\n        if (signatures !\u003d null \u0026\u0026 classGeneratingSignatures \u003d\u003d testClass) {\n            return signatures;\n        }\n        classGeneratingSignatures \u003d testClass;\n        signatures \u003d new HashMap\u003c\u003e();\n        Set\u003cMethod\u003e paramsFactories \u003d new ClassModel(testClass).getAnnotatedLeafMethods(ParametersFactory.class).keySet();\n        assertThat(paramsFactories, hasSize(1));\n        Method paramsFactory \u003d paramsFactories.iterator().next();\n        List\u003c?\u003e params;\n        try {\n            params \u003d (List\u003c?\u003e) paramsFactory.invoke(null);\n        } catch (InvocationTargetException | IllegalAccessException e) {\n            throw new RuntimeException(e);\n        }\n        for (Object p : params) {\n            TestCaseSupplier tcs \u003d (TestCaseSupplier) ((Object[]) p)[0];\n            TestCaseSupplier.TestCase tc \u003d tcs.get();\n            if (tc.getExpectedTypeError() !\u003d null) {\n                continue;\n            }\n            if (tc.getData().stream().anyMatch(t -\u003e t.type() \u003d\u003d DataType.NULL)) {\n                continue;\n            }\n            signatures.putIfAbsent(tc.getData().stream().map(TestCaseSupplier.TypedData::type).toList(), tc.expectedType());\n        }\n        return signatures;\n    }\n\n    @AfterClass\n    public static void renderDocs() throws IOException {\n        if (System.getProperty(\"generateDocs\") \u003d\u003d null) {\n            return;\n        }\n        String name \u003d functionName();\n        if (binaryOperator(name) !\u003d null || unaryOperator(name) !\u003d null || likeOrInOperator(name)) {\n            renderDocsForOperators(name);\n            return;\n        }\n        FunctionDefinition definition \u003d definition(name);\n        if (definition !\u003d null) {\n            EsqlFunctionRegistry.FunctionDescription description \u003d EsqlFunctionRegistry.description(definition);\n            renderTypes(description.argNames());\n            renderParametersList(description.argNames(), description.argDescriptions());\n            FunctionInfo info \u003d EsqlFunctionRegistry.functionInfo(definition);\n            renderDescription(description.description(), info.detailedDescription(), info.note());\n            boolean hasExamples \u003d renderExamples(info);\n            boolean hasAppendix \u003d renderAppendix(info.appendix());\n            renderFullLayout(name, info.preview(), hasExamples, hasAppendix);\n            renderKibanaInlineDocs(name, info);\n            List\u003cEsqlFunctionRegistry.ArgSignature\u003e args \u003d description.args();\n            if (name.equals(\"case\")) {\n                EsqlFunctionRegistry.ArgSignature falseValue \u003d args.get(1);\n                args \u003d List.of(\n                    args.get(0),\n                    falseValue,\n                    new EsqlFunctionRegistry.ArgSignature(\n                        \"falseValue\",\n                        falseValue.type(),\n                        falseValue.description(),\n                        true,\n                        EsqlFunctionRegistry.getTargetType(falseValue.type())\n                    )\n                );\n            }\n            renderKibanaFunctionDefinition(name, info, args, description.variadic());\n            return;\n        }\n        LogManager.getLogger(getTestClass()).info(\"Skipping rendering types because the function \u0027\" + name + \"\u0027 isn\u0027t registered\");\n    }\n\n    private static final String DOCS_WARNING \u003d\n        \"// This is generated by ESQL\u0027s AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\\n\\n\";\n\n    private static final String PREVIEW_CALLOUT \u003d\n        \"\\npreview::[\\\"Do not use `VALUES` on production environments. This functionality is in technical preview and \"\n            + \"may be changed or removed in a future release. Elastic will work to fix any issues, but features in technical preview \"\n            + \"are not subject to the support SLA of official GA features.\\\"]\\n\";\n\n    private static void renderTypes(List\u003cString\u003e argNames) throws IOException {\n        StringBuilder header \u003d new StringBuilder();\n        for (String arg : argNames) {\n            header.append(arg).append(\" | \");\n        }\n        header.append(\"result\");\n\n        List\u003cString\u003e table \u003d new ArrayList\u003c\u003e();\n        for (Map.Entry\u003cList\u003cDataType\u003e, DataType\u003e sig : signatures().entrySet()) { // TODO flip to using sortedSignatures\n            if (sig.getKey().size() \u003e argNames.size()) { // skip variadic [test] cases (but not those with optional parameters)\n                continue;\n            }\n            StringBuilder b \u003d new StringBuilder();\n            for (DataType arg : sig.getKey()) {\n                b.append(arg.typeName()).append(\" | \");\n            }\n            b.append(\"| \".repeat(argNames.size() - sig.getKey().size()));\n            b.append(sig.getValue().typeName());\n            table.add(b.toString());\n        }\n        Collections.sort(table);\n        if (table.isEmpty()) {\n            table.add(signatures.values().iterator().next().typeName());\n        }\n\n        String rendered \u003d DOCS_WARNING + \"\"\"\n            *Supported types*\n\n            [%header.monospaced.styled,format\u003ddsv,separator\u003d|]\n            |\u003d\u003d\u003d\n            \"\"\" + header + \"\\n\" + table.stream().collect(Collectors.joining(\"\\n\")) + \"\\n|\u003d\u003d\u003d\\n\";\n        LogManager.getLogger(getTestClass()).info(\"Writing function types for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"types\", rendered, \"asciidoc\");\n    }\n\n    private static void renderParametersList(List\u003cString\u003e argNames, List\u003cString\u003e argDescriptions) throws IOException {\n        StringBuilder builder \u003d new StringBuilder();\n        builder.append(DOCS_WARNING);\n        builder.append(\"*Parameters*\\n\");\n        for (int a \u003d 0; a \u003c argNames.size(); a++) {\n            builder.append(\"\\n`\").append(argNames.get(a)).append(\"`::\\n\").append(argDescriptions.get(a)).append(\u0027\\n\u0027);\n        }\n        String rendered \u003d builder.toString();\n        LogManager.getLogger(getTestClass()).info(\"Writing parameters for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"parameters\", rendered, \"asciidoc\");\n    }\n\n    private static void renderDescription(String description, String detailedDescription, String note) throws IOException {\n        String rendered \u003d DOCS_WARNING + \"\"\"\n            *Description*\n\n            \"\"\" + description + \"\\n\";\n\n        if (Strings.isNullOrEmpty(detailedDescription) \u003d\u003d false) {\n            rendered +\u003d \"\\n\" + detailedDescription + \"\\n\";\n        }\n\n        if (Strings.isNullOrEmpty(note) \u003d\u003d false) {\n            rendered +\u003d \"\\nNOTE: \" + note + \"\\n\";\n        }\n        LogManager.getLogger(getTestClass()).info(\"Writing description for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"description\", rendered, \"asciidoc\");\n    }\n\n    private static boolean renderExamples(FunctionInfo info) throws IOException {\n        if (info \u003d\u003d null || info.examples().length \u003d\u003d 0) {\n            return false;\n        }\n        StringBuilder builder \u003d new StringBuilder();\n        builder.append(DOCS_WARNING);\n        if (info.examples().length \u003d\u003d 1) {\n            builder.append(\"*Example*\\n\\n\");\n        } else {\n            builder.append(\"*Examples*\\n\\n\");\n        }\n        for (Example example : info.examples()) {\n            if (example.description().length() \u003e 0) {\n                builder.append(example.description());\n                builder.append(\"\\n\");\n            }\n            builder.append(\"\"\"\n                [source.merge.styled,esql]\n                ----\n                include::{esql-specs}/$FILE$.csv-spec[tag\u003d$TAG$]\n                ----\n                [%header.monospaced.styled,format\u003ddsv,separator\u003d|]\n                |\u003d\u003d\u003d\n                include::{esql-specs}/$FILE$.csv-spec[tag\u003d$TAG$-result]\n                |\u003d\u003d\u003d\n                \"\"\".replace(\"$FILE$\", example.file()).replace(\"$TAG$\", example.tag()));\n            if (example.explanation().length() \u003e 0) {\n                builder.append(\"\\n\");\n                builder.append(example.explanation());\n                builder.append(\"\\n\\n\");\n            }\n        }\n        builder.append(\u0027\\n\u0027);\n        String rendered \u003d builder.toString();\n        LogManager.getLogger(getTestClass()).info(\"Writing examples for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"examples\", rendered, \"asciidoc\");\n        return true;\n    }\n\n    private static boolean renderAppendix(String appendix) throws IOException {\n        if (appendix.isEmpty()) {\n            return false;\n        }\n\n        String rendered \u003d DOCS_WARNING + appendix + \"\\n\";\n\n        LogManager.getLogger(getTestClass()).info(\"Writing appendix for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"appendix\", rendered, \"asciidoc\");\n        return true;\n    }\n\n    private static void renderFullLayout(String name, boolean preview, boolean hasExamples, boolean hasAppendix) throws IOException {\n        String rendered \u003d DOCS_WARNING + \"\"\"\n            [discrete]\n            [[esql-$NAME$]]\n            \u003d\u003d\u003d `$UPPER_NAME$`\n            $PREVIEW_CALLOUT$\n            *Syntax*\n\n            [.text-center]\n            image::esql/functions/signature/$NAME$.svg[Embedded,opts\u003dinline]\n\n            include::../parameters/$NAME$.asciidoc[]\n            include::../description/$NAME$.asciidoc[]\n            include::../types/$NAME$.asciidoc[]\n            \"\"\".replace(\"$NAME$\", name)\n            .replace(\"$UPPER_NAME$\", name.toUpperCase(Locale.ROOT))\n            .replace(\"$PREVIEW_CALLOUT$\", preview ? PREVIEW_CALLOUT : \"\");\n        if (hasExamples) {\n            rendered +\u003d \"include::../examples/\" + name + \".asciidoc[]\\n\";\n        }\n        if (hasAppendix) {\n            rendered +\u003d \"include::../appendix/\" + name + \".asciidoc[]\\n\";\n        }\n        LogManager.getLogger(getTestClass()).info(\"Writing layout for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"layout\", rendered, \"asciidoc\");\n    }\n\n    private static Constructor\u003c?\u003e constructorWithFunctionInfo(Class\u003c?\u003e clazz) {\n        for (Constructor\u003c?\u003e ctor : clazz.getConstructors()) {\n            FunctionInfo functionInfo \u003d ctor.getAnnotation(FunctionInfo.class);\n            if (functionInfo !\u003d null) {\n                return ctor;\n            }\n        }\n        return null;\n    }\n\n    private static void renderDocsForOperators(String name) throws IOException {\n        Constructor\u003c?\u003e ctor \u003d constructorWithFunctionInfo(OPERATORS.get(name));\n        assert ctor !\u003d null;\n        FunctionInfo functionInfo \u003d ctor.getAnnotation(FunctionInfo.class);\n        assert functionInfo !\u003d null;\n        renderKibanaInlineDocs(name, functionInfo);\n\n        var params \u003d ctor.getParameters();\n\n        List\u003cEsqlFunctionRegistry.ArgSignature\u003e args \u003d new ArrayList\u003c\u003e(params.length);\n        for (int i \u003d 1; i \u003c params.length; i++) { // skipping 1st argument, the source\n            if (Configuration.class.isAssignableFrom(params[i].getType()) \u003d\u003d false) {\n                Param paramInfo \u003d params[i].getAnnotation(Param.class);\n                String paramName \u003d paramInfo \u003d\u003d null ? params[i].getName() : paramInfo.name();\n                String[] type \u003d paramInfo \u003d\u003d null ? new String[] { \"?\" } : paramInfo.type();\n                String desc \u003d paramInfo \u003d\u003d null ? \"\" : paramInfo.description().replace(\u0027\\n\u0027, \u0027 \u0027);\n                boolean optional \u003d paramInfo \u003d\u003d null ? false : paramInfo.optional();\n                DataType targetDataType \u003d EsqlFunctionRegistry.getTargetType(type);\n                args.add(new EsqlFunctionRegistry.ArgSignature(paramName, type, desc, optional, targetDataType));\n            }\n        }\n        renderKibanaFunctionDefinition(name, functionInfo, args, likeOrInOperator(name));\n        renderTypes(args.stream().map(EsqlFunctionRegistry.ArgSignature::name).toList());\n    }\n\n    private static void renderKibanaInlineDocs(String name, FunctionInfo info) throws IOException {\n        StringBuilder builder \u003d new StringBuilder();\n        builder.append(\"\"\"\n            \u003c!--\n            This is generated by ESQL\u0027s AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\n            --\u003e\n\n            \"\"\");\n        builder.append(\"### \").append(name.toUpperCase(Locale.ROOT)).append(\"\\n\");\n        builder.append(removeAsciidocLinks(info.description())).append(\"\\n\\n\");\n\n        if (info.examples().length \u003e 0) {\n            Example example \u003d info.examples()[0];\n            builder.append(\"```\\n\");\n            builder.append(\"read-example::\").append(example.file()).append(\".csv-spec[tag\u003d\").append(example.tag()).append(\"]\\n\");\n            builder.append(\"```\\n\");\n        }\n        if (Strings.isNullOrEmpty(info.note()) \u003d\u003d false) {\n            builder.append(\"Note: \").append(removeAsciidocLinks(info.note())).append(\"\\n\");\n        }\n        String rendered \u003d builder.toString();\n        LogManager.getLogger(getTestClass()).info(\"Writing kibana inline docs for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"kibana/docs\", rendered, \"md\");\n    }\n\n    private static void renderKibanaFunctionDefinition(\n        String name,\n        FunctionInfo info,\n        List\u003cEsqlFunctionRegistry.ArgSignature\u003e args,\n        boolean variadic\n    ) throws IOException {\n\n        XContentBuilder builder \u003d JsonXContent.contentBuilder().prettyPrint().lfAtEnd().startObject();\n        builder.field(\n            \"comment\",\n            \"This is generated by ESQL\u0027s AbstractFunctionTestCase. Do no edit it. See ../README.md for how to regenerate it.\"\n        );\n        builder.field(\"type\", isAggregation() ? \"agg\" : OPERATORS.get(name) !\u003d null ? \"operator\" : \"eval\");\n        builder.field(\"name\", name);\n        builder.field(\"description\", removeAsciidocLinks(info.description()));\n        if (Strings.isNullOrEmpty(info.note()) \u003d\u003d false) {\n            builder.field(\"note\", removeAsciidocLinks(info.note()));\n        }\n        // TODO aliases\n\n        builder.startArray(\"signatures\");\n        if (args.isEmpty()) {\n            builder.startObject();\n            builder.startArray(\"params\");\n            builder.endArray();\n            // There should only be one return type so just use that as the example\n            builder.field(\"returnType\", signatures().values().iterator().next().typeName());\n            builder.endObject();\n        } else {\n            int minArgCount \u003d (int) args.stream().filter(a -\u003e false \u003d\u003d a.optional()).count();\n            for (Map.Entry\u003cList\u003cDataType\u003e, DataType\u003e sig : sortedSignatures()) {\n                if (variadic \u0026\u0026 sig.getKey().size() \u003e args.size()) {\n                    // For variadic functions we test much longer signatures, let\u0027s just stop at the last one\n                    continue;\n                }\n                if (sig.getKey().size() \u003c minArgCount) {\n                    throw new IllegalArgumentException(\"signature \" + sig.getKey() + \" is missing non-optional arg for \" + args);\n                }\n                builder.startObject();\n                builder.startArray(\"params\");\n                for (int i \u003d 0; i \u003c sig.getKey().size(); i++) {\n                    EsqlFunctionRegistry.ArgSignature arg \u003d args.get(i);\n                    builder.startObject();\n                    builder.field(\"name\", arg.name());\n                    builder.field(\"type\", sig.getKey().get(i).typeName());\n                    builder.field(\"optional\", arg.optional());\n                    builder.field(\"description\", arg.description());\n                    builder.endObject();\n                }\n                builder.endArray();\n                builder.field(\"variadic\", variadic);\n                builder.field(\"returnType\", sig.getValue().typeName());\n                builder.endObject();\n            }\n        }\n        builder.endArray();\n\n        if (info.examples().length \u003e 0) {\n            builder.startArray(\"examples\");\n            for (Example example : info.examples()) {\n                builder.value(\"read-example::\" + example.file() + \".csv-spec[tag\u003d\" + example.tag() + \", json]\");\n            }\n            builder.endArray();\n        }\n\n        String rendered \u003d Strings.toString(builder.endObject());\n        LogManager.getLogger(getTestClass()).info(\"Writing kibana function definition for [{}]:\\n{}\", functionName(), rendered);\n        writeToTempDir(\"kibana/definition\", rendered, \"json\");\n    }\n\n    private static String removeAsciidocLinks(String asciidoc) {\n        return asciidoc.replaceAll(\"[^ ]+\\\\[([^\\\\]]+)\\\\]\", \"$1\");\n    }\n\n    private static List\u003cMap.Entry\u003cList\u003cDataType\u003e, DataType\u003e\u003e sortedSignatures() {\n        List\u003cMap.Entry\u003cList\u003cDataType\u003e, DataType\u003e\u003e sortedSignatures \u003d new ArrayList\u003c\u003e(signatures().entrySet());\n        Collections.sort(sortedSignatures, new Comparator\u003c\u003e() {\n            @Override\n            public int compare(Map.Entry\u003cList\u003cDataType\u003e, DataType\u003e lhs, Map.Entry\u003cList\u003cDataType\u003e, DataType\u003e rhs) {\n                int maxlen \u003d Math.max(lhs.getKey().size(), rhs.getKey().size());\n                for (int i \u003d 0; i \u003c maxlen; i++) {\n                    if (lhs.getKey().size() \u003c\u003d i) {\n                        return -1;\n                    }\n                    if (rhs.getKey().size() \u003c\u003d i) {\n                        return 1;\n                    }\n                    int c \u003d lhs.getKey().get(i).typeName().compareTo(rhs.getKey().get(i).typeName());\n                    if (c !\u003d 0) {\n                        return c;\n                    }\n                }\n                return lhs.getValue().typeName().compareTo(rhs.getValue().typeName());\n            }\n        });\n        return sortedSignatures;\n    }\n\n    protected static String functionName() {\n        Class\u003c?\u003e testClass \u003d getTestClass();\n        if (testClass.isAnnotationPresent(FunctionName.class)) {\n            FunctionName functionNameAnnotation \u003d testClass.getAnnotation(FunctionName.class);\n            return functionNameAnnotation.value();\n        } else {\n            return StringUtils.camelCaseToUnderscore(testClass.getSimpleName().replace(\"Tests\", \"\")).toLowerCase(Locale.ROOT);\n        }\n    }\n\n    private static FunctionDefinition definition(String name) {\n        EsqlFunctionRegistry registry \u003d new EsqlFunctionRegistry();\n        if (registry.functionExists(name)) {\n            return registry.resolveFunction(name);\n        }\n        return null;\n    }\n\n    /**\n     * If this test is a for a binary operator return its symbol, otherwise return {@code null}.\n     * This is functionally the reverse of the combination of\n     * {@link ExpressionBuilder#visitArithmeticBinary} and {@link ExpressionBuilder#visitComparison}.\n     */\n    private static String binaryOperator(String name) {\n        return switch (name) {\n            case \"add\" -\u003e \"+\";\n            case \"div\" -\u003e \"/\";\n            case \"equals\" -\u003e \"\u003d\u003d\";\n            case \"greater_than\" -\u003e \"\u003e\";\n            case \"greater_than_or_equal\" -\u003e \"\u003e\u003d\";\n            case \"less_than\" -\u003e \"\u003c\";\n            case \"less_than_or_equal\" -\u003e \"\u003c\u003d\";\n            case \"mod\" -\u003e \"%\";\n            case \"mul\" -\u003e \"*\";\n            case \"not_equals\" -\u003e \"!\u003d\";\n            case \"sub\" -\u003e \"-\";\n            default -\u003e null;\n        };\n    }\n\n    /**\n     * If this tests is for a unary operator return its symbol, otherwise return {@code null}.\n     * This is functionally the reverse of {@link ExpressionBuilder#visitArithmeticUnary}.\n     */\n    private static String unaryOperator(String name) {\n        return switch (name) {\n            case \"neg\" -\u003e \"-\";\n            default -\u003e null;\n        };\n    }\n\n    /**\n     * If this tests is for a like or rlike operator return true, otherwise return {@code null}.\n     */\n    private static boolean likeOrInOperator(String name) {\n        return name.equalsIgnoreCase(\"rlike\") || name.equalsIgnoreCase(\"like\") || name.equalsIgnoreCase(\"in\");\n    }\n\n    /**\n     * Write some text to a tempdir so we can copy it to the docs later.\n     * \u003cp\u003e\n     * We need to write to a tempdir instead of the docs because the tests\n     * don\u0027t have write permission to the docs.\n     * \u003c/p\u003e\n     */\n    private static void writeToTempDir(String subdir, String str, String extension) throws IOException {\n        // We have to write to a tempdir because it\u0027s all test are allowed to write to. Gradle can move them.\n        Path dir \u003d PathUtils.get(System.getProperty(\"java.io.tmpdir\")).resolve(\"esql\").resolve(\"functions\").resolve(subdir);\n        Files.createDirectories(dir);\n        Path file \u003d dir.resolve(functionName() + \".\" + extension);\n        Files.writeString(file, str);\n        LogManager.getLogger(getTestClass()).info(\"Wrote to file: {}\", file);\n    }\n\n    private final List\u003cCircuitBreaker\u003e breakers \u003d Collections.synchronizedList(new ArrayList\u003c\u003e());\n\n    protected final DriverContext driverContext() {\n        BigArrays bigArrays \u003d new MockBigArrays(PageCacheRecycler.NON_RECYCLING_INSTANCE, ByteSizeValue.ofMb(256)).withCircuitBreaking();\n        CircuitBreaker breaker \u003d bigArrays.breakerService().getBreaker(CircuitBreaker.REQUEST);\n        breakers.add(breaker);\n        return new DriverContext(bigArrays, new BlockFactory(breaker, bigArrays));\n    }\n\n    protected final DriverContext crankyContext() {\n        BigArrays bigArrays \u003d new MockBigArrays(PageCacheRecycler.NON_RECYCLING_INSTANCE, new CrankyCircuitBreakerService())\n            .withCircuitBreaking();\n        CircuitBreaker breaker \u003d bigArrays.breakerService().getBreaker(CircuitBreaker.REQUEST);\n        breakers.add(breaker);\n        return new DriverContext(bigArrays, new BlockFactory(breaker, bigArrays));\n    }\n\n    @After\n    public void allMemoryReleased() {\n        for (CircuitBreaker breaker : breakers) {\n            assertThat(breaker.getUsed(), equalTo(0L));\n        }\n    }\n\n    static Version randomVersion() {\n        // TODO degenerate versions and stuff\n        return switch (between(0, 2)) {\n            case 0 -\u003e new Version(Integer.toString(between(0, 100)));\n            case 1 -\u003e new Version(between(0, 100) + \".\" + between(0, 100));\n            case 2 -\u003e new Version(between(0, 100) + \".\" + between(0, 100) + \".\" + between(0, 100));\n            default -\u003e throw new IllegalArgumentException();\n        };\n    }\n\n    /**\n     * All string types (keyword, text, match_only_text, etc).\n     */\n    protected static DataType[] strings() {\n        return DataType.types().stream().filter(DataType::isString).toArray(DataType[]::new);\n    }\n\n    /**\n     * Validate that we know the types for all the test cases already created\n     * @param suppliers - list of suppliers before adding in the illegal type combinations\n     */\n    protected static void typesRequired(List\u003cTestCaseSupplier\u003e suppliers) {\n        String bad \u003d suppliers.stream().filter(s -\u003e s.types() \u003d\u003d null).map(s -\u003e s.name()).collect(Collectors.joining(\"\\n\"));\n        if (bad.equals(\"\") \u003d\u003d false) {\n            throw new IllegalArgumentException(\"types required but not found for these tests:\\n\" + bad);\n        }\n    }\n\n    /**\n     * Returns true if the current test case is for an aggregation function.\n     * \u003cp\u003e\n     *     This method requires reflection, as it\u0027s called from a static context (@AfterClass documentation rendering).\n     * \u003c/p\u003e\n     */\n    private static boolean isAggregation() {\n        return AbstractAggregationTestCase.class.isAssignableFrom(getTestClass());\n    }\n}","methodCount":65},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":1216,"lineEnd":1236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method binaryOperator to class CsvTestUtils","description":"move method binaryOperator to PsiClass:CsvTestUtils\nRationale: The binaryOperator() method provides a mapping of operator names to their symbols, which could be useful in CSV processing contexts where operators are represented as strings. Moving it to CsvTestUtils would enhance its utility in parsing and handling CSV data. This aligns with the Single Responsibility Principle, as the utility class can handle operator conversions related to CSV operations. However, it may introduce coupling if CsvTestUtils becomes overloaded with unrelated functionality.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1216,"lineEnd":1236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method binaryOperator to class AutomataMatch","description":"move method binaryOperator to PsiClass:AutomataMatch\nRationale: The binaryOperator() method could be relevant in the context of evaluating expressions in automata, where binary operations are common. Placing it in AutomataMatch would support the functionality of evaluating expressions and improve cohesion within the class. This move aligns with the Open/Closed Principle, allowing AutomataMatch to be extended with more expression handling without modifying existing code. However, care must be taken to ensure it doesn\u0027t dilute the classs primary focus on automata matching.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1216,"lineEnd":1236,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method binaryOperator to class SpatialRelatesUtils","description":"move method binaryOperator to PsiClass:SpatialRelatesUtils\nRationale: SpatialRelatesUtils deals with geometric and spatial operations, which may involve binary operations for comparisons. Relocating binaryOperator() here would enhance the utility of this class in handling operator symbols relevant to spatial queries. This adheres to the Interface Segregation Principle by keeping operator-related methods together. However, it may not be a perfect fit if spatial operations don\u0027t frequently use binary operators.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":181,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomLiteral to class TestUtils","description":"move method randomLiteral to PsiClass:TestUtils\nRationale: The randomLiteral() method generates random values based on a data type, which aligns closely with utility functions often found in testing frameworks. Moving it to TestUtils would centralize random data generation, improving code reuse and organization. This aligns with the Single Responsibility Principle, as TestUtils can focus on all testing-related utilities. A potential drawback is that it may increase the size of TestUtils if it becomes a catch-all for unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":181,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomLiteral to class TestCaseSupplier","description":"move method randomLiteral to PsiClass:TestCaseSupplier\nRationale: TestCaseSupplier is already involved in generating test cases and could benefit from having the randomLiteral() method for generating random values. This move would enhance cohesion within TestCaseSupplier, as it would centralize the logic for creating test cases and their associated random values. Adhering to the Single Responsibility Principle ensures that TestCaseSupplier manages test case generation effectively. However, it may introduce tight coupling between test case generation and random value generation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":143,"lineEnd":181,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method randomLiteral to class CsvTestUtils","description":"move method randomLiteral to PsiClass:CsvTestUtils\nRationale: CsvTestUtils deals with various types of data transformations and parsing, making it a suitable candidate for randomLiteral() since it could be helpful for generating random CSV data. This move would enhance the utility of CsvTestUtils in handling data types and improve its cohesion. However, it could lead to a dilution of focus on CSV-specific functions if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":200,"lineEnd":221,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method anyNullIsNull to class CoalesceTests","description":"move method anyNullIsNull to PsiClass:CoalesceTests\nRationale: The anyNullIsNull() method deals with test cases, specifically around null handling, which aligns directly with the purpose of CoalesceTests. Moving it here enhances cohesion by placing test-related logic within the test class, adhering to the Single Responsibility Principle. This makes the method more contextually relevant and reusable for other test scenarios. However, existing tests may need to be refactored to accommodate this change.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":200,"lineEnd":221,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method anyNullIsNull to class CsvTestUtils","description":"move method anyNullIsNull to PsiClass:CsvTestUtils\nRationale: CsvTestUtils is focused on CSV-related testing utilities, and since the method involves test case manipulation, it fits well here. This move would improve the organization of test utilities and promote the reusability of test case handling across different CSV-related tests. However, it may introduce dependencies if CSV tests do not require null handling logic, which could dilute focus.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":200,"lineEnd":221,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method anyNullIsNull to class InternalEqlScriptUtils","description":"move method anyNullIsNull to PsiClass:InternalEqlScriptUtils\nRationale: InternalEqlScriptUtils appears to handle various utility functions, including string operations and null checks. The anyNullIsNull() method\u0027s focus on null handling makes it relevant for inclusion here, promoting better organization and reusability of utility methods. This move aligns with the Open/Closed Principle as it allows for extension without modifying existing classes. However, it may lead to a bloated utility class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"randomLiteral","method_signature":"public static randomLiteral(DataType type)","target_class":"","rationale":""},{"method_name":"parameterSuppliersFromTypedData","method_signature":"protected static parameterSuppliersFromTypedData(List\u003cTestCaseSupplier\u003e suppliers)","target_class":"","rationale":""},{"method_name":"anyNullIsNull","method_signature":"protected static anyNullIsNull(boolean entirelyNullPreservesType, List\u003cTestCaseSupplier\u003e testCaseSuppliers)","target_class":"","rationale":""},{"method_name":"anyNullIsNull","method_signature":"protected static anyNullIsNull(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        ExpectedType expectedType,\n        ExpectedEvaluatorToString evaluatorToString\n    )","target_class":"","rationale":""},{"method_name":"errorsForCasesWithoutExamples","method_signature":"protected static errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        PositionalErrorMessageSupplier positionalErrorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"typeErrorMessage","method_signature":"protected static typeErrorMessage(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier expectedTypeSupplier\n    )","target_class":"","rationale":""},{"method_name":"errorsForCasesWithoutExamples","method_signature":"protected static errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        TypeErrorMessageSupplier typeErrorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"append","method_signature":"private static append(List\u003cDataType\u003e orig, DataType extra)","target_class":"","rationale":""},{"method_name":"representable","method_signature":"protected static representable()","target_class":"","rationale":""},{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        TypeErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"validPerPosition","method_signature":"private static validPerPosition(Set\u003cList\u003cDataType\u003e\u003e valid)","target_class":"","rationale":""},{"method_name":"allPermutations","method_signature":"protected static allPermutations(int argumentCount)","target_class":"","rationale":""},{"method_name":"validFunctionParameters","method_signature":"public static validFunctionParameters()","target_class":"","rationale":""},{"method_name":"field","method_signature":"public static field(String name, DataType type)","target_class":"","rationale":""},{"method_name":"deepCopyOfField","method_signature":"public static deepCopyOfField(String name, DataType type)","target_class":"","rationale":""},{"method_name":"buildFieldExpression","method_signature":"protected final buildFieldExpression(TestCaseSupplier.TestCase testCase)","target_class":"","rationale":""},{"method_name":"buildDeepCopyOfFieldExpression","method_signature":"protected final buildDeepCopyOfFieldExpression(TestCaseSupplier.TestCase testCase)","target_class":"","rationale":""},{"method_name":"buildLiteralExpression","method_signature":"protected final buildLiteralExpression(TestCaseSupplier.TestCase testCase)","target_class":"","rationale":""},{"method_name":"evaluator","method_signature":"public static evaluator(Expression e)","target_class":"","rationale":""},{"method_name":"row","method_signature":"protected final row(List\u003cObject\u003e values)","target_class":"","rationale":""},{"method_name":"rows","method_signature":"protected final rows(List\u003cTestCaseSupplier.TypedData\u003e multirowFields)","target_class":"","rationale":""},{"method_name":"buildLayout","method_signature":"protected static buildLayout(Layout.Builder builder, Expression e)","target_class":"","rationale":""},{"method_name":"toJavaObjectUnsignedLongAware","method_signature":"protected toJavaObjectUnsignedLongAware(Block block, int position)","target_class":"","rationale":""},{"method_name":"randomizeBytesRefsOffset","method_signature":"protected static randomizeBytesRefsOffset(List\u003cTestCaseSupplier\u003e testCaseSuppliers)","target_class":"","rationale":""},{"method_name":"tryRandomizeBytesRefOffset","method_signature":"private static tryRandomizeBytesRefOffset(Object value)","target_class":"","rationale":""},{"method_name":"randomizeBytesRefOffset","method_signature":"private static randomizeBytesRefOffset(BytesRef bytesRef)","target_class":"","rationale":""},{"method_name":"testSerializationOfSimple","method_signature":"public testSerializationOfSimple()","target_class":"","rationale":""},{"method_name":"testFunctionInfo","method_signature":"@AfterClass\n    public static testFunctionInfo()","target_class":"","rationale":""},{"method_name":"assertTypeResolutionFailure","method_signature":"protected final assertTypeResolutionFailure(Expression expression)","target_class":"","rationale":""},{"method_name":"renderSignature","method_signature":"@AfterClass\n    public static renderSignature()","target_class":"","rationale":""},{"method_name":"buildSignatureSvg","method_signature":"private static buildSignatureSvg(String name)","target_class":"","rationale":""},{"method_name":"signatures","method_signature":"private static signatures()","target_class":"","rationale":""},{"method_name":"renderDocs","method_signature":"@AfterClass\n    public static renderDocs()","target_class":"","rationale":""},{"method_name":"renderTypes","method_signature":"private static renderTypes(List\u003cString\u003e argNames)","target_class":"","rationale":""},{"method_name":"renderParametersList","method_signature":"private static renderParametersList(List\u003cString\u003e argNames, List\u003cString\u003e argDescriptions)","target_class":"","rationale":""},{"method_name":"renderDescription","method_signature":"private static renderDescription(String description, String detailedDescription, String note)","target_class":"","rationale":""},{"method_name":"renderExamples","method_signature":"private static renderExamples(FunctionInfo info)","target_class":"","rationale":""},{"method_name":"renderAppendix","method_signature":"private static renderAppendix(String appendix)","target_class":"","rationale":""},{"method_name":"renderFullLayout","method_signature":"private static renderFullLayout(String name, boolean preview, boolean hasExamples, boolean hasAppendix)","target_class":"","rationale":""},{"method_name":"constructorWithFunctionInfo","method_signature":"private static constructorWithFunctionInfo(Class\u003c?\u003e clazz)","target_class":"","rationale":""},{"method_name":"renderDocsForOperators","method_signature":"private static renderDocsForOperators(String name)","target_class":"","rationale":""},{"method_name":"renderKibanaInlineDocs","method_signature":"private static renderKibanaInlineDocs(String name, FunctionInfo info)","target_class":"","rationale":""},{"method_name":"renderKibanaFunctionDefinition","method_signature":"private static renderKibanaFunctionDefinition(\n        String name,\n        FunctionInfo info,\n        List\u003cEsqlFunctionRegistry.ArgSignature\u003e args,\n        boolean variadic\n    )","target_class":"","rationale":""},{"method_name":"removeAsciidocLinks","method_signature":"private static removeAsciidocLinks(String asciidoc)","target_class":"","rationale":""},{"method_name":"functionName","method_signature":"protected static functionName()","target_class":"","rationale":""},{"method_name":"definition","method_signature":"private static definition(String name)","target_class":"","rationale":""},{"method_name":"binaryOperator","method_signature":"private static binaryOperator(String name)","target_class":"","rationale":""},{"method_name":"unaryOperator","method_signature":"private static unaryOperator(String name)","target_class":"","rationale":""},{"method_name":"likeOrInOperator","method_signature":"private static likeOrInOperator(String name)","target_class":"","rationale":""},{"method_name":"writeToTempDir","method_signature":"private static writeToTempDir(String subdir, String str, String extension)","target_class":"","rationale":""},{"method_name":"driverContext","method_signature":"protected final driverContext()","target_class":"","rationale":""},{"method_name":"crankyContext","method_signature":"protected final crankyContext()","target_class":"","rationale":""},{"method_name":"allMemoryReleased","method_signature":"@After\n    public allMemoryReleased()","target_class":"","rationale":""},{"method_name":"randomVersion","method_signature":"static randomVersion()","target_class":"","rationale":""},{"method_name":"strings","method_signature":"protected static strings()","target_class":"","rationale":""},{"method_name":"typesRequired","method_signature":"protected static typesRequired(List\u003cTestCaseSupplier\u003e suppliers)","target_class":"","rationale":""},{"method_name":"isAggregation","method_signature":"private static isAggregation()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"binaryOperator","method_signature":"private static binaryOperator(String name)","target_class":"","rationale":""},{"method_name":"randomLiteral","method_signature":"public static randomLiteral(DataType type)","target_class":"","rationale":""},{"method_name":"anyNullIsNull","method_signature":"protected static anyNullIsNull(boolean entirelyNullPreservesType, List\u003cTestCaseSupplier\u003e testCaseSuppliers)","target_class":"","rationale":""},{"method_name":"writeToTempDir","method_signature":"private static writeToTempDir(String subdir, String str, String extension)","target_class":"","rationale":""},{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"assertTypeResolutionFailure","method_signature":"protected final assertTypeResolutionFailure(Expression expression)","target_class":"","rationale":""},{"method_name":"randomVersion","method_signature":"static randomVersion()","target_class":"","rationale":""},{"method_name":"errorsForCasesWithoutExamples","method_signature":"protected static errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        PositionalErrorMessageSupplier positionalErrorMessageSupplier\n    )","target_class":"","rationale":""},{"method_name":"buildLiteralExpression","method_signature":"protected final buildLiteralExpression(TestCaseSupplier.TestCase testCase)","target_class":"","rationale":""},{"method_name":"deepCopyOfField","method_signature":"public static deepCopyOfField(String name, DataType type)","target_class":"","rationale":""},{"method_name":"likeOrInOperator","method_signature":"private static likeOrInOperator(String name)","target_class":"","rationale":""},{"method_name":"randomizeBytesRefOffset","method_signature":"private static randomizeBytesRefOffset(BytesRef bytesRef)","target_class":"","rationale":""},{"method_name":"field","method_signature":"public static field(String name, DataType type)","target_class":"","rationale":""},{"method_name":"crankyContext","method_signature":"protected final crankyContext()","target_class":"","rationale":""},{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        TypeErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static binaryOperator(String name)":{"first":{"method_name":"binaryOperator","method_signature":"private static binaryOperator(String name)","target_class":"","rationale":""},"second":0.25130202981576294},"public static randomLiteral(DataType type)":{"first":{"method_name":"randomLiteral","method_signature":"public static randomLiteral(DataType type)","target_class":"","rationale":""},"second":0.2938900669509603},"protected static anyNullIsNull(boolean entirelyNullPreservesType, List\u003cTestCaseSupplier\u003e testCaseSuppliers)":{"first":{"method_name":"anyNullIsNull","method_signature":"protected static anyNullIsNull(boolean entirelyNullPreservesType, List\u003cTestCaseSupplier\u003e testCaseSuppliers)","target_class":"","rationale":""},"second":0.29422228217196045},"private static writeToTempDir(String subdir, String str, String extension)":{"first":{"method_name":"writeToTempDir","method_signature":"private static writeToTempDir(String subdir, String str, String extension)","target_class":"","rationale":""},"second":0.31209856240539247},"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier errorMessageSupplier\n    )":{"first":{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        PositionalErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""},"second":0.33703833935392324},"protected final assertTypeResolutionFailure(Expression expression)":{"first":{"method_name":"assertTypeResolutionFailure","method_signature":"protected final assertTypeResolutionFailure(Expression expression)","target_class":"","rationale":""},"second":0.34265756884295623},"static randomVersion()":{"first":{"method_name":"randomVersion","method_signature":"static randomVersion()","target_class":"","rationale":""},"second":0.3536508006411722},"protected static errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        PositionalErrorMessageSupplier positionalErrorMessageSupplier\n    )":{"first":{"method_name":"errorsForCasesWithoutExamples","method_signature":"protected static errorsForCasesWithoutExamples(\n        List\u003cTestCaseSupplier\u003e testCaseSuppliers,\n        PositionalErrorMessageSupplier positionalErrorMessageSupplier\n    )","target_class":"","rationale":""},"second":0.35413695964192354},"protected final buildLiteralExpression(TestCaseSupplier.TestCase testCase)":{"first":{"method_name":"buildLiteralExpression","method_signature":"protected final buildLiteralExpression(TestCaseSupplier.TestCase testCase)","target_class":"","rationale":""},"second":0.3583882953152225},"public static deepCopyOfField(String name, DataType type)":{"first":{"method_name":"deepCopyOfField","method_signature":"public static deepCopyOfField(String name, DataType type)","target_class":"","rationale":""},"second":0.3613011398407945},"private static likeOrInOperator(String name)":{"first":{"method_name":"likeOrInOperator","method_signature":"private static likeOrInOperator(String name)","target_class":"","rationale":""},"second":0.3655091344938906},"private static randomizeBytesRefOffset(BytesRef bytesRef)":{"first":{"method_name":"randomizeBytesRefOffset","method_signature":"private static randomizeBytesRefOffset(BytesRef bytesRef)","target_class":"","rationale":""},"second":0.3712805755075162},"public static field(String name, DataType type)":{"first":{"method_name":"field","method_signature":"public static field(String name, DataType type)","target_class":"","rationale":""},"second":0.40800225926365813},"protected final crankyContext()":{"first":{"method_name":"crankyContext","method_signature":"protected final crankyContext()","target_class":"","rationale":""},"second":0.41080031011100543},"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        TypeErrorMessageSupplier errorMessageSupplier\n    )":{"first":{"method_name":"typeErrorSupplier","method_signature":"protected static typeErrorSupplier(\n        boolean includeOrdinal,\n        List\u003cSet\u003cDataType\u003e\u003e validPerPosition,\n        List\u003cDataType\u003e types,\n        TypeErrorMessageSupplier errorMessageSupplier\n    )","target_class":"","rationale":""},"second":0.41165245249488}},"llmMethodPriority":{"priority_method_names":["randomLiteral","deepCopyOfField","anyNullIsNull","buildLiteralExpression","writeToTempDir","assertTypeResolutionFailure","crankyContext","randomizeBytesRefOffset","likeOrInOperator","binaryOperator","typeErrorSupplier","randomVersion","errorsForCasesWithoutExamples","field","typeErrorSupplier"],"llm_response_time":4917},"targetClassMap":{"binaryOperator":{"target_classes":[{"class_name":"LuceneComponent2DUtils","similarity_score":0.16975800208976974},{"class_name":"SpatialRelatesUtils","similarity_score":0.2852259189982956},{"class_name":"DateTimeTestUtils","similarity_score":0.08867378953834776},{"class_name":"FunctionTestUtils","similarity_score":0.140846046797513},{"class_name":"InternalEqlScriptUtils","similarity_score":0.18191129807492107},{"class_name":"InternalQlScriptUtils","similarity_score":0.14459107720823255},{"class_name":"InternalSqlScriptUtils","similarity_score":0.19244412709900074},{"class_name":"StringUtils","similarity_score":0.234842972974709},{"class_name":"Abs","similarity_score":0.14505896476179397},{"class_name":"AbsTests","similarity_score":0.26952802541690446},{"class_name":"Bucket","similarity_score":0.20832863441823865},{"class_name":"AutomataMatch","similarity_score":0.3044434458115934},{"class_name":"BucketTests","similarity_score":0.2562943780143807},{"class_name":"CsvTestUtils","similarity_score":0.29354151090727415},{"class_name":"AvgTests","similarity_score":0.4897203545146506},{"class_name":"CIDRMatch","similarity_score":0.22337726475629505},{"class_name":"CIDRMatchTests","similarity_score":0.265689889933368},{"class_name":"Right","similarity_score":0.1774111415108186},{"class_name":"RightTests","similarity_score":0.21426680925848707},{"class_name":"RLikeTests","similarity_score":0.26660968415003344},{"class_name":"Round","similarity_score":0.17895883203573495},{"class_name":"RoundTests","similarity_score":0.3564652746308155},{"class_name":"Least","similarity_score":0.16339878431230023},{"class_name":"LeastTests","similarity_score":0.20563009864012738},{"class_name":"Left","similarity_score":0.18102489906910946},{"class_name":"LeftTests","similarity_score":0.21808142172376646},{"class_name":"Acos","similarity_score":0.1513986089482818},{"class_name":"AcosTests","similarity_score":0.19658736424863457},{"class_name":"Length","similarity_score":0.15225855793611226},{"class_name":"LengthTests","similarity_score":0.3561001109259143}],"target_classes_sorted_by_llm":["CsvTestUtils","AutomataMatch","SpatialRelatesUtils","BucketTests","LengthTests","AbsTests","RLikeTests","AvgTests","RoundTests","CIDRMatchTests"],"llm_response_time":13739,"similarity_computation_time":29,"similarity_metric":"voyage"},"randomLiteral":{"target_classes":[{"class_name":"LuceneComponent2DUtils","similarity_score":0.2029986060095209},{"class_name":"SpatialRelatesUtils","similarity_score":0.21809256113230763},{"class_name":"FunctionTestUtils","similarity_score":0.19205422691447321},{"class_name":"DateTimeTestUtils","similarity_score":0.0859702559601774},{"class_name":"InternalEqlScriptUtils","similarity_score":0.15689926209662416},{"class_name":"InternalQlScriptUtils","similarity_score":0.1512667343008584},{"class_name":"InternalSqlScriptUtils","similarity_score":0.17151520783274035},{"class_name":"StringUtils","similarity_score":0.1624873957128795},{"class_name":"Tan","similarity_score":0.16652530970585316},{"class_name":"Tanh","similarity_score":0.16652530970585316},{"class_name":"TanhTests","similarity_score":0.22155501484002435},{"class_name":"TanTests","similarity_score":0.22155501484002435},{"class_name":"TauTests","similarity_score":0.23339149475346585},{"class_name":"Abs","similarity_score":0.17447436053759954},{"class_name":"AbsTests","similarity_score":0.3305714012742683},{"class_name":"CsvTestUtils","similarity_score":0.33555247822616896},{"class_name":"Right","similarity_score":0.19761947589742107},{"class_name":"RightTests","similarity_score":0.28848979061493846},{"class_name":"RLikeTests","similarity_score":0.37097789158858213},{"class_name":"TestCase","similarity_score":0.2235001711161748},{"class_name":"TestCaseSupplier","similarity_score":0.3580949076393573},{"class_name":"CIDRMatch","similarity_score":0.19523861525802413},{"class_name":"CIDRMatchTests","similarity_score":0.3893576240670776},{"class_name":"Round","similarity_score":0.17509898415878206},{"class_name":"RoundTests","similarity_score":0.4032894948303702},{"class_name":"RTrim","similarity_score":0.17956457352388902},{"class_name":"RTrimTests","similarity_score":0.1655920799202216},{"class_name":"TestUtils","similarity_score":0.2327604119032574},{"class_name":"Acos","similarity_score":0.1824878445933137},{"class_name":"AcosTests","similarity_score":0.21898000069235518}],"target_classes_sorted_by_llm":["TestUtils","TestCaseSupplier","CsvTestUtils","RLikeTests","TestCase","RoundTests","AbsTests","CIDRMatchTests","RightTests","TauTests"],"llm_response_time":15470,"similarity_computation_time":8,"similarity_metric":"voyage"},"anyNullIsNull":{"target_classes":[{"class_name":"LuceneComponent2DUtils","similarity_score":0.2583650722906063},{"class_name":"SpatialRelatesUtils","similarity_score":0.3878783525318771},{"class_name":"FunctionTestUtils","similarity_score":0.08636467417347721},{"class_name":"DateTimeTestUtils","similarity_score":0.05372900609150623},{"class_name":"InternalEqlScriptUtils","similarity_score":0.16713199268751794},{"class_name":"InternalQlScriptUtils","similarity_score":0.12716872990355016},{"class_name":"InternalSqlScriptUtils","similarity_score":0.1326347733275084},{"class_name":"StringUtils","similarity_score":0.3984736790816745},{"class_name":"Now","similarity_score":0.08637618869578334},{"class_name":"NowTests","similarity_score":0.09136304946339742},{"class_name":"Abs","similarity_score":0.11031441038692723},{"class_name":"AbsTests","similarity_score":0.10401493891369994},{"class_name":"CsvTestUtils","similarity_score":0.24748715120523251},{"class_name":"Right","similarity_score":0.14108374703773852},{"class_name":"RightTests","similarity_score":0.07833994826664603},{"class_name":"NumericUtilsTests","similarity_score":0.1385876812186725},{"class_name":"RLikeTests","similarity_score":0.12955467928685777},{"class_name":"CIDRMatch","similarity_score":0.2808052877602911},{"class_name":"CIDRMatchTests","similarity_score":0.06634536403474875},{"class_name":"Round","similarity_score":0.16771638729540575},{"class_name":"RoundTests","similarity_score":0.15193247450767408},{"class_name":"RTrim","similarity_score":0.1259407395922931},{"class_name":"RTrimTests","similarity_score":0.07930515857181443},{"class_name":"Acos","similarity_score":0.13260212899621707},{"class_name":"AcosTests","similarity_score":0.10648707756515279},{"class_name":"CoalesceTests","similarity_score":0.15529148547331417},{"class_name":"DateDiff","similarity_score":0.19597525930615065},{"class_name":"DateDiffTests","similarity_score":0.053964767413952466},{"class_name":"DateExtract","similarity_score":0.16912858905244643},{"class_name":"DateExtractTests","similarity_score":0.09442108504982126}],"target_classes_sorted_by_llm":["CoalesceTests","CsvTestUtils","InternalEqlScriptUtils","DateExtract","DateDiff","Round","LuceneComponent2DUtils","StringUtils","SpatialRelatesUtils","CIDRMatch"],"llm_response_time":14109,"similarity_computation_time":18,"similarity_metric":"voyage"}}}
{"id":"f95171a2-3b68-4c83-9563-3ab272a00330","methodCount":41,"hostFunctionTelemetryData":{"hostFunctionSize":384,"lineStart":62,"lineEnd":445,"bodyLineStart":62,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/io/stream/PlanNamedTypes.java","sourceCode":"/**\n * A utility class that consists solely of static methods that describe how to serialize and\n * deserialize QL and ESQL plan types.\n * \u003cP\u003e\n * All types that require to be serialized should have a pair of co-located `readFoo` and `writeFoo`\n * methods that deserialize and serialize respectively.\n * \u003cP\u003e\n * A type can be named or non-named. A named type has a name written to the stream before its\n * contents (similar to NamedWriteable), whereas a non-named type does not (similar to Writable).\n * Named types allow to determine specific deserialization implementations for more general types,\n * e.g. Literal, which is an Expression. Named types must have an entries in the namedTypeEntries\n * list.\n */\npublic final class PlanNamedTypes {\n\n    private PlanNamedTypes() {}\n\n    /**\n     * Determines the writeable name of the give class. The simple class name is commonly used for\n     * {@link NamedWriteable}s and is sufficient here too, but it could be almost anything else.\n     */\n    public static String name(Class\u003c?\u003e cls) {\n        return cls.getSimpleName();\n    }\n\n    /**\n     * List of named type entries that link concrete names to stream reader and writer implementations.\n     * Entries have the form:  category,  name,  serializer method,  deserializer method.\n     */\n    public static List\u003cPlanNameRegistry.Entry\u003e namedTypeEntries() {\n        List\u003cPlanNameRegistry.Entry\u003e declared \u003d List.of(\n            // Physical Plan Nodes\n            of(PhysicalPlan.class, AggregateExec.ENTRY),\n            of(PhysicalPlan.class, DissectExec.ENTRY),\n            of(PhysicalPlan.class, EsQueryExec.class, PlanNamedTypes::writeEsQueryExec, PlanNamedTypes::readEsQueryExec),\n            of(PhysicalPlan.class, EsSourceExec.ENTRY),\n            of(PhysicalPlan.class, EvalExec.class, PlanNamedTypes::writeEvalExec, PlanNamedTypes::readEvalExec),\n            of(PhysicalPlan.class, EnrichExec.class, PlanNamedTypes::writeEnrichExec, PlanNamedTypes::readEnrichExec),\n            of(PhysicalPlan.class, ExchangeExec.class, PlanNamedTypes::writeExchangeExec, PlanNamedTypes::readExchangeExec),\n            of(PhysicalPlan.class, ExchangeSinkExec.class, PlanNamedTypes::writeExchangeSinkExec, PlanNamedTypes::readExchangeSinkExec),\n            of(\n                PhysicalPlan.class,\n                ExchangeSourceExec.class,\n                PlanNamedTypes::writeExchangeSourceExec,\n                PlanNamedTypes::readExchangeSourceExec\n            ),\n            of(PhysicalPlan.class, FieldExtractExec.class, PlanNamedTypes::writeFieldExtractExec, PlanNamedTypes::readFieldExtractExec),\n            of(PhysicalPlan.class, FilterExec.class, PlanNamedTypes::writeFilterExec, PlanNamedTypes::readFilterExec),\n            of(PhysicalPlan.class, FragmentExec.class, PlanNamedTypes::writeFragmentExec, PlanNamedTypes::readFragmentExec),\n            of(PhysicalPlan.class, GrokExec.class, PlanNamedTypes::writeGrokExec, PlanNamedTypes::readGrokExec),\n            of(PhysicalPlan.class, LimitExec.class, PlanNamedTypes::writeLimitExec, PlanNamedTypes::readLimitExec),\n            of(PhysicalPlan.class, LocalSourceExec.class, (out, v) -\u003e v.writeTo(out), LocalSourceExec::new),\n            of(PhysicalPlan.class, HashJoinExec.class, (out, v) -\u003e v.writeTo(out), HashJoinExec::new),\n            of(PhysicalPlan.class, MvExpandExec.class, PlanNamedTypes::writeMvExpandExec, PlanNamedTypes::readMvExpandExec),\n            of(PhysicalPlan.class, OrderExec.class, PlanNamedTypes::writeOrderExec, PlanNamedTypes::readOrderExec),\n            of(PhysicalPlan.class, ProjectExec.class, PlanNamedTypes::writeProjectExec, PlanNamedTypes::readProjectExec),\n            of(PhysicalPlan.class, RowExec.class, PlanNamedTypes::writeRowExec, PlanNamedTypes::readRowExec),\n            of(PhysicalPlan.class, ShowExec.class, PlanNamedTypes::writeShowExec, PlanNamedTypes::readShowExec),\n            of(PhysicalPlan.class, TopNExec.class, PlanNamedTypes::writeTopNExec, PlanNamedTypes::readTopNExec)\n        );\n        return declared;\n    }\n\n    // -- physical plan nodes\n    static EsQueryExec readEsQueryExec(PlanStreamInput in) throws IOException {\n        return new EsQueryExec(\n            Source.readFrom(in),\n            new EsIndex(in),\n            readIndexMode(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalNamed(Expression.class),\n            in.readOptionalCollectionAsList(readerFromPlanReader(PlanNamedTypes::readFieldSort)),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec) throws IOException {\n        assert esQueryExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        esQueryExec.index().writeTo(out);\n        writeIndexMode(out, esQueryExec.indexMode());\n        out.writeNamedWriteableCollection(esQueryExec.output());\n        out.writeOptionalNamedWriteable(esQueryExec.query());\n        out.writeOptionalNamedWriteable(esQueryExec.limit());\n        out.writeOptionalCollection(esQueryExec.sorts(), writerFromPlanWriter(PlanNamedTypes::writeFieldSort));\n        out.writeOptionalInt(esQueryExec.estimatedRowSize());\n    }\n\n    public static IndexMode readIndexMode(StreamInput in) throws IOException {\n        if (in.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            return IndexMode.fromString(in.readString());\n        } else {\n            return IndexMode.STANDARD;\n        }\n    }\n\n    public static void writeIndexMode(StreamOutput out, IndexMode indexMode) throws IOException {\n        if (out.getTransportVersion().onOrAfter(TransportVersions.ESQL_ADD_INDEX_MODE_TO_SOURCE)) {\n            out.writeString(indexMode.getName());\n        } else if (indexMode !\u003d IndexMode.STANDARD) {\n            throw new IllegalStateException(\"not ready to support index mode [\" + indexMode + \"]\");\n        }\n    }\n\n    static EvalExec readEvalExec(PlanStreamInput in) throws IOException {\n        return new EvalExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeEvalExec(PlanStreamOutput out, EvalExec evalExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(evalExec.child());\n        out.writeCollection(evalExec.fields());\n    }\n\n    static EnrichExec readEnrichExec(PlanStreamInput in) throws IOException {\n        final Source source \u003d Source.readFrom(in);\n        final PhysicalPlan child \u003d in.readPhysicalPlanNode();\n        final NamedExpression matchField \u003d in.readNamedWriteable(NamedExpression.class);\n        final String policyName \u003d in.readString();\n        final String matchType \u003d (in.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) ? in.readString() : \"match\";\n        final String policyMatchField \u003d in.readString();\n        final Map\u003cString, String\u003e concreteIndices;\n        final Enrich.Mode mode;\n        if (in.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            mode \u003d in.readEnum(Enrich.Mode.class);\n            concreteIndices \u003d in.readMap(StreamInput::readString, StreamInput::readString);\n        } else {\n            mode \u003d Enrich.Mode.ANY;\n            EsIndex esIndex \u003d new EsIndex(in);\n            if (esIndex.concreteIndices().size() !\u003d 1) {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + esIndex.concreteIndices());\n            }\n            concreteIndices \u003d Map.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, Iterables.get(esIndex.concreteIndices(), 0));\n        }\n        return new EnrichExec(\n            source,\n            child,\n            mode,\n            matchType,\n            matchField,\n            policyName,\n            policyMatchField,\n            concreteIndices,\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeEnrichExec(PlanStreamOutput out, EnrichExec enrich) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(enrich.child());\n        out.writeNamedWriteable(enrich.matchField());\n        out.writeString(enrich.policyName());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) {\n            out.writeString(enrich.matchType());\n        }\n        out.writeString(enrich.policyMatchField());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_13_0)) {\n            out.writeEnum(enrich.mode());\n            out.writeMap(enrich.concreteIndices(), StreamOutput::writeString, StreamOutput::writeString);\n        } else {\n            if (enrich.concreteIndices().keySet().equals(Set.of(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY))) {\n                String concreteIndex \u003d enrich.concreteIndices().get(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY);\n                new EsIndex(concreteIndex, Map.of(), Set.of(concreteIndex)).writeTo(out);\n            } else {\n                throw new IllegalStateException(\"expected a single concrete enrich index; got \" + enrich.concreteIndices());\n            }\n        }\n        out.writeNamedWriteableCollection(enrich.enrichFields());\n    }\n\n    static ExchangeExec readExchangeExec(PlanStreamInput in) throws IOException {\n        return new ExchangeExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeExec.output());\n        out.writeBoolean(exchangeExec.isInBetweenAggs());\n        out.writePhysicalPlanNode(exchangeExec.child());\n    }\n\n    static ExchangeSinkExec readExchangeSinkExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSinkExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            in.readBoolean(),\n            in.readPhysicalPlanNode()\n        );\n    }\n\n    static void writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(exchangeSinkExec.output());\n        out.writeBoolean(exchangeSinkExec.isIntermediateAgg());\n        out.writePhysicalPlanNode(exchangeSinkExec.child());\n    }\n\n    static ExchangeSourceExec readExchangeSourceExec(PlanStreamInput in) throws IOException {\n        return new ExchangeSourceExec(Source.readFrom(in), in.readNamedWriteableCollectionAsList(Attribute.class), in.readBoolean());\n    }\n\n    static void writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec) throws IOException {\n        out.writeNamedWriteableCollection(exchangeSourceExec.output());\n        out.writeBoolean(exchangeSourceExec.isIntermediateAgg());\n    }\n\n    static FieldExtractExec readFieldExtractExec(PlanStreamInput in) throws IOException {\n        return new FieldExtractExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteableCollectionAsList(Attribute.class));\n    }\n\n    static void writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(fieldExtractExec.child());\n        out.writeNamedWriteableCollection(fieldExtractExec.attributesToExtract());\n    }\n\n    static FilterExec readFilterExec(PlanStreamInput in) throws IOException {\n        return new FilterExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteable(Expression.class));\n    }\n\n    static void writeFilterExec(PlanStreamOutput out, FilterExec filterExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(filterExec.child());\n        out.writeNamedWriteable(filterExec.condition());\n    }\n\n    static FragmentExec readFragmentExec(PlanStreamInput in) throws IOException {\n        return new FragmentExec(\n            Source.readFrom(in),\n            in.readNamedWriteable(LogicalPlan.class),\n            in.readOptionalNamedWriteable(QueryBuilder.class),\n            in.readOptionalVInt(),\n            in.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0) ? in.readOptionalPhysicalPlanNode() : null\n        );\n    }\n\n    static void writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteable(fragmentExec.fragment());\n        out.writeOptionalNamedWriteable(fragmentExec.esFilter());\n        out.writeOptionalVInt(fragmentExec.estimatedRowSize());\n        if (out.getTransportVersion().onOrAfter(TransportVersions.V_8_14_0)) {\n            out.writeOptionalPhysicalPlanNode(fragmentExec.reducer());\n        }\n    }\n\n    static GrokExec readGrokExec(PlanStreamInput in) throws IOException {\n        Source source;\n        return new GrokExec(\n            source \u003d Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(Expression.class),\n            Grok.pattern(source, in.readString()),\n            in.readNamedWriteableCollectionAsList(Attribute.class)\n        );\n    }\n\n    static void writeGrokExec(PlanStreamOutput out, GrokExec grokExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(grokExec.child());\n        out.writeNamedWriteable(grokExec.inputExpression());\n        out.writeString(grokExec.pattern().pattern());\n        out.writeNamedWriteableCollection(grokExec.extractedFields());\n    }\n\n    static LimitExec readLimitExec(PlanStreamInput in) throws IOException {\n        return new LimitExec(Source.readFrom(in), in.readPhysicalPlanNode(), in.readNamedWriteable(Expression.class));\n    }\n\n    static void writeLimitExec(PlanStreamOutput out, LimitExec limitExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(limitExec.child());\n        out.writeNamedWriteable(limitExec.limit());\n    }\n\n    static MvExpandExec readMvExpandExec(PlanStreamInput in) throws IOException {\n        return new MvExpandExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteable(NamedExpression.class),\n            in.readNamedWriteable(Attribute.class)\n        );\n    }\n\n    static void writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(mvExpandExec.child());\n        out.writeNamedWriteable(mvExpandExec.target());\n        out.writeNamedWriteable(mvExpandExec.expanded());\n    }\n\n    static OrderExec readOrderExec(PlanStreamInput in) throws IOException {\n        return new OrderExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new)\n        );\n    }\n\n    static void writeOrderExec(PlanStreamOutput out, OrderExec orderExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(orderExec.child());\n        out.writeCollection(orderExec.order());\n    }\n\n    static ProjectExec readProjectExec(PlanStreamInput in) throws IOException {\n        return new ProjectExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readNamedWriteableCollectionAsList(NamedExpression.class)\n        );\n    }\n\n    static void writeProjectExec(PlanStreamOutput out, ProjectExec projectExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(projectExec.child());\n        out.writeNamedWriteableCollection(projectExec.projections());\n    }\n\n    static RowExec readRowExec(PlanStreamInput in) throws IOException {\n        return new RowExec(Source.readFrom(in), in.readCollectionAsList(Alias::new));\n    }\n\n    static void writeRowExec(PlanStreamOutput out, RowExec rowExec) throws IOException {\n        assert rowExec.children().size() \u003d\u003d 0;\n        Source.EMPTY.writeTo(out);\n        out.writeCollection(rowExec.fields());\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    static ShowExec readShowExec(PlanStreamInput in) throws IOException {\n        return new ShowExec(\n            Source.readFrom(in),\n            in.readNamedWriteableCollectionAsList(Attribute.class),\n            (List\u003cList\u003cObject\u003e\u003e) in.readGenericValue()\n        );\n    }\n\n    static void writeShowExec(PlanStreamOutput out, ShowExec showExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writeNamedWriteableCollection(showExec.output());\n        out.writeGenericValue(showExec.values());\n    }\n\n    static TopNExec readTopNExec(PlanStreamInput in) throws IOException {\n        return new TopNExec(\n            Source.readFrom(in),\n            in.readPhysicalPlanNode(),\n            in.readCollectionAsList(org.elasticsearch.xpack.esql.expression.Order::new),\n            in.readNamedWriteable(Expression.class),\n            in.readOptionalVInt()\n        );\n    }\n\n    static void writeTopNExec(PlanStreamOutput out, TopNExec topNExec) throws IOException {\n        Source.EMPTY.writeTo(out);\n        out.writePhysicalPlanNode(topNExec.child());\n        out.writeCollection(topNExec.order());\n        out.writeNamedWriteable(topNExec.limit());\n        out.writeOptionalVInt(topNExec.estimatedRowSize());\n    }\n\n    // -- ancillary supporting classes of plan nodes, etc\n\n    static EsQueryExec.FieldSort readFieldSort(PlanStreamInput in) throws IOException {\n        return new EsQueryExec.FieldSort(\n            FieldAttribute.readFrom(in),\n            in.readEnum(Order.OrderDirection.class),\n            in.readEnum(Order.NullsPosition.class)\n        );\n    }\n\n    static void writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort) throws IOException {\n        fieldSort.field().writeTo(out);\n        out.writeEnum(fieldSort.direction());\n        out.writeEnum(fieldSort.nulls());\n    }\n}","methodCount":41},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":86,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanNameRegistry","description":"move method namedTypeEntries to PsiClass:PlanNameRegistry\nRationale: The namedTypeEntries() method is responsible for creating a registry of named types associated with various physical plan nodes, which directly relates to the functionality of the PlanNameRegistry class. Moving this method here would enhance cohesion, as it centralizes the logic related to managing entries in the registry. This aligns with the Single Responsibility Principle, ensuring that the PlanNameRegistry focuses solely on registration tasks. However, care must be taken to ensure that this method does not introduce circular dependencies.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":86,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlanStreamOutput","description":"move method namedTypeEntries to PsiClass:PlanStreamOutput\nRationale: PlanStreamOutput deals with the output of physical plans, and the namedTypeEntries() method is closely related to how these plans are serialized and deserialized. Relocating the method here would improve the encapsulation of serialization logic within the output handling class. This supports the Open/Closed Principle by allowing for future extensions of serialization methods without modifying the existing registry. One consideration is that it may complicate the output class if it becomes too overloaded with responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":86,"lineEnd":122,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method namedTypeEntries to class PlannerUtils","description":"move method namedTypeEntries to PsiClass:PlannerUtils\nRationale: The PlannerUtils class contains various utility methods for planning, making it a suitable candidate for the namedTypeEntries() method due to its utility nature. Moving it here adheres to the Single Responsibility Principle, as it would help isolate utility functions from the core logic of the physical plans. However, it may dilute the purpose of PlannerUtils if it becomes too focused on specific registry functionalities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":138,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsQueryExec to class PlanStreamOutput","description":"move method writeEsQueryExec to PsiClass:PlanStreamOutput\nRationale: The writeEsQueryExec method directly interacts with PlanStreamOutput for writing data. Moving it to this class enhances cohesion, as it centralizes all output-related functionalities. This aligns with the Single Responsibility Principle, ensuring that PlanStreamOutput handles all output operations. However, care must be taken to manage dependencies and ensure that the method\u0027s functionality does not bloat the class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":138,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsQueryExec to class SerializationTestUtils","description":"move method writeEsQueryExec to PsiClass:SerializationTestUtils\nRationale: This class seems to focus on serialization-related tasks, making it a suitable candidate for the writeEsQueryExec method, which involves writing serialized data. Moving the method here would enhance the reusability of serialization utilities. This aligns with the Interface Segregation Principle, as it allows for more specialized classes. However, it may lead to a less clear separation of concerns if SerializationTestUtils becomes too overloaded.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":138,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method writeEsQueryExec to class PlanStreamInput","description":"move method writeEsQueryExec to PsiClass:PlanStreamInput\nRationale: PlanStreamInput deals with reading physical plans, which is conceptually related to writing outputs. Relocating writeEsQueryExec here could create a more symmetric structure between input and output handling. This supports the Open/Closed Principle, allowing future extensions for input/output operations. However, it may confuse the class\u0027s primary purpose of input handling.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":176,"lineEnd":207,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEnrichExec to class PlanStreamInput","description":"move method readEnrichExec to PsiClass:PlanStreamInput\nRationale: The readEnrichExec() method heavily relies on reading data from the PlanStreamInput instance, making it a natural fit for relocation. This move adheres to the Single Responsibility Principle, as it consolidates reading operations related to the EnrichExec within the class that provides the input stream. This enhances cohesion and encapsulation. However, it may increase the complexity of PlanStreamInput if too many methods are relocated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":176,"lineEnd":207,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEnrichExec to class EsqlTestUtils","description":"move method readEnrichExec to PsiClass:EsqlTestUtils\nRationale: The method involves constructing an EnrichExec object, which could be related to various test utilities for enriching data. Moving it to EsqlTestUtils aligns with the Open/Closed Principle, allowing for easier extension of test scenarios without modifying existing code. This move would enhance the utility class\u0027s functionality, but it may blur the lines of responsibility if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":176,"lineEnd":207,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method readEnrichExec to class ConfigurationTestUtils","description":"move method readEnrichExec to PsiClass:ConfigurationTestUtils\nRationale: Given that the method interacts with configuration data (like policy names and match fields), relocating it to ConfigurationTestUtils would align with the principle of high cohesion. This ensures that configuration-related reading logic is centralized. However, it may not directly relate to configuration, which could create confusion about the class\u0027s purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"name","method_signature":"public static name(Class\u003c?\u003e cls)","target_class":"","rationale":""},{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"readIndexMode","method_signature":"public static readIndexMode(StreamInput in)","target_class":"","rationale":""},{"method_name":"writeIndexMode","method_signature":"public static writeIndexMode(StreamOutput out, IndexMode indexMode)","target_class":"","rationale":""},{"method_name":"readEvalExec","method_signature":"static readEvalExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEvalExec","method_signature":"static writeEvalExec(PlanStreamOutput out, EvalExec evalExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeEnrichExec","method_signature":"static writeEnrichExec(PlanStreamOutput out, EnrichExec enrich)","target_class":"","rationale":""},{"method_name":"readExchangeExec","method_signature":"static readExchangeExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},{"method_name":"readExchangeSinkExec","method_signature":"static readExchangeSinkExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},{"method_name":"readExchangeSourceExec","method_signature":"static readExchangeSourceExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},{"method_name":"readFieldExtractExec","method_signature":"static readFieldExtractExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldExtractExec","method_signature":"static writeFieldExtractExec(PlanStreamOutput out, FieldExtractExec fieldExtractExec)","target_class":"","rationale":""},{"method_name":"readFilterExec","method_signature":"static readFilterExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFilterExec","method_signature":"static writeFilterExec(PlanStreamOutput out, FilterExec filterExec)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFragmentExec","method_signature":"static writeFragmentExec(PlanStreamOutput out, FragmentExec fragmentExec)","target_class":"","rationale":""},{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},{"method_name":"readLimitExec","method_signature":"static readLimitExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeLimitExec","method_signature":"static writeLimitExec(PlanStreamOutput out, LimitExec limitExec)","target_class":"","rationale":""},{"method_name":"readMvExpandExec","method_signature":"static readMvExpandExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},{"method_name":"readOrderExec","method_signature":"static readOrderExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeOrderExec","method_signature":"static writeOrderExec(PlanStreamOutput out, OrderExec orderExec)","target_class":"","rationale":""},{"method_name":"readProjectExec","method_signature":"static readProjectExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeProjectExec","method_signature":"static writeProjectExec(PlanStreamOutput out, ProjectExec projectExec)","target_class":"","rationale":""},{"method_name":"readRowExec","method_signature":"static readRowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readShowExec","method_signature":"@SuppressWarnings(\"unchecked\")\n    static readShowExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeShowExec","method_signature":"static writeShowExec(PlanStreamOutput out, ShowExec showExec)","target_class":"","rationale":""},{"method_name":"readTopNExec","method_signature":"static readTopNExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""},{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static namedTypeEntries()":{"first":{"method_name":"namedTypeEntries","method_signature":"public static namedTypeEntries()","target_class":"","rationale":""},"second":0.05783645146264966},"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)":{"first":{"method_name":"writeEsQueryExec","method_signature":"static writeEsQueryExec(PlanStreamOutput out, EsQueryExec esQueryExec)","target_class":"","rationale":""},"second":0.25505118456654635},"static readEnrichExec(PlanStreamInput in)":{"first":{"method_name":"readEnrichExec","method_signature":"static readEnrichExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.285768464867082},"static writeRowExec(PlanStreamOutput out, RowExec rowExec)":{"first":{"method_name":"writeRowExec","method_signature":"static writeRowExec(PlanStreamOutput out, RowExec rowExec)","target_class":"","rationale":""},"second":0.3605992201571874},"static readFragmentExec(PlanStreamInput in)":{"first":{"method_name":"readFragmentExec","method_signature":"static readFragmentExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3703972559874963},"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)":{"first":{"method_name":"writeGrokExec","method_signature":"static writeGrokExec(PlanStreamOutput out, GrokExec grokExec)","target_class":"","rationale":""},"second":0.37608120470165807},"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)":{"first":{"method_name":"writeTopNExec","method_signature":"static writeTopNExec(PlanStreamOutput out, TopNExec topNExec)","target_class":"","rationale":""},"second":0.37608120470165807},"static readGrokExec(PlanStreamInput in)":{"first":{"method_name":"readGrokExec","method_signature":"static readGrokExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.3834586653288616},"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)":{"first":{"method_name":"writeFieldSort","method_signature":"static writeFieldSort(PlanStreamOutput out, EsQueryExec.FieldSort fieldSort)","target_class":"","rationale":""},"second":0.3894007299364419},"static readEsQueryExec(PlanStreamInput in)":{"first":{"method_name":"readEsQueryExec","method_signature":"static readEsQueryExec(PlanStreamInput in)","target_class":"","rationale":""},"second":0.39687647733218123},"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)":{"first":{"method_name":"writeExchangeExec","method_signature":"static writeExchangeExec(PlanStreamOutput out, ExchangeExec exchangeExec)","target_class":"","rationale":""},"second":0.4062003943128223},"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)":{"first":{"method_name":"writeExchangeSinkExec","method_signature":"static writeExchangeSinkExec(PlanStreamOutput out, ExchangeSinkExec exchangeSinkExec)","target_class":"","rationale":""},"second":0.4062003943128223},"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)":{"first":{"method_name":"writeMvExpandExec","method_signature":"static writeMvExpandExec(PlanStreamOutput out, MvExpandExec mvExpandExec)","target_class":"","rationale":""},"second":0.4062003943128223},"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)":{"first":{"method_name":"writeExchangeSourceExec","method_signature":"static writeExchangeSourceExec(PlanStreamOutput out, ExchangeSourceExec exchangeSourceExec)","target_class":"","rationale":""},"second":0.43534856368745467},"static readFieldSort(PlanStreamInput in)":{"first":{"method_name":"readFieldSort","method_signature":"static readFieldSort(PlanStreamInput in)","target_class":"","rationale":""},"second":0.4447495899966607}},"llmMethodPriority":{"priority_method_names":["namedTypeEntries","writeEsQueryExec","readEnrichExec","writeRowExec","readFragmentExec","writeGrokExec","writeTopNExec","readGrokExec","writeFieldSort","readEsQueryExec","writeMvExpandExec"],"llm_response_time":4753},"targetClassMap":{"namedTypeEntries":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.06603154639018421},{"class_name":"AnalyzerTestUtils","similarity_score":0.08586842432424448},{"class_name":"LuceneComponent2DUtils","similarity_score":0.0835578949567313},{"class_name":"ConfigurationTestUtils","similarity_score":0.0899783687703892},{"class_name":"Entry","similarity_score":0.0925286233647578},{"class_name":"SerializationTestUtils","similarity_score":0.08969791915865181},{"class_name":"CsvTestUtils","similarity_score":0.11190081369203314},{"class_name":"EsqlTestUtils","similarity_score":0.11840923352144624},{"class_name":"ExceptionUtils","similarity_score":0.09359440946090732},{"class_name":"DateUtils","similarity_score":0.1143867287429231},{"class_name":"SpatialRelatesUtils","similarity_score":0.11788953654421444},{"class_name":"PlanNamedTypesTests","similarity_score":0.12562813851798438},{"class_name":"PlanNameRegistry","similarity_score":0.124420484287856},{"class_name":"PlannerUtils","similarity_score":0.14198152604457573},{"class_name":"PlanStreamInput","similarity_score":0.12283038778835989},{"class_name":"PlanStreamOutput","similarity_score":0.12652561636049756},{"class_name":"PlanStreamOutputTests","similarity_score":0.07007589505358293},{"class_name":"ParserUtils","similarity_score":0.08673994273367576},{"class_name":"NumericUtilsTests","similarity_score":0.07458180225169632},{"class_name":"ResponseValueUtils","similarity_score":0.12208677804592435},{"class_name":"ResponseXContentUtils","similarity_score":0.11313308756900332},{"class_name":"ReflectionUtils","similarity_score":0.08115129636254971},{"class_name":"StringUtils","similarity_score":0.09061195459645197},{"class_name":"TestUtils","similarity_score":0.09235719658578809},{"class_name":"CertParsingUtils","similarity_score":0.11828542296290315},{"class_name":"AuditUtil","similarity_score":0.0887037851244076},{"class_name":"JwkValidateUtil","similarity_score":0.08459063659909515},{"class_name":"JwkValidateUtilTests","similarity_score":0.0787632748402185},{"class_name":"AuthorizationStatePersistenceUtils","similarity_score":0.10440363795014462}],"target_classes_sorted_by_llm":["PlanNameRegistry","PlanStreamOutput","PlannerUtils","PlanStreamInput","PlanNamedTypesTests","ResponseValueUtils","CertParsingUtils","EsqlTestUtils","DateUtils","SpatialRelatesUtils"],"llm_response_time":16534,"similarity_computation_time":21,"similarity_metric":"voyage"},"writeEsQueryExec":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.19802950859533489},{"class_name":"TestUtils","similarity_score":0.22504665034619234},{"class_name":"ExceptionUtils","similarity_score":0.08446717229993575},{"class_name":"AnalyzerTestUtils","similarity_score":0.23248385350033404},{"class_name":"SerializationTestUtils","similarity_score":0.263477777620917},{"class_name":"Entry","similarity_score":0.11963415324775042},{"class_name":"LuceneComponent2DUtils","similarity_score":0.2472351340443388},{"class_name":"EsqlTestUtils","similarity_score":0.24854799290173543},{"class_name":"CsvTestUtils","similarity_score":0.2550137560242697},{"class_name":"DateUtils","similarity_score":0.21970165498762426},{"class_name":"SpatialRelatesUtils","similarity_score":0.1802423636237332},{"class_name":"ConfigurationTestUtils","similarity_score":0.21925016397159128},{"class_name":"StringUtils","similarity_score":0.19814848097530427},{"class_name":"ReflectionUtils","similarity_score":0.1898315991504998},{"class_name":"ResponseValueUtils","similarity_score":0.16894418833445152},{"class_name":"ResponseXContentUtils","similarity_score":0.2222465766770296},{"class_name":"NumericUtilsTests","similarity_score":0.09086668605156177},{"class_name":"PlanNamedTypesTests","similarity_score":0.2076747037760121},{"class_name":"PlanNameRegistry","similarity_score":0.24903678634474247},{"class_name":"ParserUtils","similarity_score":0.21848355973067216},{"class_name":"PlannerUtils","similarity_score":0.1808973509958977},{"class_name":"PlanStreamInput","similarity_score":0.27209148387869964},{"class_name":"PlanStreamOutput","similarity_score":0.2525163046032693},{"class_name":"PlanStreamOutputTests","similarity_score":0.22114021176901394},{"class_name":"IndexerUtils","similarity_score":0.18514426062973213},{"class_name":"JwkValidateUtil","similarity_score":0.19753347274833927},{"class_name":"JwkValidateUtilTests","similarity_score":0.28984193210486947},{"class_name":"JwtUtil","similarity_score":0.25171179750921774},{"class_name":"ResultUtils","similarity_score":0.16343011261515336}],"target_classes_sorted_by_llm":["PlanStreamOutput","SerializationTestUtils","PlanStreamInput","EsqlTestUtils","JwtUtil","CsvTestUtils","AnalyzerTestUtils","LuceneComponent2DUtils","PlanNameRegistry","JwkValidateUtilTests"],"llm_response_time":14838,"similarity_computation_time":18,"similarity_metric":"voyage"},"readEnrichExec":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.28427738894389903},{"class_name":"NumericUtilsTests","similarity_score":0.1559305404590247},{"class_name":"LuceneComponent2DUtils","similarity_score":0.466590378989535},{"class_name":"ParserUtils","similarity_score":0.462342731057894},{"class_name":"CsvTestUtils","similarity_score":0.6286384952745386},{"class_name":"AnalyzerTestUtils","similarity_score":0.38603766277410523},{"class_name":"SerializationTestUtils","similarity_score":0.4158896729073611},{"class_name":"PlanNamedTypesTests","similarity_score":0.48968190781193544},{"class_name":"PlanNameRegistry","similarity_score":0.4766665188787986},{"class_name":"PlannerUtils","similarity_score":0.4835062340034312},{"class_name":"PlanStreamInput","similarity_score":0.5274644157283689},{"class_name":"PlanStreamOutput","similarity_score":0.41909702843394203},{"class_name":"PlanStreamOutputTests","similarity_score":0.6188334187002029},{"class_name":"Entry","similarity_score":0.17110939081581042},{"class_name":"DateUtils","similarity_score":0.5666680262682678},{"class_name":"EsqlTestUtils","similarity_score":0.544219346271012},{"class_name":"ExceptionUtils","similarity_score":0.12010038618199134},{"class_name":"ConfigurationTestUtils","similarity_score":0.5880861576628363},{"class_name":"SpatialRelatesUtils","similarity_score":0.31418841522845753},{"class_name":"ReflectionUtils","similarity_score":0.5255531492196681},{"class_name":"StringUtils","similarity_score":0.5774104499417144},{"class_name":"TestUtils","similarity_score":0.29888666202421155},{"class_name":"ResponseValueUtils","similarity_score":0.35048057817142897},{"class_name":"ResponseXContentUtils","similarity_score":0.41136515781023425},{"class_name":"JwkValidateUtil","similarity_score":0.5847433812118532},{"class_name":"JwkValidateUtilTests","similarity_score":0.5440593937894679},{"class_name":"MatchersUtils","similarity_score":0.4591552655829046},{"class_name":"LicenseUtils","similarity_score":0.5401406062998416},{"class_name":"LifecycleExecutionStateUtils","similarity_score":0.2538923295196217}],"target_classes_sorted_by_llm":["PlanStreamInput","EsqlTestUtils","ConfigurationTestUtils","CsvTestUtils","PlanStreamOutputTests","StringUtils","LicenseUtils","DateUtils","JwkValidateUtil","JwkValidateUtilTests"],"llm_response_time":13449,"similarity_computation_time":11,"similarity_metric":"voyage"}}}
{"id":"5a9fd310-1d12-4682-8120-db958f6d9c1f","methodCount":22,"hostFunctionTelemetryData":{"hostFunctionSize":346,"lineStart":93,"lineEnd":438,"bodyLineStart":93,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/elasticsearch/x-pack/plugin/esql/src/main/java/org/elasticsearch/xpack/esql/optimizer/LogicalPlanOptimizer.java","sourceCode":"/**\n * \u003cp\u003eThis class is part of the planner\u003c/p\u003e\n * \u003cp\u003eGlobal optimizations based strictly on the structure of the query (i.e. not factoring in information about the backing indices).\n * The bulk of query transformations happen in this step. \u003c/p\u003e\n *\n * \u003cp\u003eGlobal optimizations based strictly on the structure of the query (i.e. not factoring in information about the backing indices).  The\n * bulk of query transformations happen in this step. This has three important sub-phases:\u003c/p\u003e\n * \u003cul\u003e\n *     \u003cli\u003eThe {@link LogicalPlanOptimizer#substitutions()} phase rewrites things to expand out shorthand in the syntax.  For example,\n *     a nested expression embedded in a stats gets replaced with an eval followed by a stats, followed by another eval.  This phase\n *     also applies surrogates, such as replacing an average with a sum divided by a count.\u003c/li\u003e\n *     \u003cli\u003e{@link LogicalPlanOptimizer#operators()} (NB: The word \"operator\" is extremely overloaded and referrers to many different\n *     things.) transform the tree in various different ways.  This includes folding (i.e. computing constant expressions at parse\n *     time), combining expressions, dropping redundant clauses, and some normalization such as putting literals on the right whenever\n *     possible.  These rules are run in a loop until none of the rules make any changes to the plan (there is also a safety shut off\n *     after many iterations, although hitting that is considered a bug)\u003c/li\u003e\n *     \u003cli\u003e{@link LogicalPlanOptimizer#cleanup()}  Which can replace sorts+limit with a TopN\u003c/li\u003e\n * \u003c/ul\u003e\n *\n * \u003cp\u003eNote that the {@link LogicalPlanOptimizer#operators()} and {@link LogicalPlanOptimizer#cleanup()} steps are reapplied at the\n * {@link LocalLogicalPlanOptimizer} layer.\u003c/p\u003e\n */\npublic class LogicalPlanOptimizer extends ParameterizedRuleExecutor\u003cLogicalPlan, LogicalOptimizerContext\u003e {\n\n    private final LogicalVerifier verifier \u003d LogicalVerifier.INSTANCE;\n\n    public LogicalPlanOptimizer(LogicalOptimizerContext optimizerContext) {\n        super(optimizerContext);\n    }\n\n    public static String temporaryName(Expression inner, Expression outer, int suffix) {\n        String in \u003d toString(inner);\n        String out \u003d toString(outer);\n        return rawTemporaryName(in, out, String.valueOf(suffix));\n    }\n\n    public static String locallyUniqueTemporaryName(String inner, String outer) {\n        return FieldAttribute.SYNTHETIC_ATTRIBUTE_NAME_PREFIX + inner + \"$\" + outer + \"$\" + new NameId();\n    }\n\n    public static String rawTemporaryName(String inner, String outer, String suffix) {\n        return FieldAttribute.SYNTHETIC_ATTRIBUTE_NAME_PREFIX + inner + \"$\" + outer + \"$\" + suffix;\n    }\n\n    static String toString(Expression ex) {\n        return ex instanceof AggregateFunction af ? af.functionName() : extractString(ex);\n    }\n\n    static String extractString(Expression ex) {\n        return ex instanceof NamedExpression ne ? ne.name() : limitToString(ex.sourceText()).replace(\u0027 \u0027, \u0027_\u0027);\n    }\n\n    static int TO_STRING_LIMIT \u003d 16;\n\n    static String limitToString(String string) {\n        return string.length() \u003e TO_STRING_LIMIT ? string.substring(0, TO_STRING_LIMIT - 1) + \"\u003e\" : string;\n    }\n\n    public LogicalPlan optimize(LogicalPlan verified) {\n        var optimized \u003d execute(verified);\n\n        Failures failures \u003d verifier.verify(optimized);\n        if (failures.hasFailures()) {\n            throw new VerificationException(failures);\n        }\n        optimized.setOptimized();\n        return optimized;\n    }\n\n    @Override\n    protected List\u003cBatch\u003cLogicalPlan\u003e\u003e batches() {\n        return rules();\n    }\n\n    protected static Batch\u003cLogicalPlan\u003e substitutions() {\n        return new Batch\u003c\u003e(\n            \"Substitutions\",\n            Limiter.ONCE,\n            new ReplaceLookupWithJoin(),\n            new RemoveStatsOverride(),\n            // first extract nested expressions inside aggs\n            new ReplaceStatsNestedExpressionWithEval(),\n            // then extract nested aggs top-level\n            new ReplaceStatsAggExpressionWithEval(),\n            // lastly replace surrogate functions\n            new SubstituteSurrogates(),\n            // translate metric aggregates after surrogate substitution and replace nested expressions with eval (again)\n            new TranslateMetricsAggregate(),\n            new ReplaceStatsNestedExpressionWithEval(),\n            new ReplaceRegexMatch(),\n            new ReplaceTrivialTypeConversions(),\n            new ReplaceAliasingEvalWithProject(),\n            new SkipQueryOnEmptyMappings(),\n            new SubstituteSpatialSurrogates(),\n            new ReplaceOrderByExpressionWithEval()\n            // new NormalizeAggregate(), - waits on https://github.com/elastic/elasticsearch/issues/100634\n        );\n    }\n\n    protected static Batch\u003cLogicalPlan\u003e operators() {\n        return new Batch\u003c\u003e(\n            \"Operator Optimization\",\n            new CombineProjections(),\n            new CombineEvals(),\n            new PruneEmptyPlans(),\n            new PropagateEmptyRelation(),\n            new ConvertStringToByteRef(),\n            new FoldNull(),\n            new SplitInWithFoldableValue(),\n            new PropagateEvalFoldables(),\n            new ConstantFolding(),\n            new PartiallyFoldCase(),\n            // boolean\n            new BooleanSimplification(),\n            new LiteralsOnTheRight(),\n            // needs to occur before BinaryComparison combinations (see class)\n            new PropagateEquals(),\n            new PropagateNullable(),\n            new BooleanFunctionEqualsElimination(),\n            new CombineBinaryComparisons(),\n            new CombineDisjunctions(),\n            new SimplifyComparisonsArithmetics(DataType::areCompatible),\n            // prune/elimination\n            new PruneFilters(),\n            new PruneColumns(),\n            new PruneLiteralsInOrderBy(),\n            new PushDownAndCombineLimits(),\n            new DuplicateLimitAfterMvExpand(),\n            new PushDownAndCombineFilters(),\n            new PushDownEval(),\n            new PushDownRegexExtract(),\n            new PushDownEnrich(),\n            new PushDownAndCombineOrderBy(),\n            new PruneOrderByBeforeStats(),\n            new PruneRedundantSortClauses()\n        );\n    }\n\n    protected static Batch\u003cLogicalPlan\u003e cleanup() {\n        return new Batch\u003c\u003e(\"Clean Up\", new ReplaceLimitAndSortAsTopN());\n    }\n\n    protected static List\u003cBatch\u003cLogicalPlan\u003e\u003e rules() {\n        var skip \u003d new Batch\u003c\u003e(\"Skip Compute\", new SkipQueryOnLimitZero());\n        var defaultTopN \u003d new Batch\u003c\u003e(\"Add default TopN\", new AddDefaultTopN());\n        var label \u003d new Batch\u003c\u003e(\"Set as Optimized\", Limiter.ONCE, new SetAsOptimized());\n\n        return asList(substitutions(), operators(), skip, cleanup(), defaultTopN, label);\n    }\n\n    public static LogicalPlan skipPlan(UnaryPlan plan) {\n        return new LocalRelation(plan.source(), plan.output(), LocalSupplier.EMPTY);\n    }\n\n    public static LogicalPlan skipPlan(UnaryPlan plan, LocalSupplier supplier) {\n        return new LocalRelation(plan.source(), plan.output(), supplier);\n    }\n\n    /**\n     * Pushes LogicalPlans which generate new attributes (Eval, Grok/Dissect, Enrich), past OrderBys and Projections.\n     * Although it seems arbitrary whether the OrderBy or the generating plan is executed first, this transformation ensures that OrderBys\n     * only separated by e.g. an Eval can be combined by {@link PushDownAndCombineOrderBy}.\n     * \u003cp\u003e\n     * E.g. {@code ... | sort a | eval x \u003d b + 1 | sort x} becomes {@code ... | eval x \u003d b + 1 | sort a | sort x}\n     * \u003cp\u003e\n     * Ordering the generating plans before the OrderBys has the advantage that it\u0027s always possible to order the plans like this.\n     * E.g., in the example above it would not be possible to put the eval after the two orderBys.\n     * \u003cp\u003e\n     * In case one of the generating plan\u0027s attributes would shadow the OrderBy\u0027s attributes, we alias the generated attribute first.\n     * \u003cp\u003e\n     * E.g. {@code ... | sort a | eval a \u003d b + 1 | ...} becomes {@code ... | eval $$a \u003d a | eval a \u003d b + 1 | sort $$a | drop $$a ...}\n     * \u003cp\u003e\n     * In case the generating plan\u0027s attributes would shadow the Project\u0027s attributes, we rename the generated attributes in place.\n     * \u003cp\u003e\n     * E.g. {@code ... | rename a as z | eval a \u003d b + 1 | ...} becomes {@code ... eval $$a \u003d b + 1 | rename a as z, $$a as a ...}\n     */\n    public static \u003cPlan extends UnaryPlan \u0026 GeneratingPlan\u003cPlan\u003e\u003e LogicalPlan pushGeneratingPlanPastProjectAndOrderBy(Plan generatingPlan) {\n        LogicalPlan child \u003d generatingPlan.child();\n        if (child instanceof OrderBy orderBy) {\n            Set\u003cString\u003e evalFieldNames \u003d new LinkedHashSet\u003c\u003e(Expressions.names(generatingPlan.generatedAttributes()));\n\n            // Look for attributes in the OrderBy\u0027s expressions and create aliases with temporary names for them.\n            AttributeReplacement nonShadowedOrders \u003d renameAttributesInExpressions(evalFieldNames, orderBy.order());\n\n            AttributeMap\u003cAlias\u003e aliasesForShadowedOrderByAttrs \u003d nonShadowedOrders.replacedAttributes;\n            @SuppressWarnings(\"unchecked\")\n            List\u003cOrder\u003e newOrder \u003d (List\u003cOrder\u003e) (List\u003c?\u003e) nonShadowedOrders.rewrittenExpressions;\n\n            if (aliasesForShadowedOrderByAttrs.isEmpty() \u003d\u003d false) {\n                List\u003cAlias\u003e newAliases \u003d new ArrayList\u003c\u003e(aliasesForShadowedOrderByAttrs.values());\n\n                LogicalPlan plan \u003d new Eval(orderBy.source(), orderBy.child(), newAliases);\n                plan \u003d generatingPlan.replaceChild(plan);\n                plan \u003d new OrderBy(orderBy.source(), plan, newOrder);\n                plan \u003d new Project(generatingPlan.source(), plan, generatingPlan.output());\n\n                return plan;\n            }\n\n            return orderBy.replaceChild(generatingPlan.replaceChild(orderBy.child()));\n        } else if (child instanceof Project project) {\n            // We need to account for attribute shadowing: a rename might rely on a name generated in an Eval/Grok/Dissect/Enrich.\n            // E.g. in:\n            //\n            // Eval[[2 * x{f}#1 AS y]]\n            // \\_Project[[x{f}#1, y{f}#2, y{f}#2 AS z]]\n            //\n            // Just moving the Eval down breaks z because we shadow y{f}#2.\n            // Instead, we use a different alias in the Eval, eventually renaming back to y:\n            //\n            // Project[[x{f}#1, y{f}#2 as z, $$y{r}#3 as y]]\n            // \\_Eval[[2 * x{f}#1 as $$y]]\n\n            List\u003cAttribute\u003e generatedAttributes \u003d generatingPlan.generatedAttributes();\n\n            @SuppressWarnings(\"unchecked\")\n            Plan generatingPlanWithResolvedExpressions \u003d (Plan) resolveRenamesFromProject(generatingPlan, project);\n\n            Set\u003cString\u003e namesReferencedInRenames \u003d new HashSet\u003c\u003e();\n            for (NamedExpression ne : project.projections()) {\n                if (ne instanceof Alias as) {\n                    namesReferencedInRenames.addAll(as.child().references().names());\n                }\n            }\n            Map\u003cString, String\u003e renameGeneratedAttributeTo \u003d newNamesForConflictingAttributes(\n                generatingPlan.generatedAttributes(),\n                namesReferencedInRenames\n            );\n            List\u003cString\u003e newNames \u003d generatedAttributes.stream()\n                .map(attr -\u003e renameGeneratedAttributeTo.getOrDefault(attr.name(), attr.name()))\n                .toList();\n            Plan generatingPlanWithRenamedAttributes \u003d generatingPlanWithResolvedExpressions.withGeneratedNames(newNames);\n\n            // Put the project at the top, but include the generated attributes.\n            // Any generated attributes that had to be renamed need to be re-renamed to their original names.\n            List\u003cNamedExpression\u003e generatedAttributesRenamedToOriginal \u003d new ArrayList\u003c\u003e(generatedAttributes.size());\n            List\u003cAttribute\u003e renamedGeneratedAttributes \u003d generatingPlanWithRenamedAttributes.generatedAttributes();\n            for (int i \u003d 0; i \u003c generatedAttributes.size(); i++) {\n                Attribute originalAttribute \u003d generatedAttributes.get(i);\n                Attribute renamedAttribute \u003d renamedGeneratedAttributes.get(i);\n                if (originalAttribute.name().equals(renamedAttribute.name())) {\n                    generatedAttributesRenamedToOriginal.add(renamedAttribute);\n                } else {\n                    generatedAttributesRenamedToOriginal.add(\n                        new Alias(\n                            originalAttribute.source(),\n                            originalAttribute.name(),\n                            renamedAttribute,\n                            originalAttribute.id(),\n                            originalAttribute.synthetic()\n                        )\n                    );\n                }\n            }\n\n            Project projectWithGeneratingChild \u003d project.replaceChild(generatingPlanWithRenamedAttributes.replaceChild(project.child()));\n            return projectWithGeneratingChild.withProjections(\n                mergeOutputExpressions(generatedAttributesRenamedToOriginal, projectWithGeneratingChild.projections())\n            );\n        }\n\n        return generatingPlan;\n    }\n\n    private record AttributeReplacement(List\u003cExpression\u003e rewrittenExpressions, AttributeMap\u003cAlias\u003e replacedAttributes) {};\n\n    /**\n     * Replace attributes in the given expressions by assigning them temporary names.\n     * Returns the rewritten expressions and a map with an alias for each replaced attribute; the rewritten expressions reference\n     * these aliases.\n     */\n    private static AttributeReplacement renameAttributesInExpressions(\n        Set\u003cString\u003e attributeNamesToRename,\n        List\u003c? extends Expression\u003e expressions\n    ) {\n        AttributeMap\u003cAlias\u003e aliasesForReplacedAttributes \u003d new AttributeMap\u003c\u003e();\n        List\u003cExpression\u003e rewrittenExpressions \u003d new ArrayList\u003c\u003e();\n\n        for (Expression expr : expressions) {\n            rewrittenExpressions.add(expr.transformUp(Attribute.class, attr -\u003e {\n                if (attributeNamesToRename.contains(attr.name())) {\n                    Alias renamedAttribute \u003d aliasesForReplacedAttributes.computeIfAbsent(attr, a -\u003e {\n                        String tempName \u003d locallyUniqueTemporaryName(a.name(), \"temp_name\");\n                        // TODO: this should be synthetic\n                        // blocked on https://github.com/elastic/elasticsearch/issues/98703\n                        return new Alias(a.source(), tempName, a, null, false);\n                    });\n                    return renamedAttribute.toAttribute();\n                }\n\n                return attr;\n            }));\n        }\n\n        return new AttributeReplacement(rewrittenExpressions, aliasesForReplacedAttributes);\n    }\n\n    private static Map\u003cString, String\u003e newNamesForConflictingAttributes(\n        List\u003cAttribute\u003e potentiallyConflictingAttributes,\n        Set\u003cString\u003e reservedNames\n    ) {\n        if (reservedNames.isEmpty()) {\n            return Map.of();\n        }\n\n        Map\u003cString, String\u003e renameAttributeTo \u003d new HashMap\u003c\u003e();\n        for (Attribute attr : potentiallyConflictingAttributes) {\n            String name \u003d attr.name();\n            if (reservedNames.contains(name)) {\n                renameAttributeTo.putIfAbsent(name, locallyUniqueTemporaryName(name, \"temp_name\"));\n            }\n        }\n\n        return renameAttributeTo;\n    }\n\n    public static Project pushDownPastProject(UnaryPlan parent) {\n        if (parent.child() instanceof Project project) {\n            UnaryPlan expressionsWithResolvedAliases \u003d resolveRenamesFromProject(parent, project);\n\n            return project.replaceChild(expressionsWithResolvedAliases.replaceChild(project.child()));\n        } else {\n            throw new EsqlIllegalArgumentException(\"Expected child to be instance of Project\");\n        }\n    }\n\n    private static UnaryPlan resolveRenamesFromProject(UnaryPlan plan, Project project) {\n        AttributeMap.Builder\u003cExpression\u003e aliasBuilder \u003d AttributeMap.builder();\n        project.forEachExpression(Alias.class, a -\u003e aliasBuilder.put(a.toAttribute(), a.child()));\n        var aliases \u003d aliasBuilder.build();\n\n        return (UnaryPlan) plan.transformExpressionsOnly(ReferenceAttribute.class, r -\u003e aliases.resolve(r, r));\n    }\n\n    public abstract static class ParameterizedOptimizerRule\u003cSubPlan extends LogicalPlan, P\u003e extends ParameterizedRule\u003c\n        SubPlan,\n        LogicalPlan,\n        P\u003e {\n\n        public final LogicalPlan apply(LogicalPlan plan, P context) {\n            return plan.transformDown(typeToken(), t -\u003e rule(t, context));\n        }\n\n        protected abstract LogicalPlan rule(SubPlan plan, P context);\n    }\n}","methodCount":22},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":132,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class TestUtils","description":"move method rawTemporaryName to PsiClass:TestUtils\nRationale: The rawTemporaryName() method is a utility function that generates a specific formatted name, which aligns well with the purpose of TestUtils. This class is designed for various utility methods used in testing scenarios, making it a suitable home for this method. Moving it here adheres to the Single Responsibility Principle, as TestUtils can encapsulate all test-related utilities. However, it may lead to a bloated utility class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":132,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class EsqlTestUtils","description":"move method rawTemporaryName to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils contains methods related to testing SQL-like structures, and the rawTemporaryName() method can be useful in generating names for temporary SQL constructs. This move would enhance cohesion within the class by grouping related functionalities. It aligns with the Open/Closed Principle, allowing for extension without modifying existing code. However, it may introduce confusion if the method is not directly related to SQL operations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":132,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method rawTemporaryName to class AnalyzerTestUtils","description":"move method rawTemporaryName to PsiClass:AnalyzerTestUtils\nRationale: The rawTemporaryName() method could be relevant in the context of analyzing data structures, potentially serving as a naming convention for temporary analysis results. This aligns with the Interface Segregation Principle, as it allows the AnalyzerTestUtils to provide specific utilities for analysis without burdening other classes. A drawback could be that it might not directly relate to the core responsibilities of this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":146,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class StringUtils","description":"move method limitToString to PsiClass:StringUtils\nRationale: The limitToString() method is primarily concerned with string manipulation, specifically limiting the length of a string. Moving it to StringUtils aligns with the Single Responsibility Principle, as this class is dedicated to string operations. This enhances cohesion, making StringUtils a central location for string-related utilities. However, care should be taken to ensure that the method\u0027s static nature does not conflict with potential instance methods in StringUtils.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":146,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class CsvTestUtils","description":"move method limitToString to PsiClass:CsvTestUtils\nRationale: CsvTestUtils deals with CSV-related operations, which often involve string manipulations. Since the limitToString() method could be useful when formatting CSV data, relocating it here would enhance the utility of the class. This move supports the Open/Closed Principle, allowing for future extensions related to CSV processing. However, it may dilute the focus of CsvTestUtils if too many unrelated string methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":146,"lineEnd":148,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method limitToString to class TestUtils","description":"move method limitToString to PsiClass:TestUtils\nRationale: TestUtils serves as a general utility class for testing purposes, and the limitToString() method can be beneficial for creating concise test outputs. This relocation supports the Single Responsibility Principle by keeping utility methods related to testing in one place. However, it might lead to a bloated TestUtils class if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":140,"lineEnd":142,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class StringUtils","description":"move method extractString to PsiClass:StringUtils\nRationale: The extractString() method is primarily concerned with string manipulation, specifically formatting strings based on the type of Expression. Moving it to StringUtils aligns with the Single Responsibility Principle, as StringUtils is focused on string operations. This enhances cohesion within StringUtils and makes the method more reusable in various contexts. However, we should ensure that the method\u0027s dependencies on Expression types are well-documented to avoid confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":140,"lineEnd":142,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class EsqlTestUtils","description":"move method extractString to PsiClass:EsqlTestUtils\nRationale: EsqlTestUtils deals with various Expression types and their attributes, making it a fitting candidate for extractString(). This relocation would enhance the relevance of utility methods related to expression handling. It adheres to the Open/Closed Principle, allowing for future extensions related to expression manipulation without altering existing code. However, care must be taken to avoid bloating the EsqlTestUtils class with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":140,"lineEnd":142,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method extractString to class TestUtils","description":"move method extractString to PsiClass:TestUtils\nRationale: TestUtils serves as a general-purpose utility class for testing, and extractString() could be beneficial for various test cases involving Expressions. This move supports the Interface Segregation Principle, as it allows for more focused testing utilities. However, it may lead to a less cohesive utility class if not managed carefully.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""},{"method_name":"locallyUniqueTemporaryName","method_signature":"public static locallyUniqueTemporaryName(String inner, String outer)","target_class":"","rationale":""},{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""},{"method_name":"optimize","method_signature":"public optimize(LogicalPlan verified)","target_class":"","rationale":""},{"method_name":"substitutions","method_signature":"protected static substitutions()","target_class":"","rationale":""},{"method_name":"operators","method_signature":"protected static operators()","target_class":"","rationale":""},{"method_name":"cleanup","method_signature":"protected static cleanup()","target_class":"","rationale":""},{"method_name":"rules","method_signature":"protected static rules()","target_class":"","rationale":""},{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan)","target_class":"","rationale":""},{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan, LocalSupplier supplier)","target_class":"","rationale":""},{"method_name":"pushGeneratingPlanPastProjectAndOrderBy","method_signature":"public static pushGeneratingPlanPastProjectAndOrderBy(Plan generatingPlan)","target_class":"","rationale":""},{"method_name":"renameAttributesInExpressions","method_signature":"private static renameAttributesInExpressions(\n        Set\u003cString\u003e attributeNamesToRename,\n        List\u003c? extends Expression\u003e expressions\n    )","target_class":"","rationale":""},{"method_name":"newNamesForConflictingAttributes","method_signature":"private static newNamesForConflictingAttributes(\n        List\u003cAttribute\u003e potentiallyConflictingAttributes,\n        Set\u003cString\u003e reservedNames\n    )","target_class":"","rationale":""},{"method_name":"pushDownPastProject","method_signature":"public static pushDownPastProject(UnaryPlan parent)","target_class":"","rationale":""},{"method_name":"resolveRenamesFromProject","method_signature":"private static resolveRenamesFromProject(UnaryPlan plan, Project project)","target_class":"","rationale":""},{"method_name":"apply","method_signature":"public final apply(LogicalPlan plan, P context)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""},{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},{"method_name":"apply","method_signature":"public final apply(LogicalPlan plan, P context)","target_class":"","rationale":""},{"method_name":"locallyUniqueTemporaryName","method_signature":"public static locallyUniqueTemporaryName(String inner, String outer)","target_class":"","rationale":""},{"method_name":"resolveRenamesFromProject","method_signature":"private static resolveRenamesFromProject(UnaryPlan plan, Project project)","target_class":"","rationale":""},{"method_name":"operators","method_signature":"protected static operators()","target_class":"","rationale":""},{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""},{"method_name":"substitutions","method_signature":"protected static substitutions()","target_class":"","rationale":""},{"method_name":"pushDownPastProject","method_signature":"public static pushDownPastProject(UnaryPlan parent)","target_class":"","rationale":""},{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan)","target_class":"","rationale":""},{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan, LocalSupplier supplier)","target_class":"","rationale":""},{"method_name":"optimize","method_signature":"public optimize(LogicalPlan verified)","target_class":"","rationale":""},{"method_name":"newNamesForConflictingAttributes","method_signature":"private static newNamesForConflictingAttributes(\n        List\u003cAttribute\u003e potentiallyConflictingAttributes,\n        Set\u003cString\u003e reservedNames\n    )","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public static rawTemporaryName(String inner, String outer, String suffix)":{"first":{"method_name":"rawTemporaryName","method_signature":"public static rawTemporaryName(String inner, String outer, String suffix)","target_class":"","rationale":""},"second":0.20069427250068447},"static limitToString(String string)":{"first":{"method_name":"limitToString","method_signature":"static limitToString(String string)","target_class":"","rationale":""},"second":0.22105519110772232},"static extractString(Expression ex)":{"first":{"method_name":"extractString","method_signature":"static extractString(Expression ex)","target_class":"","rationale":""},"second":0.22930568218006497},"static toString(Expression ex)":{"first":{"method_name":"toString","method_signature":"static toString(Expression ex)","target_class":"","rationale":""},"second":0.24714473799839984},"public final apply(LogicalPlan plan, P context)":{"first":{"method_name":"apply","method_signature":"public final apply(LogicalPlan plan, P context)","target_class":"","rationale":""},"second":0.2698019801980198},"public static locallyUniqueTemporaryName(String inner, String outer)":{"first":{"method_name":"locallyUniqueTemporaryName","method_signature":"public static locallyUniqueTemporaryName(String inner, String outer)","target_class":"","rationale":""},"second":0.2821504299357535},"private static resolveRenamesFromProject(UnaryPlan plan, Project project)":{"first":{"method_name":"resolveRenamesFromProject","method_signature":"private static resolveRenamesFromProject(UnaryPlan plan, Project project)","target_class":"","rationale":""},"second":0.31939852337413766},"protected static operators()":{"first":{"method_name":"operators","method_signature":"protected static operators()","target_class":"","rationale":""},"second":0.36120651428721307},"public static temporaryName(Expression inner, Expression outer, int suffix)":{"first":{"method_name":"temporaryName","method_signature":"public static temporaryName(Expression inner, Expression outer, int suffix)","target_class":"","rationale":""},"second":0.38402198930507087},"protected static substitutions()":{"first":{"method_name":"substitutions","method_signature":"protected static substitutions()","target_class":"","rationale":""},"second":0.4668000308335379},"public static pushDownPastProject(UnaryPlan parent)":{"first":{"method_name":"pushDownPastProject","method_signature":"public static pushDownPastProject(UnaryPlan parent)","target_class":"","rationale":""},"second":0.46815510207059735},"public static skipPlan(UnaryPlan plan)":{"first":{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan)","target_class":"","rationale":""},"second":0.47286105271622714},"public static skipPlan(UnaryPlan plan, LocalSupplier supplier)":{"first":{"method_name":"skipPlan","method_signature":"public static skipPlan(UnaryPlan plan, LocalSupplier supplier)","target_class":"","rationale":""},"second":0.4730012704872391},"public optimize(LogicalPlan verified)":{"first":{"method_name":"optimize","method_signature":"public optimize(LogicalPlan verified)","target_class":"","rationale":""},"second":0.47413227888420023},"private static newNamesForConflictingAttributes(\n        List\u003cAttribute\u003e potentiallyConflictingAttributes,\n        Set\u003cString\u003e reservedNames\n    )":{"first":{"method_name":"newNamesForConflictingAttributes","method_signature":"private static newNamesForConflictingAttributes(\n        List\u003cAttribute\u003e potentiallyConflictingAttributes,\n        Set\u003cString\u003e reservedNames\n    )","target_class":"","rationale":""},"second":0.48844224858844665}},"llmMethodPriority":{"priority_method_names":["optimize","pushDownPastProject","skipPlan","skipPlan","temporaryName","locallyUniqueTemporaryName","rawTemporaryName","resolveRenamesFromProject","substitutions","operators","toString","extractString","limitToString","apply","newNamesForConflictingAttributes"],"llm_response_time":3706},"targetClassMap":{"rawTemporaryName":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.2207515735136804},{"class_name":"ExceptionUtils","similarity_score":0.09271040345873596},{"class_name":"NumericUtilsTests","similarity_score":0.12681751414778644},{"class_name":"ParserUtils","similarity_score":0.2606582356223241},{"class_name":"AnalyzerTestUtils","similarity_score":0.36246047221623257},{"class_name":"ConfigurationTestUtils","similarity_score":0.2399307833521138},{"class_name":"LuceneComponent2DUtils","similarity_score":0.21948481531639943},{"class_name":"PlannerUtils","similarity_score":0.19389774844890165},{"class_name":"SerializationTestUtils","similarity_score":0.20128338525868292},{"class_name":"EsqlTestUtils","similarity_score":0.37801333113426894},{"class_name":"CsvTestUtils","similarity_score":0.3135427112479732},{"class_name":"DateUtils","similarity_score":0.2811830073421282},{"class_name":"ReflectionUtils","similarity_score":0.22789095468755416},{"class_name":"SpatialRelatesUtils","similarity_score":0.20092351723737698},{"class_name":"ResponseValueUtils","similarity_score":0.1536865256792945},{"class_name":"ResponseXContentUtils","similarity_score":0.21696215657791337},{"class_name":"StringUtils","similarity_score":0.23690436940108828},{"class_name":"TestUtils","similarity_score":0.2977342621104822},{"class_name":"ExpectedComparison","similarity_score":0.11413844188055969},{"class_name":"CombineBinaryComparisons","similarity_score":0.11355449122812075},{"class_name":"CombineDisjunctions","similarity_score":0.13271889447507926},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.1500919393940964},{"class_name":"CombineProjections","similarity_score":0.13529198131278436},{"class_name":"LocalLogicalPlanOptimizerTests","similarity_score":0.10450406267077884},{"class_name":"LocalPhysicalPlanOptimizer","similarity_score":0.19077213817784947},{"class_name":"LocalPhysicalPlanOptimizerTests","similarity_score":0.13144513776424385},{"class_name":"LogicalPlanOptimizerTests","similarity_score":0.1399960326859813},{"class_name":"PhysicalPlanOptimizer","similarity_score":0.1592239310761176},{"class_name":"PhysicalPlanOptimizerTests","similarity_score":0.11202791705118056}],"target_classes_sorted_by_llm":["TestUtils","EsqlTestUtils","AnalyzerTestUtils","CsvTestUtils","ParserUtils","DateUtils","ReflectionUtils","FunctionTestUtils","ConfigurationTestUtils","StringUtils"],"llm_response_time":0,"similarity_computation_time":37,"similarity_metric":"voyage"},"limitToString":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.26462806201248157},{"class_name":"NumericUtilsTests","similarity_score":0.13398699786265802},{"class_name":"ParserUtils","similarity_score":0.37066345115720656},{"class_name":"ReflectionUtils","similarity_score":0.32977508813069667},{"class_name":"AnalyzerTestUtils","similarity_score":0.36602529427621217},{"class_name":"SerializationTestUtils","similarity_score":0.24326010240046275},{"class_name":"PlannerUtils","similarity_score":0.2634903362377809},{"class_name":"LuceneComponent2DUtils","similarity_score":0.24875809494239887},{"class_name":"ResponseValueUtils","similarity_score":0.2198717461683925},{"class_name":"ResponseXContentUtils","similarity_score":0.2924204115371706},{"class_name":"EsqlTestUtils","similarity_score":0.3738463570320348},{"class_name":"ExceptionUtils","similarity_score":0.1083590465746155},{"class_name":"SpatialRelatesUtils","similarity_score":0.23283035674533029},{"class_name":"CsvTestUtils","similarity_score":0.3722327548404369},{"class_name":"ConfigurationTestUtils","similarity_score":0.2846143454038151},{"class_name":"StringUtils","similarity_score":0.30261376633440124},{"class_name":"DateUtils","similarity_score":0.3260148988707637},{"class_name":"TestUtils","similarity_score":0.33510052044720356},{"class_name":"InferIsNotNull","similarity_score":0.2031888635868469},{"class_name":"PropagateEquals","similarity_score":0.2126059399883},{"class_name":"PropagateNullable","similarity_score":0.2554047221193985},{"class_name":"PruneColumns","similarity_score":0.24954512133085302},{"class_name":"PruneFilters","similarity_score":0.3144854510165755},{"class_name":"PruneOrderByBeforeStats","similarity_score":0.2245215079959261},{"class_name":"InsertFieldExtraction","similarity_score":0.19218555339901836},{"class_name":"PushDownAndCombineFilters","similarity_score":0.1975982084510317},{"class_name":"PushDownAndCombineLimits","similarity_score":0.23039525927364174},{"class_name":"PushFiltersToSource","similarity_score":0.26667520040962184},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.23793417659378174},{"class_name":"LocalLogicalPlanOptimizerTests","similarity_score":0.11632701372299747}],"target_classes_sorted_by_llm":["StringUtils","CsvTestUtils","TestUtils","AnalyzerTestUtils","EsqlTestUtils","ResponseXContentUtils","ParserUtils","DateUtils","ReflectionUtils","PruneFilters"],"llm_response_time":10480,"similarity_computation_time":10,"similarity_metric":"voyage"},"extractString":{"target_classes":[{"class_name":"FunctionTestUtils","similarity_score":0.29411764705882354},{"class_name":"CsvTestUtils","similarity_score":0.37059413343209263},{"class_name":"ConfigurationTestUtils","similarity_score":0.2977234438679369},{"class_name":"DateUtils","similarity_score":0.35065674355793663},{"class_name":"AnalyzerTestUtils","similarity_score":0.40681436994182163},{"class_name":"SerializationTestUtils","similarity_score":0.27036848774540756},{"class_name":"LuceneComponent2DUtils","similarity_score":0.253439234411917},{"class_name":"EsqlTestUtils","similarity_score":0.37201039514938183},{"class_name":"ExceptionUtils","similarity_score":0.12043434688555504},{"class_name":"ParserUtils","similarity_score":0.41761280944594076},{"class_name":"NumericUtilsTests","similarity_score":0.15264117778873884},{"class_name":"SpatialRelatesUtils","similarity_score":0.2364681568641107},{"class_name":"PlannerUtils","similarity_score":0.2982265875865959},{"class_name":"ReflectionUtils","similarity_score":0.3383303246607606},{"class_name":"ResponseValueUtils","similarity_score":0.23564614802336},{"class_name":"ResponseXContentUtils","similarity_score":0.31485064415925573},{"class_name":"StringUtils","similarity_score":0.3497898528780825},{"class_name":"TestUtils","similarity_score":0.37244340548233323},{"class_name":"ConstantFoldingTests","similarity_score":0.10340865294911424},{"class_name":"CombineBinaryComparisons","similarity_score":0.28122096633563637},{"class_name":"CombineDisjunctions","similarity_score":0.24729070686696794},{"class_name":"CombineProjections","similarity_score":0.291486874634402},{"class_name":"BooleanSimplification","similarity_score":0.267056416422748},{"class_name":"DuplicateLimitAfterMvExpand","similarity_score":0.3271996747087936},{"class_name":"LocalLogicalPlanOptimizerTests","similarity_score":0.12190223311681603},{"class_name":"LocalPhysicalPlanOptimizer","similarity_score":0.37787739364165146},{"class_name":"LocalPhysicalPlanOptimizerTests","similarity_score":0.11587976554684237},{"class_name":"SetAsOptimized","similarity_score":0.3105350470222685},{"class_name":"LogicalPlanOptimizerTests","similarity_score":0.08195031618758038}],"target_classes_sorted_by_llm":["StringUtils","EsqlTestUtils","TestUtils","CsvTestUtils","ReflectionUtils","AnalyzerTestUtils","DuplicateLimitAfterMvExpand","ParserUtils","LocalPhysicalPlanOptimizer","DateUtils"],"llm_response_time":0,"similarity_computation_time":23,"similarity_metric":"voyage"}}}
