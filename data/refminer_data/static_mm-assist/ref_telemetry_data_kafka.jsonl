{"id":"0954e327-06ea-4d65-be76-69de41fc876d","methodCount":12,"hostFunctionTelemetryData":{"hostFunctionSize":149,"lineStart":165,"lineEnd":313,"bodyLineStart":165,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/tools/src/test/java/org/apache/kafka/tools/FeatureCommandTest.java","sourceCode":"class FeatureCommandUnitTest {\n    @Test\n    public void testLevelToString() {\n        assertEquals(\"5\", FeatureCommand.levelToString(\"foo.bar\", (short) 5));\n        assertEquals(\"3.3-IV0\",\n                FeatureCommand.levelToString(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_3_IV0.featureLevel()));\n    }\n\n    @Test\n    public void testMetadataVersionsToString() {\n        assertEquals(\"3.3-IV0, 3.3-IV1, 3.3-IV2, 3.3-IV3\",\n                FeatureCommand.metadataVersionsToString(MetadataVersion.IBP_3_3_IV0, MetadataVersion.IBP_3_3_IV3));\n    }\n\n    @Test\n    public void testdowngradeType() {\n        assertEquals(SAFE_DOWNGRADE, FeatureCommand.downgradeType(\n                new Namespace(singletonMap(\"unsafe\", Boolean.FALSE))));\n        assertEquals(UNSAFE_DOWNGRADE, FeatureCommand.downgradeType(\n                new Namespace(singletonMap(\"unsafe\", Boolean.TRUE))));\n        assertEquals(SAFE_DOWNGRADE, FeatureCommand.downgradeType(new Namespace(emptyMap())));\n    }\n\n    @Test\n    public void testParseNameAndLevel() {\n        assertArrayEquals(new String[]{\"foo.bar\", \"5\"}, FeatureCommand.parseNameAndLevel(\"foo.bar\u003d5\"));\n        assertArrayEquals(new String[]{\"quux\", \"0\"}, FeatureCommand.parseNameAndLevel(\"quux\u003d0\"));\n        assertTrue(assertThrows(RuntimeException.class, () -\u003e FeatureCommand.parseNameAndLevel(\"baaz\"))\n                .getMessage().contains(\"Can\u0027t parse feature\u003dlevel string baaz: equals sign not found.\"));\n        assertTrue(assertThrows(RuntimeException.class, () -\u003e FeatureCommand.parseNameAndLevel(\"w\u003dtf\"))\n                .getMessage().contains(\"Can\u0027t parse feature\u003dlevel string w\u003dtf: unable to parse tf as a short.\"));\n    }\n\n    private static MockAdminClient buildAdminClient() {\n        Map\u003cString, Short\u003e minSupportedFeatureLevels \u003d new HashMap\u003c\u003e();\n        minSupportedFeatureLevels.put(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_3_IV0.featureLevel());\n        minSupportedFeatureLevels.put(\"foo.bar\", (short) 0);\n\n        Map\u003cString, Short\u003e featureLevels \u003d new HashMap\u003c\u003e();\n        featureLevels.put(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_3_IV2.featureLevel());\n        featureLevels.put(\"foo.bar\", (short) 5);\n\n        Map\u003cString, Short\u003e maxSupportedFeatureLevels \u003d new HashMap\u003c\u003e();\n        maxSupportedFeatureLevels.put(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_3_IV3.featureLevel());\n        maxSupportedFeatureLevels.put(\"foo.bar\", (short) 10);\n\n        return new MockAdminClient.Builder().\n                minSupportedFeatureLevels(minSupportedFeatureLevels).\n                featureLevels(featureLevels).\n                maxSupportedFeatureLevels(maxSupportedFeatureLevels).build();\n    }\n\n    @Test\n    public void testHandleDescribe() {\n        String describeResult \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            try {\n                FeatureCommand.handleDescribe(buildAdminClient());\n            } catch (Exception e) {\n                throw new RuntimeException(e);\n            }\n        });\n        assertEquals(format(\"Feature: foo.bar\\tSupportedMinVersion: 0\\tSupportedMaxVersion: 10\\tFinalizedVersionLevel: 5\\tEpoch: 123%n\" +\n                \"Feature: metadata.version\\tSupportedMinVersion: 3.3-IV0\\tSupportedMaxVersion: 3.3-IV3\\tFinalizedVersionLevel: 3.3-IV2\\tEpoch: 123\"), describeResult);\n    }\n\n    @Test\n    public void testHandleUpgrade() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"metadata\", \"3.3-IV1\");\n        namespace.put(\"feature\", Collections.singletonList(\"foo.bar\u003d6\"));\n        namespace.put(\"dry_run\", false);\n        String upgradeOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleUpgrade(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 2 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar was upgraded to 6.%n\" +\n                \"Could not upgrade metadata.version to 5. Can\u0027t upgrade to lower version.\"), upgradeOutput);\n    }\n\n    @Test\n    public void testHandleUpgradeDryRun() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"metadata\", \"3.3-IV1\");\n        namespace.put(\"feature\", Collections.singletonList(\"foo.bar\u003d6\"));\n        namespace.put(\"dry_run\", true);\n        String upgradeOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleUpgrade(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 2 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar can be upgraded to 6.%n\" +\n                \"Can not upgrade metadata.version to 5. Can\u0027t upgrade to lower version.\"), upgradeOutput);\n    }\n\n    @Test\n    public void testHandleDowngrade() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"metadata\", \"3.3-IV3\");\n        namespace.put(\"feature\", Collections.singletonList(\"foo.bar\u003d1\"));\n        namespace.put(\"dry_run\", false);\n        String downgradeOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleDowngrade(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 2 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar was downgraded to 1.%n\" +\n                \"Could not downgrade metadata.version to 7. Can\u0027t downgrade to newer version.\"), downgradeOutput);\n    }\n\n    @Test\n    public void testHandleDowngradeDryRun() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"metadata\", \"3.3-IV3\");\n        namespace.put(\"feature\", Collections.singletonList(\"foo.bar\u003d1\"));\n        namespace.put(\"dry_run\", true);\n        String downgradeOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleDowngrade(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 2 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar can be downgraded to 1.%n\" +\n                \"Can not downgrade metadata.version to 7. Can\u0027t downgrade to newer version.\"), downgradeOutput);\n    }\n\n    @Test\n    public void testHandleDisable() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"feature\", Arrays.asList(\"foo.bar\", \"metadata.version\", \"quux\"));\n        namespace.put(\"dry_run\", false);\n        String disableOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleDisable(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 3 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar was disabled.%n\" +\n                \"Could not disable metadata.version. Can\u0027t downgrade below 4%n\" +\n                \"quux was disabled.\"), disableOutput);\n    }\n\n    @Test\n    public void testHandleDisableDryRun() {\n        Map\u003cString, Object\u003e namespace \u003d new HashMap\u003c\u003e();\n        namespace.put(\"feature\", Arrays.asList(\"foo.bar\", \"metadata.version\", \"quux\"));\n        namespace.put(\"dry_run\", true);\n        String disableOutput \u003d ToolsTestUtils.captureStandardOut(() -\u003e {\n            Throwable t \u003d assertThrows(TerseException.class, () -\u003e FeatureCommand.handleDisable(new Namespace(namespace), buildAdminClient()));\n            assertTrue(t.getMessage().contains(\"1 out of 3 operation(s) failed.\"));\n        });\n        assertEquals(format(\"foo.bar can be disabled.%n\" +\n                \"Can not disable metadata.version. Can\u0027t downgrade below 4%n\" +\n                \"quux can be disabled.\"), disableOutput);\n    }\n}","methodCount":12},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":197,"lineEnd":214,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAdminClient to class AssignmentTestUtils","description":"move method buildAdminClient to PsiClass:AssignmentTestUtils\nRationale: The buildAdminClient() method is responsible for creating a MockAdminClient, which is closely related to the assignment logic in AssignmentTestUtils. Moving this method here adheres to the Single Responsibility Principle, as it consolidates utility functions related to client management and assignment testing. This improves cohesion and makes the method more reusable in assignment-related tests. However, care must be taken to ensure that the method\u0027s dependencies on specific feature levels do not clutter the utility class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":197,"lineEnd":214,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAdminClient to class ToolsTestUtils","description":"move method buildAdminClient to PsiClass:ToolsTestUtils\nRationale: ToolsTestUtils is a general-purpose utility class that provides various testing utilities. Moving buildAdminClient() here would centralize the client-building logic, enhancing reusability across different tests. This aligns with the Open/Closed Principle, as it allows for extension without modifying existing code. However, it may dilute the focus of ToolsTestUtils if it becomes overloaded with client-specific logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":197,"lineEnd":214,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildAdminClient to class ClientMetricsTestUtils","description":"move method buildAdminClient to PsiClass:ClientMetricsTestUtils\nRationale: ClientMetricsTestUtils is focused on client-related testing. Moving buildAdminClient() here would enhance the class\u0027s utility by providing a way to create mock clients for testing client metrics. This aligns with the Single Responsibility Principle, as it keeps client-related functionalities together. However, it may require additional context or parameters to ensure the method\u0027s flexibility.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"buildAdminClient","method_signature":"private static buildAdminClient()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"buildAdminClient","method_signature":"private static buildAdminClient()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static buildAdminClient()":{"first":{"method_name":"buildAdminClient","method_signature":"private static buildAdminClient()","target_class":"","rationale":""},"second":0.31948282183647037}},"llmMethodPriority":{"priority_method_names":["buildAdminClient"],"llm_response_time":1234},"targetClassMap":{"buildAdminClient":{"target_classes":[{"class_name":"CsvUtils","similarity_score":0.2896953082939204},{"class_name":"ConsumerGroupCommandTestUtils","similarity_score":0.34925651638496286},{"class_name":"ToolsTestUtils","similarity_score":0.3749597139270878},{"class_name":"ToolsUtils","similarity_score":0.3250481933958116},{"class_name":"RequestTestUtils","similarity_score":0.2811316875405122},{"class_name":"RequestUtils","similarity_score":0.2620133544003864},{"class_name":"RetryUtil","similarity_score":0.1413518753084809},{"class_name":"AdminClientTestUtils","similarity_score":0.2944208835381293},{"class_name":"AdminUtils","similarity_score":0.21111745318195643},{"class_name":"OffsetFetcherUtils","similarity_score":0.32980161379041123},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.3341425187651616},{"class_name":"OffsetUtils","similarity_score":0.1557827251499392},{"class_name":"LogFileUtils","similarity_score":0.07176340018275494},{"class_name":"SchemaUtil","similarity_score":0.27468064139978915},{"class_name":"MetricsTestUtils","similarity_score":0.30574067067809085},{"class_name":"MetricsUtils","similarity_score":0.16333635810871314},{"class_name":"NetworkClientUtils","similarity_score":0.14407733193541963},{"class_name":"ScramCredentialUtils","similarity_score":0.33613646607466174},{"class_name":"NetworkTestUtils","similarity_score":0.2694615352141151},{"class_name":"PluginUtils","similarity_score":0.2502641506511729},{"class_name":"MirrorUtils","similarity_score":0.24742846068258284},{"class_name":"ApiUtils","similarity_score":0.23900244784011815},{"class_name":"MockitoUtils","similarity_score":0.04146145171645056},{"class_name":"SecurityUtils","similarity_score":0.3467913212472622},{"class_name":"ProcessorContextUtils","similarity_score":0.1971447096040996},{"class_name":"ProducerTestUtils","similarity_score":0.1747161147295357},{"class_name":"PropertiesUtils","similarity_score":0.25683040366015253},{"class_name":"AssignmentTestUtil","similarity_score":0.29554004461167865},{"class_name":"AssignmentTestUtils","similarity_score":0.40664095878142864},{"class_name":"OAuthBearerScopeUtils","similarity_score":0.11303231465211397},{"class_name":"OAuthBearerValidationUtils","similarity_score":0.08811061757696427},{"class_name":"OAuthBearerValidationUtilsTest","similarity_score":0.381218548220955},{"class_name":"MessageUtil","similarity_score":0.28457480056984624},{"class_name":"FutureUtils","similarity_score":0.14729750787289733},{"class_name":"AuthorizerUtils","similarity_score":0.17301336577538542},{"class_name":"QuorumControllerIntegrationTestUtils","similarity_score":0.24922673703300766},{"class_name":"FetchUtils","similarity_score":0.01931812693721734},{"class_name":"ExceptionUtils","similarity_score":0.2493916090006894},{"class_name":"IntegrationTestUtils","similarity_score":0.20601343493896743},{"class_name":"RaftUtil","similarity_score":0.20164460885139515},{"class_name":"InternalQueryResultUtil","similarity_score":0.17932465457586946},{"class_name":"ClaimValidationUtils","similarity_score":0.07669015580713771},{"class_name":"SinkUtils","similarity_score":0.2823546315027159},{"class_name":"GraphGraceSearchUtil","similarity_score":0.2607274230136563},{"class_name":"SmokeTestUtil","similarity_score":0.2716497439264888},{"class_name":"RecordsUtil","similarity_score":0.24422500434906544},{"class_name":"RecordTestUtils","similarity_score":0.3030265079429215},{"class_name":"ClientMetricsTestUtils","similarity_score":0.3578810105803186},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.359351092065849},{"class_name":"ClientTelemetryUtils","similarity_score":0.30313945127737846}],"target_classes_sorted_by_llm":["AssignmentTestUtils","ToolsTestUtils","ClientMetricsTestUtils","ConsumerGroupCommandTestUtils","SecurityUtils","OffsetsForLeaderEpochUtils","OffsetFetcherUtils","ScramCredentialUtils","ControllerMetricsTestUtils","OAuthBearerValidationUtilsTest"],"llm_response_time":10564,"similarity_computation_time":206,"similarity_metric":"voyage"}}}
{"id":"b3529148-5497-41e0-abcd-24a2a55e93c2","methodCount":48,"hostFunctionTelemetryData":{"hostFunctionSize":1230,"lineStart":47,"lineEnd":1276,"bodyLineStart":47,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/connect/api/src/main/java/org/apache/kafka/connect/data/Values.java","sourceCode":"/**\n * Utility for converting from one Connect value to a different form. This is useful when the caller expects a value of a particular type\n * but is uncertain whether the actual value is one that isn\u0027t directly that type but can be converted into that type.\n *\n * \u003cp\u003eFor example, a caller might expect a particular {@link org.apache.kafka.connect.header.Header} to contain a {@link Type#INT64}\n * value, when in fact that header contains a string representation of a 32-bit integer. Here, the caller can use the methods in this\n * class to convert the value to the desired type:\n * \u003cpre\u003e\n *     Header header \u003d ...\n *     long value \u003d Values.convertToLong(header.schema(), header.value());\n * \u003c/pre\u003e\n *\n * \u003cp\u003eThis class is able to convert any value to a string representation as well as parse those string representations back into most of\n * the types. The only exception is {@link Struct} values that require a schema and thus cannot be parsed from a simple string.\n */\npublic class Values {\n\n    private static final Logger LOG \u003d LoggerFactory.getLogger(Values.class);\n\n    private static final TimeZone UTC \u003d TimeZone.getTimeZone(\"UTC\");\n    private static final SchemaAndValue NULL_SCHEMA_AND_VALUE \u003d new SchemaAndValue(null, null);\n    private static final SchemaAndValue TRUE_SCHEMA_AND_VALUE \u003d new SchemaAndValue(Schema.BOOLEAN_SCHEMA, Boolean.TRUE);\n    private static final SchemaAndValue FALSE_SCHEMA_AND_VALUE \u003d new SchemaAndValue(Schema.BOOLEAN_SCHEMA, Boolean.FALSE);\n    private static final Schema ARRAY_SELECTOR_SCHEMA \u003d SchemaBuilder.array(Schema.STRING_SCHEMA).build();\n    private static final Schema MAP_SELECTOR_SCHEMA \u003d SchemaBuilder.map(Schema.STRING_SCHEMA, Schema.STRING_SCHEMA).build();\n    private static final Schema STRUCT_SELECTOR_SCHEMA \u003d SchemaBuilder.struct().build();\n    private static final String TRUE_LITERAL \u003d Boolean.TRUE.toString();\n    private static final String FALSE_LITERAL \u003d Boolean.FALSE.toString();\n    private static final long MILLIS_PER_DAY \u003d 24 * 60 * 60 * 1000;\n    private static final String NULL_VALUE \u003d \"null\";\n    static final String ISO_8601_DATE_FORMAT_PATTERN \u003d \"yyyy-MM-dd\";\n    static final String ISO_8601_TIME_FORMAT_PATTERN \u003d \"HH:mm:ss.SSS\u0027Z\u0027\";\n    static final String ISO_8601_TIMESTAMP_FORMAT_PATTERN \u003d ISO_8601_DATE_FORMAT_PATTERN + \"\u0027T\u0027\" + ISO_8601_TIME_FORMAT_PATTERN;\n    private static final Set\u003cString\u003e TEMPORAL_LOGICAL_TYPE_NAMES \u003d\n            Collections.unmodifiableSet(\n                    new HashSet\u003c\u003e(\n                            Arrays.asList(Time.LOGICAL_NAME,\n                            Timestamp.LOGICAL_NAME,\n                            Date.LOGICAL_NAME\n                            )\n                    )\n            );\n\n    private static final String QUOTE_DELIMITER \u003d \"\\\"\";\n    private static final String COMMA_DELIMITER \u003d \",\";\n    private static final String ENTRY_DELIMITER \u003d \":\";\n    private static final String ARRAY_BEGIN_DELIMITER \u003d \"[\";\n    private static final String ARRAY_END_DELIMITER \u003d \"]\";\n    private static final String MAP_BEGIN_DELIMITER \u003d \"{\";\n    private static final String MAP_END_DELIMITER \u003d \"}\";\n    private static final int ISO_8601_DATE_LENGTH \u003d ISO_8601_DATE_FORMAT_PATTERN.length();\n    private static final int ISO_8601_TIME_LENGTH \u003d ISO_8601_TIME_FORMAT_PATTERN.length() - 2; // subtract single quotes\n    private static final int ISO_8601_TIMESTAMP_LENGTH \u003d ISO_8601_TIMESTAMP_FORMAT_PATTERN.length() - 4; // subtract single quotes\n\n    private static final Pattern TWO_BACKSLASHES \u003d Pattern.compile(\"\\\\\\\\\");\n\n    private static final Pattern DOUBLE_QUOTE \u003d Pattern.compile(\"\\\"\");\n\n    /**\n     * Convert the specified value to a {@link Type#BOOLEAN} value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a boolean.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a boolean, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a boolean\n     */\n    public static Boolean convertToBoolean(Schema schema, Object value) throws DataException {\n        return (Boolean) convertTo(Schema.OPTIONAL_BOOLEAN_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to an {@link Type#INT8} byte value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a byte.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a byte, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a byte\n     */\n    public static Byte convertToByte(Schema schema, Object value) throws DataException {\n        return (Byte) convertTo(Schema.OPTIONAL_INT8_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to an {@link Type#INT16} short value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a short.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a short, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a short\n     */\n    public static Short convertToShort(Schema schema, Object value) throws DataException {\n        return (Short) convertTo(Schema.OPTIONAL_INT16_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to an {@link Type#INT32} int value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to an integer.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as an integer, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to an integer\n     */\n    public static Integer convertToInteger(Schema schema, Object value) throws DataException {\n        return (Integer) convertTo(Schema.OPTIONAL_INT32_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to an {@link Type#INT64} long value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a long.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a long, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a long\n     */\n    public static Long convertToLong(Schema schema, Object value) throws DataException {\n        return (Long) convertTo(Schema.OPTIONAL_INT64_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Type#FLOAT32} float value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a floating point number.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a float, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a float\n     */\n    public static Float convertToFloat(Schema schema, Object value) throws DataException {\n        return (Float) convertTo(Schema.OPTIONAL_FLOAT32_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Type#FLOAT64} double value. The supplied schema is required if the value is a logical\n     * type when the schema contains critical information that might be necessary for converting to a floating point number.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a double, or null if the supplied value was null\n     * @throws DataException if the value could not be converted to a double\n     */\n    public static Double convertToDouble(Schema schema, Object value) throws DataException {\n        return (Double) convertTo(Schema.OPTIONAL_FLOAT64_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Type#STRING} value.\n     * Not supplying a schema may limit the ability to convert to the desired type.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a string, or null if the supplied value was null\n     */\n    public static String convertToString(Schema schema, Object value) {\n        return (String) convertTo(Schema.OPTIONAL_STRING_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to an {@link Type#ARRAY} value. If the value is a string representation of an array, this method\n     * will parse the string and its elements to infer the schemas for those elements. Thus, this method supports\n     * arrays of other primitives and structured types. If the value is already an array (or list), this method simply casts and\n     * returns it.\n     *\n     * \u003cp\u003eThis method currently does not use the schema, though it may be used in the future.\u003c/p\u003e\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a list, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a list value\n     */\n    public static List\u003c?\u003e convertToList(Schema schema, Object value) {\n        return (List\u003c?\u003e) convertTo(ARRAY_SELECTOR_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Type#MAP} value. If the value is a string representation of a map, this method\n     * will parse the string and its entries to infer the schemas for those entries. Thus, this method supports\n     * maps with primitives and structured keys and values. If the value is already a map, this method simply casts and returns it.\n     *\n     * \u003cp\u003eThis method currently does not use the schema, though it may be used in the future.\u003c/p\u003e\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a map, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a map value\n     */\n    public static Map\u003c?, ?\u003e convertToMap(Schema schema, Object value) {\n        return (Map\u003c?, ?\u003e) convertTo(MAP_SELECTOR_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Type#STRUCT} value. Structs cannot be converted from other types, so this method returns\n     * a struct only if the supplied value is a struct. If not a struct, this method throws an exception.\n     *\n     * \u003cp\u003eThis method currently does not use the schema, though it may be used in the future.\u003c/p\u003e\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a struct, or null if the supplied value was null\n     * @throws DataException if the value is not a struct\n     */\n    public static Struct convertToStruct(Schema schema, Object value) {\n        return (Struct) convertTo(STRUCT_SELECTOR_SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Time#SCHEMA time} value.\n     * Not supplying a schema may limit the ability to convert to the desired type.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a time, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a time value\n     */\n    public static java.util.Date convertToTime(Schema schema, Object value) {\n        return (java.util.Date) convertTo(Time.SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Date#SCHEMA date} value.\n     * Not supplying a schema may limit the ability to convert to the desired type.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a date, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a date value\n     */\n    public static java.util.Date convertToDate(Schema schema, Object value) {\n        return (java.util.Date) convertTo(Date.SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Timestamp#SCHEMA timestamp} value.\n     * Not supplying a schema may limit the ability to convert to the desired type.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a timestamp, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a timestamp value\n     */\n    public static java.util.Date convertToTimestamp(Schema schema, Object value) {\n        return (java.util.Date) convertTo(Timestamp.SCHEMA, schema, value);\n    }\n\n    /**\n     * Convert the specified value to a {@link Decimal decimal} value.\n     * Not supplying a schema may limit the ability to convert to the desired type.\n     *\n     * @param schema the schema for the value; may be null\n     * @param value  the value to be converted; may be null\n     * @return the representation as a decimal, or null if the supplied value was null\n     * @throws DataException if the value cannot be converted to a decimal value\n     */\n    public static BigDecimal convertToDecimal(Schema schema, Object value, int scale) {\n        return (BigDecimal) convertTo(Decimal.schema(scale), schema, value);\n    }\n\n    /**\n     * If possible infer a schema for the given value.\n     *\n     * @param value the value whose schema is to be inferred; may be null\n     * @return the inferred schema, or null if the value is null or no schema could be inferred\n     */\n    public static Schema inferSchema(Object value) {\n        if (value instanceof String) {\n            return Schema.STRING_SCHEMA;\n        }\n        if (value instanceof Boolean) {\n            return Schema.BOOLEAN_SCHEMA;\n        }\n        if (value instanceof Byte) {\n            return Schema.INT8_SCHEMA;\n        }\n        if (value instanceof Short) {\n            return Schema.INT16_SCHEMA;\n        }\n        if (value instanceof Integer) {\n            return Schema.INT32_SCHEMA;\n        }\n        if (value instanceof Long) {\n            return Schema.INT64_SCHEMA;\n        }\n        if (value instanceof Float) {\n            return Schema.FLOAT32_SCHEMA;\n        }\n        if (value instanceof Double) {\n            return Schema.FLOAT64_SCHEMA;\n        }\n        if (value instanceof byte[] || value instanceof ByteBuffer) {\n            return Schema.BYTES_SCHEMA;\n        }\n        if (value instanceof List) {\n            List\u003c?\u003e list \u003d (List\u003c?\u003e) value;\n            if (list.isEmpty()) {\n                return null;\n            }\n            SchemaDetector detector \u003d new SchemaDetector();\n            for (Object element : list) {\n                if (!detector.canDetect(element)) {\n                    return null;\n                }\n            }\n            return SchemaBuilder.array(detector.schema()).build();\n        }\n        if (value instanceof Map) {\n            Map\u003c?, ?\u003e map \u003d (Map\u003c?, ?\u003e) value;\n            if (map.isEmpty()) {\n                return null;\n            }\n            SchemaDetector keyDetector \u003d new SchemaDetector();\n            SchemaDetector valueDetector \u003d new SchemaDetector();\n            for (Map.Entry\u003c?, ?\u003e entry : map.entrySet()) {\n                if (!keyDetector.canDetect(entry.getKey()) || !valueDetector.canDetect(entry.getValue())) {\n                    return null;\n                }\n            }\n            return SchemaBuilder.map(keyDetector.schema(), valueDetector.schema()).build();\n        }\n        if (value instanceof Struct) {\n            return ((Struct) value).schema();\n        }\n        return null;\n    }\n\n\n    /**\n     * Parse the specified string representation of a value into its schema and value.\n     *\n     * @param value the string form of the value\n     * @return the schema and value; never null, but whose schema and value may be null\n     * @see #convertToString\n     */\n    public static SchemaAndValue parseString(String value) {\n        if (value \u003d\u003d null) {\n            return NULL_SCHEMA_AND_VALUE;\n        }\n        if (value.isEmpty()) {\n            return new SchemaAndValue(Schema.STRING_SCHEMA, value);\n        }\n        Parser parser \u003d new Parser(value);\n        return parse(parser, false);\n    }\n\n    /**\n     * Convert the value to the desired type.\n     *\n     * @param toSchema   the schema for the desired type; may not be null\n     * @param fromSchema the schema for the supplied value; may be null if not known\n     * @return the converted value; never null\n     * @throws DataException if the value could not be converted to the desired type\n     */\n    protected static Object convertTo(Schema toSchema, Schema fromSchema, Object value) throws DataException {\n        if (value \u003d\u003d null) {\n            if (toSchema.isOptional()) {\n                return null;\n            }\n            throw new DataException(\"Unable to convert a null value to a schema that requires a value\");\n        }\n        switch (toSchema.type()) {\n            case BYTES:\n                if (Decimal.LOGICAL_NAME.equals(toSchema.name())) {\n                    if (value instanceof ByteBuffer) {\n                        value \u003d Utils.toArray((ByteBuffer) value);\n                    }\n                    if (value instanceof byte[]) {\n                        return Decimal.toLogical(toSchema, (byte[]) value);\n                    }\n                    if (value instanceof BigDecimal) {\n                        return value;\n                    }\n                    if (value instanceof Number) {\n                        // Not already a decimal, so treat it as a double ...\n                        double converted \u003d ((Number) value).doubleValue();\n                        return BigDecimal.valueOf(converted);\n                    }\n                    if (value instanceof String) {\n                        return new BigDecimal(value.toString());\n                    }\n                }\n                if (value instanceof ByteBuffer) {\n                    return Utils.toArray((ByteBuffer) value);\n                }\n                if (value instanceof byte[]) {\n                    return value;\n                }\n                if (value instanceof BigDecimal) {\n                    return Decimal.fromLogical(toSchema, (BigDecimal) value);\n                }\n                break;\n            case STRING:\n                StringBuilder sb \u003d new StringBuilder();\n                append(sb, value, false);\n                return sb.toString();\n            case BOOLEAN:\n                if (value instanceof Boolean) {\n                    return value;\n                }\n                if (value instanceof String) {\n                    SchemaAndValue parsed \u003d parseString(value.toString());\n                    if (parsed.value() instanceof Boolean) {\n                        return parsed.value();\n                    }\n                }\n                return asLong(value, fromSchema, null) \u003d\u003d 0L ? Boolean.FALSE : Boolean.TRUE;\n            case INT8:\n                if (value instanceof Byte) {\n                    return value;\n                }\n                return (byte) asLong(value, fromSchema, null);\n            case INT16:\n                if (value instanceof Short) {\n                    return value;\n                }\n                return (short) asLong(value, fromSchema, null);\n            case INT32:\n                if (Date.LOGICAL_NAME.equals(toSchema.name())) {\n                    if (value instanceof String) {\n                        SchemaAndValue parsed \u003d parseString(value.toString());\n                        value \u003d parsed.value();\n                    }\n                    if (value instanceof java.util.Date) {\n                        if (fromSchema !\u003d null) {\n                            String fromSchemaName \u003d fromSchema.name();\n                            if (Date.LOGICAL_NAME.equals(fromSchemaName)) {\n                                return value;\n                            }\n                            if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                                // Just get the number of days from this timestamp\n                                long millis \u003d ((java.util.Date) value).getTime();\n                                int days \u003d (int) (millis / MILLIS_PER_DAY); // truncates\n                                return Date.toLogical(toSchema, days);\n                            }\n                        } else {\n                            // There is no fromSchema, so no conversion is needed\n                            return value;\n                        }\n                    }\n                    long numeric \u003d asLong(value, fromSchema, null);\n                    return Date.toLogical(toSchema, (int) numeric);\n                }\n                if (Time.LOGICAL_NAME.equals(toSchema.name())) {\n                    if (value instanceof String) {\n                        SchemaAndValue parsed \u003d parseString(value.toString());\n                        value \u003d parsed.value();\n                    }\n                    if (value instanceof java.util.Date) {\n                        if (fromSchema !\u003d null) {\n                            String fromSchemaName \u003d fromSchema.name();\n                            if (Time.LOGICAL_NAME.equals(fromSchemaName)) {\n                                return value;\n                            }\n                            if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                                // Just get the time portion of this timestamp\n                                Calendar calendar \u003d Calendar.getInstance(UTC);\n                                calendar.setTime((java.util.Date) value);\n                                calendar.set(Calendar.YEAR, 1970);\n                                calendar.set(Calendar.MONTH, 0); // Months are zero-based\n                                calendar.set(Calendar.DAY_OF_MONTH, 1);\n                                return Time.toLogical(toSchema, (int) calendar.getTimeInMillis());\n                            }\n                        } else {\n                            // There is no fromSchema, so no conversion is needed\n                            return value;\n                        }\n                    }\n                    long numeric \u003d asLong(value, fromSchema, null);\n                    return Time.toLogical(toSchema, (int) numeric);\n                }\n                if (value instanceof Integer) {\n                    return value;\n                }\n                return (int) asLong(value, fromSchema, null);\n            case INT64:\n                if (Timestamp.LOGICAL_NAME.equals(toSchema.name())) {\n                    if (value instanceof String) {\n                        SchemaAndValue parsed \u003d parseString(value.toString());\n                        value \u003d parsed.value();\n                    }\n                    if (value instanceof java.util.Date) {\n                        java.util.Date date \u003d (java.util.Date) value;\n                        if (fromSchema !\u003d null) {\n                            String fromSchemaName \u003d fromSchema.name();\n                            if (Date.LOGICAL_NAME.equals(fromSchemaName)) {\n                                int days \u003d Date.fromLogical(fromSchema, date);\n                                long millis \u003d days * MILLIS_PER_DAY;\n                                return Timestamp.toLogical(toSchema, millis);\n                            }\n                            if (Time.LOGICAL_NAME.equals(fromSchemaName)) {\n                                long millis \u003d Time.fromLogical(fromSchema, date);\n                                return Timestamp.toLogical(toSchema, millis);\n                            }\n                            if (Timestamp.LOGICAL_NAME.equals(fromSchemaName)) {\n                                return value;\n                            }\n                        } else {\n                            // There is no fromSchema, so no conversion is needed\n                            return value;\n                        }\n                    }\n                    long numeric \u003d asLong(value, fromSchema, null);\n                    return Timestamp.toLogical(toSchema, numeric);\n                }\n                if (value instanceof Long) {\n                    return value;\n                }\n                return asLong(value, fromSchema, null);\n            case FLOAT32:\n                if (value instanceof Float) {\n                    return value;\n                }\n                return (float) asDouble(value, fromSchema, null);\n            case FLOAT64:\n                if (value instanceof Double) {\n                    return value;\n                }\n                return asDouble(value, fromSchema, null);\n            case ARRAY:\n                if (value instanceof String) {\n                    SchemaAndValue schemaAndValue \u003d parseString(value.toString());\n                    value \u003d schemaAndValue.value();\n                }\n                if (value instanceof List) {\n                    return value;\n                }\n                break;\n            case MAP:\n                if (value instanceof String) {\n                    SchemaAndValue schemaAndValue \u003d parseString(value.toString());\n                    value \u003d schemaAndValue.value();\n                }\n                if (value instanceof Map) {\n                    return value;\n                }\n                break;\n            case STRUCT:\n                if (value instanceof Struct) {\n                    return value;\n                }\n        }\n        throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to \" + toSchema);\n    }\n\n    /**\n     * Convert the specified value to the desired scalar value type.\n     *\n     * @param value      the value to be converted; may not be null\n     * @param fromSchema the schema for the current value type; may not be null\n     * @param error      any previous error that should be included in an exception message; may be null\n     * @return the long value after conversion; never null\n     * @throws DataException if the value could not be converted to a long\n     */\n    protected static long asLong(Object value, Schema fromSchema, Throwable error) {\n        try {\n            if (value instanceof Number) {\n                Number number \u003d (Number) value;\n                return number.longValue();\n            }\n            if (value instanceof String) {\n                return new BigDecimal(value.toString()).longValue();\n            }\n        } catch (NumberFormatException e) {\n            error \u003d e;\n            // fall through\n        }\n        if (fromSchema !\u003d null) {\n            String schemaName \u003d fromSchema.name();\n            if (value instanceof java.util.Date) {\n                if (Date.LOGICAL_NAME.equals(schemaName)) {\n                    return Date.fromLogical(fromSchema, (java.util.Date) value);\n                }\n                if (Time.LOGICAL_NAME.equals(schemaName)) {\n                    return Time.fromLogical(fromSchema, (java.util.Date) value);\n                }\n                if (Timestamp.LOGICAL_NAME.equals(schemaName)) {\n                    return Timestamp.fromLogical(fromSchema, (java.util.Date) value);\n                }\n            }\n            throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to \" + fromSchema, error);\n        }\n        throw new DataException(\"Unable to convert \" + value + \" (\" + value.getClass() + \") to a number\", error);\n    }\n\n    /**\n     * Convert the specified value with the desired floating point type.\n     *\n     * @param value  the value to be converted; may not be null\n     * @param schema the schema for the current value type; may not be null\n     * @param error  any previous error that should be included in an exception message; may be null\n     * @return the double value after conversion; never null\n     * @throws DataException if the value could not be converted to a double\n     */\n    protected static double asDouble(Object value, Schema schema, Throwable error) {\n        try {\n            if (value instanceof Number) {\n                Number number \u003d (Number) value;\n                return number.doubleValue();\n            }\n            if (value instanceof String) {\n                return new BigDecimal(value.toString()).doubleValue();\n            }\n        } catch (NumberFormatException e) {\n            error \u003d e;\n            // fall through\n        }\n        return asLong(value, schema, error);\n    }\n\n    protected static void append(StringBuilder sb, Object value, boolean embedded) {\n        if (value \u003d\u003d null) {\n            sb.append(NULL_VALUE);\n        } else if (value instanceof Number) {\n            sb.append(value);\n        } else if (value instanceof Boolean) {\n            sb.append(value);\n        } else if (value instanceof String) {\n            if (embedded) {\n                String escaped \u003d escape((String) value);\n                sb.append(\u0027\"\u0027).append(escaped).append(\u0027\"\u0027);\n            } else {\n                sb.append(value);\n            }\n        } else if (value instanceof byte[]) {\n            value \u003d Base64.getEncoder().encodeToString((byte[]) value);\n            if (embedded) {\n                sb.append(\u0027\"\u0027).append(value).append(\u0027\"\u0027);\n            } else {\n                sb.append(value);\n            }\n        } else if (value instanceof ByteBuffer) {\n            byte[] bytes \u003d Utils.readBytes((ByteBuffer) value);\n            append(sb, bytes, embedded);\n        } else if (value instanceof List) {\n            List\u003c?\u003e list \u003d (List\u003c?\u003e) value;\n            sb.append(\u0027[\u0027);\n            appendIterable(sb, list.iterator());\n            sb.append(\u0027]\u0027);\n        } else if (value instanceof Map) {\n            Map\u003c?, ?\u003e map \u003d (Map\u003c?, ?\u003e) value;\n            sb.append(\u0027{\u0027);\n            appendIterable(sb, map.entrySet().iterator());\n            sb.append(\u0027}\u0027);\n        } else if (value instanceof Struct) {\n            Struct struct \u003d (Struct) value;\n            Schema schema \u003d struct.schema();\n            boolean first \u003d true;\n            sb.append(\u0027{\u0027);\n            for (Field field : schema.fields()) {\n                if (first) {\n                    first \u003d false;\n                } else {\n                    sb.append(\u0027,\u0027);\n                }\n                append(sb, field.name(), true);\n                sb.append(\u0027:\u0027);\n                append(sb, struct.get(field), true);\n            }\n            sb.append(\u0027}\u0027);\n        } else if (value instanceof Map.Entry) {\n            Map.Entry\u003c?, ?\u003e entry \u003d (Map.Entry\u003c?, ?\u003e) value;\n            append(sb, entry.getKey(), true);\n            sb.append(\u0027:\u0027);\n            append(sb, entry.getValue(), true);\n        } else if (value instanceof java.util.Date) {\n            java.util.Date dateValue \u003d (java.util.Date) value;\n            String formatted \u003d dateFormatFor(dateValue).format(dateValue);\n            sb.append(formatted);\n        } else {\n            throw new DataException(\"Failed to serialize unexpected value type \" + value.getClass().getName() + \": \" + value);\n        }\n    }\n\n    protected static void appendIterable(StringBuilder sb, Iterator\u003c?\u003e iter) {\n        if (iter.hasNext()) {\n            append(sb, iter.next(), true);\n            while (iter.hasNext()) {\n                sb.append(\u0027,\u0027);\n                append(sb, iter.next(), true);\n            }\n        }\n    }\n\n    protected static String escape(String value) {\n        String replace1 \u003d TWO_BACKSLASHES.matcher(value).replaceAll(\"\\\\\\\\\\\\\\\\\");\n        return DOUBLE_QUOTE.matcher(replace1).replaceAll(\"\\\\\\\\\\\"\");\n    }\n\n    public static DateFormat dateFormatFor(java.util.Date value) {\n        if (value.getTime() \u003c MILLIS_PER_DAY) {\n            return new SimpleDateFormat(ISO_8601_TIME_FORMAT_PATTERN);\n        }\n        if (value.getTime() % MILLIS_PER_DAY \u003d\u003d 0) {\n            return new SimpleDateFormat(ISO_8601_DATE_FORMAT_PATTERN);\n        }\n        return new SimpleDateFormat(ISO_8601_TIMESTAMP_FORMAT_PATTERN);\n    }\n\n    protected static boolean canParseSingleTokenLiteral(Parser parser, boolean embedded, String tokenLiteral) {\n        int startPosition \u003d parser.mark();\n        // If the next token is what we expect, then either...\n        if (parser.canConsume(tokenLiteral)) {\n            //   ...we\u0027re reading an embedded value, in which case the next token will be handled appropriately\n            //      by the caller if it\u0027s something like an end delimiter for a map or array, or a comma to\n            //      separate multiple embedded values...\n            //   ...or it\u0027s being parsed as part of a top-level string, in which case, any other tokens should\n            //      cause use to stop parsing this single-token literal as such and instead just treat it like\n            //      a string. For example, the top-level string \"true}\" will be tokenized as the tokens \"true\" and\n            //      \"}\", but should ultimately be parsed as just the string \"true}\" instead of the boolean true.\n            if (embedded || !parser.hasNext()) {\n                return true;\n            }\n        }\n        parser.rewindTo(startPosition);\n        return false;\n    }\n\n    protected static SchemaAndValue parse(Parser parser, boolean embedded) throws NoSuchElementException {\n        if (!parser.hasNext()) {\n            return null;\n        }\n        if (embedded) {\n            if (parser.canConsume(QUOTE_DELIMITER)) {\n                StringBuilder sb \u003d new StringBuilder();\n                while (parser.hasNext()) {\n                    if (parser.canConsume(QUOTE_DELIMITER)) {\n                        break;\n                    }\n                    sb.append(parser.next());\n                }\n                String content \u003d sb.toString();\n                // We can parse string literals as temporal logical types, but all others\n                // are treated as strings\n                SchemaAndValue parsed \u003d parseString(content);\n                if (parsed !\u003d null \u0026\u0026 TEMPORAL_LOGICAL_TYPE_NAMES.contains(parsed.schema().name())) {\n                    return parsed;\n                }\n                return new SchemaAndValue(Schema.STRING_SCHEMA, content);\n            }\n        }\n\n        if (canParseSingleTokenLiteral(parser, embedded, NULL_VALUE)) {\n            return null;\n        }\n        if (canParseSingleTokenLiteral(parser, embedded, TRUE_LITERAL)) {\n            return TRUE_SCHEMA_AND_VALUE;\n        }\n        if (canParseSingleTokenLiteral(parser, embedded, FALSE_LITERAL)) {\n            return FALSE_SCHEMA_AND_VALUE;\n        }\n\n        int startPosition \u003d parser.mark();\n\n        try {\n            if (parser.canConsume(ARRAY_BEGIN_DELIMITER)) {\n                List\u003cObject\u003e result \u003d new ArrayList\u003c\u003e();\n                boolean compatible \u003d true;\n                Schema elementSchema \u003d null;\n                while (parser.hasNext()) {\n                    if (parser.canConsume(ARRAY_END_DELIMITER)) {\n                        Schema listSchema;\n                        if (elementSchema !\u003d null \u0026\u0026 compatible) {\n                            listSchema \u003d SchemaBuilder.array(elementSchema).schema();\n                            result \u003d alignListEntriesWithSchema(listSchema, result);\n                        } else {\n                            // Every value is null\n                            listSchema \u003d SchemaBuilder.arrayOfNull().build();\n                        }\n                        return new SchemaAndValue(listSchema, result);\n                    }\n\n                    if (parser.canConsume(COMMA_DELIMITER)) {\n                        throw new DataException(\"Unable to parse an empty array element: \" + parser.original());\n                    }\n                    SchemaAndValue element \u003d parse(parser, true);\n                    elementSchema \u003d commonSchemaFor(elementSchema, element);\n                    if (elementSchema \u003d\u003d null \u0026\u0026 element !\u003d null \u0026\u0026 element.schema() !\u003d null) {\n                        compatible \u003d false;\n                    }\n                    result.add(element !\u003d null ? element.value() : null);\n\n                    int currentPosition \u003d parser.mark();\n                    if (parser.canConsume(ARRAY_END_DELIMITER)) {\n                        parser.rewindTo(currentPosition);\n                    } else if (!parser.canConsume(COMMA_DELIMITER)) {\n                        throw new DataException(\"Array elements missing \u0027\" + COMMA_DELIMITER + \"\u0027 delimiter\");\n                    }\n                }\n\n                // Missing either a comma or an end delimiter\n                if (COMMA_DELIMITER.equals(parser.previous())) {\n                    throw new DataException(\"Array is missing element after \u0027,\u0027: \" + parser.original());\n                }\n                throw new DataException(\"Array is missing terminating \u0027]\u0027: \" + parser.original());\n            }\n\n            if (parser.canConsume(MAP_BEGIN_DELIMITER)) {\n                Map\u003cObject, Object\u003e result \u003d new LinkedHashMap\u003c\u003e();\n                boolean keyCompatible \u003d true;\n                Schema keySchema \u003d null;\n                boolean valueCompatible \u003d true;\n                Schema valueSchema \u003d null;\n                while (parser.hasNext()) {\n                    if (parser.canConsume(MAP_END_DELIMITER)) {\n                        Schema mapSchema;\n                        if (keySchema !\u003d null \u0026\u0026 valueSchema !\u003d null \u0026\u0026 keyCompatible \u0026\u0026 valueCompatible) {\n                            mapSchema \u003d SchemaBuilder.map(keySchema, valueSchema).build();\n                            result \u003d alignMapKeysAndValuesWithSchema(mapSchema, result);\n                        } else if (keySchema !\u003d null \u0026\u0026 keyCompatible) {\n                            mapSchema \u003d SchemaBuilder.mapWithNullValues(keySchema);\n                            result \u003d alignMapKeysWithSchema(mapSchema, result);\n                        } else {\n                            mapSchema \u003d SchemaBuilder.mapOfNull().build();\n                        }\n                        return new SchemaAndValue(mapSchema, result);\n                    }\n\n                    if (parser.canConsume(COMMA_DELIMITER)) {\n                        throw new DataException(\"Unable to parse a map entry with no key or value: \" + parser.original());\n                    }\n                    SchemaAndValue key \u003d parse(parser, true);\n                    if (key \u003d\u003d null || key.value() \u003d\u003d null) {\n                        throw new DataException(\"Map entry may not have a null key: \" + parser.original());\n                    }\n\n                    if (!parser.canConsume(ENTRY_DELIMITER)) {\n                        throw new DataException(\"Map entry is missing \u0027\" + ENTRY_DELIMITER\n                                                + \"\u0027 at \" + parser.position()\n                                                + \" in \" + parser.original());\n                    }\n                    SchemaAndValue value \u003d parse(parser, true);\n                    Object entryValue \u003d value !\u003d null ? value.value() : null;\n                    result.put(key.value(), entryValue);\n\n                    parser.canConsume(COMMA_DELIMITER);\n                    keySchema \u003d commonSchemaFor(keySchema, key);\n                    if (keySchema \u003d\u003d null \u0026\u0026 key.schema() !\u003d null) {\n                        keyCompatible \u003d false;\n                    }\n                    valueSchema \u003d commonSchemaFor(valueSchema, value);\n                    if (valueSchema \u003d\u003d null \u0026\u0026 value !\u003d null \u0026\u0026 value.schema() !\u003d null) {\n                        valueCompatible \u003d false;\n                    }\n                }\n                // Missing either a comma or an end delimiter\n                if (COMMA_DELIMITER.equals(parser.previous())) {\n                    throw new DataException(\"Map is missing element after \u0027,\u0027: \" + parser.original());\n                }\n                throw new DataException(\"Map is missing terminating \u0027}\u0027: \" + parser.original());\n            }\n        } catch (DataException e) {\n            LOG.trace(\"Unable to parse the value as a map or an array; reverting to string\", e);\n            parser.rewindTo(startPosition);\n        }\n\n        String token \u003d parser.next();\n        if (Utils.isBlank(token)) {\n            return new SchemaAndValue(Schema.STRING_SCHEMA, token);\n        }\n        token \u003d token.trim();\n\n        char firstChar \u003d token.charAt(0);\n        boolean firstCharIsDigit \u003d Character.isDigit(firstChar);\n\n        // Temporal types are more restrictive, so try them first\n        if (firstCharIsDigit) {\n            // The time and timestamp literals may be split into 5 tokens since an unescaped colon\n            // is a delimiter. Check these first since the first of these tokens is a simple numeric\n            int position \u003d parser.mark();\n            String remainder \u003d parser.next(4);\n            if (remainder !\u003d null) {\n                String timeOrTimestampStr \u003d token + remainder;\n                SchemaAndValue temporal \u003d parseAsTemporal(timeOrTimestampStr);\n                if (temporal !\u003d null) {\n                    return temporal;\n                }\n            }\n            // No match was found using the 5 tokens, so rewind and see if the current token has a date, time, or timestamp\n            parser.rewindTo(position);\n            SchemaAndValue temporal \u003d parseAsTemporal(token);\n            if (temporal !\u003d null) {\n                return temporal;\n            }\n        }\n        if (firstCharIsDigit || firstChar \u003d\u003d \u0027+\u0027 || firstChar \u003d\u003d \u0027-\u0027) {\n            try {\n                // Try to parse as a number ...\n                BigDecimal decimal \u003d new BigDecimal(token);\n                try {\n                    return new SchemaAndValue(Schema.INT8_SCHEMA, decimal.byteValueExact());\n                } catch (ArithmeticException e) {\n                    // continue\n                }\n                try {\n                    return new SchemaAndValue(Schema.INT16_SCHEMA, decimal.shortValueExact());\n                } catch (ArithmeticException e) {\n                    // continue\n                }\n                try {\n                    return new SchemaAndValue(Schema.INT32_SCHEMA, decimal.intValueExact());\n                } catch (ArithmeticException e) {\n                    // continue\n                }\n                try {\n                    return new SchemaAndValue(Schema.INT64_SCHEMA, decimal.longValueExact());\n                } catch (ArithmeticException e) {\n                    // continue\n                }\n                float fValue \u003d decimal.floatValue();\n                if (fValue !\u003d Float.NEGATIVE_INFINITY \u0026\u0026 fValue !\u003d Float.POSITIVE_INFINITY\n                    \u0026\u0026 decimal.scale() !\u003d 0) {\n                    return new SchemaAndValue(Schema.FLOAT32_SCHEMA, fValue);\n                }\n                double dValue \u003d decimal.doubleValue();\n                if (dValue !\u003d Double.NEGATIVE_INFINITY \u0026\u0026 dValue !\u003d Double.POSITIVE_INFINITY\n                    \u0026\u0026 decimal.scale() !\u003d 0) {\n                    return new SchemaAndValue(Schema.FLOAT64_SCHEMA, dValue);\n                }\n                Schema schema \u003d Decimal.schema(decimal.scale());\n                return new SchemaAndValue(schema, decimal);\n            } catch (NumberFormatException e) {\n                // can\u0027t parse as a number\n            }\n        }\n        if (embedded) {\n            throw new DataException(\"Failed to parse embedded value\");\n        }\n        // At this point, the only thing this non-embedded value can be is a string.\n        return new SchemaAndValue(Schema.STRING_SCHEMA, parser.original());\n    }\n\n    private static SchemaAndValue parseAsTemporal(String token) {\n        if (token \u003d\u003d null) {\n            return null;\n        }\n        // If the colons were escaped, we\u0027ll see the escape chars and need to remove them\n        token \u003d token.replace(\"\\\\:\", \":\");\n        int tokenLength \u003d token.length();\n        if (tokenLength \u003d\u003d ISO_8601_TIME_LENGTH) {\n            try {\n                return new SchemaAndValue(Time.SCHEMA, new SimpleDateFormat(ISO_8601_TIME_FORMAT_PATTERN).parse(token));\n            } catch (ParseException e) {\n              // not a valid date\n            }\n        } else if (tokenLength \u003d\u003d ISO_8601_TIMESTAMP_LENGTH) {\n            try {\n                return new SchemaAndValue(Timestamp.SCHEMA, new SimpleDateFormat(ISO_8601_TIMESTAMP_FORMAT_PATTERN).parse(token));\n            } catch (ParseException e) {\n              // not a valid date\n            }\n        } else if (tokenLength \u003d\u003d ISO_8601_DATE_LENGTH) {\n            try {\n                return new SchemaAndValue(Date.SCHEMA, new SimpleDateFormat(ISO_8601_DATE_FORMAT_PATTERN).parse(token));\n            } catch (ParseException e) {\n                // not a valid date\n            }\n        }\n        return null;\n    }\n\n    protected static Schema commonSchemaFor(Schema previous, SchemaAndValue latest) {\n        if (latest \u003d\u003d null) {\n            return previous;\n        }\n        if (previous \u003d\u003d null) {\n            return latest.schema();\n        }\n        Schema newSchema \u003d latest.schema();\n        Type previousType \u003d previous.type();\n        Type newType \u003d newSchema.type();\n        if (previousType !\u003d newType) {\n            switch (previous.type()) {\n                case INT8:\n                    if (newType \u003d\u003d Type.INT16 || newType \u003d\u003d Type.INT32 || newType \u003d\u003d Type.INT64 || newType \u003d\u003d Type.FLOAT32 || newType \u003d\u003d\n                                                                                                                              Type.FLOAT64) {\n                        return newSchema;\n                    }\n                    break;\n                case INT16:\n                    if (newType \u003d\u003d Type.INT8) {\n                        return previous;\n                    }\n                    if (newType \u003d\u003d Type.INT32 || newType \u003d\u003d Type.INT64 || newType \u003d\u003d Type.FLOAT32 || newType \u003d\u003d Type.FLOAT64) {\n                        return newSchema;\n                    }\n                    break;\n                case INT32:\n                    if (newType \u003d\u003d Type.INT8 || newType \u003d\u003d Type.INT16) {\n                        return previous;\n                    }\n                    if (newType \u003d\u003d Type.INT64 || newType \u003d\u003d Type.FLOAT32 || newType \u003d\u003d Type.FLOAT64) {\n                        return newSchema;\n                    }\n                    break;\n                case INT64:\n                    if (newType \u003d\u003d Type.INT8 || newType \u003d\u003d Type.INT16 || newType \u003d\u003d Type.INT32) {\n                        return previous;\n                    }\n                    if (newType \u003d\u003d Type.FLOAT32 || newType \u003d\u003d Type.FLOAT64) {\n                        return newSchema;\n                    }\n                    break;\n                case FLOAT32:\n                    if (newType \u003d\u003d Type.INT8 || newType \u003d\u003d Type.INT16 || newType \u003d\u003d Type.INT32 || newType \u003d\u003d Type.INT64) {\n                        return previous;\n                    }\n                    if (newType \u003d\u003d Type.FLOAT64) {\n                        return newSchema;\n                    }\n                    break;\n                case FLOAT64:\n                    if (newType \u003d\u003d Type.INT8 || newType \u003d\u003d Type.INT16 || newType \u003d\u003d Type.INT32 || newType \u003d\u003d Type.INT64 || newType \u003d\u003d\n                                                                                                                           Type.FLOAT32) {\n                        return previous;\n                    }\n                    break;\n            }\n            return null;\n        }\n        if (previous.isOptional() \u003d\u003d newSchema.isOptional()) {\n            // Use the optional one\n            return previous.isOptional() ? previous : newSchema;\n        }\n        if (!previous.equals(newSchema)) {\n            return null;\n        }\n        return previous;\n    }\n\n    protected static List\u003cObject\u003e alignListEntriesWithSchema(Schema schema, List\u003cObject\u003e input) {\n        Schema valueSchema \u003d schema.valueSchema();\n        List\u003cObject\u003e result \u003d new ArrayList\u003c\u003e();\n        for (Object value : input) {\n            Object newValue \u003d convertTo(valueSchema, null, value);\n            result.add(newValue);\n        }\n        return result;\n    }\n\n    protected static Map\u003cObject, Object\u003e alignMapKeysAndValuesWithSchema(Schema mapSchema, Map\u003cObject, Object\u003e input) {\n        Schema keySchema \u003d mapSchema.keySchema();\n        Schema valueSchema \u003d mapSchema.valueSchema();\n        Map\u003cObject, Object\u003e result \u003d new LinkedHashMap\u003c\u003e();\n        for (Map.Entry\u003c?, ?\u003e entry : input.entrySet()) {\n            Object newKey \u003d convertTo(keySchema, null, entry.getKey());\n            Object newValue \u003d convertTo(valueSchema, null, entry.getValue());\n            result.put(newKey, newValue);\n        }\n        return result;\n    }\n\n    protected static Map\u003cObject, Object\u003e alignMapKeysWithSchema(Schema mapSchema, Map\u003cObject, Object\u003e input) {\n        Schema keySchema \u003d mapSchema.keySchema();\n        Map\u003cObject, Object\u003e result \u003d new LinkedHashMap\u003c\u003e();\n        for (Map.Entry\u003c?, ?\u003e entry : input.entrySet()) {\n            Object newKey \u003d convertTo(keySchema, null, entry.getKey());\n            result.put(newKey, entry.getValue());\n        }\n        return result;\n    }\n\n    protected static class SchemaDetector {\n        private Type knownType \u003d null;\n        private boolean optional \u003d false;\n\n        public SchemaDetector() {\n        }\n\n        public boolean canDetect(Object value) {\n            if (value \u003d\u003d null) {\n                optional \u003d true;\n                return true;\n            }\n            Schema schema \u003d inferSchema(value);\n            if (schema \u003d\u003d null) {\n                return false;\n            }\n            if (knownType \u003d\u003d null) {\n                knownType \u003d schema.type();\n            } else if (knownType !\u003d schema.type()) {\n                return false;\n            }\n            return true;\n        }\n\n        public Schema schema() {\n            SchemaBuilder builder \u003d SchemaBuilder.type(knownType);\n            if (optional) {\n                builder.optional();\n            }\n            return builder.schema();\n        }\n    }\n\n    protected static class Parser {\n        private final String original;\n        private final CharacterIterator iter;\n        private String nextToken \u003d null;\n        private String previousToken \u003d null;\n\n        public Parser(String original) {\n            this.original \u003d original;\n            this.iter \u003d new StringCharacterIterator(this.original);\n        }\n\n        public int position() {\n            return iter.getIndex();\n        }\n\n        public int mark() {\n            return iter.getIndex() - (nextToken !\u003d null ? nextToken.length() : 0);\n        }\n\n        public void rewindTo(int position) {\n            iter.setIndex(position);\n            nextToken \u003d null;\n            previousToken \u003d null;\n        }\n\n        public String original() {\n            return original;\n        }\n\n        public boolean hasNext() {\n            return nextToken !\u003d null || canConsumeNextToken();\n        }\n\n        protected boolean canConsumeNextToken() {\n            return iter.getEndIndex() \u003e iter.getIndex();\n        }\n\n        public String next() {\n            if (nextToken !\u003d null) {\n                previousToken \u003d nextToken;\n                nextToken \u003d null;\n            } else {\n                previousToken \u003d consumeNextToken();\n            }\n            return previousToken;\n        }\n\n        public String next(int n) {\n            int current \u003d mark();\n            int start \u003d mark();\n            for (int i \u003d 0; i !\u003d n; ++i) {\n                if (!hasNext()) {\n                    rewindTo(start);\n                    return null;\n                }\n                next();\n            }\n            return original.substring(current, position());\n        }\n\n        private String consumeNextToken() throws NoSuchElementException {\n            boolean escaped \u003d false;\n            int start \u003d iter.getIndex();\n            char c \u003d iter.current();\n            while (canConsumeNextToken()) {\n                switch (c) {\n                    case \u0027\\\\\u0027:\n                        escaped \u003d !escaped;\n                        break;\n                    case \u0027:\u0027:\n                    case \u0027,\u0027:\n                    case \u0027{\u0027:\n                    case \u0027}\u0027:\n                    case \u0027[\u0027:\n                    case \u0027]\u0027:\n                    case \u0027\\\"\u0027:\n                        if (!escaped) {\n                            if (start \u003c iter.getIndex()) {\n                                // Return the previous token\n                                return original.substring(start, iter.getIndex());\n                            }\n                            // Consume and return this delimiter as a token\n                            iter.next();\n                            return original.substring(start, start + 1);\n                        }\n                        // escaped, so continue\n                        escaped \u003d false;\n                        break;\n                    default:\n                        // If escaped, then we don\u0027t care what was escaped\n                        escaped \u003d false;\n                        break;\n                }\n                c \u003d iter.next();\n            }\n            return original.substring(start, iter.getIndex());\n        }\n\n        public String previous() {\n            return previousToken;\n        }\n\n        public boolean canConsume(String expected) {\n            return canConsume(expected, true);\n        }\n\n        public boolean canConsume(String expected, boolean ignoreLeadingAndTrailingWhitespace) {\n            if (isNext(expected, ignoreLeadingAndTrailingWhitespace)) {\n                // consume this token ...\n                nextToken \u003d null;\n                return true;\n            }\n            return false;\n        }\n\n        protected boolean isNext(String expected, boolean ignoreLeadingAndTrailingWhitespace) {\n            if (nextToken \u003d\u003d null) {\n                if (!hasNext()) {\n                    return false;\n                }\n                // There\u0027s another token, so consume it\n                nextToken \u003d consumeNextToken();\n            }\n            if (ignoreLeadingAndTrailingWhitespace) {\n                while (Utils.isBlank(nextToken) \u0026\u0026 canConsumeNextToken()) {\n                    nextToken \u003d consumeNextToken();\n                }\n            }\n            return ignoreLeadingAndTrailingWhitespace\n                ? nextToken.trim().equals(expected)\n                : nextToken.equals(expected);\n        }\n    }\n}","methodCount":48},"candidatesTelemetryData":{"numberOfSuggestions":3,"candidates":[{"lineStart":224,"lineEnd":238,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method convertToMap to class ConnectUtils","description":"move method convertToMap to PsiClass:ConnectUtils\nRationale: The convertToMap() method is utility-like in nature, as it performs a conversion operation that can be broadly applicable across various contexts. ConnectUtils already contains several utility methods related to data transformation, making it a suitable candidate for this method. Moving it here enhances cohesion by grouping similar functionalities, adhering to the Single Responsibility Principle. However, the utility class may grow too large if it accumulates too many unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":224,"lineEnd":238,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method convertToMap to class ClaimValidationUtils","description":"move method convertToMap to PsiClass:ClaimValidationUtils\nRationale: Although primarily focused on validation, ClaimValidationUtils may benefit from a conversion utility like convertToMap() since it deals with structured data. The method\u0027s functionality can complement the existing validation methods by allowing for easier manipulation of map-like data structures. This move would improve cohesion within the class, but it could also dilute the class\u0027s primary focus on validation.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":224,"lineEnd":238,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method convertToMap to class Decimal","description":"move method convertToMap to PsiClass:Decimal\nRationale: The convertToMap() method\u0027s functionality can be relevant in contexts where numerical data types need to be converted into structured formats. The Decimal class handles numerical representations and conversions, making it a reasonable candidate for this method. This alignment with data types adheres to the Interface Segregation Principle, but it may introduce confusion regarding the class\u0027s primary purpose if not clearly documented.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"convertToBoolean","method_signature":"public static convertToBoolean(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToByte","method_signature":"public static convertToByte(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToShort","method_signature":"public static convertToShort(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToInteger","method_signature":"public static convertToInteger(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToLong","method_signature":"public static convertToLong(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToFloat","method_signature":"public static convertToFloat(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToDouble","method_signature":"public static convertToDouble(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToString","method_signature":"public static convertToString(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToList","method_signature":"public static convertToList(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToMap","method_signature":"public static convertToMap(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToStruct","method_signature":"public static convertToStruct(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToTime","method_signature":"public static convertToTime(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToDate","method_signature":"public static convertToDate(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToTimestamp","method_signature":"public static convertToTimestamp(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToDecimal","method_signature":"public static convertToDecimal(Schema schema, Object value, int scale)","target_class":"","rationale":""},{"method_name":"inferSchema","method_signature":"public static inferSchema(Object value)","target_class":"","rationale":""},{"method_name":"parseString","method_signature":"public static parseString(String value)","target_class":"","rationale":""},{"method_name":"convertTo","method_signature":"protected static convertTo(Schema toSchema, Schema fromSchema, Object value)","target_class":"","rationale":""},{"method_name":"asLong","method_signature":"protected static asLong(Object value, Schema fromSchema, Throwable error)","target_class":"","rationale":""},{"method_name":"asDouble","method_signature":"protected static asDouble(Object value, Schema schema, Throwable error)","target_class":"","rationale":""},{"method_name":"append","method_signature":"protected static append(StringBuilder sb, Object value, boolean embedded)","target_class":"","rationale":""},{"method_name":"appendIterable","method_signature":"protected static appendIterable(StringBuilder sb, Iterator\u003c?\u003e iter)","target_class":"","rationale":""},{"method_name":"escape","method_signature":"protected static escape(String value)","target_class":"","rationale":""},{"method_name":"dateFormatFor","method_signature":"public static dateFormatFor(java.util.Date value)","target_class":"","rationale":""},{"method_name":"canParseSingleTokenLiteral","method_signature":"protected static canParseSingleTokenLiteral(Parser parser, boolean embedded, String tokenLiteral)","target_class":"","rationale":""},{"method_name":"parse","method_signature":"protected static parse(Parser parser, boolean embedded)","target_class":"","rationale":""},{"method_name":"parseAsTemporal","method_signature":"private static parseAsTemporal(String token)","target_class":"","rationale":""},{"method_name":"commonSchemaFor","method_signature":"protected static commonSchemaFor(Schema previous, SchemaAndValue latest)","target_class":"","rationale":""},{"method_name":"alignListEntriesWithSchema","method_signature":"protected static alignListEntriesWithSchema(Schema schema, List\u003cObject\u003e input)","target_class":"","rationale":""},{"method_name":"alignMapKeysAndValuesWithSchema","method_signature":"protected static alignMapKeysAndValuesWithSchema(Schema mapSchema, Map\u003cObject, Object\u003e input)","target_class":"","rationale":""},{"method_name":"alignMapKeysWithSchema","method_signature":"protected static alignMapKeysWithSchema(Schema mapSchema, Map\u003cObject, Object\u003e input)","target_class":"","rationale":""},{"method_name":"canDetect","method_signature":"public canDetect(Object value)","target_class":"","rationale":""},{"method_name":"schema","method_signature":"public schema()","target_class":"","rationale":""},{"method_name":"position","method_signature":"public position()","target_class":"","rationale":""},{"method_name":"mark","method_signature":"public mark()","target_class":"","rationale":""},{"method_name":"rewindTo","method_signature":"public rewindTo(int position)","target_class":"","rationale":""},{"method_name":"hasNext","method_signature":"public hasNext()","target_class":"","rationale":""},{"method_name":"canConsumeNextToken","method_signature":"protected canConsumeNextToken()","target_class":"","rationale":""},{"method_name":"next","method_signature":"public next()","target_class":"","rationale":""},{"method_name":"next","method_signature":"public next(int n)","target_class":"","rationale":""},{"method_name":"consumeNextToken","method_signature":"private consumeNextToken()","target_class":"","rationale":""},{"method_name":"canConsume","method_signature":"public canConsume(String expected)","target_class":"","rationale":""},{"method_name":"canConsume","method_signature":"public canConsume(String expected, boolean ignoreLeadingAndTrailingWhitespace)","target_class":"","rationale":""},{"method_name":"isNext","method_signature":"protected isNext(String expected, boolean ignoreLeadingAndTrailingWhitespace)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"mark","method_signature":"public mark()","target_class":"","rationale":""},{"method_name":"rewindTo","method_signature":"public rewindTo(int position)","target_class":"","rationale":""},{"method_name":"convertToMap","method_signature":"public static convertToMap(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"canConsumeNextToken","method_signature":"protected canConsumeNextToken()","target_class":"","rationale":""},{"method_name":"commonSchemaFor","method_signature":"protected static commonSchemaFor(Schema previous, SchemaAndValue latest)","target_class":"","rationale":""},{"method_name":"convertToString","method_signature":"public static convertToString(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToInteger","method_signature":"public static convertToInteger(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToDecimal","method_signature":"public static convertToDecimal(Schema schema, Object value, int scale)","target_class":"","rationale":""},{"method_name":"convertToLong","method_signature":"public static convertToLong(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToDouble","method_signature":"public static convertToDouble(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToBoolean","method_signature":"public static convertToBoolean(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToStruct","method_signature":"public static convertToStruct(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToByte","method_signature":"public static convertToByte(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToShort","method_signature":"public static convertToShort(Schema schema, Object value)","target_class":"","rationale":""},{"method_name":"convertToFloat","method_signature":"public static convertToFloat(Schema schema, Object value)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public mark()":{"first":{"method_name":"mark","method_signature":"public mark()","target_class":"","rationale":""},"second":0.35910855745933773},"public rewindTo(int position)":{"first":{"method_name":"rewindTo","method_signature":"public rewindTo(int position)","target_class":"","rationale":""},"second":0.3839488243592556},"public static convertToMap(Schema schema, Object value)":{"first":{"method_name":"convertToMap","method_signature":"public static convertToMap(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4080699739536421},"protected canConsumeNextToken()":{"first":{"method_name":"canConsumeNextToken","method_signature":"protected canConsumeNextToken()","target_class":"","rationale":""},"second":0.41907783779563856},"protected static commonSchemaFor(Schema previous, SchemaAndValue latest)":{"first":{"method_name":"commonSchemaFor","method_signature":"protected static commonSchemaFor(Schema previous, SchemaAndValue latest)","target_class":"","rationale":""},"second":0.4191610125265198},"public static convertToString(Schema schema, Object value)":{"first":{"method_name":"convertToString","method_signature":"public static convertToString(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4300157603966554},"public static convertToInteger(Schema schema, Object value)":{"first":{"method_name":"convertToInteger","method_signature":"public static convertToInteger(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4316807335356828},"public static convertToDecimal(Schema schema, Object value, int scale)":{"first":{"method_name":"convertToDecimal","method_signature":"public static convertToDecimal(Schema schema, Object value, int scale)","target_class":"","rationale":""},"second":0.43180837777105413},"public static convertToLong(Schema schema, Object value)":{"first":{"method_name":"convertToLong","method_signature":"public static convertToLong(Schema schema, Object value)","target_class":"","rationale":""},"second":0.43196179469843937},"public static convertToDouble(Schema schema, Object value)":{"first":{"method_name":"convertToDouble","method_signature":"public static convertToDouble(Schema schema, Object value)","target_class":"","rationale":""},"second":0.43203400460714797},"public static convertToBoolean(Schema schema, Object value)":{"first":{"method_name":"convertToBoolean","method_signature":"public static convertToBoolean(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4320483447066967},"public static convertToStruct(Schema schema, Object value)":{"first":{"method_name":"convertToStruct","method_signature":"public static convertToStruct(Schema schema, Object value)","target_class":"","rationale":""},"second":0.43241849414609257},"public static convertToByte(Schema schema, Object value)":{"first":{"method_name":"convertToByte","method_signature":"public static convertToByte(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4325192568338814},"public static convertToShort(Schema schema, Object value)":{"first":{"method_name":"convertToShort","method_signature":"public static convertToShort(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4325192568338814},"public static convertToFloat(Schema schema, Object value)":{"first":{"method_name":"convertToFloat","method_signature":"public static convertToFloat(Schema schema, Object value)","target_class":"","rationale":""},"second":0.4326117537416313}},"llmMethodPriority":{"priority_method_names":["convertToBoolean","convertToByte","convertToShort","convertToInteger","convertToLong","convertToFloat","convertToDouble","convertToString","convertToDecimal","convertToMap","convertToStruct","commonSchemaFor","canConsumeNextToken","mark","rewindTo"],"llm_response_time":3125},"targetClassMap":{"mark":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":371,"similarity_computation_time":2,"similarity_metric":"voyage"},"rewindTo":{"target_classes":[],"target_classes_sorted_by_llm":[],"llm_response_time":595,"similarity_computation_time":0,"similarity_metric":"voyage"},"convertToMap":{"target_classes":[{"class_name":"MirrorUtils","similarity_score":0.5916709833292259},{"class_name":"MockitoUtils","similarity_score":0.6514966047668417},{"class_name":"RetryUtil","similarity_score":0.5791035856770657},{"class_name":"OffsetUtils","similarity_score":0.5210572147498431},{"class_name":"SchemaUtil","similarity_score":0.08832589642016424},{"class_name":"ConcurrencyUtils","similarity_score":0.6368874865052578},{"class_name":"ConnectIntegrationTestUtils","similarity_score":0.1341651874577714},{"class_name":"ConnectorUtils","similarity_score":0.43755396189464646},{"class_name":"ConnectUtils","similarity_score":0.7861498278552056},{"class_name":"PluginUtils","similarity_score":0.3694296120144217},{"class_name":"SinkUtils","similarity_score":0.5506954170900705},{"class_name":"WorkerTestUtils","similarity_score":0.06998308240763462},{"class_name":"TestUtils","similarity_score":0.34982884572882134},{"class_name":"SSLUtils","similarity_score":0.22286723324674568},{"class_name":"RemoteClusterUtils","similarity_score":0.373180957676629},{"class_name":"SchemaBuilder","similarity_score":0.5551303714605061},{"class_name":"SchemaProjector","similarity_score":0.2861679573743821},{"class_name":"ConnectSchema","similarity_score":0.4609040541549735},{"class_name":"Date","similarity_score":0.6251654481204895},{"class_name":"Time","similarity_score":0.6673880723084192},{"class_name":"Decimal","similarity_score":0.6628187578347742},{"class_name":"Timestamp","similarity_score":0.6645341033447707},{"class_name":"LogFileUtils","similarity_score":0.6019622617005587},{"class_name":"NetworkClientUtils","similarity_score":0.6046206523366561},{"class_name":"MetricsTestUtils","similarity_score":0.075090485651157},{"class_name":"MetricsUtils","similarity_score":0.5617188559273194},{"class_name":"NetworkTestUtils","similarity_score":0.11673706608076574},{"class_name":"ClaimValidationUtils","similarity_score":0.6623494470583469},{"class_name":"RequestTestUtils","similarity_score":0.06814336807728602},{"class_name":"RequestUtils","similarity_score":0.28326202955365437},{"class_name":"MessageUtil","similarity_score":0.22181905961218615},{"class_name":"ClientMetricsTestUtils","similarity_score":0.08218416090394215},{"class_name":"ClientTelemetryUtils","similarity_score":0.28853385065313963},{"class_name":"ClientUtils","similarity_score":0.2065265015898059},{"class_name":"CollectionUtils","similarity_score":0.3944199677258002},{"class_name":"OAuthBearerScopeUtils","similarity_score":0.6094176042424448},{"class_name":"AdminClientTestUtils","similarity_score":0.3865485540114387},{"class_name":"AdminUtils","similarity_score":0.5459215099748509},{"class_name":"OAuthBearerValidationUtils","similarity_score":0.7044629446660872},{"class_name":"OAuthBearerValidationUtilsTest","similarity_score":0.10126734652068362},{"class_name":"CommandLineUtils","similarity_score":0.4096929088743842},{"class_name":"CommandLineUtilsTest","similarity_score":0.09086666262507406},{"class_name":"CommandUtils","similarity_score":0.43723732427553036},{"class_name":"AuthorizerUtils","similarity_score":0.08433737975046875},{"class_name":"OffsetFetcherUtils","similarity_score":0.35193059427586504},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.1370462326747652},{"class_name":"ByteUtils","similarity_score":0.6160280592225147},{"class_name":"ByteUtilsBenchmark","similarity_score":0.22088925550562696},{"class_name":"ScramCredentialUtils","similarity_score":0.2381222657368121}],"target_classes_sorted_by_llm":["ConnectUtils","ClaimValidationUtils","Decimal","Time","Timestamp","Date","ConcurrencyUtils","ByteUtils","OAuthBearerValidationUtils","MockitoUtils"],"llm_response_time":10356,"similarity_computation_time":193,"similarity_metric":"voyage"}}}
{"id":"440849d4-b503-411c-8771-52c5072ce8cf","methodCount":3,"hostFunctionTelemetryData":{"hostFunctionSize":39,"lineStart":109,"lineEnd":147,"bodyLineStart":109,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/rest/RestClientTest.java","sourceCode":"@RunWith(Parameterized.class)\n    public static class RequestFailureParameterizedTest {\n\n        @Rule\n        public MockitoRule initRule \u003d MockitoJUnit.rule().strictness(Strictness.STRICT_STUBS);\n\n        @Mock\n        private HttpClient httpClient;\n\n        @Parameterized.Parameter\n        public Throwable requestException;\n        \n        @Parameterized.Parameters\n        public static Collection\u003cObject[]\u003e requestExceptions() {\n            return Arrays.asList(new Object[][]{\n                    {new InterruptedException()},\n                    {new ExecutionException(null)},\n                    {new TimeoutException()}\n            });\n        }\n\n        private static Request buildThrowingMockRequest(Throwable t) throws ExecutionException, InterruptedException, TimeoutException {\n            Request req \u003d mock(Request.class);\n            when(req.header(anyString(), anyString())).thenReturn(req);\n            when(req.send()).thenThrow(t);\n            return req;\n        }\n\n        @Test\n        public void testFailureDuringRequestCausesInternalServerError() throws Exception {\n            Request request \u003d buildThrowingMockRequest(requestException);\n            when(httpClient.newRequest(anyString())).thenReturn(request);\n            ConnectRestException e \u003d assertThrows(ConnectRestException.class, () -\u003e httpRequest(\n                    httpClient, MOCK_URL, TEST_METHOD, TEST_TYPE, TEST_SIGNATURE_ALGORITHM\n            ));\n            assertIsInternalServerError(e);\n            assertEquals(requestException, e.getCause());\n        }\n    }","methodCount":3},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":120,"lineEnd":127,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method requestExceptions to class NetworkTestUtils","description":"move method requestExceptions to PsiClass:NetworkTestUtils\nRationale: The requestExceptions() method generates exceptions related to network operations. Moving it to NetworkTestUtils aligns with the context of network testing, improving cohesion. This adheres to the Single Responsibility Principle by keeping exception generation related to network functionalities in one class. However, it may require careful integration with existing network tests.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":120,"lineEnd":127,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method requestExceptions to class RestClientTest","description":"move method requestExceptions to PsiClass:RestClientTest\nRationale: Since requestExceptions() produces exceptions that are likely to be encountered during REST client operations, moving it to RestClientTest enhances the relevance of the method within the context of REST interactions. This supports the Open/Closed Principle, allowing the test suite to evolve without modifying existing code. A potential drawback is that it may introduce dependencies on specific REST client implementations.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":120,"lineEnd":127,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method requestExceptions to class ControllerMetricsTestUtils","description":"move method requestExceptions to PsiClass:ControllerMetricsTestUtils\nRationale: The method can be useful for testing metrics related to request handling failures. By relocating it to ControllerMetricsTestUtils, we maintain a clear focus on metrics-related testing, which adheres to the Interface Segregation Principle. However, this could lead to a broader scope of responsibilities for the metrics utility.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":129,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildThrowingMockRequest to class RestClientTest","description":"move method buildThrowingMockRequest to PsiClass:RestClientTest\nRationale: The buildThrowingMockRequest() method is designed to create mock requests for testing purposes, which aligns closely with the functionality of RestClientTest. Moving it here adheres to the Single Responsibility Principle, as it centralizes mocking behavior related to REST requests, improving cohesion. This move also enhances test readability and maintainability. However, it may increase the size of RestClientTest, which could lead to a more complex test class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":129,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildThrowingMockRequest to class InternalRequestSignatureTest","description":"move method buildThrowingMockRequest to PsiClass:InternalRequestSignatureTest\nRationale: This method is related to creating mock requests that may be used in signature validation tests. Relocating it to InternalRequestSignatureTest would group related testing utilities together, improving cohesion. It aligns with the Open/Closed Principle by allowing InternalRequestSignatureTest to be extended with more mocking capabilities without modifying existing code. The downside could be that it may not be directly related to signature validation, leading to potential confusion.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":129,"lineEnd":134,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildThrowingMockRequest to class ExactlyOnceWorkerSourceTaskTest","description":"move method buildThrowingMockRequest to PsiClass:ExactlyOnceWorkerSourceTaskTest\nRationale: ExactlyOnceWorkerSourceTaskTest involves various tests that may require mock requests. Moving buildThrowingMockRequest() here would provide a centralized location for creating mock requests used in different test scenarios, enhancing reusability. This alignment with the Single Responsibility Principle improves the organization of test utilities. However, it might introduce indirect dependencies that could complicate the class\u0027s purpose.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"requestExceptions","method_signature":"@Parameterized.Parameters\n        public static requestExceptions()","target_class":"","rationale":""},{"method_name":"buildThrowingMockRequest","method_signature":"private static buildThrowingMockRequest(Throwable t)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"requestExceptions","method_signature":"@Parameterized.Parameters\n        public static requestExceptions()","target_class":"","rationale":""},{"method_name":"buildThrowingMockRequest","method_signature":"private static buildThrowingMockRequest(Throwable t)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"@Parameterized.Parameters\n        public static requestExceptions()":{"first":{"method_name":"requestExceptions","method_signature":"@Parameterized.Parameters\n        public static requestExceptions()","target_class":"","rationale":""},"second":0.14816681483355562},"private static buildThrowingMockRequest(Throwable t)":{"first":{"method_name":"buildThrowingMockRequest","method_signature":"private static buildThrowingMockRequest(Throwable t)","target_class":"","rationale":""},"second":0.33739293426932}},"llmMethodPriority":{"priority_method_names":["requestExceptions","buildThrowingMockRequest"],"llm_response_time":596},"targetClassMap":{"requestExceptions":{"target_classes":[{"class_name":"RestClientTest","similarity_score":0.289266402408709},{"class_name":"SSLUtils","similarity_score":0.1895590242079552},{"class_name":"PluginUtils","similarity_score":0.23116796322380606},{"class_name":"WorkerTestUtils","similarity_score":0.24692057669693723},{"class_name":"RestClient","similarity_score":0.17665147576828188},{"class_name":"RetryUtil","similarity_score":0.13745713485327285},{"class_name":"OffsetUtils","similarity_score":0.1354502079141182},{"class_name":"SchemaUtil","similarity_score":0.31719576756473444},{"class_name":"ConcurrencyUtils","similarity_score":0.12832838666786217},{"class_name":"MirrorUtils","similarity_score":0.20064505326831172},{"class_name":"MockitoUtils","similarity_score":0.08063808629864941},{"class_name":"ConnectorsResourceTest","similarity_score":0.16428745682639914},{"class_name":"ConnectorUtils","similarity_score":0.09052544090947708},{"class_name":"ConnectUtils","similarity_score":0.17596243769573466},{"class_name":"InternalConfig","similarity_score":0.3284358621940117},{"class_name":"InternalRequestSignature","similarity_score":0.24712819443801454},{"class_name":"InternalRequestSignatureTest","similarity_score":0.21569091171488114},{"class_name":"SinkUtils","similarity_score":0.19381748474093957},{"class_name":"Tests","similarity_score":0.17075957849167392},{"class_name":"TestUtils","similarity_score":0.16974745388928425},{"class_name":"PublicConfig","similarity_score":0.3635896241727897},{"class_name":"RemoteClusterUtils","similarity_score":0.22199079402972974},{"class_name":"FutureUtils","similarity_score":0.13701116417546072},{"class_name":"EagerAssignor","similarity_score":0.17230890748408167},{"class_name":"DistributedConfig","similarity_score":0.2622389686695833},{"class_name":"DistributedHerder","similarity_score":0.20834241625884295},{"class_name":"DistributedHerderTest","similarity_score":0.14391716017870707},{"class_name":"LogFileUtils","similarity_score":0.10747054247834278},{"class_name":"NetworkClientUtils","similarity_score":0.165581585686617},{"class_name":"NetworkTestUtils","similarity_score":0.304589928556672},{"class_name":"AbstractHerderTest","similarity_score":0.16675710133059118},{"class_name":"RequestTestUtils","similarity_score":0.2367246286672597},{"class_name":"RequestUtils","similarity_score":0.30159285836566985},{"class_name":"FetchUtils","similarity_score":0.04508602731264772},{"class_name":"GraphGraceSearchUtil","similarity_score":0.24553683128543735},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.2933651867845827},{"class_name":"ControllerRequestContextUtil","similarity_score":0.36992354344781053},{"class_name":"ControlRecordUtils","similarity_score":0.3728729238375568},{"class_name":"RetryWithToleranceOperatorTest","similarity_score":0.2598757653470454},{"class_name":"ExactlyOnceWorkerSourceTask","similarity_score":0.2396861510936305},{"class_name":"ExactlyOnceWorkerSourceTaskTest","similarity_score":0.1910158965993946},{"class_name":"ExceptionUtils","similarity_score":0.24907458899902216},{"class_name":"ClaimValidationUtils","similarity_score":0.06853028307062774},{"class_name":"ExtendedAssignment","similarity_score":0.21466802521761605},{"class_name":"CsvUtils","similarity_score":0.33881720949396205},{"class_name":"AdminClientTestUtils","similarity_score":0.22448762138853914},{"class_name":"OAuthBearerScopeUtils","similarity_score":0.13578090752936636},{"class_name":"AdminUtils","similarity_score":0.0850072076850968},{"class_name":"OAuthBearerValidationUtils","similarity_score":0.11544638073779405}],"target_classes_sorted_by_llm":["NetworkTestUtils","RestClientTest","ControllerMetricsTestUtils","RequestUtils","CsvUtils","ControlRecordUtils","ControllerRequestContextUtil","InternalConfig","PublicConfig","SchemaUtil"],"llm_response_time":9008,"similarity_computation_time":590,"similarity_metric":"voyage"},"buildThrowingMockRequest":{"target_classes":[{"class_name":"RestClientTest","similarity_score":0.4447802580066538},{"class_name":"SSLUtils","similarity_score":0.25527421250882987},{"class_name":"PluginUtils","similarity_score":0.2875754670956345},{"class_name":"WorkerTestUtils","similarity_score":0.20470544319294587},{"class_name":"InternalConfig","similarity_score":0.28784345572855},{"class_name":"InternalRequestSignature","similarity_score":0.3237492359474084},{"class_name":"InternalRequestSignatureTest","similarity_score":0.3657711769715194},{"class_name":"ConcurrencyUtils","similarity_score":0.10805737826496586},{"class_name":"RestClient","similarity_score":0.3035981220833518},{"class_name":"RetryUtil","similarity_score":0.18739525994838171},{"class_name":"Tests","similarity_score":0.3071620073956433},{"class_name":"SinkUtils","similarity_score":0.2422120283277993},{"class_name":"ConnectorsResourceTest","similarity_score":0.28933397785690873},{"class_name":"ConnectorUtils","similarity_score":0.1388399617665651},{"class_name":"TestUtils","similarity_score":0.23341161070712593},{"class_name":"ConnectUtils","similarity_score":0.16855395554646643},{"class_name":"SchemaUtil","similarity_score":0.32432465244948644},{"class_name":"OffsetUtils","similarity_score":0.1530727721620895},{"class_name":"MirrorUtils","similarity_score":0.23517710278144396},{"class_name":"MockitoUtils","similarity_score":0.06976572680885752},{"class_name":"PublicConfig","similarity_score":0.359369157895042},{"class_name":"RemoteClusterUtils","similarity_score":0.32852364678849993},{"class_name":"AuthorizerUtils","similarity_score":0.3200512122912777},{"class_name":"ExactlyOnceWorkerSourceTask","similarity_score":0.29981015264236316},{"class_name":"ExactlyOnceWorkerSourceTaskTest","similarity_score":0.36292479288026863},{"class_name":"FutureUtils","similarity_score":0.15282594678438124},{"class_name":"ExceptionUtils","similarity_score":0.308287726505694},{"class_name":"DistributedConfig","similarity_score":0.3063043863364798},{"class_name":"DistributedHerder","similarity_score":0.2987077784399614},{"class_name":"DistributedHerderTest","similarity_score":0.27676356639414645},{"class_name":"FetchUtils","similarity_score":0.05378254348272378},{"class_name":"AbstractHerderTest","similarity_score":0.31443764444023314},{"class_name":"ClaimValidationUtils","similarity_score":0.07831406782704563},{"class_name":"ExtendedAssignment","similarity_score":0.26108070509968434},{"class_name":"ApiUtils","similarity_score":0.26292151427950844},{"class_name":"GraphGraceSearchUtil","similarity_score":0.32200558505538823},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.3352477197892781},{"class_name":"ControllerRequestContextUtil","similarity_score":0.28654353798196575},{"class_name":"ControlRecordUtils","similarity_score":0.3532198181153885},{"class_name":"ClientMetricsTestUtils","similarity_score":0.2919727474407247},{"class_name":"ClientTelemetryUtils","similarity_score":0.3846328028700728},{"class_name":"ClientUtils","similarity_score":0.37632233139932925},{"class_name":"EagerAssignor","similarity_score":0.27326110404816883},{"class_name":"AssignmentTestUtil","similarity_score":0.2809647898950457},{"class_name":"AssignmentTestUtils","similarity_score":0.2890249255170693},{"class_name":"AssignorBenchmarkUtils","similarity_score":0.24283339755490588},{"class_name":"AdminClientTestUtils","similarity_score":0.23836110610511235},{"class_name":"AdminUtils","similarity_score":0.14431621527029256},{"class_name":"CollectionUtils","similarity_score":0.21144594810892933}],"target_classes_sorted_by_llm":["RestClientTest","InternalRequestSignatureTest","ExactlyOnceWorkerSourceTaskTest","ClientUtils","ClientTelemetryUtils","ControlRecordUtils","PublicConfig","SchemaUtil","RemoteClusterUtils","ControllerMetricsTestUtils"],"llm_response_time":16153,"similarity_computation_time":74,"similarity_metric":"voyage"}}}
{"id":"de0f43ca-564a-440d-8c1d-d7250defcb35","methodCount":51,"hostFunctionTelemetryData":{"hostFunctionSize":1976,"lineStart":59,"lineEnd":2034,"bodyLineStart":59,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java","sourceCode":"public final class KafkaRaftClientSnapshotTest {\n    @Test\n    public void testLatestSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withEmptySnapshot(snapshotId)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        assertEquals(Optional.of(snapshotId), context.client.latestSnapshotId());\n    }\n\n    @Test\n    public void testLatestSnapshotIdMissing() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        assertEquals(Optional.empty(), context.client.latestSnapshotId());\n    }\n\n    @ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public void testLeaderListenerNotified(boolean entireLog) throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext.Builder contextBuilder \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withEmptySnapshot(snapshotId);\n\n        if (!entireLog) {\n            contextBuilder.deleteBeforeSnapshot(snapshotId);\n        }\n\n        RaftClientTestContext context \u003d contextBuilder.build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        // Advance the highWatermark\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, localLogEndOffset, epoch, 0));\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(localLogEndOffset, context.client.highWatermark().getAsLong());\n\n        // Check that listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e snapshot \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.emptyList(), snapshot);\n        }\n    }\n\n    @ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public void testFollowerListenerNotified(boolean entireLog) throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext.Builder contextBuilder \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withEmptySnapshot(snapshotId)\n            .withElectedLeader(epoch, leaderId);\n\n        if (!entireLog) {\n            contextBuilder.deleteBeforeSnapshot(snapshotId);\n        }\n\n        RaftClientTestContext context \u003d contextBuilder.build();\n\n        // Advance the highWatermark\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, localLogEndOffset, snapshotId.epoch());\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            context.fetchResponse(epoch, leaderId, MemoryRecords.EMPTY, localLogEndOffset, Errors.NONE)\n        );\n\n        context.pollUntilRequest();\n        context.assertSentFetchRequest(epoch, localLogEndOffset, snapshotId.epoch());\n\n        // Check that listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e snapshot \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.emptyList(), snapshot);\n        }\n    }\n\n    @ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public void testSecondListenerNotified(boolean entireLog) throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext.Builder contextBuilder \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withEmptySnapshot(snapshotId)\n            .withElectedLeader(epoch, leaderId);\n\n        if (!entireLog) {\n            contextBuilder.deleteBeforeSnapshot(snapshotId);\n        }\n\n        RaftClientTestContext context \u003d contextBuilder.build();\n\n        // Advance the highWatermark\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, localLogEndOffset, snapshotId.epoch());\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            context.fetchResponse(epoch, leaderId, MemoryRecords.EMPTY, localLogEndOffset, Errors.NONE)\n        );\n\n        context.pollUntilRequest();\n        context.assertSentFetchRequest(epoch, localLogEndOffset, snapshotId.epoch());\n\n        RaftClientTestContext.MockListener secondListener \u003d new RaftClientTestContext.MockListener(OptionalInt.of(localId));\n        context.client.register(secondListener);\n        context.client.poll();\n\n        // Check that the second listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e snapshot \u003d secondListener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.emptyList(), snapshot);\n        }\n    }\n\n    @Test\n    public void testListenerRenotified() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"g\", \"h\", \"i\"))\n            .withEmptySnapshot(snapshotId)\n            .deleteBeforeSnapshot(snapshotId)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        // Stop the listener from reading commit batches\n        context.listener.updateReadCommit(false);\n\n        // Advance the highWatermark\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, localLogEndOffset, epoch, 0));\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n        assertEquals(localLogEndOffset, context.client.highWatermark().getAsLong());\n\n        // Check that listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e snapshot \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.emptyList(), snapshot);\n        }\n\n        // Generate a new snapshot\n        OffsetAndEpoch secondSnapshotId \u003d new OffsetAndEpoch(localLogEndOffset, epoch);\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(secondSnapshotId, 0).get()) {\n            assertEquals(secondSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.log.deleteBeforeSnapshot(secondSnapshotId);\n        context.client.poll();\n\n        // Resume the listener from reading commit batches\n        context.listener.updateReadCommit(true);\n\n        context.client.poll();\n        // Check that listener was notified of the second snapshot\n        try (SnapshotReader\u003cString\u003e snapshot \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(secondSnapshotId, snapshot.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.emptyList(), snapshot);\n        }\n    }\n\n    @Test\n    public void testLeaderImmediatelySendsSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(3, 4);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withUnknownLeader(snapshotId.epoch())\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(snapshotId.epoch(), Arrays.asList(\"g\", \"h\", \"i\"))\n            .withEmptySnapshot(snapshotId)\n            .deleteBeforeSnapshot(snapshotId)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        // Send a fetch request for an end offset and epoch which has been snapshotted\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, 6, 2, 500));\n        context.client.poll();\n\n        // Expect that the leader replies immediately with a snapshot id\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(snapshotId.epoch(), partitionResponse.snapshotId().epoch());\n        assertEquals(snapshotId.offset(), partitionResponse.snapshotId().endOffset());\n    }\n\n    @Test\n    public void testFetchRequestOffsetLessThanLogStart() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        List\u003cString\u003e appendRecords \u003d Arrays.asList(\"a\", \"b\", \"c\");\n        context.client.scheduleAppend(epoch, appendRecords);\n        context.time.sleep(context.appendLingerMs());\n        context.client.poll();\n\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        assertTrue(\n            appendRecords.size() \u003c\u003d localLogEndOffset,\n            String.format(\"Record length \u003d %s, log end offset \u003d %s\", appendRecords.size(), localLogEndOffset)\n        );\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(localLogEndOffset, epoch);\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.log.deleteBeforeSnapshot(snapshotId);\n        context.client.poll();\n\n        // Send Fetch request less than start offset\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, snapshotId.offset() - 2, snapshotId.epoch(), 0));\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(snapshotId.epoch(), partitionResponse.snapshotId().epoch());\n        assertEquals(snapshotId.offset(), partitionResponse.snapshotId().endOffset());\n    }\n\n    @Test\n    public void testFetchRequestOffsetAtZero() throws Exception {\n        // When the follower sends a FETCH request at offset 0, reply with snapshot id if it exists\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        List\u003cString\u003e appendRecords \u003d Arrays.asList(\"a\", \"b\", \"c\");\n        context.client.scheduleAppend(epoch, appendRecords);\n        context.time.sleep(context.appendLingerMs());\n        context.client.poll();\n\n        long localLogEndOffset \u003d context.log.endOffset().offset;\n        assertTrue(\n            appendRecords.size() \u003c\u003d localLogEndOffset,\n            String.format(\"Record length \u003d %s, log end offset \u003d %s\", appendRecords.size(), localLogEndOffset)\n        );\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Generate a snapshot at the LEO\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(localLogEndOffset, epoch);\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n\n        // Send Fetch request for offset 0\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, 0, 0, 0));\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(snapshotId.epoch(), partitionResponse.snapshotId().epoch());\n        assertEquals(snapshotId.offset(), partitionResponse.snapshotId().endOffset());\n    }\n\n    @Test\n    public void testFetchRequestWithLargerLastFetchedEpoch() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n\n        OffsetAndEpoch oldestSnapshotId \u003d new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch() + 1, epoch);\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Create a snapshot at the high watermark\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(oldestSnapshotId, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        context.client.scheduleAppend(epoch, Arrays.asList(\"g\", \"h\", \"i\"));\n        context.time.sleep(context.appendLingerMs());\n        context.client.poll();\n\n        // It is an invalid request to send an last fetched epoch greater than the current epoch\n        context.deliverRequest(context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset() + 1, epoch + 1, 0));\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.INVALID_REQUEST, epoch, OptionalInt.of(localId));\n    }\n\n    @Test\n    public void testFetchRequestTruncateToLogStart() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        int syncNodeId \u003d otherNodeId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId \u003d new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch() + 2, Arrays.asList(\"d\", \"e\", \"f\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch() + 2 + 1, epoch);\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Create a snapshot at the high watermark\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(oldestSnapshotId, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        // This should truncate to the old snapshot\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset() + 1, oldestSnapshotId.epoch() + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch(), partitionResponse.divergingEpoch().epoch());\n        assertEquals(oldestSnapshotId.offset(), partitionResponse.divergingEpoch().endOffset());\n    }\n\n    @Test\n    public void testFetchRequestAtLogStartOffsetWithValidEpoch() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        int syncNodeId \u003d otherNodeId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId \u003d new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch() + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch() + 2 + 1, epoch);\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Create a snapshot at the high watermark\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(oldestSnapshotId, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        // Send fetch request at log start offset with valid last fetched epoch\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset(), oldestSnapshotId.epoch(), 0)\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchPartitionResponse(Errors.NONE, epoch, OptionalInt.of(localId));\n    }\n\n    @Test\n    public void testFetchRequestAtLogStartOffsetWithInvalidEpoch() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        int syncNodeId \u003d otherNodeId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId \u003d new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch() + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch() + 2 + 1, epoch);\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Create a snapshot at the high watermark\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(oldestSnapshotId, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.log.deleteBeforeSnapshot(oldestSnapshotId);\n        context.client.poll();\n\n        // Send fetch with log start offset and invalid last fetched epoch\n        context.deliverRequest(\n            context.fetchRequest(epoch, otherNodeId, oldestSnapshotId.offset(), oldestSnapshotId.epoch() + 1, 0)\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch(), partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset(), partitionResponse.snapshotId().endOffset());\n    }\n\n    @Test\n    public void testFetchRequestWithLastFetchedEpochLessThanOldestSnapshot() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        int syncNodeId \u003d otherNodeId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId, syncNodeId);\n\n        OffsetAndEpoch oldestSnapshotId \u003d new OffsetAndEpoch(3, 2);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"a\", \"b\", \"c\"))\n            .appendToLog(oldestSnapshotId.epoch(), Arrays.asList(\"d\", \"e\", \"f\"))\n            .appendToLog(oldestSnapshotId.epoch() + 2, Arrays.asList(\"g\", \"h\", \"i\"))\n            .withAppendLingerMs(1)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n        assertEquals(oldestSnapshotId.epoch() + 2 + 1, epoch);\n\n        // Advance the highWatermark\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        // Create a snapshot at the high watermark\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(oldestSnapshotId, 0).get()) {\n            assertEquals(oldestSnapshotId, snapshot.snapshotId());\n            snapshot.freeze();\n        }\n        context.client.poll();\n\n        // Send a epoch less than the oldest snapshot\n        context.deliverRequest(\n            context.fetchRequest(\n                epoch,\n                otherNodeId,\n                context.log.endOffset().offset,\n                oldestSnapshotId.epoch() - 1,\n                0\n            )\n        );\n        context.pollUntilResponse();\n        FetchResponseData.PartitionData partitionResponse \u003d context.assertSentFetchPartitionResponse();\n        assertEquals(Errors.NONE, Errors.forCode(partitionResponse.errorCode()));\n        assertEquals(epoch, partitionResponse.currentLeader().leaderEpoch());\n        assertEquals(localId, partitionResponse.currentLeader().leaderId());\n        assertEquals(oldestSnapshotId.epoch(), partitionResponse.snapshotId().epoch());\n        assertEquals(oldestSnapshotId.offset(), partitionResponse.snapshotId().endOffset());\n    }\n\n    @Test\n    public void testFetchSnapshotRequestMissingSnapshot() throws Exception {\n        int localId \u003d 0;\n        int epoch \u003d 2;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n\n        RaftClientTestContext context \u003d RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.SNAPSHOT_NOT_FOUND, Errors.forCode(response.errorCode()));\n    }\n\n    @Test\n    public void testFetchSnapshotRequestUnknownPartition() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        int epoch \u003d 2;\n        TopicPartition topicPartition \u003d new TopicPartition(\"unknown\", 0);\n\n        RaftClientTestContext context \u003d RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                topicPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(topicPartition).get();\n        assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION, Errors.forCode(response.errorCode()));\n    }\n\n    @Test\n    public void testFetchSnapshotRequestAsLeader() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(1, 1);\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Collections.singletonList(\"a\"))\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.append(records);\n            snapshot.freeze();\n        }\n\n        RawSnapshotReader snapshot \u003d context.log.readSnapshot(snapshotId).get();\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context\n            .assertSentFetchSnapshotResponse(context.metadataPartition)\n            .get();\n\n        assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n        assertEquals(snapshot.sizeInBytes(), response.size());\n        assertEquals(0, response.position());\n        assertEquals(snapshot.sizeInBytes(), response.unalignedRecords().sizeInBytes());\n\n        UnalignedMemoryRecords memoryRecords \u003d (UnalignedMemoryRecords) snapshot.slice(0, Math.toIntExact(snapshot.sizeInBytes()));\n\n        assertEquals(memoryRecords.buffer(), ((UnalignedMemoryRecords) response.unalignedRecords()).buffer());\n    }\n\n    @Test\n    public void testLeaderShouldResignLeadershipIfNotGetFetchSnapshotRequestFromMajorityVoters() throws Exception {\n        int localId \u003d 0;\n        int voter1 \u003d 1;\n        int voter2 \u003d 2;\n        int observerId3 \u003d 3;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, voter1, voter2);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(1, 1);\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n                .appendToLog(snapshotId.epoch(), Collections.singletonList(\"a\"))\n                .build();\n\n        int resignLeadershipTimeout \u003d context.checkQuorumTimeoutMs;\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        FetchSnapshotRequestData voter1FetchSnapshotRequest \u003d fetchSnapshotRequest(\n                context.clusterId.toString(),\n                voter1,\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n        );\n\n        FetchSnapshotRequestData voter2FetchSnapshotRequest \u003d fetchSnapshotRequest(\n                context.clusterId.toString(),\n                voter2,\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n        );\n\n        FetchSnapshotRequestData observerFetchSnapshotRequest \u003d fetchSnapshotRequest(\n                context.clusterId.toString(),\n                observerId3,\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n        );\n\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.append(records);\n            snapshot.freeze();\n        }\n\n        // fetch timeout is not expired, the leader should not get resigned\n        context.time.sleep(resignLeadershipTimeout / 2);\n        context.client.poll();\n        assertFalse(context.client.quorum().isResigned());\n\n        // voter1 sends fetchSnapshotRequest, the fetch timer should be reset\n        context.deliverRequest(voter1FetchSnapshotRequest);\n        context.client.poll();\n        context.assertSentFetchSnapshotResponse(context.metadataPartition);\n\n        // Since the fetch timer is reset, the leader should not get resigned\n        context.time.sleep(resignLeadershipTimeout / 2);\n        context.client.poll();\n        assertFalse(context.client.quorum().isResigned());\n\n        // voter2 sends fetchSnapshotRequest, the fetch timer should be reset\n        context.deliverRequest(voter2FetchSnapshotRequest);\n        context.client.poll();\n        context.assertSentFetchSnapshotResponse(context.metadataPartition);\n\n        // Since the fetch timer is reset, the leader should not get resigned\n        context.time.sleep(resignLeadershipTimeout / 2);\n        context.client.poll();\n        assertFalse(context.client.quorum().isResigned());\n\n        // An observer sends fetchSnapshotRequest, but the fetch timer should not be reset.\n        context.deliverRequest(observerFetchSnapshotRequest);\n        context.client.poll();\n        context.assertSentFetchSnapshotResponse(context.metadataPartition);\n\n        // After this sleep, the fetch timeout should expire since we don\u0027t receive fetch request from the majority voters within fetchTimeoutMs\n        context.time.sleep(resignLeadershipTimeout / 2);\n        context.client.poll();\n        assertTrue(context.client.quorum().isResigned());\n    }\n\n    @Test\n    public void testPartialFetchSnapshotRequestAsLeader() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(2, 1);\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), records)\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.append(records);\n            snapshot.freeze();\n        }\n\n        RawSnapshotReader snapshot \u003d context.log.readSnapshot(snapshotId).get();\n        // Fetch half of the snapshot\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Math.toIntExact(snapshot.sizeInBytes() / 2),\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context\n            .assertSentFetchSnapshotResponse(context.metadataPartition)\n            .get();\n\n        assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n        assertEquals(snapshot.sizeInBytes(), response.size());\n        assertEquals(0, response.position());\n        assertEquals(snapshot.sizeInBytes() / 2, response.unalignedRecords().sizeInBytes());\n\n        UnalignedMemoryRecords memoryRecords \u003d (UnalignedMemoryRecords) snapshot.slice(0, Math.toIntExact(snapshot.sizeInBytes()));\n        ByteBuffer snapshotBuffer \u003d memoryRecords.buffer();\n\n        ByteBuffer responseBuffer \u003d ByteBuffer.allocate(Math.toIntExact(snapshot.sizeInBytes()));\n        responseBuffer.put(((UnalignedMemoryRecords) response.unalignedRecords()).buffer());\n\n        ByteBuffer expectedBytes \u003d snapshotBuffer.duplicate();\n        expectedBytes.limit(Math.toIntExact(snapshot.sizeInBytes() / 2));\n\n        assertEquals(expectedBytes, responseBuffer.duplicate().flip());\n\n        // Fetch the remainder of the snapshot\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                responseBuffer.position()\n            )\n        );\n\n        context.client.poll();\n\n        response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n        assertEquals(snapshot.sizeInBytes(), response.size());\n        assertEquals(responseBuffer.position(), response.position());\n        assertEquals(snapshot.sizeInBytes() - (snapshot.sizeInBytes() / 2), response.unalignedRecords().sizeInBytes());\n\n        responseBuffer.put(((UnalignedMemoryRecords) response.unalignedRecords()).buffer());\n        assertEquals(snapshotBuffer, responseBuffer.flip());\n    }\n\n    @Test\n    public void testFetchSnapshotRequestAsFollower() throws IOException {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(0, 0);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.NOT_LEADER_OR_FOLLOWER, Errors.forCode(response.errorCode()));\n        assertEquals(epoch, response.currentLeader().leaderEpoch());\n        assertEquals(leaderId, response.currentLeader().leaderId());\n    }\n\n    @Test\n    public void testFetchSnapshotRequestWithInvalidPosition() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(1, 1);\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .appendToLog(snapshotId.epoch(), Collections.singletonList(\"a\"))\n            .build();\n\n        context.becomeLeader();\n        int epoch \u003d context.currentEpoch();\n\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n\n        try (SnapshotWriter\u003cString\u003e snapshot \u003d context.client.createSnapshot(snapshotId, 0).get()) {\n            assertEquals(snapshotId, snapshot.snapshotId());\n            snapshot.append(records);\n            snapshot.freeze();\n        }\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                -1\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.POSITION_OUT_OF_RANGE, Errors.forCode(response.errorCode()));\n        assertEquals(epoch, response.currentLeader().leaderEpoch());\n        assertEquals(localId, response.currentLeader().leaderId());\n\n        RawSnapshotReader snapshot \u003d context.log.readSnapshot(snapshotId).get();\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch,\n                snapshotId,\n                Integer.MAX_VALUE,\n                snapshot.sizeInBytes()\n            )\n        );\n\n        context.client.poll();\n\n        response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.POSITION_OUT_OF_RANGE, Errors.forCode(response.errorCode()));\n        assertEquals(epoch, response.currentLeader().leaderEpoch());\n        assertEquals(localId, response.currentLeader().leaderId());\n    }\n\n    @Test\n    public void testFetchSnapshotRequestWithOlderEpoch() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(0, 0);\n\n        RaftClientTestContext context \u003d RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch - 1,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.FENCED_LEADER_EPOCH, Errors.forCode(response.errorCode()));\n        assertEquals(epoch, response.currentLeader().leaderEpoch());\n        assertEquals(localId, response.currentLeader().leaderId());\n    }\n\n    @Test\n    public void testFetchSnapshotRequestWithNewerEpoch() throws Exception {\n        int localId \u003d 0;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, localId + 1);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(0, 0);\n\n        RaftClientTestContext context \u003d RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.metadataPartition,\n                epoch + 1,\n                snapshotId,\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n\n        context.client.poll();\n\n        FetchSnapshotResponseData.PartitionSnapshot response \u003d context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n        assertEquals(Errors.UNKNOWN_LEADER_EPOCH, Errors.forCode(response.errorCode()));\n        assertEquals(epoch, response.currentLeader().leaderEpoch());\n        assertEquals(localId, response.currentLeader().leaderId());\n    }\n\n    @Test\n    public void testFetchResponseWithInvalidSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch invalidEpoch \u003d new OffsetAndEpoch(100L, -1);\n        OffsetAndEpoch invalidEndOffset \u003d new OffsetAndEpoch(-1L, 1);\n        int slept \u003d 0;\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, invalidEpoch, 200L)\n        );\n\n        // Handle the invalid response\n        context.client.poll();\n\n        // Expect another fetch request after backoff has expired\n        context.time.sleep(context.retryBackoffMs);\n        slept +\u003d context.retryBackoffMs;\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, invalidEndOffset, 200L)\n        );\n\n        // Handle the invalid response\n        context.client.poll();\n\n        // Expect another fetch request after backoff has expired\n        context.time.sleep(context.retryBackoffMs);\n        slept +\u003d context.retryBackoffMs;\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        // Fetch timer is not reset; sleeping for remainder should transition to candidate\n        context.time.sleep(context.fetchTimeoutMs - slept);\n\n        context.pollUntilRequest();\n\n        context.assertSentVoteRequest(epoch + 1, 0, 0L, 1);\n        context.assertVotedCandidate(epoch + 1, localId);\n    }\n\n    @Test\n    public void testFetchResponseWithSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n        MemorySnapshotWriter memorySnapshot \u003d new MemorySnapshotWriter(snapshotId);\n        try (SnapshotWriter\u003cString\u003e snapshotWriter \u003d snapshotWriter(context, memorySnapshot)) {\n            snapshotWriter.append(records);\n            snapshotWriter.freeze();\n        }\n\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            fetchSnapshotResponse(\n                context.metadataPartition,\n                epoch,\n                leaderId,\n                snapshotId,\n                memorySnapshot.buffer().remaining(),\n                0L,\n                memorySnapshot.buffer().slice()\n            )\n        );\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, snapshotId.offset(), snapshotId.epoch());\n\n        // Check that the snapshot was written to the log\n        RawSnapshotReader snapshot \u003d context.log.readSnapshot(snapshotId).get();\n        assertEquals(memorySnapshot.buffer().remaining(), snapshot.sizeInBytes());\n        SnapshotWriterReaderTest.assertSnapshot(Collections.singletonList(records), snapshot);\n\n        // Check that listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e reader \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, reader.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.singletonList(records), reader);\n        }\n    }\n\n    @Test\n    public void testFetchSnapshotResponsePartialData() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        List\u003cString\u003e records \u003d Arrays.asList(\"foo\", \"bar\");\n        MemorySnapshotWriter memorySnapshot \u003d new MemorySnapshotWriter(snapshotId);\n        try (SnapshotWriter\u003cString\u003e snapshotWriter \u003d snapshotWriter(context, memorySnapshot)) {\n            snapshotWriter.append(records);\n            snapshotWriter.freeze();\n        }\n\n        ByteBuffer sendingBuffer \u003d memorySnapshot.buffer().slice();\n        sendingBuffer.limit(sendingBuffer.limit() / 2);\n\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            fetchSnapshotResponse(\n                context.metadataPartition,\n                epoch,\n                leaderId,\n                snapshotId,\n                memorySnapshot.buffer().remaining(),\n                0L,\n                sendingBuffer\n            )\n        );\n\n        context.pollUntilRequest();\n        snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(sendingBuffer.limit(), request.position());\n\n        sendingBuffer \u003d memorySnapshot.buffer().slice();\n        sendingBuffer.position(Math.toIntExact(request.position()));\n\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            fetchSnapshotResponse(\n                context.metadataPartition,\n                epoch,\n                leaderId,\n                snapshotId,\n                memorySnapshot.buffer().remaining(),\n                request.position(),\n                sendingBuffer\n            )\n        );\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, snapshotId.offset(), snapshotId.epoch());\n\n        // Check that the snapshot was written to the log\n        RawSnapshotReader snapshot \u003d context.log.readSnapshot(snapshotId).get();\n        assertEquals(memorySnapshot.buffer().remaining(), snapshot.sizeInBytes());\n        SnapshotWriterReaderTest.assertSnapshot(Collections.singletonList(records), snapshot);\n\n        // Check that listener was notified of the new snapshot\n        try (SnapshotReader\u003cString\u003e reader \u003d context.listener.drainHandledSnapshot().get()) {\n            assertEquals(snapshotId, reader.snapshotId());\n            SnapshotWriterReaderTest.assertSnapshot(Collections.singletonList(records), reader);\n        }\n    }\n\n    @Test\n    public void testFetchSnapshotResponseMissingSnapshot() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with a snapshot not found error\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch)\n                        .setLeaderId(leaderId);\n\n                    return responsePartitionSnapshot\n                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n    }\n\n    @Test\n    public void testFetchSnapshotResponseFromNewerEpochNotLeader() throws Exception {\n        int localId \u003d 0;\n        int firstLeaderId \u003d localId + 1;\n        int secondLeaderId \u003d firstLeaderId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, firstLeaderId, secondLeaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, firstLeaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, firstLeaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with new leader response\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch + 1)\n                        .setLeaderId(secondLeaderId);\n\n                    return responsePartitionSnapshot\n                        .setErrorCode(Errors.FENCED_LEADER_EPOCH.code());\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch + 1, 0L, 0);\n    }\n\n    @Test\n    public void testFetchSnapshotResponseFromNewerEpochLeader() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with new leader epoch\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch + 1)\n                        .setLeaderId(leaderId);\n\n                    return responsePartitionSnapshot\n                        .setErrorCode(Errors.FENCED_LEADER_EPOCH.code());\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch + 1, 0L, 0);\n    }\n\n    @Test\n    public void testFetchSnapshotResponseFromOlderEpoch() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with unknown leader epoch\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch - 1)\n                        .setLeaderId(leaderId + 1);\n\n                    return responsePartitionSnapshot\n                        .setErrorCode(Errors.UNKNOWN_LEADER_EPOCH.code());\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n\n        // Follower should resend the fetch snapshot request\n        snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n    }\n\n    @Test\n    public void testFetchSnapshotResponseWithInvalidId() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with an invalid snapshot id endOffset\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch)\n                        .setLeaderId(leaderId);\n\n                    responsePartitionSnapshot\n                        .snapshotId()\n                        .setEndOffset(-1)\n                        .setEpoch(snapshotId.epoch());\n\n                    return responsePartitionSnapshot;\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n\n        // Follower should send a fetch request\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n\n        snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Reply with an invalid snapshot id epoch\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch)\n                        .setLeaderId(leaderId);\n\n                    responsePartitionSnapshot\n                        .snapshotId()\n                        .setEndOffset(snapshotId.offset())\n                        .setEpoch(-1);\n\n                    return responsePartitionSnapshot;\n                }\n            )\n        );\n\n        context.pollUntilRequest();\n\n        // Follower should send a fetch request\n        fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n    }\n\n    @Test\n    public void testFetchSnapshotResponseToNotFollower() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId);\n        int epoch \u003d 2;\n        OffsetAndEpoch snapshotId \u003d new OffsetAndEpoch(100L, 1);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n            .withElectedLeader(epoch, leaderId)\n            .build();\n\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            snapshotFetchResponse(context.metadataPartition, context.metadataTopicId, epoch, leaderId, snapshotId, 200L)\n        );\n\n        context.pollUntilRequest();\n\n        RaftRequest.Outbound snapshotRequest \u003d context.assertSentFetchSnapshotRequest();\n        FetchSnapshotRequestData.PartitionSnapshot request \u003d assertFetchSnapshotRequest(\n                snapshotRequest,\n                context.metadataPartition,\n                localId,\n                Integer.MAX_VALUE\n        ).get();\n        assertEquals(snapshotId.offset(), request.snapshotId().endOffset());\n        assertEquals(snapshotId.epoch(), request.snapshotId().epoch());\n        assertEquals(0, request.position());\n\n        // Sleeping for fetch timeout should transition to candidate\n        context.time.sleep(context.fetchTimeoutMs);\n\n        context.pollUntilRequest();\n\n        context.assertSentVoteRequest(epoch + 1, 0, 0L, 1);\n        context.assertVotedCandidate(epoch + 1, localId);\n\n        // Send the response late\n        context.deliverResponse(\n            snapshotRequest.correlationId(),\n            snapshotRequest.destination(),\n            FetchSnapshotResponse.singleton(\n                context.metadataPartition,\n                responsePartitionSnapshot -\u003e {\n                    responsePartitionSnapshot\n                        .currentLeader()\n                        .setLeaderEpoch(epoch)\n                        .setLeaderId(leaderId);\n\n                    responsePartitionSnapshot\n                        .snapshotId()\n                        .setEndOffset(snapshotId.offset())\n                        .setEpoch(snapshotId.epoch());\n\n                    return responsePartitionSnapshot;\n                }\n            )\n        );\n\n        // Assert that the response is ignored and the replicas stays as a candidate\n        context.client.poll();\n        context.assertVotedCandidate(epoch + 1, localId);\n    }\n\n    @Test\n    public void testFetchSnapshotRequestClusterIdValidation() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d 1;\n        int epoch \u003d 5;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n\n        RaftClientTestContext context \u003d RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n\n        // null cluster id is accepted\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                context.clusterId.toString(),\n                otherNodeId,\n                context.metadataPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchSnapshotResponse(context.metadataPartition);\n\n        // null cluster id is accepted\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                null,\n                otherNodeId,\n                context.metadataPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchSnapshotResponse(context.metadataPartition);\n\n        // empty cluster id is rejected\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                \"\",\n                otherNodeId,\n                context.metadataPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchSnapshotResponse(Errors.INCONSISTENT_CLUSTER_ID);\n\n        // invalid cluster id is rejected\n        context.deliverRequest(\n            fetchSnapshotRequest(\n                \"invalid-uuid\",\n                otherNodeId,\n                context.metadataPartition,\n                epoch,\n                new OffsetAndEpoch(0, 0),\n                Integer.MAX_VALUE,\n                0\n            )\n        );\n        context.pollUntilResponse();\n        context.assertSentFetchSnapshotResponse(Errors.INCONSISTENT_CLUSTER_ID);\n    }\n\n    @Test\n    public void testCreateSnapshotAsLeaderWithInvalidSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int otherNodeId \u003d localId + 1;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, otherNodeId);\n        int epoch \u003d 2;\n\n        List\u003cString\u003e appendRecords \u003d Arrays.asList(\"a\", \"b\", \"c\");\n        OffsetAndEpoch invalidSnapshotId1 \u003d new OffsetAndEpoch(4, epoch);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n                .appendToLog(epoch, appendRecords)\n                .withAppendLingerMs(1)\n                .build();\n\n        context.becomeLeader();\n        int currentEpoch \u003d context.currentEpoch();\n\n        // When leader creating snapshot:\n        // 1.1 high watermark cannot be empty\n        assertEquals(OptionalLong.empty(), context.client.highWatermark());\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId1, 0));\n\n        // 1.2 high watermark must larger than or equal to the snapshotId\u0027s endOffset\n        context.advanceLocalLeaderHighWatermarkToLogEndOffset();\n        // append some more records to make the LEO \u003e high watermark\n        List\u003cString\u003e newRecords \u003d Arrays.asList(\"d\", \"e\", \"f\");\n        context.client.scheduleAppend(currentEpoch, newRecords);\n        context.time.sleep(context.appendLingerMs());\n        context.client.poll();\n        assertEquals(context.log.endOffset().offset, context.client.highWatermark().getAsLong() + newRecords.size());\n\n        OffsetAndEpoch invalidSnapshotId2 \u003d new OffsetAndEpoch(context.client.highWatermark().getAsLong() + 2, currentEpoch);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId2, 0));\n\n        // 2 the quorum epoch must larger than or equal to the snapshotId\u0027s epoch\n        OffsetAndEpoch invalidSnapshotId3 \u003d new OffsetAndEpoch(context.client.highWatermark().getAsLong(), currentEpoch + 1);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId3, 0));\n\n        // 3 the snapshotId should be validated against endOffsetForEpoch\n        OffsetAndEpoch endOffsetForEpoch \u003d context.log.endOffsetForEpoch(epoch);\n        assertEquals(epoch, endOffsetForEpoch.epoch());\n        OffsetAndEpoch invalidSnapshotId4 \u003d new OffsetAndEpoch(endOffsetForEpoch.offset() + 2, epoch);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId4, 0));\n    }\n\n    @Test\n    public void testCreateSnapshotAsFollowerWithInvalidSnapshotId() throws Exception {\n        int localId \u003d 0;\n        int leaderId \u003d 1;\n        int otherFollowerId \u003d 2;\n        int epoch \u003d 5;\n        Set\u003cInteger\u003e voters \u003d Utils.mkSet(localId, leaderId, otherFollowerId);\n\n        RaftClientTestContext context \u003d new RaftClientTestContext.Builder(localId, voters)\n                .withElectedLeader(epoch, leaderId)\n                .build();\n        context.assertElectedLeader(epoch, leaderId);\n\n        // When follower creating snapshot:\n        // 1) The high watermark cannot be empty\n        assertEquals(OptionalLong.empty(), context.client.highWatermark());\n        OffsetAndEpoch invalidSnapshotId1 \u003d new OffsetAndEpoch(1, 0);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId1, 0));\n\n        // Poll for our first fetch request\n        context.pollUntilRequest();\n        RaftRequest.Outbound fetchRequest \u003d context.assertSentFetchRequest();\n        assertTrue(voters.contains(fetchRequest.destination().id()));\n        context.assertFetchRequestData(fetchRequest, epoch, 0L, 0);\n\n        // The response does not advance the high watermark\n        List\u003cString\u003e records1 \u003d Arrays.asList(\"a\", \"b\", \"c\");\n        MemoryRecords batch1 \u003d context.buildBatch(0L, 3, records1);\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            context.fetchResponse(epoch, leaderId, batch1, 0L, Errors.NONE)\n        );\n        context.client.poll();\n\n        // 2) The high watermark must be larger than or equal to the snapshotId\u0027s endOffset\n        int currentEpoch \u003d context.currentEpoch();\n        OffsetAndEpoch invalidSnapshotId2 \u003d new OffsetAndEpoch(context.client.highWatermark().getAsLong() + 1, currentEpoch);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId2, 0));\n\n        // 3) The quorum epoch must be larger than or equal to the snapshotId\u0027s epoch\n        OffsetAndEpoch invalidSnapshotId3 \u003d new OffsetAndEpoch(context.client.highWatermark().getAsLong() + 1, currentEpoch + 1);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId3, 0));\n\n        // The high watermark advances to be larger than log.endOffsetForEpoch(3), to test the case 3\n        context.pollUntilRequest();\n        fetchRequest \u003d context.assertSentFetchRequest();\n        assertTrue(voters.contains(fetchRequest.destination().id()));\n        context.assertFetchRequestData(fetchRequest, epoch, 3L, 3);\n\n        List\u003cString\u003e records2 \u003d Arrays.asList(\"d\", \"e\", \"f\");\n        MemoryRecords batch2 \u003d context.buildBatch(3L, 4, records2);\n        context.deliverResponse(\n            fetchRequest.correlationId(),\n            fetchRequest.destination(),\n            context.fetchResponse(epoch, leaderId, batch2, 6L, Errors.NONE)\n        );\n        context.client.poll();\n        assertEquals(6L, context.client.highWatermark().getAsLong());\n\n        // 4) The snapshotId should be validated against endOffsetForEpoch\n        OffsetAndEpoch endOffsetForEpoch \u003d context.log.endOffsetForEpoch(3);\n        assertEquals(3, endOffsetForEpoch.epoch());\n        OffsetAndEpoch invalidSnapshotId4 \u003d new OffsetAndEpoch(endOffsetForEpoch.offset() + 1, epoch);\n        assertThrows(IllegalArgumentException.class, () -\u003e context.client.createSnapshot(invalidSnapshotId4, 0));\n    }\n\n    private static FetchSnapshotRequestData fetchSnapshotRequest(\n            TopicPartition topicPartition,\n            int epoch,\n            OffsetAndEpoch offsetAndEpoch,\n            int maxBytes,\n            long position\n    ) {\n        return fetchSnapshotRequest(null, -1, topicPartition, epoch, offsetAndEpoch, maxBytes, position);\n    }\n\n    private static FetchSnapshotRequestData fetchSnapshotRequest(\n        String clusterId,\n        int replicaId,\n        TopicPartition topicPartition,\n        int epoch,\n        OffsetAndEpoch offsetAndEpoch,\n        int maxBytes,\n        long position\n    ) {\n        FetchSnapshotRequestData.SnapshotId snapshotId \u003d new FetchSnapshotRequestData.SnapshotId()\n            .setEndOffset(offsetAndEpoch.offset())\n            .setEpoch(offsetAndEpoch.epoch());\n\n        FetchSnapshotRequestData request \u003d FetchSnapshotRequest.singleton(\n            clusterId,\n            replicaId,\n            topicPartition,\n            snapshotPartition -\u003e snapshotPartition\n                .setCurrentLeaderEpoch(epoch)\n                .setSnapshotId(snapshotId)\n                .setPosition(position)\n        );\n\n        return request.setMaxBytes(maxBytes);\n    }\n\n    private static FetchSnapshotResponseData fetchSnapshotResponse(\n        TopicPartition topicPartition,\n        int leaderEpoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long size,\n        long position,\n        ByteBuffer buffer\n    ) {\n        return FetchSnapshotResponse.singleton(\n            topicPartition,\n            partitionSnapshot -\u003e {\n                partitionSnapshot.currentLeader()\n                    .setLeaderEpoch(leaderEpoch)\n                    .setLeaderId(leaderId);\n\n                partitionSnapshot.snapshotId()\n                    .setEndOffset(snapshotId.offset())\n                    .setEpoch(snapshotId.epoch());\n\n                return partitionSnapshot\n                    .setSize(size)\n                    .setPosition(position)\n                    .setUnalignedRecords(MemoryRecords.readableRecords(buffer.slice()));\n            }\n        );\n    }\n\n    private static FetchResponseData snapshotFetchResponse(\n        TopicPartition topicPartition,\n        Uuid topicId,\n        int epoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long highWatermark\n    ) {\n        return RaftUtil.singletonFetchResponse(topicPartition, topicId, Errors.NONE, partitionData -\u003e {\n            partitionData.setHighWatermark(highWatermark);\n\n            partitionData.currentLeader()\n                .setLeaderEpoch(epoch)\n                .setLeaderId(leaderId);\n\n            partitionData.snapshotId()\n                .setEpoch(snapshotId.epoch())\n                .setEndOffset(snapshotId.offset());\n        });\n    }\n\n    private static Optional\u003cFetchSnapshotRequestData.PartitionSnapshot\u003e assertFetchSnapshotRequest(\n        RaftRequest.Outbound request,\n        TopicPartition topicPartition,\n        int replicaId,\n        int maxBytes\n    ) {\n        assertInstanceOf(FetchSnapshotRequestData.class, request.data());\n\n        FetchSnapshotRequestData data \u003d (FetchSnapshotRequestData) request.data();\n\n        assertEquals(replicaId, data.replicaId());\n        assertEquals(maxBytes, data.maxBytes());\n\n        return FetchSnapshotRequest.forTopicPartition(data, topicPartition);\n    }\n\n    private static SnapshotWriter\u003cString\u003e snapshotWriter(RaftClientTestContext context, RawSnapshotWriter snapshot) {\n        return new RecordsSnapshotWriter.Builder()\n            .setTime(context.time)\n            .setRawSnapshotWriter(snapshot)\n            .build(new StringSerde());\n    }\n\n    private static final class MemorySnapshotWriter implements RawSnapshotWriter {\n        private final OffsetAndEpoch snapshotId;\n        private final AtomicLong frozenPosition;\n        private ByteBuffer data;\n\n        public MemorySnapshotWriter(OffsetAndEpoch snapshotId) {\n            this.snapshotId \u003d snapshotId;\n            this.data \u003d ByteBuffer.allocate(0);\n            this.frozenPosition \u003d new AtomicLong(-1L);\n        }\n\n        @Override\n        public OffsetAndEpoch snapshotId() {\n            return snapshotId;\n        }\n\n        @Override\n        public long sizeInBytes() {\n            long position \u003d frozenPosition.get();\n            return (position \u003c 0) ? data.position() : position;\n        }\n\n        @Override\n        public void append(UnalignedMemoryRecords records) {\n            if (isFrozen()) {\n                throw new RuntimeException(\"Snapshot is already frozen \" + snapshotId);\n            }\n            append(records.buffer());\n        }\n\n        @Override\n        public void append(MemoryRecords records) {\n            if (isFrozen()) {\n                throw new RuntimeException(\"Snapshot is already frozen \" + snapshotId);\n            }\n            append(records.buffer());\n        }\n\n        private void append(ByteBuffer buffer) {\n            if (!(data.remaining() \u003e\u003d buffer.remaining())) {\n                ByteBuffer old \u003d data;\n                old.flip();\n\n                int newSize \u003d Math.max(data.capacity() * 2, data.capacity() + buffer.remaining());\n                data \u003d ByteBuffer.allocate(newSize);\n\n                data.put(old);\n            }\n            data.put(buffer);\n        }\n\n        @Override\n        public boolean isFrozen() {\n            return frozenPosition.get() \u003e\u003d 0;\n        }\n\n        @Override\n        public void freeze() {\n            if (!frozenPosition.compareAndSet(-1L, data.position())) {\n                throw new RuntimeException(\"Snapshot is already frozen \" + snapshotId);\n            }\n            data.flip();\n        }\n\n        @Override\n        public void close() {}\n\n        public ByteBuffer buffer() {\n            return data;\n        }\n    }\n}","methodCount":51},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":1918,"lineEnd":1937,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method snapshotFetchResponse to class ClientUtils","description":"move method snapshotFetchResponse to PsiClass:ClientUtils\nRationale: The snapshotFetchResponse() method is primarily concerned with fetching response data related to a client operation, which aligns closely with the responsibilities of ClientUtils. Moving it here adheres to the Single Responsibility Principle, as it centralizes client-related utility functions. This enhances cohesion and makes the method more reusable across client-related contexts. However, care must be taken to ensure that dependencies on the current class\u0027s state are properly managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1918,"lineEnd":1937,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method snapshotFetchResponse to class NetworkTestUtils","description":"move method snapshotFetchResponse to PsiClass:NetworkTestUtils\nRationale: Given that snapshotFetchResponse() deals with fetching data, it could be seen as part of network operations. NetworkTestUtils is focused on creating and managing network connections, which might align with the fetching operations. This move could improve the organization of network-related functionalities. However, it may dilute the focus of NetworkTestUtils if it starts encompassing too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1918,"lineEnd":1937,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method snapshotFetchResponse to class ControllerRequestContextUtil","description":"move method snapshotFetchResponse to PsiClass:ControllerRequestContextUtil\nRationale: This method involves manipulating partition data, which could be relevant to the context of a controller\u0027s request. Moving it here would encapsulate the logic related to request contexts and their associated data manipulations. This aligns with the Open/Closed Principle by allowing future modifications related to request contexts without altering existing code. However, it may introduce unnecessary coupling if not carefully managed.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1854,"lineEnd":1862,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotRequest to class RequestUtils","description":"move method fetchSnapshotRequest to PsiClass:RequestUtils\nRationale: The fetchSnapshotRequest() method is related to fetching request data, which aligns well with the purpose of RequestUtils. Moving it here adheres to the Single Responsibility Principle by ensuring that request-related functionalities are grouped together. This improves cohesion and makes the method more reusable in contexts that deal with requests. However, existing dependencies on the current class should be evaluated to avoid breaking changes.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1854,"lineEnd":1862,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotRequest to class ClientUtils","description":"move method fetchSnapshotRequest to PsiClass:ClientUtils\nRationale: The method fetchSnapshotRequest() deals with fetching data related to client operations, making ClientUtils a suitable target class. This move would improve the organization of client-related utilities and adhere to the Open/Closed Principle by allowing ClientUtils to be extended without modifying existing code. However, care must be taken to ensure that ClientUtils does not become too bloated with unrelated methods.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1854,"lineEnd":1862,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotRequest to class ProducerTestUtils","description":"move method fetchSnapshotRequest to PsiClass:ProducerTestUtils\nRationale: The fetchSnapshotRequest() method could be relevant in testing scenarios for producers, especially if it relates to how producers handle snapshot requests. Moving it to ProducerTestUtils keeps testing utilities organized and adheres to the Single Responsibility Principle. However, this method may not be directly related to testing, so its relevance should be carefully considered.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1890,"lineEnd":1916,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotResponse to class ClientUtils","description":"move method fetchSnapshotResponse to PsiClass:ClientUtils\nRationale: The fetchSnapshotResponse method deals with aspects related to topic partitions, leader epochs, and snapshot data, which are closely related to client operations in a messaging system. Moving it to ClientUtils enhances cohesion, as this class already contains methods that deal with client-related metrics and operations. This aligns with the Single Responsibility Principle by concentrating client-related functionalities in one place. A potential drawback is that it may increase the complexity of ClientUtils if not managed properly.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1890,"lineEnd":1916,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotResponse to class RequestUtils","description":"move method fetchSnapshotResponse to PsiClass:RequestUtils\nRationale: The fetchSnapshotResponse method involves fetching and managing snapshot data, which aligns with the responsibilities of RequestUtils that handles various request-related functionalities. This move would enhance the clarity of the codebase by grouping related functionalities together, adhering to the Open/Closed Principle. However, care must be taken to ensure that RequestUtils does not become a \u0027God Class\u0027 by adding too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1890,"lineEnd":1916,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method fetchSnapshotResponse to class MessageUtil","description":"move method fetchSnapshotResponse to PsiClass:MessageUtil\nRationale: The method processes data in a way that could be related to message handling, particularly in a messaging system context. By relocating fetchSnapshotResponse to MessageUtil, we can enhance the cohesion of message-related operations. This move supports the Interface Segregation Principle by ensuring that classes only have methods relevant to their specific responsibilities. However, the method\u0027s specific focus on fetching snapshots may dilute the purpose of MessageUtil if not carefully integrated.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"testLeaderListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testLeaderListenerNotified(boolean entireLog)","target_class":"","rationale":""},{"method_name":"testFollowerListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testFollowerListenerNotified(boolean entireLog)","target_class":"","rationale":""},{"method_name":"testSecondListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testSecondListenerNotified(boolean entireLog)","target_class":"","rationale":""},{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n            TopicPartition topicPartition,\n            int epoch,\n            OffsetAndEpoch offsetAndEpoch,\n            int maxBytes,\n            long position\n    )","target_class":"","rationale":""},{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n        String clusterId,\n        int replicaId,\n        TopicPartition topicPartition,\n        int epoch,\n        OffsetAndEpoch offsetAndEpoch,\n        int maxBytes,\n        long position\n    )","target_class":"","rationale":""},{"method_name":"fetchSnapshotResponse","method_signature":"private static fetchSnapshotResponse(\n        TopicPartition topicPartition,\n        int leaderEpoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long size,\n        long position,\n        ByteBuffer buffer\n    )","target_class":"","rationale":""},{"method_name":"snapshotFetchResponse","method_signature":"private static snapshotFetchResponse(\n        TopicPartition topicPartition,\n        Uuid topicId,\n        int epoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long highWatermark\n    )","target_class":"","rationale":""},{"method_name":"assertFetchSnapshotRequest","method_signature":"private static assertFetchSnapshotRequest(\n        RaftRequest.Outbound request,\n        TopicPartition topicPartition,\n        int replicaId,\n        int maxBytes\n    )","target_class":"","rationale":""},{"method_name":"snapshotWriter","method_signature":"private static snapshotWriter(RaftClientTestContext context, RawSnapshotWriter snapshot)","target_class":"","rationale":""},{"method_name":"append","method_signature":"private append(ByteBuffer buffer)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"snapshotFetchResponse","method_signature":"private static snapshotFetchResponse(\n        TopicPartition topicPartition,\n        Uuid topicId,\n        int epoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long highWatermark\n    )","target_class":"","rationale":""},{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n            TopicPartition topicPartition,\n            int epoch,\n            OffsetAndEpoch offsetAndEpoch,\n            int maxBytes,\n            long position\n    )","target_class":"","rationale":""},{"method_name":"fetchSnapshotResponse","method_signature":"private static fetchSnapshotResponse(\n        TopicPartition topicPartition,\n        int leaderEpoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long size,\n        long position,\n        ByteBuffer buffer\n    )","target_class":"","rationale":""},{"method_name":"snapshotWriter","method_signature":"private static snapshotWriter(RaftClientTestContext context, RawSnapshotWriter snapshot)","target_class":"","rationale":""},{"method_name":"assertFetchSnapshotRequest","method_signature":"private static assertFetchSnapshotRequest(\n        RaftRequest.Outbound request,\n        TopicPartition topicPartition,\n        int replicaId,\n        int maxBytes\n    )","target_class":"","rationale":""},{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n        String clusterId,\n        int replicaId,\n        TopicPartition topicPartition,\n        int epoch,\n        OffsetAndEpoch offsetAndEpoch,\n        int maxBytes,\n        long position\n    )","target_class":"","rationale":""},{"method_name":"append","method_signature":"private append(ByteBuffer buffer)","target_class":"","rationale":""},{"method_name":"testLeaderListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testLeaderListenerNotified(boolean entireLog)","target_class":"","rationale":""},{"method_name":"testFollowerListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testFollowerListenerNotified(boolean entireLog)","target_class":"","rationale":""},{"method_name":"testSecondListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testSecondListenerNotified(boolean entireLog)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private static snapshotFetchResponse(\n        TopicPartition topicPartition,\n        Uuid topicId,\n        int epoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long highWatermark\n    )":{"first":{"method_name":"snapshotFetchResponse","method_signature":"private static snapshotFetchResponse(\n        TopicPartition topicPartition,\n        Uuid topicId,\n        int epoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long highWatermark\n    )","target_class":"","rationale":""},"second":0.1383666258123128},"private static fetchSnapshotRequest(\n            TopicPartition topicPartition,\n            int epoch,\n            OffsetAndEpoch offsetAndEpoch,\n            int maxBytes,\n            long position\n    )":{"first":{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n            TopicPartition topicPartition,\n            int epoch,\n            OffsetAndEpoch offsetAndEpoch,\n            int maxBytes,\n            long position\n    )","target_class":"","rationale":""},"second":0.16191168727309885},"private static fetchSnapshotResponse(\n        TopicPartition topicPartition,\n        int leaderEpoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long size,\n        long position,\n        ByteBuffer buffer\n    )":{"first":{"method_name":"fetchSnapshotResponse","method_signature":"private static fetchSnapshotResponse(\n        TopicPartition topicPartition,\n        int leaderEpoch,\n        int leaderId,\n        OffsetAndEpoch snapshotId,\n        long size,\n        long position,\n        ByteBuffer buffer\n    )","target_class":"","rationale":""},"second":0.17230030280425201},"private static snapshotWriter(RaftClientTestContext context, RawSnapshotWriter snapshot)":{"first":{"method_name":"snapshotWriter","method_signature":"private static snapshotWriter(RaftClientTestContext context, RawSnapshotWriter snapshot)","target_class":"","rationale":""},"second":0.18816160034501347},"private static assertFetchSnapshotRequest(\n        RaftRequest.Outbound request,\n        TopicPartition topicPartition,\n        int replicaId,\n        int maxBytes\n    )":{"first":{"method_name":"assertFetchSnapshotRequest","method_signature":"private static assertFetchSnapshotRequest(\n        RaftRequest.Outbound request,\n        TopicPartition topicPartition,\n        int replicaId,\n        int maxBytes\n    )","target_class":"","rationale":""},"second":0.2769655698651786},"private static fetchSnapshotRequest(\n        String clusterId,\n        int replicaId,\n        TopicPartition topicPartition,\n        int epoch,\n        OffsetAndEpoch offsetAndEpoch,\n        int maxBytes,\n        long position\n    )":{"first":{"method_name":"fetchSnapshotRequest","method_signature":"private static fetchSnapshotRequest(\n        String clusterId,\n        int replicaId,\n        TopicPartition topicPartition,\n        int epoch,\n        OffsetAndEpoch offsetAndEpoch,\n        int maxBytes,\n        long position\n    )","target_class":"","rationale":""},"second":0.41867750596354747},"private append(ByteBuffer buffer)":{"first":{"method_name":"append","method_signature":"private append(ByteBuffer buffer)","target_class":"","rationale":""},"second":0.5376940839220562},"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testLeaderListenerNotified(boolean entireLog)":{"first":{"method_name":"testLeaderListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testLeaderListenerNotified(boolean entireLog)","target_class":"","rationale":""},"second":0.8432365062099887},"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testFollowerListenerNotified(boolean entireLog)":{"first":{"method_name":"testFollowerListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testFollowerListenerNotified(boolean entireLog)","target_class":"","rationale":""},"second":0.8449114787125362},"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testSecondListenerNotified(boolean entireLog)":{"first":{"method_name":"testSecondListenerNotified","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testSecondListenerNotified(boolean entireLog)","target_class":"","rationale":""},"second":0.8491604864534964}},"llmMethodPriority":{"priority_method_names":["snapshotWriter","snapshotFetchResponse","fetchSnapshotRequest","fetchSnapshotResponse","assertFetchSnapshotRequest","fetchSnapshotRequest","append","testLeaderListenerNotified","testFollowerListenerNotified","testSecondListenerNotified"],"llm_response_time":4937},"targetClassMap":{"snapshotFetchResponse":{"target_classes":[{"class_name":"RaftUtil","similarity_score":0.2548293413946394},{"class_name":"FutureUtils","similarity_score":0.14167344441641133},{"class_name":"RequestTestUtils","similarity_score":0.26687519184557085},{"class_name":"RequestUtils","similarity_score":0.30755414521479946},{"class_name":"FetchUtils","similarity_score":0.051282259406837075},{"class_name":"RetryUtil","similarity_score":0.1632968520898752},{"class_name":"GraphGraceSearchUtil","similarity_score":0.27928128128468566},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.3533111477483942},{"class_name":"ControllerRequestContextUtil","similarity_score":0.33150994544754736},{"class_name":"ControlRecordUtils","similarity_score":0.27858688064795206},{"class_name":"ExceptionUtils","similarity_score":0.2783349703706404},{"class_name":"ClaimValidationUtils","similarity_score":0.06266447243375514},{"class_name":"CsvUtils","similarity_score":0.33774990747593103},{"class_name":"CommandLineUtils","similarity_score":0.28744500940368584},{"class_name":"CommandLineUtilsTest","similarity_score":0.14610048588040714},{"class_name":"CommandUtils","similarity_score":0.23207670718800102},{"class_name":"ClientMetricsTestUtils","similarity_score":0.23683273335783545},{"class_name":"ConfigUtils","similarity_score":0.17319035431204055},{"class_name":"ConsumerGroupCommandTestUtils","similarity_score":0.2192075456090598},{"class_name":"SchemaUtil","similarity_score":0.2785033259480083},{"class_name":"ClientTelemetryUtils","similarity_score":0.3300765286704632},{"class_name":"ConnectorUtils","similarity_score":0.13728862858688265},{"class_name":"ClientUtils","similarity_score":0.318957840546745},{"class_name":"ConsumerProtocolUtils","similarity_score":0.3064624264397709},{"class_name":"ConsumerRecordUtil","similarity_score":0.17177950029416045},{"class_name":"ConnectUtils","similarity_score":0.15590256685737527},{"class_name":"ConsumerUtils","similarity_score":0.2651518941063092},{"class_name":"ConcurrencyUtils","similarity_score":0.1144821378868805},{"class_name":"ScramCredentialUtils","similarity_score":0.2624453295839119},{"class_name":"CollectionUtils","similarity_score":0.18817501445615398},{"class_name":"AuthorizerUtils","similarity_score":0.34416668087621743},{"class_name":"SecurityUtils","similarity_score":0.3170951069113163},{"class_name":"ByteUtils","similarity_score":0.191010655242182},{"class_name":"ByteUtilsBenchmark","similarity_score":0.30588936354289414},{"class_name":"IntegrationTestUtils","similarity_score":0.2381206703188669},{"class_name":"ApiUtils","similarity_score":0.23998500140610352},{"class_name":"InternalQueryResultUtil","similarity_score":0.16829646289202074},{"class_name":"AdminUtils","similarity_score":0.17756879978776557},{"class_name":"AdminClientTestUtils","similarity_score":0.1767733274479183},{"class_name":"AssignmentTestUtil","similarity_score":0.31023838562896633},{"class_name":"AssignmentTestUtils","similarity_score":0.22572677614846784},{"class_name":"AssignorBenchmarkUtils","similarity_score":0.24762384288991146},{"class_name":"JsonUtil","similarity_score":0.22307194388844742},{"class_name":"LogFileUtils","similarity_score":0.08890208045650085},{"class_name":"JaasOptionsUtils","similarity_score":0.2385439703837672},{"class_name":"JaasUtils","similarity_score":0.14092753700898536},{"class_name":"NetworkClientUtils","similarity_score":0.16419182447332933},{"class_name":"NetworkTestUtils","similarity_score":0.3192775647606376},{"class_name":"SystemTestUtil","similarity_score":0.17912059879227826},{"class_name":"MetricsTestUtils","similarity_score":0.3106218662217784}],"target_classes_sorted_by_llm":["ClientUtils","NetworkTestUtils","ControllerRequestContextUtil","MetricsTestUtils","ControllerMetricsTestUtils","SecurityUtils","AuthorizerUtils","AssignmentTestUtil","CsvUtils","ClientTelemetryUtils"],"llm_response_time":8538,"similarity_computation_time":48,"similarity_metric":"voyage"},"fetchSnapshotRequest":{"target_classes":[{"class_name":"RaftUtil","similarity_score":0.2185067700740813},{"class_name":"AuthorizerUtils","similarity_score":0.285462665862998},{"class_name":"FutureUtils","similarity_score":0.1009701885353091},{"class_name":"RequestTestUtils","similarity_score":0.2207690804065308},{"class_name":"RequestUtils","similarity_score":0.261345270458263},{"class_name":"ClaimValidationUtils","similarity_score":0.053919697168025894},{"class_name":"AdminClientTestUtils","similarity_score":0.14465031406937198},{"class_name":"AdminUtils","similarity_score":0.14432207214070225},{"class_name":"ApiUtils","similarity_score":0.19642473664320984},{"class_name":"RetryUtil","similarity_score":0.13371447673510323},{"class_name":"ByteUtils","similarity_score":0.16634186553004646},{"class_name":"ByteUtilsBenchmark","similarity_score":0.2415808827405127},{"class_name":"GraphGraceSearchUtil","similarity_score":0.22933195885153773},{"class_name":"ClientMetricsTestUtils","similarity_score":0.2097817260387595},{"class_name":"ClientTelemetryUtils","similarity_score":0.2613827051218073},{"class_name":"ClientUtils","similarity_score":0.25573520574668424},{"class_name":"AssignmentTestUtil","similarity_score":0.19800524473338071},{"class_name":"AssignmentTestUtils","similarity_score":0.1980967092001755},{"class_name":"AssignorBenchmarkUtils","similarity_score":0.1684588328891613},{"class_name":"CollectionUtils","similarity_score":0.14528767661904926},{"class_name":"CommandLineUtils","similarity_score":0.21376809793323848},{"class_name":"CommandLineUtilsTest","similarity_score":0.10059565406206353},{"class_name":"FetchUtils","similarity_score":0.04264014327112208},{"class_name":"CommandUtils","similarity_score":0.1730933273916592},{"class_name":"SchemaUtil","similarity_score":0.21653278478430668},{"class_name":"ExceptionUtils","similarity_score":0.21253757099690063},{"class_name":"ScramCredentialUtils","similarity_score":0.2306874839637634},{"class_name":"ConcurrencyUtils","similarity_score":0.0917899150453113},{"class_name":"SecurityUtils","similarity_score":0.25424169623241416},{"class_name":"NetworkClientUtils","similarity_score":0.13164633276182638},{"class_name":"NetworkTestUtils","similarity_score":0.272331441934157},{"class_name":"ConfigUtils","similarity_score":0.12122803833037532},{"class_name":"QuorumControllerIntegrationTestUtils","similarity_score":0.16840052861008897},{"class_name":"ConnectorUtils","similarity_score":0.12230643125527943},{"class_name":"PluginUtils","similarity_score":0.1873948029530921},{"class_name":"ConnectUtils","similarity_score":0.12762777149654544},{"class_name":"RackAwareOptimizationParams","similarity_score":0.17390104861447966},{"class_name":"RackUtils","similarity_score":0.19114699832823506},{"class_name":"ProcessorContextUtils","similarity_score":0.21289128119056816},{"class_name":"ProducerTestUtils","similarity_score":0.30606668389141994},{"class_name":"OffsetFetcherUtils","similarity_score":0.21675862477159435},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.22577744852354023},{"class_name":"OffsetUtils","similarity_score":0.10113326297029142},{"class_name":"ConsumerGroupCommandTestUtils","similarity_score":0.16467326516511843},{"class_name":"ConsumerProtocolUtils","similarity_score":0.252838805955433},{"class_name":"PropertiesUtils","similarity_score":0.16196904809427348},{"class_name":"ConsumerRecordUtil","similarity_score":0.16833667614028097},{"class_name":"ConsumerUtils","similarity_score":0.2280961539053511},{"class_name":"LogFileUtils","similarity_score":0.07920026810467563},{"class_name":"IntegrationTestUtils","similarity_score":0.18960093743339193}],"target_classes_sorted_by_llm":["RequestUtils","ClientUtils","ProducerTestUtils","ConsumerProtocolUtils","NetworkTestUtils","ClientTelemetryUtils","SecurityUtils","ScramCredentialUtils","ByteUtilsBenchmark","AuthorizerUtils"],"llm_response_time":10086,"similarity_computation_time":95,"similarity_metric":"voyage"},"fetchSnapshotResponse":{"target_classes":[{"class_name":"RaftUtil","similarity_score":0.2764373269373138},{"class_name":"SystemTestUtil","similarity_score":0.1911614575879201},{"class_name":"FutureUtils","similarity_score":0.15241635856238978},{"class_name":"LogFileUtils","similarity_score":0.11021764424126344},{"class_name":"NetworkClientUtils","similarity_score":0.19742372277130235},{"class_name":"TaskAssignmentUtils","similarity_score":0.2738023526417739},{"class_name":"TaskAssignmentUtilsTest","similarity_score":0.20136655278087712},{"class_name":"TaskBuilder","similarity_score":0.32406235328078015},{"class_name":"RequestTestUtils","similarity_score":0.29258079250824653},{"class_name":"RequestUtils","similarity_score":0.3597211417157876},{"class_name":"NetworkTestUtils","similarity_score":0.3537195263059309},{"class_name":"TestCloseable","similarity_score":0.28336742802815035},{"class_name":"GraphGraceSearchUtil","similarity_score":0.3553252129950138},{"class_name":"RetryUtil","similarity_score":0.19735903191358886},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.34349983401973866},{"class_name":"TestSslUtils","similarity_score":0.26848475678063044},{"class_name":"ControllerRequestContextUtil","similarity_score":0.33652931566804606},{"class_name":"TestUtil","similarity_score":0.27297434161777523},{"class_name":"TestUtils","similarity_score":0.2991694400172147},{"class_name":"ControlRecordUtils","similarity_score":0.3256569611248645},{"class_name":"ThreadUtils","similarity_score":0.23177626732527662},{"class_name":"TieredStorageTestUtils","similarity_score":0.1371659390680236},{"class_name":"ClaimValidationUtils","similarity_score":0.07761088905123925},{"class_name":"AdminClientTestUtils","similarity_score":0.2103695395474878},{"class_name":"AdminUtils","similarity_score":0.17899587785338422},{"class_name":"OAuthBearerScopeUtils","similarity_score":0.14769115769970137},{"class_name":"OAuthBearerValidationUtils","similarity_score":0.14362406586914372},{"class_name":"OAuthBearerValidationUtilsTest","similarity_score":0.26216244677596307},{"class_name":"CommandLineUtils","similarity_score":0.31807706696311705},{"class_name":"CommandLineUtilsTest","similarity_score":0.16836811731194978},{"class_name":"CommandUtils","similarity_score":0.2578037303358603},{"class_name":"CsvUtils","similarity_score":0.3900696360749633},{"class_name":"MessageUtil","similarity_score":0.3649852280534622},{"class_name":"ClientMetricsTestUtils","similarity_score":0.25624740453202444},{"class_name":"OffsetFetcherUtils","similarity_score":0.31875316720556923},{"class_name":"ToolsTestUtils","similarity_score":0.34408791356598245},{"class_name":"ToolsUtils","similarity_score":0.2888075504269051},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.31506473241129024},{"class_name":"ClientTelemetryUtils","similarity_score":0.3857939611429698},{"class_name":"ClientUtils","similarity_score":0.3821376377803748},{"class_name":"OffsetUtils","similarity_score":0.1535348796953654},{"class_name":"TopologyMetadataBuilder","similarity_score":0.31282475480231},{"class_name":"SchemaUtil","similarity_score":0.3268602252303067},{"class_name":"ConcurrencyUtils","similarity_score":0.13301622404223282},{"class_name":"ApiUtils","similarity_score":0.27754646036647435},{"class_name":"ScramCredentialUtils","similarity_score":0.2810913475705226},{"class_name":"MetricsTestUtils","similarity_score":0.3449557892028146},{"class_name":"MetricsUtils","similarity_score":0.16783218203174283},{"class_name":"MirrorUtils","similarity_score":0.24805404002405124},{"class_name":"ConfigUtils","similarity_score":0.19342117994496863}],"target_classes_sorted_by_llm":["ClientUtils","RequestUtils","MessageUtil","ClientTelemetryUtils","MetricsTestUtils","ToolsTestUtils","NetworkTestUtils","GraphGraceSearchUtil","ControllerMetricsTestUtils","CsvUtils"],"llm_response_time":10132,"similarity_computation_time":271,"similarity_metric":"voyage"}}}
{"id":"be8dc52f-687a-4fc3-817c-2d87b2904b8a","methodCount":81,"hostFunctionTelemetryData":{"hostFunctionSize":1374,"lineStart":67,"lineEnd":1440,"bodyLineStart":67,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/consumer/ConsumerGroup.java","sourceCode":"/**\n * A Consumer Group. All the metadata in this class are backed by\n * records in the __consumer_offsets partitions.\n */\npublic class ConsumerGroup implements Group {\n\n    public enum ConsumerGroupState {\n        EMPTY(\"Empty\"),\n        ASSIGNING(\"Assigning\"),\n        RECONCILING(\"Reconciling\"),\n        STABLE(\"Stable\"),\n        DEAD(\"Dead\");\n\n        private final String name;\n\n        private final String lowerCaseName;\n\n        ConsumerGroupState(String name) {\n            this.name \u003d name;\n            this.lowerCaseName \u003d name.toLowerCase(Locale.ROOT);\n        }\n\n        @Override\n        public String toString() {\n            return name;\n        }\n\n        public String toLowerCaseString() {\n            return lowerCaseName;\n        }\n    }\n\n    public static class DeadlineAndEpoch {\n        static final DeadlineAndEpoch EMPTY \u003d new DeadlineAndEpoch(0L, 0);\n\n        public final long deadlineMs;\n        public final int epoch;\n\n        DeadlineAndEpoch(long deadlineMs, int epoch) {\n            this.deadlineMs \u003d deadlineMs;\n            this.epoch \u003d epoch;\n        }\n    }\n\n    /**\n     * The snapshot registry.\n     */\n    private final SnapshotRegistry snapshotRegistry;\n\n    /**\n     * The group id.\n     */\n    private final String groupId;\n\n    /**\n     * The group state.\n     */\n    private final TimelineObject\u003cConsumerGroupState\u003e state;\n\n    /**\n     * The group epoch. The epoch is incremented whenever the subscriptions\n     * are updated and it will trigger the computation of a new assignment\n     * for the group.\n     */\n    private final TimelineInteger groupEpoch;\n\n    /**\n     * The group members.\n     */\n    private final TimelineHashMap\u003cString, ConsumerGroupMember\u003e members;\n\n    /**\n     * The static group members.\n     */\n    private final TimelineHashMap\u003cString, String\u003e staticMembers;\n\n    /**\n     * The number of members supporting each server assignor name.\n     */\n    private final TimelineHashMap\u003cString, Integer\u003e serverAssignors;\n\n    /**\n     * The number of subscribers per topic.\n     */\n    private final TimelineHashMap\u003cString, Integer\u003e subscribedTopicNames;\n\n    /**\n     * The metadata associated with each subscribed topic name.\n     */\n    private final TimelineHashMap\u003cString, TopicMetadata\u003e subscribedTopicMetadata;\n\n    /**\n     * The consumer group\u0027s subscription type.\n     * This value is set to Homogeneous by default.\n     */\n    private final TimelineObject\u003cSubscriptionType\u003e subscriptionType;\n\n    /**\n     * The target assignment epoch. An assignment epoch smaller than the group epoch\n     * means that a new assignment is required. The assignment epoch is updated when\n     * a new assignment is installed.\n     */\n    private final TimelineInteger targetAssignmentEpoch;\n\n    /**\n     * The target assignment per member id.\n     */\n    private final TimelineHashMap\u003cString, Assignment\u003e targetAssignment;\n\n    /**\n     * Reverse lookup map representing topic partitions with\n     * their current member assignments.\n     */\n    private final TimelineHashMap\u003cUuid, TimelineHashMap\u003cInteger, String\u003e\u003e invertedTargetAssignment;\n\n    /**\n     * The current partition epoch maps each topic-partitions to their current epoch where\n     * the epoch is the epoch of their owners. When a member revokes a partition, it removes\n     * its epochs from this map. When a member gets a partition, it adds its epochs to this map.\n     */\n    private final TimelineHashMap\u003cUuid, TimelineHashMap\u003cInteger, Integer\u003e\u003e currentPartitionEpoch;\n\n    /**\n     * The coordinator metrics.\n     */\n    private final GroupCoordinatorMetricsShard metrics;\n\n    /**\n     * The metadata refresh deadline. It consists of a timestamp in milliseconds together with\n     * the group epoch at the time of setting it. The metadata refresh time is considered as a\n     * soft state (read that it is not stored in a timeline data structure). It is like this\n     * because it is not persisted to the log. The group epoch is here to ensure that the\n     * metadata refresh deadline is invalidated if the group epoch does not correspond to\n     * the current group epoch. This can happen if the metadata refresh deadline is updated\n     * after having refreshed the metadata but the write operation failed. In this case, the\n     * time is not automatically rolled back.\n     */\n    private DeadlineAndEpoch metadataRefreshDeadline \u003d DeadlineAndEpoch.EMPTY;\n\n    /**\n     * The number of members that use the classic protocol.\n     */\n    private final TimelineInteger numClassicProtocolMembers;\n\n    /**\n     * Map of protocol names to the number of members that use classic protocol and support them.\n     */\n    private final TimelineHashMap\u003cString, Integer\u003e classicProtocolMembersSupportedProtocols;\n\n    public ConsumerGroup(\n        SnapshotRegistry snapshotRegistry,\n        String groupId,\n        GroupCoordinatorMetricsShard metrics\n    ) {\n        this.snapshotRegistry \u003d Objects.requireNonNull(snapshotRegistry);\n        this.groupId \u003d Objects.requireNonNull(groupId);\n        this.state \u003d new TimelineObject\u003c\u003e(snapshotRegistry, EMPTY);\n        this.groupEpoch \u003d new TimelineInteger(snapshotRegistry);\n        this.members \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.staticMembers \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.serverAssignors \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.subscribedTopicNames \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.subscribedTopicMetadata \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.subscriptionType \u003d new TimelineObject\u003c\u003e(snapshotRegistry, HOMOGENEOUS);\n        this.targetAssignmentEpoch \u003d new TimelineInteger(snapshotRegistry);\n        this.targetAssignment \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.invertedTargetAssignment \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.currentPartitionEpoch \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n        this.metrics \u003d Objects.requireNonNull(metrics);\n        this.numClassicProtocolMembers \u003d new TimelineInteger(snapshotRegistry);\n        this.classicProtocolMembersSupportedProtocols \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, 0);\n    }\n\n    /**\n     * @return The group type (Consumer).\n     */\n    @Override\n    public GroupType type() {\n        return GroupType.CONSUMER;\n    }\n\n    /**\n     * @return The current state as a String.\n     */\n    @Override\n    public String stateAsString() {\n        return state.get().toString();\n    }\n\n    /**\n     * @return The current state as a String with given committedOffset.\n     */\n    public String stateAsString(long committedOffset) {\n        return state.get(committedOffset).toString();\n    }\n\n    /**\n     * @return the group formatted as a list group response based on the committed offset.\n     */\n    public ListGroupsResponseData.ListedGroup asListedGroup(long committedOffset) {\n        return new ListGroupsResponseData.ListedGroup()\n            .setGroupId(groupId)\n            .setProtocolType(ConsumerProtocol.PROTOCOL_TYPE)\n            .setGroupState(state.get(committedOffset).toString())\n            .setGroupType(type().toString());\n    }\n\n    /**\n     * @return The group id.\n     */\n    @Override\n    public String groupId() {\n        return groupId;\n    }\n\n    /**\n     * @return The current state.\n     */\n    public ConsumerGroupState state() {\n        return state.get();\n    }\n\n    /**\n     * @return The current state based on committed offset.\n     */\n    public ConsumerGroupState state(long committedOffset) {\n        return state.get(committedOffset);\n    }\n\n    /**\n     * @return The group epoch.\n     */\n    public int groupEpoch() {\n        return groupEpoch.get();\n    }\n\n    /**\n     * Sets the group epoch.\n     *\n     * @param groupEpoch The new group epoch.\n     */\n    public void setGroupEpoch(int groupEpoch) {\n        this.groupEpoch.set(groupEpoch);\n        maybeUpdateGroupState();\n    }\n\n    /**\n     * @return The target assignment epoch.\n     */\n    public int assignmentEpoch() {\n        return targetAssignmentEpoch.get();\n    }\n\n    /**\n     * Sets the assignment epoch.\n     *\n     * @param targetAssignmentEpoch The new assignment epoch.\n     */\n    public void setTargetAssignmentEpoch(int targetAssignmentEpoch) {\n        this.targetAssignmentEpoch.set(targetAssignmentEpoch);\n        maybeUpdateGroupState();\n    }\n\n    /**\n     * Sets the number of members using the classic protocol.\n     *\n     * @param numClassicProtocolMembers The new NumClassicProtocolMembers.\n     */\n    public void setNumClassicProtocolMembers(int numClassicProtocolMembers) {\n        this.numClassicProtocolMembers.set(numClassicProtocolMembers);\n    }\n\n    /**\n     * Get member id of a static member that matches the given group\n     * instance id.\n     *\n     * @param groupInstanceId The group instance id.\n     *\n     * @return The member id corresponding to the given instance id or null if it does not exist\n     */\n    public String staticMemberId(String groupInstanceId) {\n        return staticMembers.get(groupInstanceId);\n    }\n\n    /**\n     * Gets or creates a new member but without adding it to the group. Adding a member\n     * is done via the {@link ConsumerGroup#updateMember(ConsumerGroupMember)} method.\n     *\n     * @param memberId          The member id.\n     * @param createIfNotExists Booleans indicating whether the member must be\n     *                          created if it does not exist.\n     *\n     * @return A ConsumerGroupMember.\n     */\n    public ConsumerGroupMember getOrMaybeCreateMember(\n        String memberId,\n        boolean createIfNotExists\n    ) {\n        ConsumerGroupMember member \u003d members.get(memberId);\n        if (member !\u003d null) return member;\n\n        if (!createIfNotExists) {\n            throw new UnknownMemberIdException(\n                String.format(\"Member %s is not a member of group %s.\", memberId, groupId)\n            );\n        }\n\n        return new ConsumerGroupMember.Builder(memberId).build();\n    }\n\n    /**\n     * Gets a static member.\n     *\n     * @param instanceId The group instance id.\n     *\n     * @return The member corresponding to the given instance id or null if it does not exist\n     */\n    public ConsumerGroupMember staticMember(String instanceId) {\n        String existingMemberId \u003d staticMemberId(instanceId);\n        return existingMemberId \u003d\u003d null ? null : getOrMaybeCreateMember(existingMemberId, false);\n    }\n\n    /**\n     * Adds or updates the member.\n     *\n     * @param newMember The new member state.\n     */\n    public void updateMember(ConsumerGroupMember newMember) {\n        if (newMember \u003d\u003d null) {\n            throw new IllegalArgumentException(\"newMember cannot be null.\");\n        }\n        ConsumerGroupMember oldMember \u003d members.put(newMember.memberId(), newMember);\n        maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(oldMember, newMember);\n        maybeUpdateServerAssignors(oldMember, newMember);\n        maybeUpdatePartitionEpoch(oldMember, newMember);\n        updateStaticMember(newMember);\n        maybeUpdateGroupState();\n        maybeUpdateNumClassicProtocolMembers(oldMember, newMember);\n        maybeUpdateClassicProtocolMembersSupportedProtocols(oldMember, newMember);\n    }\n\n    /**\n     * Updates the member id stored against the instance id if the member is a static member.\n     *\n     * @param newMember The new member state.\n     */\n    private void updateStaticMember(ConsumerGroupMember newMember) {\n        if (newMember.instanceId() !\u003d null) {\n            staticMembers.put(newMember.instanceId(), newMember.memberId());\n        }\n    }\n\n    /**\n     * Remove the member from the group.\n     *\n     * @param memberId The member id to remove.\n     */\n    public void removeMember(String memberId) {\n        ConsumerGroupMember oldMember \u003d members.remove(memberId);\n        maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(oldMember, null);\n        maybeUpdateServerAssignors(oldMember, null);\n        maybeRemovePartitionEpoch(oldMember);\n        removeStaticMember(oldMember);\n        maybeUpdateGroupState();\n        maybeUpdateNumClassicProtocolMembers(oldMember, null);\n        maybeUpdateClassicProtocolMembersSupportedProtocols(oldMember, null);\n    }\n\n    /**\n     * Remove the static member mapping if the removed member is static.\n     *\n     * @param oldMember The member to remove.\n     */\n    private void removeStaticMember(ConsumerGroupMember oldMember) {\n        if (oldMember.instanceId() !\u003d null) {\n            staticMembers.remove(oldMember.instanceId());\n        }\n    }\n\n    /**\n     * Returns true if the member exists.\n     *\n     * @param memberId The member id.\n     *\n     * @return A boolean indicating whether the member exists or not.\n     */\n    public boolean hasMember(String memberId) {\n        return members.containsKey(memberId);\n    }\n\n    /**\n     * @return The number of members.\n     */\n    public int numMembers() {\n        return members.size();\n    }\n\n    /**\n     * @return The number of members that use the classic protocol.\n     */\n    public int numClassicProtocolMembers() {\n        return numClassicProtocolMembers.get();\n    }\n\n    /**\n     * @return The map of the protocol name and the number of members using the classic protocol that support it.\n     */\n    public Map\u003cString, Integer\u003e classicMembersSupportedProtocols() {\n        return Collections.unmodifiableMap(classicProtocolMembersSupportedProtocols);\n    }\n\n    /**\n     * @return An immutable Map containing all the members keyed by their id.\n     */\n    public Map\u003cString, ConsumerGroupMember\u003e members() {\n        return Collections.unmodifiableMap(members);\n    }\n\n    /**\n     * @return An immutable Map containing all the static members keyed by instance id.\n     */\n    public Map\u003cString, String\u003e staticMembers() {\n        return Collections.unmodifiableMap(staticMembers);\n    }\n\n    /**\n     * @return An immutable map containing all the subscribed topic names\n     *         with the subscribers counts per topic.\n     */\n    public Map\u003cString, Integer\u003e subscribedTopicNames() {\n        return Collections.unmodifiableMap(subscribedTopicNames);\n    }\n\n    /**\n     * Returns true if the consumer group is actively subscribed to the topic.\n     *\n     * @param topic  The topic name.\n     *\n     * @return Whether the group is subscribed to the topic.\n     */\n    @Override\n    public boolean isSubscribedToTopic(String topic) {\n        return subscribedTopicNames.containsKey(topic);\n    }\n\n    /**\n     * @return The group\u0027s subscription type.\n     */\n    public SubscriptionType subscriptionType() {\n        return subscriptionType.get();\n    }\n\n    /**\n     * Returns the target assignment of the member.\n     *\n     * @return The ConsumerGroupMemberAssignment or an EMPTY one if it does not\n     *         exist.\n     */\n    public Assignment targetAssignment(String memberId) {\n        return targetAssignment.getOrDefault(memberId, Assignment.EMPTY);\n    }\n\n    /**\n     * @return An immutable map containing all the topic partitions\n     *         with their current member assignments.\n     */\n    public Map\u003cUuid, Map\u003cInteger, String\u003e\u003e invertedTargetAssignment() {\n        return Collections.unmodifiableMap(invertedTargetAssignment);\n    }\n\n    /**\n     * Updates the target assignment of a member.\n     *\n     * @param memberId              The member id.\n     * @param newTargetAssignment   The new target assignment.\n     */\n    public void updateTargetAssignment(String memberId, Assignment newTargetAssignment) {\n        updateInvertedTargetAssignment(\n            memberId,\n            targetAssignment.getOrDefault(memberId, new Assignment(Collections.emptyMap())),\n            newTargetAssignment\n        );\n        targetAssignment.put(memberId, newTargetAssignment);\n    }\n\n    /**\n     * Updates the reverse lookup map of the target assignment.\n     *\n     * @param memberId              The member Id.\n     * @param oldTargetAssignment   The old target assignment.\n     * @param newTargetAssignment   The new target assignment.\n     */\n    private void updateInvertedTargetAssignment(\n        String memberId,\n        Assignment oldTargetAssignment,\n        Assignment newTargetAssignment\n    ) {\n        // Combine keys from both old and new assignments.\n        Set\u003cUuid\u003e allTopicIds \u003d new HashSet\u003c\u003e();\n        allTopicIds.addAll(oldTargetAssignment.partitions().keySet());\n        allTopicIds.addAll(newTargetAssignment.partitions().keySet());\n\n        for (Uuid topicId : allTopicIds) {\n            Set\u003cInteger\u003e oldPartitions \u003d oldTargetAssignment.partitions().getOrDefault(topicId, Collections.emptySet());\n            Set\u003cInteger\u003e newPartitions \u003d newTargetAssignment.partitions().getOrDefault(topicId, Collections.emptySet());\n\n            TimelineHashMap\u003cInteger, String\u003e topicPartitionAssignment \u003d invertedTargetAssignment.computeIfAbsent(\n                topicId, k -\u003e new TimelineHashMap\u003c\u003e(snapshotRegistry, Math.max(oldPartitions.size(), newPartitions.size()))\n            );\n\n            // Remove partitions that aren\u0027t present in the new assignment only if the partition is currently\n            // still assigned to the member in question.\n            // If p0 was moved from A to B, and the target assignment map was updated for B first, we don\u0027t want to\n            // remove the key p0 from the inverted map and undo the action when A eventually tries to update its assignment.\n            for (Integer partition : oldPartitions) {\n                if (!newPartitions.contains(partition) \u0026\u0026 memberId.equals(topicPartitionAssignment.get(partition))) {\n                    topicPartitionAssignment.remove(partition);\n                }\n            }\n\n            // Add partitions that are in the new assignment but not in the old assignment.\n            for (Integer partition : newPartitions) {\n                if (!oldPartitions.contains(partition)) {\n                    topicPartitionAssignment.put(partition, memberId);\n                }\n            }\n\n            if (topicPartitionAssignment.isEmpty()) {\n                invertedTargetAssignment.remove(topicId);\n            } else {\n                invertedTargetAssignment.put(topicId, topicPartitionAssignment);\n            }\n        }\n    }\n\n    /**\n     * Removes the target assignment of a member.\n     *\n     * @param memberId The member id.\n     */\n    public void removeTargetAssignment(String memberId) {\n        updateInvertedTargetAssignment(\n            memberId,\n            targetAssignment.getOrDefault(memberId, Assignment.EMPTY),\n            Assignment.EMPTY\n        );\n        targetAssignment.remove(memberId);\n    }\n\n    /**\n     * @return An immutable Map containing all the target assignment keyed by member id.\n     */\n    public Map\u003cString, Assignment\u003e targetAssignment() {\n        return Collections.unmodifiableMap(targetAssignment);\n    }\n\n    /**\n     * Returns the current epoch of a partition or -1 if the partition\n     * does not have one.\n     *\n     * @param topicId       The topic id.\n     * @param partitionId   The partition id.\n     *\n     * @return The epoch or -1.\n     */\n    public int currentPartitionEpoch(\n        Uuid topicId, int partitionId\n    ) {\n        Map\u003cInteger, Integer\u003e partitions \u003d currentPartitionEpoch.get(topicId);\n        if (partitions \u003d\u003d null) {\n            return -1;\n        } else {\n            return partitions.getOrDefault(partitionId, -1);\n        }\n    }\n\n    /**\n     * Compute the preferred (server side) assignor for the group while\n     * taking into account the updated member. The computation relies\n     * on {{@link ConsumerGroup#serverAssignors}} persisted structure\n     * but it does not update it.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     *\n     * @return An Optional containing the preferred assignor.\n     */\n    public Optional\u003cString\u003e computePreferredServerAssignor(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        // Copy the current count and update it.\n        Map\u003cString, Integer\u003e counts \u003d new HashMap\u003c\u003e(this.serverAssignors);\n        maybeUpdateServerAssignors(counts, oldMember, newMember);\n\n        return counts.entrySet().stream()\n            .max(Map.Entry.comparingByValue())\n            .map(Map.Entry::getKey);\n    }\n\n    /**\n     * @return The preferred assignor for the group.\n     */\n    public Optional\u003cString\u003e preferredServerAssignor() {\n        return preferredServerAssignor(Long.MAX_VALUE);\n    }\n\n    /**\n     * @return The preferred assignor for the group with given offset.\n     */\n    public Optional\u003cString\u003e preferredServerAssignor(long committedOffset) {\n        return serverAssignors.entrySet(committedOffset).stream()\n            .max(Map.Entry.comparingByValue())\n            .map(Map.Entry::getKey);\n    }\n\n    /**\n     * @return An immutable Map of subscription metadata for\n     *         each topic that the consumer group is subscribed to.\n     */\n    public Map\u003cString, TopicMetadata\u003e subscriptionMetadata() {\n        return Collections.unmodifiableMap(subscribedTopicMetadata);\n    }\n\n    /**\n     * Updates the subscription metadata. This replaces the previous one.\n     *\n     * @param subscriptionMetadata The new subscription metadata.\n     */\n    public void setSubscriptionMetadata(\n        Map\u003cString, TopicMetadata\u003e subscriptionMetadata\n    ) {\n        this.subscribedTopicMetadata.clear();\n        this.subscribedTopicMetadata.putAll(subscriptionMetadata);\n    }\n\n    /**\n     * Computes the subscription metadata based on the current subscription info.\n     *\n     * @param subscribedTopicNames      Map of topic names to the number of subscribers.\n     * @param topicsImage               The current metadata for all available topics.\n     * @param clusterImage              The current metadata for the Kafka cluster.\n     *\n     * @return An immutable map of subscription metadata for each topic that the consumer group is subscribed to.\n     */\n    public Map\u003cString, TopicMetadata\u003e computeSubscriptionMetadata(\n        Map\u003cString, Integer\u003e subscribedTopicNames,\n        TopicsImage topicsImage,\n        ClusterImage clusterImage\n    ) {\n        // Create the topic metadata for each subscribed topic.\n        Map\u003cString, TopicMetadata\u003e newSubscriptionMetadata \u003d new HashMap\u003c\u003e(subscribedTopicNames.size());\n\n        subscribedTopicNames.forEach((topicName, count) -\u003e {\n            TopicImage topicImage \u003d topicsImage.getTopic(topicName);\n            if (topicImage !\u003d null) {\n                Map\u003cInteger, Set\u003cString\u003e\u003e partitionRacks \u003d new HashMap\u003c\u003e();\n                topicImage.partitions().forEach((partition, partitionRegistration) -\u003e {\n                    Set\u003cString\u003e racks \u003d new HashSet\u003c\u003e();\n                    for (int replica : partitionRegistration.replicas) {\n                        Optional\u003cString\u003e rackOptional \u003d clusterImage.broker(replica).rack();\n                        // Only add the rack if it is available for the broker/replica.\n                        rackOptional.ifPresent(racks::add);\n                    }\n                    // If rack information is unavailable for all replicas of this partition,\n                    // no corresponding entry will be stored for it in the map.\n                    if (!racks.isEmpty())\n                        partitionRacks.put(partition, racks);\n                });\n\n                newSubscriptionMetadata.put(topicName, new TopicMetadata(\n                    topicImage.id(),\n                    topicImage.name(),\n                    topicImage.partitions().size(),\n                    partitionRacks)\n                );\n            }\n        });\n\n        return Collections.unmodifiableMap(newSubscriptionMetadata);\n    }\n\n    /**\n     * Updates the metadata refresh deadline.\n     *\n     * @param deadlineMs The deadline in milliseconds.\n     * @param groupEpoch The associated group epoch.\n     */\n    public void setMetadataRefreshDeadline(\n        long deadlineMs,\n        int groupEpoch\n    ) {\n        this.metadataRefreshDeadline \u003d new DeadlineAndEpoch(deadlineMs, groupEpoch);\n    }\n\n    /**\n     * Requests a metadata refresh.\n     */\n    public void requestMetadataRefresh() {\n        this.metadataRefreshDeadline \u003d DeadlineAndEpoch.EMPTY;\n    }\n\n    /**\n     * Checks if a metadata refresh is required. A refresh is required in two cases:\n     * 1) The deadline is smaller or equal to the current time;\n     * 2) The group epoch associated with the deadline is larger than\n     *    the current group epoch. This means that the operations which updated\n     *    the deadline failed.\n     *\n     * @param currentTimeMs The current time in milliseconds.\n     * @return A boolean indicating whether a refresh is required or not.\n     */\n    public boolean hasMetadataExpired(long currentTimeMs) {\n        return currentTimeMs \u003e\u003d metadataRefreshDeadline.deadlineMs || groupEpoch() \u003c metadataRefreshDeadline.epoch;\n    }\n\n    /**\n     * @return The metadata refresh deadline.\n     */\n    public DeadlineAndEpoch metadataRefreshDeadline() {\n        return metadataRefreshDeadline;\n    }\n\n    /**\n     * Validates the OffsetCommit request.\n     *\n     * @param memberId          The member id.\n     * @param groupInstanceId   The group instance id.\n     * @param memberEpoch       The member epoch.\n     * @param isTransactional   Whether the offset commit is transactional or not. It has no\n     *                          impact when a consumer group is used.\n     * @param apiVersion        The api version.\n     * @throws UnknownMemberIdException     If the member is not found.\n     * @throws StaleMemberEpochException    If the member uses the consumer protocol and the provided\n     *                                      member epoch doesn\u0027t match the actual member epoch.\n     * @throws IllegalGenerationException   If the member uses the classic protocol and the provided\n     *                                      generation id is not equal to the member epoch.\n     */\n    @Override\n    public void validateOffsetCommit(\n        String memberId,\n        String groupInstanceId,\n        int memberEpoch,\n        boolean isTransactional,\n        short apiVersion\n    ) throws UnknownMemberIdException, StaleMemberEpochException, IllegalGenerationException {\n        // When the member epoch is -1, the request comes from either the admin client\n        // or a consumer which does not use the group management facility. In this case,\n        // the request can commit offsets if the group is empty.\n        if (memberEpoch \u003c 0 \u0026\u0026 members().isEmpty()) return;\n\n        final ConsumerGroupMember member \u003d getOrMaybeCreateMember(memberId, false);\n\n        // If the commit is not transactional and the member uses the new consumer protocol (KIP-848),\n        // the member should be using the OffsetCommit API version \u003e\u003d 9.\n        if (!isTransactional \u0026\u0026 !member.useClassicProtocol() \u0026\u0026 apiVersion \u003c 9) {\n            throw new UnsupportedVersionException(\"OffsetCommit version 9 or above must be used \" +\n                \"by members using the consumer group protocol\");\n        }\n\n        validateMemberEpoch(memberEpoch, member.memberEpoch(), member.useClassicProtocol());\n    }\n\n    /**\n     * Validates the OffsetFetch request.\n     *\n     * @param memberId              The member id for consumer groups.\n     * @param memberEpoch           The member epoch for consumer groups.\n     * @param lastCommittedOffset   The last committed offsets in the timeline.\n     * @throws UnknownMemberIdException     If the member is not found.\n     * @throws StaleMemberEpochException    If the member uses the consumer protocol and the provided\n     *                                      member epoch doesn\u0027t match the actual member epoch.\n     * @throws IllegalGenerationException   If the member uses the classic protocol and the provided\n     *                                      generation id is not equal to the member epoch.\n     */\n    @Override\n    public void validateOffsetFetch(\n        String memberId,\n        int memberEpoch,\n        long lastCommittedOffset\n    ) throws UnknownMemberIdException, StaleMemberEpochException, IllegalGenerationException {\n        // When the member id is null and the member epoch is -1, the request either comes\n        // from the admin client or from a client which does not provide them. In this case,\n        // the fetch request is accepted.\n        if (memberId \u003d\u003d null \u0026\u0026 memberEpoch \u003c 0) return;\n\n        final ConsumerGroupMember member \u003d members.get(memberId, lastCommittedOffset);\n        if (member \u003d\u003d null) {\n            throw new UnknownMemberIdException(String.format(\"Member %s is not a member of group %s.\",\n                memberId, groupId));\n        }\n        validateMemberEpoch(memberEpoch, member.memberEpoch(), member.useClassicProtocol());\n    }\n\n    /**\n     * Validates the OffsetDelete request.\n     */\n    @Override\n    public void validateOffsetDelete() {}\n\n    /**\n     * Validates the DeleteGroups request.\n     */\n    @Override\n    public void validateDeleteGroup() throws ApiException {\n        if (state() !\u003d ConsumerGroupState.EMPTY) {\n            throw Errors.NON_EMPTY_GROUP.exception();\n        }\n    }\n\n    /**\n     * Populates the list of records with tombstone(s) for deleting the group.\n     *\n     * @param records The list of records.\n     */\n    @Override\n    public void createGroupTombstoneRecords(List\u003cCoordinatorRecord\u003e records) {\n        members().forEach((memberId, member) -\u003e\n            records.add(CoordinatorRecordHelpers.newCurrentAssignmentTombstoneRecord(groupId(), memberId))\n        );\n\n        members().forEach((memberId, member) -\u003e\n            records.add(CoordinatorRecordHelpers.newTargetAssignmentTombstoneRecord(groupId(), memberId))\n        );\n        records.add(CoordinatorRecordHelpers.newTargetAssignmentEpochTombstoneRecord(groupId()));\n\n        members().forEach((memberId, member) -\u003e\n            records.add(CoordinatorRecordHelpers.newMemberSubscriptionTombstoneRecord(groupId(), memberId))\n        );\n\n        records.add(CoordinatorRecordHelpers.newGroupSubscriptionMetadataTombstoneRecord(groupId()));\n        records.add(CoordinatorRecordHelpers.newGroupEpochTombstoneRecord(groupId()));\n    }\n\n    @Override\n    public boolean isEmpty() {\n        return state() \u003d\u003d ConsumerGroupState.EMPTY;\n    }\n\n    /**\n     * See {@link org.apache.kafka.coordinator.group.OffsetExpirationCondition}\n     *\n     * @return The offset expiration condition for the group or Empty if no such condition exists.\n     */\n    @Override\n    public Optional\u003cOffsetExpirationCondition\u003e offsetExpirationCondition() {\n        return Optional.of(new OffsetExpirationConditionImpl(offsetAndMetadata -\u003e offsetAndMetadata.commitTimestampMs));\n    }\n\n    @Override\n    public boolean isInStates(Set\u003cString\u003e statesFilter, long committedOffset) {\n        return statesFilter.contains(state.get(committedOffset).toLowerCaseString());\n    }\n\n    /**\n     * Throws an exception if the received member epoch does not match the expected member epoch.\n     *\n     * @param receivedMemberEpoch   The received member epoch or generation id.\n     * @param expectedMemberEpoch   The expected member epoch.\n     * @param useClassicProtocol    The boolean indicating whether the checked member uses the classic protocol.\n     * @throws StaleMemberEpochException    if the member with unmatched member epoch uses the consumer protocol.\n     * @throws IllegalGenerationException   if the member with unmatched generation id uses the classic protocol.\n     */\n    private void validateMemberEpoch(\n        int receivedMemberEpoch,\n        int expectedMemberEpoch,\n        boolean useClassicProtocol\n    ) throws StaleMemberEpochException, IllegalGenerationException {\n        if (receivedMemberEpoch !\u003d expectedMemberEpoch) {\n            if (useClassicProtocol) {\n                throw new IllegalGenerationException(String.format(\"The received generation id %d does not match \" +\n                    \"the expected member epoch %d.\", receivedMemberEpoch, expectedMemberEpoch));\n            } else {\n                throw new StaleMemberEpochException(String.format(\"The received member epoch %d does not match \"\n                    + \"the expected member epoch %d.\", receivedMemberEpoch, expectedMemberEpoch));\n            }\n        }\n    }\n\n    /**\n     * Updates the current state of the group.\n     */\n    private void maybeUpdateGroupState() {\n        ConsumerGroupState previousState \u003d state.get();\n        ConsumerGroupState newState \u003d STABLE;\n        if (members.isEmpty()) {\n            newState \u003d EMPTY;\n        } else if (groupEpoch.get() \u003e targetAssignmentEpoch.get()) {\n            newState \u003d ASSIGNING;\n        } else {\n            for (ConsumerGroupMember member : members.values()) {\n                if (!member.isReconciledTo(targetAssignmentEpoch.get())) {\n                    newState \u003d RECONCILING;\n                    break;\n                }\n            }\n        }\n\n        state.set(newState);\n        metrics.onConsumerGroupStateTransition(previousState, newState);\n    }\n\n    /**\n     * Updates the server assignors count.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     */\n    private void maybeUpdateServerAssignors(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        maybeUpdateServerAssignors(serverAssignors, oldMember, newMember);\n    }\n\n    /**\n     * Updates the server assignors count.\n     *\n     * @param serverAssignorCount   The count to update.\n     * @param oldMember             The old member.\n     * @param newMember             The new member.\n     */\n    private static void maybeUpdateServerAssignors(\n        Map\u003cString, Integer\u003e serverAssignorCount,\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        if (oldMember !\u003d null) {\n            oldMember.serverAssignorName().ifPresent(name -\u003e\n                serverAssignorCount.compute(name, ConsumerGroup::decValue)\n            );\n        }\n        if (newMember !\u003d null) {\n            newMember.serverAssignorName().ifPresent(name -\u003e\n                serverAssignorCount.compute(name, ConsumerGroup::incValue)\n            );\n        }\n    }\n\n    /**\n     * Updates the number of the members that use the classic protocol.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     */\n    private void maybeUpdateNumClassicProtocolMembers(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        int delta \u003d 0;\n        if (oldMember !\u003d null \u0026\u0026 oldMember.useClassicProtocol()) {\n            delta--;\n        }\n        if (newMember !\u003d null \u0026\u0026 newMember.useClassicProtocol()) {\n            delta++;\n        }\n        setNumClassicProtocolMembers(numClassicProtocolMembers() + delta);\n    }\n\n    /**\n     * Updates the supported protocol count of the members that use the classic protocol.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     */\n    private void maybeUpdateClassicProtocolMembersSupportedProtocols(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        if (oldMember !\u003d null) {\n            oldMember.supportedClassicProtocols().ifPresent(protocols -\u003e\n                protocols.forEach(protocol -\u003e\n                    classicProtocolMembersSupportedProtocols.compute(protocol.name(), ConsumerGroup::decValue)\n                )\n            );\n        }\n        if (newMember !\u003d null) {\n            newMember.supportedClassicProtocols().ifPresent(protocols -\u003e\n                protocols.forEach(protocol -\u003e\n                    classicProtocolMembersSupportedProtocols.compute(protocol.name(), ConsumerGroup::incValue)\n                )\n            );\n        }\n    }\n\n    /**\n     * Updates the subscribed topic names count.\n     * The subscription type is updated as a consequence.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     */\n    private void maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        maybeUpdateSubscribedTopicNames(subscribedTopicNames, oldMember, newMember);\n        subscriptionType.set(subscriptionType(subscribedTopicNames, members.size()));\n    }\n\n    /**\n     * Updates the subscription count.\n     *\n     * @param subscribedTopicCount  The map to update.\n     * @param oldMember             The old member.\n     * @param newMember             The new member.\n     */\n    private static void maybeUpdateSubscribedTopicNames(\n        Map\u003cString, Integer\u003e subscribedTopicCount,\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        if (oldMember !\u003d null) {\n            oldMember.subscribedTopicNames().forEach(topicName -\u003e\n                subscribedTopicCount.compute(topicName, ConsumerGroup::decValue)\n            );\n        }\n\n        if (newMember !\u003d null) {\n            newMember.subscribedTopicNames().forEach(topicName -\u003e\n                subscribedTopicCount.compute(topicName, ConsumerGroup::incValue)\n            );\n        }\n    }\n\n    /**\n     * Updates the subscription count.\n     *\n     * @param oldMember             The old member.\n     * @param newMember             The new member.\n     *\n     * @return Copy of the map of topics to the count of number of subscribers.\n     */\n    public Map\u003cString, Integer\u003e computeSubscribedTopicNames(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        Map\u003cString, Integer\u003e subscribedTopicNames \u003d new HashMap\u003c\u003e(this.subscribedTopicNames);\n        maybeUpdateSubscribedTopicNames(\n            subscribedTopicNames,\n            oldMember,\n            newMember\n        );\n        return subscribedTopicNames;\n    }\n\n    /**\n     * Updates the subscription count with a set of members removed.\n     *\n     * @param removedMembers        The set of removed members.\n     *\n     * @return Copy of the map of topics to the count of number of subscribers.\n     */\n    public Map\u003cString, Integer\u003e computeSubscribedTopicNames(\n        Set\u003cConsumerGroupMember\u003e removedMembers\n    ) {\n        Map\u003cString, Integer\u003e subscribedTopicNames \u003d new HashMap\u003c\u003e(this.subscribedTopicNames);\n        if (removedMembers !\u003d null) {\n            removedMembers.forEach(removedMember -\u003e\n                maybeUpdateSubscribedTopicNames(\n                    subscribedTopicNames,\n                    removedMember,\n                    null\n                )\n            );\n        }\n        return subscribedTopicNames;\n    }\n\n    /**\n     * Compute the subscription type of the consumer group.\n     *\n     * @param subscribedTopicNames      A map of topic names to the count of members subscribed to each topic.\n     *\n     * @return {@link SubscriptionType#HOMOGENEOUS} if all members are subscribed to exactly the same topics;\n     *         otherwise, {@link SubscriptionType#HETEROGENEOUS}.\n     */\n    public static SubscriptionType subscriptionType(\n        Map\u003cString, Integer\u003e subscribedTopicNames,\n        int numberOfMembers\n    ) {\n        if (subscribedTopicNames.isEmpty()) {\n            return HOMOGENEOUS;\n        }\n\n        for (int subscriberCount : subscribedTopicNames.values()) {\n            if (subscriberCount !\u003d numberOfMembers) {\n                return HETEROGENEOUS;\n            }\n        }\n        return HOMOGENEOUS;\n    }\n\n    /**\n     * Updates the partition epochs based on the old and the new member.\n     *\n     * @param oldMember The old member.\n     * @param newMember The new member.\n     */\n    private void maybeUpdatePartitionEpoch(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    ) {\n        maybeRemovePartitionEpoch(oldMember);\n        addPartitionEpochs(newMember.assignedPartitions(), newMember.memberEpoch());\n        addPartitionEpochs(newMember.partitionsPendingRevocation(), newMember.memberEpoch());\n    }\n\n    /**\n     * Removes the partition epochs for the provided member.\n     *\n     * @param oldMember The old member.\n     */\n    private void maybeRemovePartitionEpoch(\n        ConsumerGroupMember oldMember\n    ) {\n        if (oldMember !\u003d null) {\n            removePartitionEpochs(oldMember.assignedPartitions(), oldMember.memberEpoch());\n            removePartitionEpochs(oldMember.partitionsPendingRevocation(), oldMember.memberEpoch());\n        }\n    }\n\n    /**\n     * Removes the partition epochs based on the provided assignment.\n     *\n     * @param assignment    The assignment.\n     * @param expectedEpoch The expected epoch.\n     * @throws IllegalStateException if the epoch does not match the expected one.\n     * package-private for testing.\n     */\n    void removePartitionEpochs(\n        Map\u003cUuid, Set\u003cInteger\u003e\u003e assignment,\n        int expectedEpoch\n    ) {\n        assignment.forEach((topicId, assignedPartitions) -\u003e {\n            currentPartitionEpoch.compute(topicId, (__, partitionsOrNull) -\u003e {\n                if (partitionsOrNull !\u003d null) {\n                    assignedPartitions.forEach(partitionId -\u003e {\n                        Integer prevValue \u003d partitionsOrNull.remove(partitionId);\n                        if (prevValue !\u003d expectedEpoch) {\n                            throw new IllegalStateException(\n                                String.format(\"Cannot remove the epoch %d from %s-%s because the partition is \" +\n                                    \"still owned at a different epoch %d\", expectedEpoch, topicId, partitionId, prevValue));\n                        }\n                    });\n                    if (partitionsOrNull.isEmpty()) {\n                        return null;\n                    } else {\n                        return partitionsOrNull;\n                    }\n                } else {\n                    throw new IllegalStateException(\n                        String.format(\"Cannot remove the epoch %d from %s because it does not have any epoch\",\n                            expectedEpoch, topicId));\n                }\n            });\n        });\n    }\n\n    /**\n     * Adds the partitions epoch based on the provided assignment.\n     *\n     * @param assignment    The assignment.\n     * @param epoch         The new epoch.\n     * @throws IllegalStateException if the partition already has an epoch assigned.\n     * package-private for testing.\n     */\n    void addPartitionEpochs(\n        Map\u003cUuid, Set\u003cInteger\u003e\u003e assignment,\n        int epoch\n    ) {\n        assignment.forEach((topicId, assignedPartitions) -\u003e {\n            currentPartitionEpoch.compute(topicId, (__, partitionsOrNull) -\u003e {\n                if (partitionsOrNull \u003d\u003d null) {\n                    partitionsOrNull \u003d new TimelineHashMap\u003c\u003e(snapshotRegistry, assignedPartitions.size());\n                }\n                for (Integer partitionId : assignedPartitions) {\n                    Integer prevValue \u003d partitionsOrNull.put(partitionId, epoch);\n                    if (prevValue !\u003d null) {\n                        throw new IllegalStateException(\n                            String.format(\"Cannot set the epoch of %s-%s to %d because the partition is \" +\n                                \"still owned at epoch %d\", topicId, partitionId, epoch, prevValue));\n                    }\n                }\n                return partitionsOrNull;\n            });\n        });\n    }\n\n    /**\n     * Decrements value by 1; returns null when reaching zero. This helper is\n     * meant to be used with Map#compute.\n     */\n    private static Integer decValue(String key, Integer value) {\n        if (value \u003d\u003d null) return null;\n        return value \u003d\u003d 1 ? null : value - 1;\n    }\n\n    /**\n     * Increments value by 1; This helper is meant to be used with Map#compute.\n     */\n    private static Integer incValue(String key, Integer value) {\n        return value \u003d\u003d null ? 1 : value + 1;\n    }\n\n    public ConsumerGroupDescribeResponseData.DescribedGroup asDescribedGroup(\n        long committedOffset,\n        String defaultAssignor,\n        TopicsImage topicsImage\n    ) {\n        ConsumerGroupDescribeResponseData.DescribedGroup describedGroup \u003d new ConsumerGroupDescribeResponseData.DescribedGroup()\n            .setGroupId(groupId)\n            .setAssignorName(preferredServerAssignor(committedOffset).orElse(defaultAssignor))\n            .setGroupEpoch(groupEpoch.get(committedOffset))\n            .setGroupState(state.get(committedOffset).toString())\n            .setAssignmentEpoch(targetAssignmentEpoch.get(committedOffset));\n        members.entrySet(committedOffset).forEach(\n            entry -\u003e describedGroup.members().add(\n                entry.getValue().asConsumerGroupDescribeMember(\n                    targetAssignment.get(entry.getValue().memberId(), committedOffset),\n                    topicsImage\n                )\n            )\n        );\n        return describedGroup;\n    }\n\n    /**\n     * Create a new consumer group according to the given classic group.\n     *\n     * @param snapshotRegistry  The SnapshotRegistry.\n     * @param metrics           The GroupCoordinatorMetricsShard.\n     * @param classicGroup      The converted classic group.\n     * @param topicsImage       The TopicsImage for topic id and topic name conversion.\n     * @return  The created ConsumerGruop.\n     */\n    public static ConsumerGroup fromClassicGroup(\n        SnapshotRegistry snapshotRegistry,\n        GroupCoordinatorMetricsShard metrics,\n        ClassicGroup classicGroup,\n        TopicsImage topicsImage\n    ) {\n        String groupId \u003d classicGroup.groupId();\n        ConsumerGroup consumerGroup \u003d new ConsumerGroup(snapshotRegistry, groupId, metrics);\n        consumerGroup.setGroupEpoch(classicGroup.generationId());\n        consumerGroup.setTargetAssignmentEpoch(classicGroup.generationId());\n\n        classicGroup.allMembers().forEach(classicGroupMember -\u003e {\n            Map\u003cUuid, Set\u003cInteger\u003e\u003e assignedPartitions \u003d toTopicPartitionMap(\n                ConsumerProtocol.deserializeConsumerProtocolAssignment(\n                    ByteBuffer.wrap(classicGroupMember.assignment())\n                ),\n                topicsImage\n            );\n            ConsumerProtocolSubscription subscription \u003d ConsumerProtocol.deserializeConsumerProtocolSubscription(\n                ByteBuffer.wrap(classicGroupMember.metadata(classicGroup.protocolName().get()))\n            );\n\n            // The target assignment and the assigned partitions of each member are set based on the last\n            // assignment of the classic group. All the members are put in the Stable state. If the classic\n            // group was in Preparing Rebalance or Completing Rebalance states, the classic members are\n            // asked to rejoin the group to re-trigger a rebalance or collect their assignments.\n            ConsumerGroupMember newMember \u003d new ConsumerGroupMember.Builder(classicGroupMember.memberId())\n                .setMemberEpoch(classicGroup.generationId())\n                .setState(MemberState.STABLE)\n                .setPreviousMemberEpoch(classicGroup.generationId())\n                .setInstanceId(classicGroupMember.groupInstanceId().orElse(null))\n                .setRackId(toOptional(subscription.rackId()).orElse(null))\n                .setRebalanceTimeoutMs(classicGroupMember.rebalanceTimeoutMs())\n                .setClientId(classicGroupMember.clientId())\n                .setClientHost(classicGroupMember.clientHost())\n                .setSubscribedTopicNames(subscription.topics())\n                .setAssignedPartitions(assignedPartitions)\n                .setClassicMemberMetadata(\n                    new ConsumerGroupMemberMetadataValue.ClassicMemberMetadata()\n                        .setSessionTimeoutMs(classicGroupMember.sessionTimeoutMs())\n                        .setSupportedProtocols(ConsumerGroupMember.classicProtocolListFromJoinRequestProtocolCollection(\n                            classicGroupMember.supportedProtocols()\n                        ))\n                )\n                .build();\n            consumerGroup.updateTargetAssignment(newMember.memberId(), new Assignment(assignedPartitions));\n            consumerGroup.updateMember(newMember);\n        });\n\n        return consumerGroup;\n    }\n\n    /**\n     * Populate the record list with the records needed to create the given consumer group.\n     *\n     * @param records The list to which the new records are added.\n     */\n    public void createConsumerGroupRecords(\n        List\u003cCoordinatorRecord\u003e records\n    ) {\n        members().forEach((__, consumerGroupMember) -\u003e\n            records.add(CoordinatorRecordHelpers.newMemberSubscriptionRecord(groupId(), consumerGroupMember))\n        );\n\n        records.add(CoordinatorRecordHelpers.newGroupEpochRecord(groupId(), groupEpoch()));\n\n        members().forEach((consumerGroupMemberId, consumerGroupMember) -\u003e\n            records.add(CoordinatorRecordHelpers.newTargetAssignmentRecord(\n                groupId(),\n                consumerGroupMemberId,\n                targetAssignment(consumerGroupMemberId).partitions()\n            ))\n        );\n\n        records.add(CoordinatorRecordHelpers.newTargetAssignmentEpochRecord(groupId(), groupEpoch()));\n\n        members().forEach((__, consumerGroupMember) -\u003e\n            records.add(CoordinatorRecordHelpers.newCurrentAssignmentRecord(groupId(), consumerGroupMember))\n        );\n    }\n\n    /**\n     * Checks whether at least one of the given protocols can be supported. A\n     * protocol can be supported if it is supported by all members that use the\n     * classic protocol.\n     *\n     * @param memberProtocolType  The member protocol type.\n     * @param memberProtocols     The set of protocol names.\n     *\n     * @return A boolean based on the condition mentioned above.\n     */\n    public boolean supportsClassicProtocols(String memberProtocolType, Set\u003cString\u003e memberProtocols) {\n        if (ConsumerProtocol.PROTOCOL_TYPE.equals(memberProtocolType)) {\n            if (isEmpty()) {\n                return !memberProtocols.isEmpty();\n            } else {\n                return memberProtocols.stream().anyMatch(\n                    name -\u003e classicProtocolMembersSupportedProtocols.getOrDefault(name, 0) \u003d\u003d numClassicProtocolMembers()\n                );\n            }\n        }\n        return false;\n    }\n\n    /**\n     * Checks whether all the members use the classic protocol except the given member.\n     *\n     * @param memberId The member to remove.\n     * @return A boolean indicating whether all the members use the classic protocol.\n     */\n    public boolean allMembersUseClassicProtocolExcept(String memberId) {\n        return numClassicProtocolMembers() \u003d\u003d members().size() - 1 \u0026\u0026\n            !getOrMaybeCreateMember(memberId, false).useClassicProtocol();\n    }\n\n    /**\n     * Checks whether the member has any unreleased partition.\n     *\n     * @param member The member to check.\n     * @return A boolean indicating whether the member has partitions in the target\n     *         assignment that hasn\u0027t been revoked by other members.\n     */\n    public boolean waitingOnUnreleasedPartition(ConsumerGroupMember member) {\n        if (member.state() \u003d\u003d MemberState.UNRELEASED_PARTITIONS) {\n            for (Map.Entry\u003cUuid, Set\u003cInteger\u003e\u003e entry : targetAssignment().get(member.memberId()).partitions().entrySet()) {\n                Uuid topicId \u003d entry.getKey();\n                Set\u003cInteger\u003e assignedPartitions \u003d member.assignedPartitions().getOrDefault(topicId, Collections.emptySet());\n\n                for (int partition : entry.getValue()) {\n                    if (!assignedPartitions.contains(partition) \u0026\u0026 currentPartitionEpoch(topicId, partition) !\u003d -1) {\n                        return true;\n                    }\n                }\n            }\n        }\n        return false;\n    }\n}","methodCount":81},"candidatesTelemetryData":{"numberOfSuggestions":5,"candidates":[{"lineStart":1354,"lineEnd":1381,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createConsumerGroupRecords to class GroupCoordinatorMetricsShard","description":"Move method createConsumerGroupRecords to org.apache.kafka.coordinator.group.metrics.GroupCoordinatorMetricsShard\nRationale: The createConsumerGroupRecords() method is responsible for creating records related to consumer groups, which aligns closely with the responsibilities of GroupCoordinatorMetricsShard. Moving this method here adheres to the Single Responsibility Principle, as it centralizes consumer group management. This would enhance cohesion within the class by combining related functionalities. However, care must be taken to ensure that the method does not introduce unnecessary dependencies on metrics-related logic.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1354,"lineEnd":1381,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createConsumerGroupRecords to class SnapshotRegistry","description":"Move method createConsumerGroupRecords to org.apache.kafka.timeline.SnapshotRegistry\nRationale: The method deals with records that may be snapshots of consumer group states. By relocating it to SnapshotRegistry, it can leverage existing snapshot management functionalities. This adheres to the Open/Closed Principle, allowing future extensions for record management without modifying existing code. Nevertheless, it may lead to a cluttered class if too many unrelated methods are added.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1354,"lineEnd":1381,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createConsumerGroupRecords to class DeadlineAndEpoch","description":"Move method createConsumerGroupRecords to org.apache.kafka.coordinator.group.consumer.ConsumerGroup.DeadlineAndEpoch\nRationale: The createConsumerGroupRecords() method heavily utilizes group IDs and epochs, which are central to the DeadlineAndEpoch class. Moving this method here enhances the encapsulation of related functionalities and aligns with the Interface Segregation Principle by keeping the consumer group logic focused. However, this class may become overly specialized, which could limit its reusability in broader contexts.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":418,"lineEnd":432,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method removeMember to class DeadlineAndEpoch","description":"Move method removeMember to org.apache.kafka.coordinator.group.consumer.ConsumerGroup.DeadlineAndEpoch\nRationale: The removeMember() method appears to deal with the management of group members and their associated states, which may relate to the timing and lifecycle of group memberships. Moving this method to DeadlineAndEpoch could enhance cohesion, as it suggests a focus on the temporal aspects of group membership (e.g., deadlines and epochs). This aligns with the Single Responsibility Principle by consolidating related functionalities that manage the lifecycle of group members within a single class. However, it\u0027s important to note that the DeadlineAndEpoch class may not inherently possess the context of group management, so care must be taken to ensure that the method\u0027s dependencies do not lead to a lack of clarity or increased coupling with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":1159,"lineEnd":1172,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method maybeUpdatePartitionEpoch to class DeadlineAndEpoch","description":"Move method maybeUpdatePartitionEpoch to org.apache.kafka.coordinator.group.consumer.ConsumerGroup.DeadlineAndEpoch\nRationale: The maybeUpdatePartitionEpoch() method deals with updating partition epochs based on consumer group members, which is closely related to the concept of deadlines and epochs in a partitioned system. Moving this method to DeadlineAndEpoch aligns with the Single Responsibility Principle (SRP) as it centralizes the logic related to epoch management within a class that presumably deals with deadlines and epochs. This enhances cohesion by grouping related functionalities, making the codebase easier to understand and maintain. Additionally, it adheres to the Open/Closed Principle (OCP) as the DeadlineAndEpoch class can be extended without modifying existing code. However, a potential drawback is that this class may become overloaded if it starts handling too many responsibilities beyond its primary focus, so careful consideration of its design is necessary.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"stateAsString","method_signature":"public stateAsString(long committedOffset)","target_class":"","rationale":""},{"method_name":"asListedGroup","method_signature":"public asListedGroup(long committedOffset)","target_class":"","rationale":""},{"method_name":"state","method_signature":"public state()","target_class":"","rationale":""},{"method_name":"state","method_signature":"public state(long committedOffset)","target_class":"","rationale":""},{"method_name":"groupEpoch","method_signature":"public groupEpoch()","target_class":"","rationale":""},{"method_name":"assignmentEpoch","method_signature":"public assignmentEpoch()","target_class":"","rationale":""},{"method_name":"staticMemberId","method_signature":"public staticMemberId(String groupInstanceId)","target_class":"","rationale":""},{"method_name":"getOrMaybeCreateMember","method_signature":"public getOrMaybeCreateMember(\n        String memberId,\n        boolean createIfNotExists\n    )","target_class":"","rationale":""},{"method_name":"staticMember","method_signature":"public staticMember(String instanceId)","target_class":"","rationale":""},{"method_name":"updateMember","method_signature":"public updateMember(ConsumerGroupMember newMember)","target_class":"","rationale":""},{"method_name":"updateStaticMember","method_signature":"private updateStaticMember(ConsumerGroupMember newMember)","target_class":"","rationale":""},{"method_name":"removeMember","method_signature":"public removeMember(String memberId)","target_class":"","rationale":""},{"method_name":"removeStaticMember","method_signature":"private removeStaticMember(ConsumerGroupMember oldMember)","target_class":"","rationale":""},{"method_name":"hasMember","method_signature":"public hasMember(String memberId)","target_class":"","rationale":""},{"method_name":"numMembers","method_signature":"public numMembers()","target_class":"","rationale":""},{"method_name":"numClassicProtocolMembers","method_signature":"public numClassicProtocolMembers()","target_class":"","rationale":""},{"method_name":"classicMembersSupportedProtocols","method_signature":"public classicMembersSupportedProtocols()","target_class":"","rationale":""},{"method_name":"members","method_signature":"public members()","target_class":"","rationale":""},{"method_name":"staticMembers","method_signature":"public staticMembers()","target_class":"","rationale":""},{"method_name":"subscribedTopicNames","method_signature":"public subscribedTopicNames()","target_class":"","rationale":""},{"method_name":"subscriptionType","method_signature":"public subscriptionType()","target_class":"","rationale":""},{"method_name":"targetAssignment","method_signature":"public targetAssignment(String memberId)","target_class":"","rationale":""},{"method_name":"invertedTargetAssignment","method_signature":"public invertedTargetAssignment()","target_class":"","rationale":""},{"method_name":"updateTargetAssignment","method_signature":"public updateTargetAssignment(String memberId, Assignment newTargetAssignment)","target_class":"","rationale":""},{"method_name":"updateInvertedTargetAssignment","method_signature":"private updateInvertedTargetAssignment(\n        String memberId,\n        Assignment oldTargetAssignment,\n        Assignment newTargetAssignment\n    )","target_class":"","rationale":""},{"method_name":"removeTargetAssignment","method_signature":"public removeTargetAssignment(String memberId)","target_class":"","rationale":""},{"method_name":"targetAssignment","method_signature":"public targetAssignment()","target_class":"","rationale":""},{"method_name":"currentPartitionEpoch","method_signature":"public currentPartitionEpoch(\n        Uuid topicId, int partitionId\n    )","target_class":"","rationale":""},{"method_name":"computePreferredServerAssignor","method_signature":"public computePreferredServerAssignor(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"preferredServerAssignor","method_signature":"public preferredServerAssignor()","target_class":"","rationale":""},{"method_name":"preferredServerAssignor","method_signature":"public preferredServerAssignor(long committedOffset)","target_class":"","rationale":""},{"method_name":"subscriptionMetadata","method_signature":"public subscriptionMetadata()","target_class":"","rationale":""},{"method_name":"computeSubscriptionMetadata","method_signature":"public computeSubscriptionMetadata(\n        Map\u003cString, Integer\u003e subscribedTopicNames,\n        TopicsImage topicsImage,\n        ClusterImage clusterImage\n    )","target_class":"","rationale":""},{"method_name":"hasMetadataExpired","method_signature":"public hasMetadataExpired(long currentTimeMs)","target_class":"","rationale":""},{"method_name":"validateMemberEpoch","method_signature":"private validateMemberEpoch(\n        int receivedMemberEpoch,\n        int expectedMemberEpoch,\n        boolean useClassicProtocol\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateGroupState","method_signature":"private maybeUpdateGroupState()","target_class":"","rationale":""},{"method_name":"maybeUpdateServerAssignors","method_signature":"private maybeUpdateServerAssignors(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateServerAssignors","method_signature":"private static maybeUpdateServerAssignors(\n        Map\u003cString, Integer\u003e serverAssignorCount,\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateNumClassicProtocolMembers","method_signature":"private maybeUpdateNumClassicProtocolMembers(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateClassicProtocolMembersSupportedProtocols","method_signature":"private maybeUpdateClassicProtocolMembersSupportedProtocols(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType","method_signature":"private maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateSubscribedTopicNames","method_signature":"private static maybeUpdateSubscribedTopicNames(\n        Map\u003cString, Integer\u003e subscribedTopicCount,\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"computeSubscribedTopicNames","method_signature":"public computeSubscribedTopicNames(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"computeSubscribedTopicNames","method_signature":"public computeSubscribedTopicNames(\n        Set\u003cConsumerGroupMember\u003e removedMembers\n    )","target_class":"","rationale":""},{"method_name":"subscriptionType","method_signature":"public static subscriptionType(\n        Map\u003cString, Integer\u003e subscribedTopicNames,\n        int numberOfMembers\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdatePartitionEpoch","method_signature":"private maybeUpdatePartitionEpoch(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"maybeRemovePartitionEpoch","method_signature":"private maybeRemovePartitionEpoch(\n        ConsumerGroupMember oldMember\n    )","target_class":"","rationale":""},{"method_name":"removePartitionEpochs","method_signature":" removePartitionEpochs(\n        Map\u003cUuid, Set\u003cInteger\u003e\u003e assignment,\n        int expectedEpoch\n    )","target_class":"","rationale":""},{"method_name":"addPartitionEpochs","method_signature":" addPartitionEpochs(\n        Map\u003cUuid, Set\u003cInteger\u003e\u003e assignment,\n        int epoch\n    )","target_class":"","rationale":""},{"method_name":"decValue","method_signature":"private static decValue(String key, Integer value)","target_class":"","rationale":""},{"method_name":"incValue","method_signature":"private static incValue(String key, Integer value)","target_class":"","rationale":""},{"method_name":"asDescribedGroup","method_signature":"public asDescribedGroup(\n        long committedOffset,\n        String defaultAssignor,\n        TopicsImage topicsImage\n    )","target_class":"","rationale":""},{"method_name":"fromClassicGroup","method_signature":"public static fromClassicGroup(\n        SnapshotRegistry snapshotRegistry,\n        GroupCoordinatorMetricsShard metrics,\n        ClassicGroup classicGroup,\n        TopicsImage topicsImage\n    )","target_class":"","rationale":""},{"method_name":"createConsumerGroupRecords","method_signature":"public createConsumerGroupRecords(\n        List\u003cCoordinatorRecord\u003e records\n    )","target_class":"","rationale":""},{"method_name":"supportsClassicProtocols","method_signature":"public supportsClassicProtocols(String memberProtocolType, Set\u003cString\u003e memberProtocols)","target_class":"","rationale":""},{"method_name":"allMembersUseClassicProtocolExcept","method_signature":"public allMembersUseClassicProtocolExcept(String memberId)","target_class":"","rationale":""},{"method_name":"waitingOnUnreleasedPartition","method_signature":"public waitingOnUnreleasedPartition(ConsumerGroupMember member)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"createConsumerGroupRecords","method_signature":"public createConsumerGroupRecords(\n        List\u003cCoordinatorRecord\u003e records\n    )","target_class":"","rationale":""},{"method_name":"removeMember","method_signature":"public removeMember(String memberId)","target_class":"","rationale":""},{"method_name":"maybeUpdatePartitionEpoch","method_signature":"private maybeUpdatePartitionEpoch(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"incValue","method_signature":"private static incValue(String key, Integer value)","target_class":"","rationale":""},{"method_name":"removeTargetAssignment","method_signature":"public removeTargetAssignment(String memberId)","target_class":"","rationale":""},{"method_name":"staticMember","method_signature":"public staticMember(String instanceId)","target_class":"","rationale":""},{"method_name":"updateMember","method_signature":"public updateMember(ConsumerGroupMember newMember)","target_class":"","rationale":""},{"method_name":"hasMetadataExpired","method_signature":"public hasMetadataExpired(long currentTimeMs)","target_class":"","rationale":""},{"method_name":"allMembersUseClassicProtocolExcept","method_signature":"public allMembersUseClassicProtocolExcept(String memberId)","target_class":"","rationale":""},{"method_name":"decValue","method_signature":"private static decValue(String key, Integer value)","target_class":"","rationale":""},{"method_name":"asDescribedGroup","method_signature":"public asDescribedGroup(\n        long committedOffset,\n        String defaultAssignor,\n        TopicsImage topicsImage\n    )","target_class":"","rationale":""},{"method_name":"maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType","method_signature":"private maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"updateTargetAssignment","method_signature":"public updateTargetAssignment(String memberId, Assignment newTargetAssignment)","target_class":"","rationale":""},{"method_name":"maybeUpdateServerAssignors","method_signature":"private maybeUpdateServerAssignors(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},{"method_name":"asListedGroup","method_signature":"public asListedGroup(long committedOffset)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"public createConsumerGroupRecords(\n        List\u003cCoordinatorRecord\u003e records\n    )":{"first":{"method_name":"createConsumerGroupRecords","method_signature":"public createConsumerGroupRecords(\n        List\u003cCoordinatorRecord\u003e records\n    )","target_class":"","rationale":""},"second":0.10206891707411518},"public removeMember(String memberId)":{"first":{"method_name":"removeMember","method_signature":"public removeMember(String memberId)","target_class":"","rationale":""},"second":0.1265503256269191},"private maybeUpdatePartitionEpoch(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )":{"first":{"method_name":"maybeUpdatePartitionEpoch","method_signature":"private maybeUpdatePartitionEpoch(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},"second":0.16550947734955115},"private static incValue(String key, Integer value)":{"first":{"method_name":"incValue","method_signature":"private static incValue(String key, Integer value)","target_class":"","rationale":""},"second":0.18300879828995043},"public removeTargetAssignment(String memberId)":{"first":{"method_name":"removeTargetAssignment","method_signature":"public removeTargetAssignment(String memberId)","target_class":"","rationale":""},"second":0.18409691720691532},"public staticMember(String instanceId)":{"first":{"method_name":"staticMember","method_signature":"public staticMember(String instanceId)","target_class":"","rationale":""},"second":0.1859582808336838},"public updateMember(ConsumerGroupMember newMember)":{"first":{"method_name":"updateMember","method_signature":"public updateMember(ConsumerGroupMember newMember)","target_class":"","rationale":""},"second":0.19144022223086513},"public hasMetadataExpired(long currentTimeMs)":{"first":{"method_name":"hasMetadataExpired","method_signature":"public hasMetadataExpired(long currentTimeMs)","target_class":"","rationale":""},"second":0.192708323634812},"public allMembersUseClassicProtocolExcept(String memberId)":{"first":{"method_name":"allMembersUseClassicProtocolExcept","method_signature":"public allMembersUseClassicProtocolExcept(String memberId)","target_class":"","rationale":""},"second":0.1930525546117113},"private static decValue(String key, Integer value)":{"first":{"method_name":"decValue","method_signature":"private static decValue(String key, Integer value)","target_class":"","rationale":""},"second":0.19475568226958895},"public asDescribedGroup(\n        long committedOffset,\n        String defaultAssignor,\n        TopicsImage topicsImage\n    )":{"first":{"method_name":"asDescribedGroup","method_signature":"public asDescribedGroup(\n        long committedOffset,\n        String defaultAssignor,\n        TopicsImage topicsImage\n    )","target_class":"","rationale":""},"second":0.19763160425069876},"private maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )":{"first":{"method_name":"maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType","method_signature":"private maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},"second":0.1996782759805272},"public updateTargetAssignment(String memberId, Assignment newTargetAssignment)":{"first":{"method_name":"updateTargetAssignment","method_signature":"public updateTargetAssignment(String memberId, Assignment newTargetAssignment)","target_class":"","rationale":""},"second":0.20474998804073968},"private maybeUpdateServerAssignors(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )":{"first":{"method_name":"maybeUpdateServerAssignors","method_signature":"private maybeUpdateServerAssignors(\n        ConsumerGroupMember oldMember,\n        ConsumerGroupMember newMember\n    )","target_class":"","rationale":""},"second":0.23569955074609314},"public asListedGroup(long committedOffset)":{"first":{"method_name":"asListedGroup","method_signature":"public asListedGroup(long committedOffset)","target_class":"","rationale":""},"second":0.23988387465154856}},"llmMethodPriority":{"priority_method_names":["createConsumerGroupRecords","removeMember","maybeUpdatePartitionEpoch","incValue","removeTargetAssignment","staticMember","updateMember","hasMetadataExpired","allMembersUseClassicProtocolExcept","decValue","asDescribedGroup","maybeUpdateSubscribedTopicNamesAndGroupSubscriptionType","updateTargetAssignment","maybeUpdateServerAssignors","asListedGroup"],"llm_response_time":3919},"targetClassMap":{"createConsumerGroupRecords":{"target_classes":[{"class_name":"SnapshotRegistry","similarity_score":0.42235448409963106},{"class_name":"TimelineInteger","similarity_score":0.1570987180441174},{"class_name":"TimelineInteger","similarity_score":0.1570987180441174},{"class_name":"GroupCoordinatorMetricsShard","similarity_score":0.4371349730192102},{"class_name":"DeadlineAndEpoch","similarity_score":0.08670081183498067},{"class_name":"TimelineInteger","similarity_score":0.1570987180441174}],"target_classes_sorted_by_llm":["GroupCoordinatorMetricsShard","SnapshotRegistry","DeadlineAndEpoch","TimelineInteger","TimelineInteger","TimelineInteger"],"llm_response_time":5348,"similarity_computation_time":25,"similarity_metric":"voyage"},"removeMember":{"target_classes":[{"class_name":"DeadlineAndEpoch","similarity_score":0.1526762041381148}],"target_classes_sorted_by_llm":["DeadlineAndEpoch"],"llm_response_time":1798,"similarity_computation_time":1,"similarity_metric":"voyage"},"maybeUpdatePartitionEpoch":{"target_classes":[{"class_name":"DeadlineAndEpoch","similarity_score":0.07658395810674835}],"target_classes_sorted_by_llm":["DeadlineAndEpoch"],"llm_response_time":1917,"similarity_computation_time":1,"similarity_metric":"voyage"}}}
{"id":"0a2433e3-8999-4155-8ff7-1dc5b2942fdf","methodCount":15,"hostFunctionTelemetryData":{"hostFunctionSize":395,"lineStart":70,"lineEnd":464,"bodyLineStart":70,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/server/src/test/java/org/apache/kafka/server/AssignmentsManagerTest.java","sourceCode":"public class AssignmentsManagerTest {\n\n    private static final Uuid TOPIC_1 \u003d Uuid.fromString(\"88rnFIqYSZykX4ZSKv81bg\");\n    private static final Uuid TOPIC_2 \u003d Uuid.fromString(\"VKCnzHdhR5uDQc1shqBYrQ\");\n    private static final Uuid DIR_1 \u003d Uuid.fromString(\"cbgD8WdLQCyzLrFIMBhv3w\");\n    private static final Uuid DIR_2 \u003d Uuid.fromString(\"zO0bDc0vSuam7Db9iH7rYQ\");\n    private static final Uuid DIR_3 \u003d Uuid.fromString(\"CGBWbrFkRkeJQy6Aryzq2Q\");\n\n    private MockTime time;\n    private NodeToControllerChannelManager channelManager;\n    private AssignmentsManager manager;\n\n    @BeforeEach\n    public void setup() {\n        time \u003d new MockTime();\n        channelManager \u003d mock(NodeToControllerChannelManager.class);\n        Map\u003cUuid, String\u003e topicNames \u003d new HashMap\u003c\u003e();\n        topicNames.put(TOPIC_1, \"TOPIC_1\");\n        topicNames.put(TOPIC_2, \"TOPIC_2\");\n        Map\u003cUuid, String\u003e dirPaths \u003d new HashMap\u003c\u003e();\n        dirPaths.put(DIR_1, \"DIR_1\");\n        dirPaths.put(DIR_2, \"DIR_2\");\n        dirPaths.put(DIR_3, \"DIR_3\");\n        manager \u003d new AssignmentsManager(time, channelManager, 8, () -\u003e 100L,\n                id -\u003e Optional.ofNullable(dirPaths.get(id)), id -\u003e Optional.ofNullable(topicNames.get(id)));\n    }\n\n    @AfterEach\n    void tearDown() throws InterruptedException {\n        manager.close();\n    }\n\n    AssignReplicasToDirsRequestData normalize(AssignReplicasToDirsRequestData request) {\n        request \u003d request.duplicate();\n        request.directories().sort(Comparator.comparing(\n            AssignReplicasToDirsRequestData.DirectoryData::id));\n        for (AssignReplicasToDirsRequestData.DirectoryData directory : request.directories()) {\n            directory.topics().sort(Comparator.comparing(\n                AssignReplicasToDirsRequestData.TopicData::topicId));\n            for (AssignReplicasToDirsRequestData.TopicData topic : directory.topics()) {\n                topic.partitions().sort(Comparator.comparing(\n                    AssignReplicasToDirsRequestData.PartitionData::partitionIndex));\n            }\n        }\n        return request;\n    }\n\n\n    void assertRequestEquals(\n        AssignReplicasToDirsRequestData expected,\n        AssignReplicasToDirsRequestData actual\n    ) {\n        assertEquals(normalize(expected), normalize(actual));\n    }\n\n    @Test\n    void testBuildRequestData() {\n        Map\u003cTopicIdPartition, Uuid\u003e assignment \u003d new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                put(new TopicIdPartition(TOPIC_1, 1), DIR_1);\n                put(new TopicIdPartition(TOPIC_1, 2), DIR_2);\n                put(new TopicIdPartition(TOPIC_1, 3), DIR_3);\n                put(new TopicIdPartition(TOPIC_1, 4), DIR_1);\n                put(new TopicIdPartition(TOPIC_2, 5), DIR_2);\n            }};\n        AssignReplicasToDirsRequestData built \u003d AssignmentsManager.buildRequestData(8, 100L, assignment);\n        AssignReplicasToDirsRequestData expected \u003d new AssignReplicasToDirsRequestData()\n            .setBrokerId(8)\n            .setBrokerEpoch(100L)\n            .setDirectories(Arrays.asList(\n                new AssignReplicasToDirsRequestData.DirectoryData()\n                    .setId(DIR_2)\n                    .setTopics(Arrays.asList(\n                        new AssignReplicasToDirsRequestData.TopicData()\n                            .setTopicId(TOPIC_1)\n                            .setPartitions(Collections.singletonList(\n                                    new AssignReplicasToDirsRequestData.PartitionData()\n                                            .setPartitionIndex(2))),\n                new AssignReplicasToDirsRequestData.TopicData()\n                    .setTopicId(TOPIC_2)\n                    .setPartitions(Collections.singletonList(\n                            new AssignReplicasToDirsRequestData.PartitionData()\n                                    .setPartitionIndex(5))))),\n            new AssignReplicasToDirsRequestData.DirectoryData()\n                .setId(DIR_3)\n                .setTopics(Collections.singletonList(\n                    new AssignReplicasToDirsRequestData.TopicData()\n                        .setTopicId(TOPIC_1)\n                        .setPartitions(Collections.singletonList(\n                            new AssignReplicasToDirsRequestData.PartitionData()\n                                    .setPartitionIndex(3))))),\n            new AssignReplicasToDirsRequestData.DirectoryData()\n                .setId(DIR_1)\n                .setTopics(Collections.singletonList(\n                    new AssignReplicasToDirsRequestData.TopicData()\n                        .setTopicId(TOPIC_1)\n                        .setPartitions(Arrays.asList(\n                            new AssignReplicasToDirsRequestData.PartitionData()\n                                .setPartitionIndex(4),\n                            new AssignReplicasToDirsRequestData.PartitionData()\n                                .setPartitionIndex(1)))))));\n        assertRequestEquals(expected, built);\n    }\n\n    @Test\n    public void testAssignmentAggregation() throws InterruptedException {\n        CountDownLatch readyToAssert \u003d new CountDownLatch(1);\n        doAnswer(invocation -\u003e {\n            readyToAssert.countDown();\n            return null;\n        }).when(channelManager).sendRequest(any(AssignReplicasToDirsRequest.Builder.class),\n            any(ControllerRequestCompletionHandler.class));\n\n        manager.onAssignment(new TopicIdPartition(TOPIC_1, 1), DIR_1, \"testAssignmentAggregation\", () -\u003e { });\n        manager.onAssignment(new TopicIdPartition(TOPIC_1, 2), DIR_2, \"testAssignmentAggregation\", () -\u003e { });\n        manager.onAssignment(new TopicIdPartition(TOPIC_1, 3), DIR_3, \"testAssignmentAggregation\", () -\u003e { });\n        manager.onAssignment(new TopicIdPartition(TOPIC_1, 4), DIR_1, \"testAssignmentAggregation\", () -\u003e { });\n        manager.onAssignment(new TopicIdPartition(TOPIC_2, 5), DIR_2, \"testAssignmentAggregation\", () -\u003e { });\n        TestUtils.waitForCondition(() -\u003e {\n            time.sleep(100);\n            manager.wakeup();\n            return readyToAssert.await(1, TimeUnit.MILLISECONDS);\n        }, \"Timed out waiting for AssignReplicasToDirsRequest to be sent.\");\n\n        ArgumentCaptor\u003cAssignReplicasToDirsRequest.Builder\u003e captor \u003d\n            ArgumentCaptor.forClass(AssignReplicasToDirsRequest.Builder.class);\n        verify(channelManager, times(1)).start();\n        verify(channelManager).sendRequest(captor.capture(), any(ControllerRequestCompletionHandler.class));\n        verify(channelManager, atMostOnce()).shutdown();\n        verifyNoMoreInteractions(channelManager);\n        assertEquals(1, captor.getAllValues().size());\n        AssignReplicasToDirsRequestData actual \u003d captor.getValue().build().data();\n        AssignReplicasToDirsRequestData expected \u003d buildRequestData(\n            8, 100L, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                    put(new TopicIdPartition(TOPIC_1, 1), DIR_1);\n                    put(new TopicIdPartition(TOPIC_1, 2), DIR_2);\n                    put(new TopicIdPartition(TOPIC_1, 3), DIR_3);\n                    put(new TopicIdPartition(TOPIC_1, 4), DIR_1);\n                    put(new TopicIdPartition(TOPIC_2, 5), DIR_2);\n                }}\n        );\n        assertRequestEquals(expected, actual);\n    }\n\n    @Test\n    void testRequeuesFailedAssignmentPropagations() throws InterruptedException {\n        CountDownLatch readyToAssert \u003d new CountDownLatch(5);\n        doAnswer(invocation -\u003e {\n            readyToAssert.countDown();\n            if (readyToAssert.getCount() \u003d\u003d 4) {\n                invocation.getArgument(1, ControllerRequestCompletionHandler.class).onTimeout();\n                manager.onAssignment(new TopicIdPartition(TOPIC_1, 2), DIR_3, \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n            }\n            if (readyToAssert.getCount() \u003d\u003d 3) {\n                invocation.getArgument(1, ControllerRequestCompletionHandler.class).onComplete(\n                    new ClientResponse(null, null, null, 0L, 0L, false, false,\n                        new UnsupportedVersionException(\"test unsupported version exception\"), null, null));\n\n                // duplicate should be ignored\n                manager.onAssignment(new TopicIdPartition(TOPIC_1, 2), DIR_3, \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n\n                manager.onAssignment(new TopicIdPartition(TOPIC_1, 3),\n                     Uuid.fromString(\"xHLCnG54R9W3lZxTPnpk1Q\"), \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n            }\n            if (readyToAssert.getCount() \u003d\u003d 2) {\n                invocation.getArgument(1, ControllerRequestCompletionHandler.class).onComplete(\n                        new ClientResponse(null, null, null, 0L, 0L, false, false, null,\n                                new AuthenticationException(\"test authentication exception\"), null)\n                );\n\n                // duplicate should be ignored\n                manager.onAssignment(new TopicIdPartition(TOPIC_1, 3),\n                     Uuid.fromString(\"xHLCnG54R9W3lZxTPnpk1Q\"), \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n\n                manager.onAssignment(new TopicIdPartition(TOPIC_1, 4),\n                     Uuid.fromString(\"RCYu1A0CTa6eEIpuKDOfxw\"), \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n            }\n            if (readyToAssert.getCount() \u003d\u003d 1) {\n                invocation.getArgument(1, ControllerRequestCompletionHandler.class).onComplete(\n                    new ClientResponse(null, null, null, 0L, 0L, false, false, null, null,\n                        new AssignReplicasToDirsResponse(new AssignReplicasToDirsResponseData()\n                            .setErrorCode(Errors.NOT_CONTROLLER.code())\n                            .setThrottleTimeMs(0))));\n            }\n            return null;\n        }).when(channelManager).sendRequest(any(AssignReplicasToDirsRequest.Builder.class),\n            any(ControllerRequestCompletionHandler.class));\n\n        manager.onAssignment(new TopicIdPartition(TOPIC_1, 1), DIR_1, \"testRequeuesFailedAssignmentPropagations\", () -\u003e { });\n        TestUtils.waitForCondition(() -\u003e {\n            time.sleep(TimeUnit.SECONDS.toMillis(1));\n            manager.wakeup();\n            return readyToAssert.await(1, TimeUnit.MILLISECONDS);\n        }, \"Timed out waiting for AssignReplicasToDirsRequest to be sent.\");\n\n        ArgumentCaptor\u003cAssignReplicasToDirsRequest.Builder\u003e captor \u003d\n            ArgumentCaptor.forClass(AssignReplicasToDirsRequest.Builder.class);\n        verify(channelManager, times(1)).start();\n        verify(channelManager, times(5)).sendRequest(captor.capture(),\n            any(ControllerRequestCompletionHandler.class));\n        verify(channelManager, atMostOnce()).shutdown();\n        verifyNoMoreInteractions(channelManager);\n        assertEquals(5, captor.getAllValues().size());\n        assertRequestEquals(buildRequestData(\n            8, 100L, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                    put(new TopicIdPartition(TOPIC_1, 1), DIR_1);\n                }}\n        ), captor.getAllValues().get(0).build().data());\n        assertRequestEquals(buildRequestData(\n            8, 100L, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                    put(new TopicIdPartition(TOPIC_1, 1), DIR_1);\n                    put(new TopicIdPartition(TOPIC_1, 2), DIR_3);\n                }}\n        ), captor.getAllValues().get(1).build().data());\n        assertRequestEquals(buildRequestData(\n            8, 100L, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                    put(new TopicIdPartition(TOPIC_1, 1), DIR_1);\n                    put(new TopicIdPartition(TOPIC_1, 2), DIR_3);\n                    put(new TopicIdPartition(TOPIC_1, 3), Uuid.fromString(\"xHLCnG54R9W3lZxTPnpk1Q\"));\n                    put(new TopicIdPartition(TOPIC_1, 4), Uuid.fromString(\"RCYu1A0CTa6eEIpuKDOfxw\"));\n                }}\n        ), captor.getAllValues().get(4).build().data());\n    }\n\n    @Timeout(30)\n    @Test\n    void testOnCompletion() throws Exception {\n        CountDownLatch readyToAssert \u003d new CountDownLatch(300);\n        doAnswer(invocation -\u003e {\n            AssignReplicasToDirsRequestData request \u003d invocation.getArgument(0, AssignReplicasToDirsRequest.Builder.class).build().data();\n            ControllerRequestCompletionHandler completionHandler \u003d invocation.getArgument(1, ControllerRequestCompletionHandler.class);\n            completionHandler.onComplete(buildSuccessfulResponse(request));\n\n            return null;\n        }).when(channelManager).sendRequest(any(AssignReplicasToDirsRequest.Builder.class),\n                any(ControllerRequestCompletionHandler.class));\n\n        for (int i \u003d 0; i \u003c 300; i++) {\n            manager.onAssignment(new TopicIdPartition(TOPIC_1, i % 5), DIR_1, \"testOnCompletion\", readyToAssert::countDown);\n        }\n\n        TestUtils.waitForCondition(() -\u003e {\n            time.sleep(TimeUnit.SECONDS.toMillis(1));\n            manager.wakeup();\n            return readyToAssert.await(1, TimeUnit.MILLISECONDS);\n        }, \"Timed out waiting for AssignReplicasToDirsRequest to be sent.\");\n    }\n\n    private static ClientResponse buildSuccessfulResponse(AssignReplicasToDirsRequestData request) {\n        return buildResponse(request, topicIdPartition -\u003e Errors.NONE);\n    }\n\n    private static ClientResponse buildResponse(AssignReplicasToDirsRequestData request,\n                                                Function\u003cTopicIdPartition, Errors\u003e perPartitionError) {\n        Map\u003cUuid, Map\u003cTopicIdPartition, Errors\u003e\u003e errors \u003d new HashMap\u003c\u003e();\n        for (AssignReplicasToDirsRequestData.DirectoryData directory : request.directories()) {\n            for (AssignReplicasToDirsRequestData.TopicData topic : directory.topics()) {\n                for (AssignReplicasToDirsRequestData.PartitionData partition : topic.partitions()) {\n                    TopicIdPartition topicIdPartition \u003d new TopicIdPartition(topic.topicId(), partition.partitionIndex());\n                    Errors error \u003d perPartitionError.apply(topicIdPartition);\n                    if (error \u003d\u003d null) {\n                        error \u003d Errors.NONE;\n                    }\n                    errors.computeIfAbsent(directory.id(), d -\u003e new HashMap\u003c\u003e()).put(topicIdPartition, error);\n                }\n            }\n        }\n        AssignReplicasToDirsResponseData responseData \u003d AssignmentsHelper.buildResponseData(Errors.NONE.code(), 0, errors);\n        return new ClientResponse(null, null, null,\n                0L, 0L, false, false, null, null,\n                new AssignReplicasToDirsResponse(responseData));\n    }\n\n    @Test\n    public void testAssignmentCompaction() throws Exception {\n        // Delay the first controller response to force assignment compaction logic\n        CompletableFuture\u003cRunnable\u003e completionFuture \u003d new CompletableFuture\u003c\u003e();\n        doAnswer(invocation -\u003e {\n            AssignReplicasToDirsRequestData request \u003d invocation.getArgument(0, AssignReplicasToDirsRequest.Builder.class).build().data();\n            ControllerRequestCompletionHandler completionHandler \u003d invocation.getArgument(1, ControllerRequestCompletionHandler.class);\n            ClientResponse response \u003d buildSuccessfulResponse(request);\n            Runnable completion \u003d () -\u003e completionHandler.onComplete(response);\n            if (completionFuture.isDone()) completion.run();\n            else completionFuture.complete(completion);\n            return null;\n        }).when(channelManager).sendRequest(any(AssignReplicasToDirsRequest.Builder.class),\n                any(ControllerRequestCompletionHandler.class));\n\n        CountDownLatch remainingInvocations \u003d new CountDownLatch(20);\n        Runnable onComplete \u003d () -\u003e {\n            assertTrue(completionFuture.isDone(), \"Premature invocation\");\n            assertTrue(remainingInvocations.getCount() \u003e 0, \"Extra invocation\");\n            remainingInvocations.countDown();\n        };\n        Uuid[] dirs \u003d {DIR_1, DIR_2, DIR_3};\n        for (int i \u003d 0; i \u003c remainingInvocations.getCount(); i++) {\n            time.sleep(100);\n            manager.onAssignment(new TopicIdPartition(TOPIC_1, 0), dirs[i % 3], \"testAssignmentCompaction\", onComplete);\n        }\n        activeWait(completionFuture::isDone);\n        completionFuture.get().run();\n        activeWait(() -\u003e remainingInvocations.getCount() \u003d\u003d 0);\n    }\n\n    void activeWait(Supplier\u003cBoolean\u003e predicate) throws InterruptedException {\n        TestUtils.waitForCondition(() -\u003e {\n            boolean conditionSatisfied \u003d predicate.get();\n            if (!conditionSatisfied) {\n                time.sleep(100);\n                manager.wakeup();\n            }\n            return conditionSatisfied;\n        }, TestUtils.DEFAULT_MAX_WAIT_MS, 50, null);\n    }\n\n    static Metric findMetric(String name) {\n        for (Map.Entry\u003cMetricName, Metric\u003e entry : KafkaYammerMetrics.defaultRegistry().allMetrics().entrySet()) {\n            MetricName metricName \u003d entry.getKey();\n            if (AssignmentsManager.class.getSimpleName().equals(metricName.getType()) \u0026\u0026 metricName.getName().equals(name)) {\n                return entry.getValue();\n            }\n        }\n        throw new IllegalArgumentException(\"metric named \" + name + \" not found\");\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    @Test\n    void testQueuedReplicaToDirAssignmentsMetric() throws Exception {\n        CountDownLatch readyToAssert \u003d new CountDownLatch(1);\n        doAnswer(invocation -\u003e {\n            readyToAssert.countDown();\n            return null;\n        }).when(channelManager).sendRequest(any(AssignReplicasToDirsRequest.Builder.class), any(ControllerRequestCompletionHandler.class));\n\n        Gauge\u003cInteger\u003e queuedReplicaToDirAssignments \u003d (Gauge\u003cInteger\u003e) findMetric(AssignmentsManager.QUEUE_REPLICA_TO_DIR_ASSIGNMENTS_METRIC_NAME);\n        assertEquals(0, queuedReplicaToDirAssignments.value());\n\n        for (int i \u003d 0; i \u003c 4; i++) {\n            manager.onAssignment(new TopicIdPartition(TOPIC_1, i), DIR_1, \"testQueuedReplicaToDirAssignmentsMetric\", () -\u003e { });\n        }\n        TestUtils.waitForCondition(() -\u003e {\n            time.sleep(100);\n            return readyToAssert.await(1, TimeUnit.MILLISECONDS);\n        }, \"Timed out waiting for AssignReplicasToDirsRequest to be sent.\");\n        assertEquals(4, queuedReplicaToDirAssignments.value());\n\n        for (int i \u003d 4; i \u003c 8; i++) {\n            manager.onAssignment(new TopicIdPartition(TOPIC_1, i), DIR_1, \"testQueuedReplicaToDirAssignmentsMetric\", () -\u003e { });\n        }\n        TestUtils.retryOnExceptionWithTimeout(5_000, () -\u003e assertEquals(8, queuedReplicaToDirAssignments.value()));\n    }\n\n    // AssignmentsManager retries to propagate assignments (via AssignReplicasToDirsRequest) after failures.\n    // When an assignment fails to propagate with NOT_LEADER_OR_FOLLOWER, AssignmentsManager should conclude\n    // that the broker has been removed as a replica for the partition, and stop trying to propagate it.\n    @Test\n    void testDropsOldAssignments() throws InterruptedException {\n        TopicIdPartition tp1 \u003d new TopicIdPartition(TOPIC_1, 1), tp2 \u003d new TopicIdPartition(TOPIC_1, 2);\n        List\u003cAssignReplicasToDirsRequestData\u003e requests \u003d new ArrayList\u003c\u003e();\n        CountDownLatch readyToAssert \u003d new CountDownLatch(2);\n        doAnswer(invocation -\u003e {\n            AssignReplicasToDirsRequestData request \u003d invocation.getArgument(0, AssignReplicasToDirsRequest.Builder.class).build().data();\n            ControllerRequestCompletionHandler completionHandler \u003d invocation.getArgument(1, ControllerRequestCompletionHandler.class);\n            if (readyToAssert.getCount() \u003d\u003d 2) {\n                // First request, reply with a partition-level NOT_LEADER_OR_FOLLOWER error and queue a different assignment\n                completionHandler.onComplete(buildResponse(request, topicIdPartition -\u003e Errors.NOT_LEADER_OR_FOLLOWER));\n                manager.onAssignment(tp2, DIR_1, \"testDropsOldAssignments-second\");\n            }\n            if (readyToAssert.getCount() \u003d\u003d 1) {\n                // Second request, reply with success\n                completionHandler.onComplete(buildSuccessfulResponse(request));\n            }\n            requests.add(request);\n            readyToAssert.countDown();\n            return null;\n        }).when(channelManager).sendRequest(any(), any());\n\n        manager.onAssignment(tp1, DIR_1, \"testDropsOldAssignments-first\");\n        TestUtils.waitForCondition(() -\u003e {\n            time.sleep(TimeUnit.SECONDS.toMillis(1));\n            manager.wakeup();\n            return readyToAssert.await(1, TimeUnit.MILLISECONDS);\n        }, \"Timed out waiting for AssignReplicasToDirsRequest to be sent.\");\n\n        assertEquals(Arrays.asList(\n                buildRequestData(8, 100, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                        put(tp1, DIR_1);\n                    }}),\n                // Even though the controller replied with NOT_LEADER_OR_FOLLOWER, the second request does not include\n                // partition 1, meaning AssignmentManager dropped (no longer retries) the assignment.\n                buildRequestData(8, 100, new HashMap\u003cTopicIdPartition, Uuid\u003e() {{\n                        put(tp2, DIR_1);\n                    }})\n        ), requests);\n    }\n}","methodCount":15},"candidatesTelemetryData":{"numberOfSuggestions":7,"candidates":[{"lineStart":117,"lineEnd":122,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertRequestEquals to class AssignmentsManager","description":"Move method assertRequestEquals to org.apache.kafka.server.AssignmentsManager\nRationale: The assertRequestEquals() method is primarily focused on comparing two instances of AssignReplicasToDirsRequestData, which is closely related to the assignment operations managed by the AssignmentsManager. Moving this method out of its current class enhances the cohesion of the AssignmentsManager, as it will better encapsulate the logic related to assignment requests. This aligns with the Single Responsibility Principle by ensuring that the AssignmentsManager handles the specifics of assignment-related operations, including request validation. A potential drawback is that if the current class has dependencies on the state of the request, those would need to be managed carefully to avoid breaking existing functionality.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":117,"lineEnd":122,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method assertRequestEquals to class NodeToControllerChannelManager","description":"Move method assertRequestEquals to org.apache.kafka.server.NodeToControllerChannelManager\nRationale: The NodeToControllerChannelManager is responsible for sending requests and managing communication with the controller, which could include validating request formats. The assertRequestEquals() method could fit here as it deals with ensuring the integrity of requests being sent. Moving the method here could enhance the clarity of the request handling process, aligning with the Interface Segregation Principle by keeping request validation logic within the context of communication management. However, this class may become overloaded with responsibilities if it starts to handle too many aspects of request validation and processing.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":96,"lineEnd":99,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method tearDown to class NodeToControllerChannelManager","description":"Move method tearDown to org.apache.kafka.server.NodeToControllerChannelManager\nRationale: The tearDown() method is responsible for closing the manager, which suggests a cleanup or shutdown operation. The NodeToControllerChannelManager has a shutdown method, indicating it is responsible for managing the lifecycle of connections and resources. Moving tearDown() here aligns with the Single Responsibility Principle, as it centralizes resource management within the class that deals with channel communication. This change enhances cohesion by keeping related lifecycle management methods together. However, care must be taken to ensure that all dependencies and interactions with the manager are appropriately handled during the move.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":96,"lineEnd":99,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method tearDown to class AssignmentsManager","description":"Move method tearDown to org.apache.kafka.server.AssignmentsManager\nRationale: The tearDown() method closes the manager, which could be related to the various assignment operations handled by the AssignmentsManager. Although it is not directly related to assignment logic, it may be appropriate to keep all manager-related cleanup in one place. This move could enhance the clarity of resource management within the AssignmentsManager. However, it may dilute the class\u0027s focus if the manager\u0027s role is not closely tied to assignments, potentially leading to decreased cohesion and confusion about the class\u0027s responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":316,"lineEnd":318,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildSuccessfulResponse to class RequestUtils","description":"move method buildSuccessfulResponse to PsiClass:RequestUtils\nRationale: The buildSuccessfulResponse() method constructs a response based on a request, which aligns closely with the responsibilities of RequestUtils, which likely deals with request handling and response creation. Moving it here adheres to the Single Responsibility Principle, as it centralizes request-related logic. This enhances cohesion and makes the method more reusable in other contexts. However, care must be taken to ensure that RequestUtils does not become overloaded with unrelated responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":316,"lineEnd":318,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildSuccessfulResponse to class ClientUtils","description":"move method buildSuccessfulResponse to PsiClass:ClientUtils\nRationale: The ClientUtils class manages various client-related utilities, including metrics and identifiers. Since the buildSuccessfulResponse() method is likely involved in client interactions, this move would enhance the logical grouping of client-related functionalities. It aligns with the Open/Closed Principle by allowing future extensions related to client responses without modifying existing code. Potential drawbacks include the risk of cluttering ClientUtils with too many responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":316,"lineEnd":318,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method buildSuccessfulResponse to class ControlRecordUtils","description":"move method buildSuccessfulResponse to PsiClass:ControlRecordUtils\nRationale: ControlRecordUtils deals with utility functions related to control records, which might include response management. If buildSuccessfulResponse() relates to control records in some way, this move would enhance cohesion. It adheres to the Interface Segregation Principle by allowing clients to only depend on the methods they use. However, the connection must be clear to avoid confusion about the responsibilities of ControlRecordUtils.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},{"method_name":"tearDown","method_signature":"@AfterEach tearDown()","target_class":"","rationale":""},{"method_name":"normalize","method_signature":" normalize(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},{"method_name":"assertRequestEquals","method_signature":" assertRequestEquals(\n        AssignReplicasToDirsRequestData expected,\n        AssignReplicasToDirsRequestData actual\n    )","target_class":"","rationale":""},{"method_name":"buildSuccessfulResponse","method_signature":"private static buildSuccessfulResponse(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},{"method_name":"buildResponse","method_signature":"private static buildResponse(AssignReplicasToDirsRequestData request,\n                                                Function\u003cTopicIdPartition, Errors\u003e perPartitionError)","target_class":"","rationale":""},{"method_name":"activeWait","method_signature":" activeWait(Supplier\u003cBoolean\u003e predicate)","target_class":"","rationale":""},{"method_name":"findMetric","method_signature":"static findMetric(String name)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"assertRequestEquals","method_signature":" assertRequestEquals(\n        AssignReplicasToDirsRequestData expected,\n        AssignReplicasToDirsRequestData actual\n    )","target_class":"","rationale":""},{"method_name":"tearDown","method_signature":"@AfterEach tearDown()","target_class":"","rationale":""},{"method_name":"buildSuccessfulResponse","method_signature":"private static buildSuccessfulResponse(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},{"method_name":"findMetric","method_signature":"static findMetric(String name)","target_class":"","rationale":""},{"method_name":"normalize","method_signature":" normalize(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},{"method_name":"activeWait","method_signature":" activeWait(Supplier\u003cBoolean\u003e predicate)","target_class":"","rationale":""},{"method_name":"buildResponse","method_signature":"private static buildResponse(AssignReplicasToDirsRequestData request,\n                                                Function\u003cTopicIdPartition, Errors\u003e perPartitionError)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{" assertRequestEquals(\n        AssignReplicasToDirsRequestData expected,\n        AssignReplicasToDirsRequestData actual\n    )":{"first":{"method_name":"assertRequestEquals","method_signature":" assertRequestEquals(\n        AssignReplicasToDirsRequestData expected,\n        AssignReplicasToDirsRequestData actual\n    )","target_class":"","rationale":""},"second":0.3644286935888501},"@AfterEach tearDown()":{"first":{"method_name":"tearDown","method_signature":"@AfterEach tearDown()","target_class":"","rationale":""},"second":0.42059112793412196},"private static buildSuccessfulResponse(AssignReplicasToDirsRequestData request)":{"first":{"method_name":"buildSuccessfulResponse","method_signature":"private static buildSuccessfulResponse(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},"second":0.4319644972516608},"static findMetric(String name)":{"first":{"method_name":"findMetric","method_signature":"static findMetric(String name)","target_class":"","rationale":""},"second":0.4527564618140076}," normalize(AssignReplicasToDirsRequestData request)":{"first":{"method_name":"normalize","method_signature":" normalize(AssignReplicasToDirsRequestData request)","target_class":"","rationale":""},"second":0.45724562423473836},"@BeforeEach\n    public setup()":{"first":{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},"second":0.5118044482572051}," activeWait(Supplier\u003cBoolean\u003e predicate)":{"first":{"method_name":"activeWait","method_signature":" activeWait(Supplier\u003cBoolean\u003e predicate)","target_class":"","rationale":""},"second":0.5329731766244666},"private static buildResponse(AssignReplicasToDirsRequestData request,\n                                                Function\u003cTopicIdPartition, Errors\u003e perPartitionError)":{"first":{"method_name":"buildResponse","method_signature":"private static buildResponse(AssignReplicasToDirsRequestData request,\n                                                Function\u003cTopicIdPartition, Errors\u003e perPartitionError)","target_class":"","rationale":""},"second":0.6426028931631272}},"llmMethodPriority":{"priority_method_names":["assertRequestEquals","tearDown","buildSuccessfulResponse","findMetric","normalize","setup","activeWait","buildResponse"],"llm_response_time":1974},"targetClassMap":{"assertRequestEquals":{"target_classes":[{"class_name":"NodeToControllerChannelManager","similarity_score":0.2719641466102106},{"class_name":"AssignmentsManager","similarity_score":0.3036178402259392}],"target_classes_sorted_by_llm":["AssignmentsManager","NodeToControllerChannelManager"],"llm_response_time":2631,"similarity_computation_time":23,"similarity_metric":"voyage"},"tearDown":{"target_classes":[{"class_name":"NodeToControllerChannelManager","similarity_score":0.34668762264076824},{"class_name":"AssignmentsManager","similarity_score":0.38703832299674}],"target_classes_sorted_by_llm":["NodeToControllerChannelManager","AssignmentsManager"],"llm_response_time":2650,"similarity_computation_time":2,"similarity_metric":"voyage"},"buildSuccessfulResponse":{"target_classes":[{"class_name":"CommandLineUtils","similarity_score":0.36181889941796797},{"class_name":"CommandLineUtilsTest","similarity_score":0.18988397371327054},{"class_name":"ClientMetricsTestUtils","similarity_score":0.28414557138675545},{"class_name":"RemoteLogMetadataManagerTestUtils","similarity_score":0.41129059552836916},{"class_name":"FutureUtils","similarity_score":0.1724394251251618},{"class_name":"CommandUtils","similarity_score":0.2759055916864268},{"class_name":"AuthorizerUtils","similarity_score":0.4225176052670035},{"class_name":"ControllerMetricsTestUtils","similarity_score":0.346418399861435},{"class_name":"ControllerRequestContextUtil","similarity_score":0.40350105590873053},{"class_name":"ControlRecordUtils","similarity_score":0.402347308162278},{"class_name":"ClientTelemetryUtils","similarity_score":0.4240761541556118},{"class_name":"ClientUtils","similarity_score":0.42020741152262675},{"class_name":"ClaimValidationUtils","similarity_score":0.08092354537217256},{"class_name":"RequestTestUtils","similarity_score":0.2842263717462127},{"class_name":"RequestUtils","similarity_score":0.3887407915116121},{"class_name":"ConcurrencyUtils","similarity_score":0.13585964026279942},{"class_name":"CsvUtils","similarity_score":0.39528470752104744},{"class_name":"RetryUtil","similarity_score":0.18395742654730987},{"class_name":"CollectionUtils","similarity_score":0.24812594486934292},{"class_name":"ConfigUtils","similarity_score":0.22585777095003984},{"class_name":"ApiUtils","similarity_score":0.3216764452549963},{"class_name":"ConnectorUtils","similarity_score":0.10443899828608923},{"class_name":"ConnectUtils","similarity_score":0.21027300049672143},{"class_name":"AdminClientTestUtils","similarity_score":0.2589908656605218},{"class_name":"AdminUtils","similarity_score":0.16007590583360043},{"class_name":"AssignmentTestUtil","similarity_score":0.3212504157459161},{"class_name":"AssignmentTestUtils","similarity_score":0.26182031179380766},{"class_name":"AssignorBenchmarkUtils","similarity_score":0.246598480958036},{"class_name":"ConsumerGroupCommandTestUtils","similarity_score":0.3083830497515679},{"class_name":"ConsumerProtocolUtils","similarity_score":0.3101694051967514},{"class_name":"ConsumerRecordUtil","similarity_score":0.18294793072126084},{"class_name":"ConsumerUtils","similarity_score":0.35557262063450784},{"class_name":"ByteUtils","similarity_score":0.19983756833705094},{"class_name":"ByteUtilsBenchmark","similarity_score":0.3468046131967812},{"class_name":"SystemTestUtil","similarity_score":0.20929790394104195},{"class_name":"SchemaUtil","similarity_score":0.36980013081681945},{"class_name":"ScramCredentialUtils","similarity_score":0.351382110749967},{"class_name":"OffsetFetcherUtils","similarity_score":0.329529579233403},{"class_name":"NetworkClientUtils","similarity_score":0.20719527465846324},{"class_name":"NetworkTestUtils","similarity_score":0.34727054475830477},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.3341766132011226},{"class_name":"OffsetUtils","similarity_score":0.17765272567841506},{"class_name":"TaskAssignmentUtils","similarity_score":0.294536410193373},{"class_name":"TaskAssignmentUtilsTest","similarity_score":0.16087955821909072},{"class_name":"QuorumControllerIntegrationTestUtils","similarity_score":0.23966554522627118},{"class_name":"TaskBuilder","similarity_score":0.39282289291218914},{"class_name":"PluginUtils","similarity_score":0.3164815804619929},{"class_name":"SecurityUtils","similarity_score":0.43420035732460066},{"class_name":"ExceptionUtils","similarity_score":0.3629770043203139},{"class_name":"RackAwareOptimizationParams","similarity_score":0.27414699743097226}],"target_classes_sorted_by_llm":["RequestUtils","ClientUtils","ControlRecordUtils","TaskBuilder","AuthorizerUtils","ClientTelemetryUtils","SecurityUtils","CsvUtils","ControllerRequestContextUtil","RemoteLogMetadataManagerTestUtils"],"llm_response_time":9149,"similarity_computation_time":81,"similarity_metric":"voyage"}}}
{"id":"d4ec2207-c6c6-42e2-bcd8-c29f0675a46d","methodCount":15,"hostFunctionTelemetryData":{"hostFunctionSize":198,"lineStart":74,"lineEnd":271,"bodyLineStart":74,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/clients/src/test/java/org/apache/kafka/clients/consumer/internals/ConsumerNetworkThreadTest.java","sourceCode":"public class ConsumerNetworkThreadTest {\n    private final Time time;\n    private final BlockingQueue\u003cApplicationEvent\u003e applicationEventsQueue;\n    private final ApplicationEventProcessor applicationEventProcessor;\n    private final OffsetsRequestManager offsetsRequestManager;\n    private final HeartbeatRequestManager heartbeatRequestManager;\n    private final CoordinatorRequestManager coordinatorRequestManager;\n    private final ConsumerNetworkThread consumerNetworkThread;\n    private final NetworkClientDelegate networkClientDelegate;\n    private final RequestManagers requestManagers;\n    private final CompletableEventReaper applicationEventReaper;\n\n    ConsumerNetworkThreadTest() {\n        this.networkClientDelegate \u003d mock(NetworkClientDelegate.class);\n        this.requestManagers \u003d mock(RequestManagers.class);\n        this.offsetsRequestManager \u003d mock(OffsetsRequestManager.class);\n        this.heartbeatRequestManager \u003d mock(HeartbeatRequestManager.class);\n        this.coordinatorRequestManager \u003d mock(CoordinatorRequestManager.class);\n        this.applicationEventProcessor \u003d mock(ApplicationEventProcessor.class);\n        this.applicationEventReaper \u003d mock(CompletableEventReaper.class);\n        this.time \u003d new MockTime();\n        this.applicationEventsQueue \u003d new LinkedBlockingQueue\u003c\u003e();\n        LogContext logContext \u003d new LogContext();\n\n        this.consumerNetworkThread \u003d new ConsumerNetworkThread(\n                logContext,\n                time,\n                applicationEventsQueue,\n                applicationEventReaper,\n                () -\u003e applicationEventProcessor,\n                () -\u003e networkClientDelegate,\n                () -\u003e requestManagers\n        );\n    }\n\n    @BeforeEach\n    public void setup() {\n        consumerNetworkThread.initializeResources();\n    }\n\n    @AfterEach\n    public void tearDown() {\n        if (consumerNetworkThread !\u003d null)\n            consumerNetworkThread.close();\n    }\n\n    @Test\n    public void testEnsureCloseStopsRunningThread() {\n        assertTrue(consumerNetworkThread.isRunning(),\n            \"ConsumerNetworkThread should start running when created\");\n\n        consumerNetworkThread.close();\n        assertFalse(consumerNetworkThread.isRunning(),\n            \"close() should make consumerNetworkThread.running false by calling closeInternal(Duration timeout)\");\n    }\n\n    @ParameterizedTest\n    @ValueSource(longs \u003d {ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS - 1, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS + 1})\n    public void testConsumerNetworkThreadPollTimeComputations(long exampleTime) {\n        List\u003cOptional\u003c? extends RequestManager\u003e\u003e list \u003d new ArrayList\u003c\u003e();\n        list.add(Optional.of(coordinatorRequestManager));\n        list.add(Optional.of(heartbeatRequestManager));\n\n        when(requestManagers.entries()).thenReturn(list);\n\n        NetworkClientDelegate.PollResult pollResult \u003d new NetworkClientDelegate.PollResult(exampleTime);\n        NetworkClientDelegate.PollResult pollResult1 \u003d new NetworkClientDelegate.PollResult(exampleTime + 100);\n\n        long t \u003d time.milliseconds();\n        when(coordinatorRequestManager.poll(t)).thenReturn(pollResult);\n        when(coordinatorRequestManager.maximumTimeToWait(t)).thenReturn(exampleTime);\n        when(heartbeatRequestManager.poll(t)).thenReturn(pollResult1);\n        when(heartbeatRequestManager.maximumTimeToWait(t)).thenReturn(exampleTime + 100);\n        when(networkClientDelegate.addAll(pollResult)).thenReturn(pollResult.timeUntilNextPollMs);\n        when(networkClientDelegate.addAll(pollResult1)).thenReturn(pollResult1.timeUntilNextPollMs);\n        consumerNetworkThread.runOnce();\n\n        verify(networkClientDelegate).poll(Math.min(exampleTime, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS), time.milliseconds());\n        assertEquals(consumerNetworkThread.maximumTimeToWait(), exampleTime);\n    }\n\n    @Test\n    public void testStartupAndTearDown() throws InterruptedException {\n        consumerNetworkThread.start();\n        TestCondition isStarted \u003d consumerNetworkThread::isRunning;\n        TestCondition isClosed \u003d () -\u003e !(consumerNetworkThread.isRunning() || consumerNetworkThread.isAlive());\n\n        // There\u0027s a nonzero amount of time between starting the thread and having it\n        // begin to execute our code. Wait for a bit before checking...\n        TestUtils.waitForCondition(isStarted,\n                \"The consumer network thread did not start within \" + DEFAULT_MAX_WAIT_MS + \" ms\");\n\n        consumerNetworkThread.close(Duration.ofMillis(DEFAULT_MAX_WAIT_MS));\n\n        TestUtils.waitForCondition(isClosed,\n                \"The consumer network thread did not stop within \" + DEFAULT_MAX_WAIT_MS + \" ms\");\n    }\n\n    @Test\n    public void testRequestsTransferFromManagersToClientOnThreadRun() {\n        List\u003cOptional\u003c? extends RequestManager\u003e\u003e list \u003d new ArrayList\u003c\u003e();\n        list.add(Optional.of(coordinatorRequestManager));\n        list.add(Optional.of(heartbeatRequestManager));\n        list.add(Optional.of(offsetsRequestManager));\n\n        when(requestManagers.entries()).thenReturn(list);\n        when(coordinatorRequestManager.poll(anyLong())).thenReturn(mock(NetworkClientDelegate.PollResult.class));\n        consumerNetworkThread.runOnce();\n        requestManagers.entries().forEach(rmo -\u003e rmo.ifPresent(rm -\u003e verify(rm).poll(anyLong())));\n        requestManagers.entries().forEach(rmo -\u003e rmo.ifPresent(rm -\u003e verify(rm).maximumTimeToWait(anyLong())));\n        verify(networkClientDelegate).addAll(any(NetworkClientDelegate.PollResult.class));\n        verify(networkClientDelegate).poll(anyLong(), anyLong());\n    }\n\n    @ParameterizedTest\n    @MethodSource(\"applicationEvents\")\n    public void testApplicationEventIsProcessed(ApplicationEvent e) {\n        applicationEventsQueue.add(e);\n        consumerNetworkThread.runOnce();\n\n        if (e instanceof CompletableEvent)\n            verify(applicationEventReaper).add((CompletableEvent\u003c?\u003e) e);\n\n        verify(applicationEventProcessor).process(any(e.getClass()));\n        assertTrue(applicationEventsQueue.isEmpty());\n    }\n\n    @ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public void testListOffsetsEventIsProcessed(boolean requireTimestamp) {\n        Map\u003cTopicPartition, Long\u003e timestamps \u003d Collections.singletonMap(new TopicPartition(\"topic1\", 1), 5L);\n        ApplicationEvent e \u003d new ListOffsetsEvent(timestamps, calculateDeadlineMs(time, 100), requireTimestamp);\n        applicationEventsQueue.add(e);\n        consumerNetworkThread.runOnce();\n        verify(applicationEventProcessor).process(any(ListOffsetsEvent.class));\n        assertTrue(applicationEventsQueue.isEmpty());\n    }\n\n    @Test\n    public void testResetPositionsProcessFailureIsIgnored() {\n        doThrow(new NullPointerException()).when(offsetsRequestManager).resetPositionsIfNeeded();\n\n        ResetPositionsEvent event \u003d new ResetPositionsEvent(calculateDeadlineMs(time, 100));\n        applicationEventsQueue.add(event);\n        assertDoesNotThrow(() -\u003e consumerNetworkThread.runOnce());\n\n        verify(applicationEventProcessor).process(any(ResetPositionsEvent.class));\n    }\n\n    @Test\n    public void testMaximumTimeToWait() {\n        final int defaultHeartbeatIntervalMs \u003d 1000;\n        // Initial value before runOnce has been called\n        assertEquals(ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, consumerNetworkThread.maximumTimeToWait());\n\n        when(requestManagers.entries()).thenReturn(Collections.singletonList(Optional.of(heartbeatRequestManager)));\n        when(heartbeatRequestManager.maximumTimeToWait(time.milliseconds())).thenReturn((long) defaultHeartbeatIntervalMs);\n\n        consumerNetworkThread.runOnce();\n        // After runOnce has been called, it takes the default heartbeat interval from the heartbeat request manager\n        assertEquals(defaultHeartbeatIntervalMs, consumerNetworkThread.maximumTimeToWait());\n    }\n\n    @Test\n    public void testCleanupInvokesReaper() {\n        LinkedList\u003cNetworkClientDelegate.UnsentRequest\u003e queue \u003d new LinkedList\u003c\u003e();\n        when(networkClientDelegate.unsentRequests()).thenReturn(queue);\n        consumerNetworkThread.cleanup();\n        verify(applicationEventReaper).reap(applicationEventsQueue);\n    }\n\n    @Test\n    public void testRunOnceInvokesReaper() {\n        consumerNetworkThread.runOnce();\n        verify(applicationEventReaper).reap(any(Long.class));\n    }\n\n    @Test\n    public void testSendUnsentRequests() {\n        when(networkClientDelegate.hasAnyPendingRequests()).thenReturn(true).thenReturn(true).thenReturn(false);\n        consumerNetworkThread.cleanup();\n        verify(networkClientDelegate, times(2)).poll(anyLong(), anyLong());\n    }\n\n    private static Stream\u003cArguments\u003e applicationEvents() {\n        Map\u003cTopicPartition, OffsetAndMetadata\u003e offset \u003d new HashMap\u003c\u003e();\n        final long currentTimeMs \u003d 12345;\n        return Stream.of(\n                Arguments.of(new PollEvent(100)),\n                Arguments.of(new NewTopicsMetadataUpdateRequestEvent()),\n                Arguments.of(new AsyncCommitEvent(new HashMap\u003c\u003e())),\n                Arguments.of(new SyncCommitEvent(new HashMap\u003c\u003e(), 500)),\n                Arguments.of(new ResetPositionsEvent(500)),\n                Arguments.of(new ValidatePositionsEvent(500)),\n                Arguments.of(new TopicMetadataEvent(\"topic\", Long.MAX_VALUE)),\n                Arguments.of(new AssignmentChangeEvent(offset, currentTimeMs)));\n    }\n}","methodCount":15},"candidatesTelemetryData":{"numberOfSuggestions":6,"candidates":[{"lineStart":187,"lineEnd":198,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method testApplicationEventIsProcessed to class Time","description":"Move method testApplicationEventIsProcessed to org.apache.kafka.common.utils.Time\nRationale: The testApplicationEventIsProcessed() method is primarily concerned with processing application events, which involves timing aspects such as when events are added and processed. Moving this method to the Time class could be justified if the Time class is responsible for managing time-related operations, as it would centralize the timing logic related to event processing. This aligns with the Single Responsibility Principle, as it separates event processing from the current class\u0027s responsibilities. However, this move raises concerns about the cohesion of the Time class, which is primarily focused on time management rather than event processing. Additionally, it could lead to confusion regarding the purpose of the Time class, as it would be handling event-related logic that may not align with its intended use. Thus, while there are potential benefits, careful consideration of class responsibilities and cohesion is essential.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":257,"lineEnd":269,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method applicationEvents to class AssignmentTestUtils","description":"move method applicationEvents to PsiClass:AssignmentTestUtils\nRationale: The applicationEvents() method generates various event arguments that are likely used in testing scenarios related to assignment management. Moving it to AssignmentTestUtils aligns with the Single Responsibility Principle, as this class appears to be focused on utilities for assignment-related tests. This enhances cohesion and reusability of the event generation functionality. However, care should be taken to ensure that the method\u0027s static nature does not conflict with instance-based utilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":257,"lineEnd":269,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method applicationEvents to class AsyncKafkaConsumerTest","description":"move method applicationEvents to PsiClass:AsyncKafkaConsumerTest\nRationale: The applicationEvents() method produces a stream of application events that are likely relevant to the tests conducted in AsyncKafkaConsumerTest. Relocating it here would improve the organization of test-related methods, ensuring that all event-related logic is centralized. This adheres to the Open/Closed Principle by allowing the test class to be extended with new event types without modifying existing code. However, it may increase the complexity of AsyncKafkaConsumerTest if it grows too large.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":257,"lineEnd":269,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method applicationEvents to class TopicMetadataRequestManagerTest","description":"move method applicationEvents to PsiClass:TopicMetadataRequestManagerTest\nRationale: The events generated by applicationEvents() are likely to be relevant for testing topic metadata requests, making TopicMetadataRequestManagerTest a suitable target class. This move would enhance the cohesion of the test class, focusing it on relevant event types. It aligns with the Interface Segregation Principle by ensuring that classes only depend on the methods they use. One consideration is ensuring that the events generated are indeed relevant to the tests in this class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":113,"lineEnd":117,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method tearDown to class ConsumerNetworkThread","description":"Move method tearDown to org.apache.kafka.clients.consumer.internals.ConsumerNetworkThread\nRationale: The tearDown() method is responsible for closing the consumerNetworkThread, which indicates that it is directly related to the lifecycle management of the ConsumerNetworkThread instance. Moving this method to the ConsumerNetworkThread class adheres to the Single Responsibility Principle, as it centralizes the resource management within the class that owns the resource. This enhances cohesion, making it clear that the ConsumerNetworkThread is responsible for its own cleanup. Additionally, this aligns with the Dependency Inversion Principle, as it allows higher-level components to depend on abstractions rather than concrete implementations. A potential drawback could be that if there are multiple threads or instances needing similar cleanup logic, this could lead to code duplication unless abstracted further.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":113,"lineEnd":117,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method tearDown to class Time","description":"Move method tearDown to org.apache.kafka.common.utils.Time\nRationale: Although the Time class does not have a direct correlation with the consumerNetworkThread, moving tearDown() here could be considered if the method is part of a broader timing or scheduling framework. However, this is less appropriate than the first suggestion, as the Time class focuses on time-related functionalities and does not manage resources like threads. This move would not adhere to the Single Responsibility Principle, as it would mix resource management with time functionalities. The primary benefit would be to centralize cleanup logic if there were time-based operations involved, but this could lead to a violation of cohesion, making the Time class less focused on its intended purpose. Therefore, this option is less optimal.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},{"method_name":"tearDown","method_signature":"@AfterEach\n    public tearDown()","target_class":"","rationale":""},{"method_name":"testConsumerNetworkThreadPollTimeComputations","method_signature":"@ParameterizedTest\n    @ValueSource(longs \u003d {ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS - 1, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS + 1})\n    public testConsumerNetworkThreadPollTimeComputations(long exampleTime)","target_class":"","rationale":""},{"method_name":"testApplicationEventIsProcessed","method_signature":"@ParameterizedTest\n    @MethodSource(\"applicationEvents\")\n    public testApplicationEventIsProcessed(ApplicationEvent e)","target_class":"","rationale":""},{"method_name":"testListOffsetsEventIsProcessed","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testListOffsetsEventIsProcessed(boolean requireTimestamp)","target_class":"","rationale":""},{"method_name":"applicationEvents","method_signature":"private static applicationEvents()","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"testApplicationEventIsProcessed","method_signature":"@ParameterizedTest\n    @MethodSource(\"applicationEvents\")\n    public testApplicationEventIsProcessed(ApplicationEvent e)","target_class":"","rationale":""},{"method_name":"applicationEvents","method_signature":"private static applicationEvents()","target_class":"","rationale":""},{"method_name":"tearDown","method_signature":"@AfterEach\n    public tearDown()","target_class":"","rationale":""},{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},{"method_name":"testListOffsetsEventIsProcessed","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testListOffsetsEventIsProcessed(boolean requireTimestamp)","target_class":"","rationale":""},{"method_name":"testConsumerNetworkThreadPollTimeComputations","method_signature":"@ParameterizedTest\n    @ValueSource(longs \u003d {ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS - 1, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS + 1})\n    public testConsumerNetworkThreadPollTimeComputations(long exampleTime)","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"@ParameterizedTest\n    @MethodSource(\"applicationEvents\")\n    public testApplicationEventIsProcessed(ApplicationEvent e)":{"first":{"method_name":"testApplicationEventIsProcessed","method_signature":"@ParameterizedTest\n    @MethodSource(\"applicationEvents\")\n    public testApplicationEventIsProcessed(ApplicationEvent e)","target_class":"","rationale":""},"second":0.21378023199857898},"private static applicationEvents()":{"first":{"method_name":"applicationEvents","method_signature":"private static applicationEvents()","target_class":"","rationale":""},"second":0.2164929031232733},"@AfterEach\n    public tearDown()":{"first":{"method_name":"tearDown","method_signature":"@AfterEach\n    public tearDown()","target_class":"","rationale":""},"second":0.234685859539543},"@BeforeEach\n    public setup()":{"first":{"method_name":"setup","method_signature":"@BeforeEach\n    public setup()","target_class":"","rationale":""},"second":0.33557802760701216},"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testListOffsetsEventIsProcessed(boolean requireTimestamp)":{"first":{"method_name":"testListOffsetsEventIsProcessed","method_signature":"@ParameterizedTest\n    @ValueSource(booleans \u003d {true, false})\n    public testListOffsetsEventIsProcessed(boolean requireTimestamp)","target_class":"","rationale":""},"second":0.4001846319530726},"@ParameterizedTest\n    @ValueSource(longs \u003d {ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS - 1, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS + 1})\n    public testConsumerNetworkThreadPollTimeComputations(long exampleTime)":{"first":{"method_name":"testConsumerNetworkThreadPollTimeComputations","method_signature":"@ParameterizedTest\n    @ValueSource(longs \u003d {ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS - 1, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS, ConsumerNetworkThread.MAX_POLL_TIMEOUT_MS + 1})\n    public testConsumerNetworkThreadPollTimeComputations(long exampleTime)","target_class":"","rationale":""},"second":0.43346074756559816}},"llmMethodPriority":{"priority_method_names":["testApplicationEventIsProcessed","applicationEvents","tearDown","setup","testListOffsetsEventIsProcessed","testConsumerNetworkThreadPollTimeComputations"],"llm_response_time":1478},"targetClassMap":{"testApplicationEventIsProcessed":{"target_classes":[{"class_name":"Time","similarity_score":0.09370520762651201}],"target_classes_sorted_by_llm":["Time"],"llm_response_time":1984,"similarity_computation_time":2,"similarity_metric":"voyage"},"applicationEvents":{"target_classes":[{"class_name":"FetchUtils","similarity_score":0.025482359571881278},{"class_name":"OffsetFetcherUtils","similarity_score":0.2643175338305979},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.23387491037547753},{"class_name":"ConsumerUtils","similarity_score":0.24884899630250318},{"class_name":"ProducerTestUtils","similarity_score":0.1554733542042308},{"class_name":"RequestFuture","similarity_score":0.13103671320539137},{"class_name":"RequestFutureTest","similarity_score":0.2025374871452388},{"class_name":"RequestManagers","similarity_score":0.24265984339267566},{"class_name":"Fetch","similarity_score":0.15408970728439894},{"class_name":"TaskAssignmentUtilsTest","similarity_score":0.22065490022869094},{"class_name":"FetchBufferTest","similarity_score":0.213352298825066},{"class_name":"FetchCollectorTest","similarity_score":0.24208407518008812},{"class_name":"FetcherTest","similarity_score":0.23595107689383377},{"class_name":"FetchMetricsManager","similarity_score":0.256888374891631},{"class_name":"FetchRequestManagerTest","similarity_score":0.23326673232207948},{"class_name":"AbstractPartitionAssignorTest","similarity_score":0.25090260553988875},{"class_name":"GraphGraceSearchUtil","similarity_score":0.23790168754125599},{"class_name":"Acknowledgements","similarity_score":0.13614594230690372},{"class_name":"ExceptionUtils","similarity_score":0.20957556296649676},{"class_name":"AdminClientTestUtils","similarity_score":0.1617359876781498},{"class_name":"HeartbeatRequestManagerTest","similarity_score":0.23050294480170339},{"class_name":"TimedRequestState","similarity_score":0.19801321188225987},{"class_name":"StandbyTaskAssignmentUtils","similarity_score":0.17618112900581342},{"class_name":"StandbyTaskAssignmentUtilsTest","similarity_score":0.22063250497179882},{"class_name":"StateManagerUtil","similarity_score":0.16164966686237187},{"class_name":"StoreQueryUtils","similarity_score":0.25152010930227814},{"class_name":"ApplicationEventProcessor","similarity_score":0.15988541817186452},{"class_name":"TopicMetadataRequestManagerTest","similarity_score":0.2847360149770205},{"class_name":"WrappingNullableUtils","similarity_score":0.20850395827599474},{"class_name":"ClientTelemetryUtils","similarity_score":0.22780048021120808},{"class_name":"ClientUtils","similarity_score":0.23619339015826027},{"class_name":"CsvUtils","similarity_score":0.23237900077244503},{"class_name":"StreamStreamJoinUtil","similarity_score":0.11975337775498705},{"class_name":"CommitRequestManager","similarity_score":0.20682008432640023},{"class_name":"CommitRequestManagerTest","similarity_score":0.2367531020895609},{"class_name":"AssignmentTestUtils","similarity_score":0.2765507021565337},{"class_name":"AsyncKafkaConsumer","similarity_score":0.21178742167014017},{"class_name":"AsyncKafkaConsumerTest","similarity_score":0.25970579336412797},{"class_name":"CompletedFetch","similarity_score":0.20948880454153365},{"class_name":"CompletedFetchTest","similarity_score":0.2571521661459982},{"class_name":"ShareCompletedFetch","similarity_score":0.22947004402432136},{"class_name":"ShareCompletedFetchTest","similarity_score":0.23908869881887285},{"class_name":"ShareConsumeRequestManagerTest","similarity_score":0.2535530834868539},{"class_name":"ShareConsumerImpl","similarity_score":0.22379636476464115},{"class_name":"ShareFetch","similarity_score":0.1276340811225311},{"class_name":"ShareFetchBufferTest","similarity_score":0.2218513426206568},{"class_name":"ShareFetchCollectorTest","similarity_score":0.25441297563681364},{"class_name":"InternalQueryResultUtil","similarity_score":0.12288076127325037},{"class_name":"ShareHeartbeatRequestManagerTest","similarity_score":0.22984315823759166},{"class_name":"ShareMembershipManagerTest","similarity_score":0.20169276684020948}],"target_classes_sorted_by_llm":["AssignmentTestUtils","AsyncKafkaConsumerTest","TopicMetadataRequestManagerTest","CompletedFetchTest","ShareConsumeRequestManagerTest","FetchMetricsManager","OffsetFetcherUtils","StoreQueryUtils","ShareFetchCollectorTest","AbstractPartitionAssignorTest"],"llm_response_time":9759,"similarity_computation_time":305,"similarity_metric":"voyage"},"tearDown":{"target_classes":[{"class_name":"Time","similarity_score":0.12507976106435625},{"class_name":"ConsumerNetworkThread","similarity_score":0.2100225669704419}],"target_classes_sorted_by_llm":["ConsumerNetworkThread","Time"],"llm_response_time":2865,"similarity_computation_time":27,"similarity_metric":"voyage"}}}
{"id":"bfd6e521-525b-4cd3-b2ad-a433b209ce87","methodCount":81,"hostFunctionTelemetryData":{"hostFunctionSize":1244,"lineStart":72,"lineEnd":1315,"bodyLineStart":72,"language":"java","filePath":"/Users/fraolbatole/Documents/RunRefMiner/MM-Assist-oracle/kafka/clients/src/main/java/org/apache/kafka/clients/consumer/internals/CommitRequestManager.java","sourceCode":"public class CommitRequestManager implements RequestManager, MemberStateListener {\n    private final Time time;\n    private final SubscriptionState subscriptions;\n    private final LogContext logContext;\n    private final Logger log;\n    private final Optional\u003cAutoCommitState\u003e autoCommitState;\n    private final CoordinatorRequestManager coordinatorRequestManager;\n    private final OffsetCommitCallbackInvoker offsetCommitCallbackInvoker;\n    private final OffsetCommitMetricsManager metricsManager;\n    private final long retryBackoffMs;\n    private final String groupId;\n    private final Optional\u003cString\u003e groupInstanceId;\n    private final long retryBackoffMaxMs;\n    // For testing only\n    private final OptionalDouble jitter;\n    private final boolean throwOnFetchStableOffsetUnsupported;\n    final PendingRequests pendingRequests;\n    private boolean closing \u003d false;\n\n    /**\n     * Last member epoch sent in a commit request. Empty if no epoch was included in the last\n     * request. Used for logging.\n     */\n    private Optional\u003cInteger\u003e lastEpochSentOnCommit;\n\n    /**\n     *  Latest member ID and epoch received via the {@link #onMemberEpochUpdated(Optional, Optional)},\n     *  to be included in the OffsetFetch and OffsetCommit requests if present. This will have\n     *  the latest values received from the broker, or empty of the member is not part of the\n     *  group anymore.\n     */\n    private final MemberInfo memberInfo;\n\n    public CommitRequestManager(\n            final Time time,\n            final LogContext logContext,\n            final SubscriptionState subscriptions,\n            final ConsumerConfig config,\n            final CoordinatorRequestManager coordinatorRequestManager,\n            final OffsetCommitCallbackInvoker offsetCommitCallbackInvoker,\n            final String groupId,\n            final Optional\u003cString\u003e groupInstanceId,\n            final Metrics metrics) {\n        this(time,\n            logContext,\n            subscriptions,\n            config,\n            coordinatorRequestManager,\n            offsetCommitCallbackInvoker,\n            groupId,\n            groupInstanceId,\n            config.getLong(ConsumerConfig.RETRY_BACKOFF_MS_CONFIG),\n            config.getLong(ConsumerConfig.RETRY_BACKOFF_MAX_MS_CONFIG),\n            OptionalDouble.empty(),\n            metrics);\n    }\n\n    // Visible for testing\n    CommitRequestManager(\n        final Time time,\n        final LogContext logContext,\n        final SubscriptionState subscriptions,\n        final ConsumerConfig config,\n        final CoordinatorRequestManager coordinatorRequestManager,\n        final OffsetCommitCallbackInvoker offsetCommitCallbackInvoker,\n        final String groupId,\n        final Optional\u003cString\u003e groupInstanceId,\n        final long retryBackoffMs,\n        final long retryBackoffMaxMs,\n        final OptionalDouble jitter,\n        final Metrics metrics) {\n        Objects.requireNonNull(coordinatorRequestManager, \"Coordinator is needed upon committing offsets\");\n        this.time \u003d time;\n        this.logContext \u003d logContext;\n        this.log \u003d logContext.logger(getClass());\n        this.pendingRequests \u003d new PendingRequests();\n        if (config.getBoolean(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG)) {\n            final long autoCommitInterval \u003d\n                Integer.toUnsignedLong(config.getInt(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG));\n            this.autoCommitState \u003d Optional.of(new AutoCommitState(time, autoCommitInterval, logContext));\n        } else {\n            this.autoCommitState \u003d Optional.empty();\n        }\n        this.coordinatorRequestManager \u003d coordinatorRequestManager;\n        this.groupId \u003d groupId;\n        this.groupInstanceId \u003d groupInstanceId;\n        this.subscriptions \u003d subscriptions;\n        this.retryBackoffMs \u003d retryBackoffMs;\n        this.retryBackoffMaxMs \u003d retryBackoffMaxMs;\n        this.jitter \u003d jitter;\n        this.throwOnFetchStableOffsetUnsupported \u003d config.getBoolean(THROW_ON_FETCH_STABLE_OFFSET_UNSUPPORTED);\n        this.memberInfo \u003d new MemberInfo();\n        this.metricsManager \u003d new OffsetCommitMetricsManager(metrics);\n        this.offsetCommitCallbackInvoker \u003d offsetCommitCallbackInvoker;\n        this.lastEpochSentOnCommit \u003d Optional.empty();\n    }\n\n    /**\n     * Poll for the {@link OffsetFetchRequest} and {@link OffsetCommitRequest} request if there\u0027s any. The function will\n     * also try to autocommit the offsets, if feature is enabled.\n     */\n    @Override\n    public NetworkClientDelegate.PollResult poll(final long currentTimeMs) {\n        // poll only when the coordinator node is known.\n        if (!coordinatorRequestManager.coordinator().isPresent())\n            return EMPTY;\n\n        if (closing) {\n            return drainPendingOffsetCommitRequests();\n        }\n\n        maybeAutoCommitAsync();\n        if (!pendingRequests.hasUnsentRequests())\n            return EMPTY;\n\n        List\u003cNetworkClientDelegate.UnsentRequest\u003e requests \u003d pendingRequests.drain(currentTimeMs);\n        // min of the remainingBackoffMs of all the request that are still backing off\n        final long timeUntilNextPoll \u003d Math.min(\n            findMinTime(unsentOffsetCommitRequests(), currentTimeMs),\n            findMinTime(unsentOffsetFetchRequests(), currentTimeMs));\n        return new NetworkClientDelegate.PollResult(timeUntilNextPoll, requests);\n    }\n\n    @Override\n    public void signalClose() {\n        closing \u003d true;\n    }\n\n    /**\n     * Returns the delay for which the application thread can safely wait before it should be responsive\n     * to results from the request managers. For example, the subscription state can change when heartbeats\n     * are sent, so blocking for longer than the heartbeat interval might mean the application thread is not\n     * responsive to changes.\n     */\n    @Override\n    public long maximumTimeToWait(long currentTimeMs) {\n        return autoCommitState.map(ac -\u003e ac.remainingMs(currentTimeMs)).orElse(Long.MAX_VALUE);\n    }\n\n    private static long findMinTime(final Collection\u003c? extends RequestState\u003e requests, final long currentTimeMs) {\n        return requests.stream()\n            .mapToLong(request -\u003e request.remainingBackoffMs(currentTimeMs))\n            .min()\n            .orElse(Long.MAX_VALUE);\n    }\n\n    private KafkaException maybeWrapAsTimeoutException(Throwable t) {\n        if (t instanceof TimeoutException)\n            return (TimeoutException) t;\n        else\n            return new TimeoutException(t);\n    }\n\n    /**\n     * Generate a request to commit consumed offsets. Add the request to the queue of pending\n     * requests to be sent out on the next call to {@link #poll(long)}. If there are empty\n     * offsets to commit, no request will be generated and a completed future will be returned.\n     *\n     * @param requestState Commit request\n     * @return Future containing the offsets that were committed, or an error if the request\n     * failed.\n     */\n    private CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e requestAutoCommit(final OffsetCommitRequestState requestState) {\n        AutoCommitState autocommit \u003d autoCommitState.get();\n        CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result;\n        if (requestState.offsets.isEmpty()) {\n            result \u003d CompletableFuture.completedFuture(Collections.emptyMap());\n        } else {\n            autocommit.setInflightCommitStatus(true);\n            OffsetCommitRequestState request \u003d pendingRequests.addOffsetCommitRequest(requestState);\n            result \u003d request.future;\n            result.whenComplete(autoCommitCallback(request.offsets));\n        }\n        return result;\n    }\n\n    /**\n     * If auto-commit is enabled, and the auto-commit interval has expired, this will generate and\n     * enqueue a request to commit all consumed offsets, and will reset the auto-commit timer to the\n     * interval. The request will be sent on the next call to {@link #poll(long)}.\n     * \u003cp/\u003e\n     * If the request completes with a retriable error, this will reset the auto-commit timer with\n     * the exponential backoff. If it fails with a non-retriable error, no action is taken, so\n     * the next commit will be generated when the interval expires.\n     * \u003cp/\u003e\n     * This will not generate a new commit request if a previous one hasn\u0027t received a response.\n     * In that case, the next auto-commit request will be sent on the next call to poll, after a\n     * response for the in-flight is received.\n     */\n    public void maybeAutoCommitAsync() {\n        if (autoCommitEnabled() \u0026\u0026 autoCommitState.get().shouldAutoCommit()) {\n            OffsetCommitRequestState requestState \u003d createOffsetCommitRequest(\n                subscriptions.allConsumed(),\n                Long.MAX_VALUE);\n            CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result \u003d requestAutoCommit(requestState);\n            // Reset timer to the interval (even if no request was generated), but ensure that if\n            // the request completes with a retriable error, the timer is reset to send the next\n            // auto-commit after the backoff expires.\n            resetAutoCommitTimer();\n            maybeResetTimerWithBackoff(result);\n        }\n    }\n\n    /**\n     * Reset auto-commit timer to retry with backoff if the future failed with a RetriableCommitFailedException.\n     */\n    private void maybeResetTimerWithBackoff(final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result) {\n        result.whenComplete((offsets, error) -\u003e {\n            if (error !\u003d null) {\n                if (error instanceof RetriableCommitFailedException) {\n                    log.debug(\"Asynchronous auto-commit of offsets {} failed due to retriable error.\", offsets, error);\n                    resetAutoCommitTimer(retryBackoffMs);\n                } else {\n                    log.debug(\"Asynchronous auto-commit of offsets {} failed: {}\", offsets, error.getMessage());\n                }\n            } else {\n                log.debug(\"Completed asynchronous auto-commit of offsets {}\", offsets);\n            }\n        });\n    }\n\n    /**\n     * Commit consumed offsets if auto-commit is enabled, regardless of the auto-commit interval.\n     * This is used for committing offsets before revoking partitions. This will retry committing\n     * the latest offsets until the request succeeds, fails with a fatal error, or the timeout\n     * expires. Note that:\n     * \u003cul\u003e\n     *     \u003cli\u003eConsiders {@link Errors#STALE_MEMBER_EPOCH} as a retriable error, and will retry it\n     *     including the latest member ID and epoch received from the broker.\u003c/li\u003e\n     *     \u003cli\u003eConsiders {@link Errors#UNKNOWN_TOPIC_OR_PARTITION} as a fatal error, and will not\n     *     retry it although the error extends RetriableException. The reason is that if a topic\n     *     or partition is deleted, revocation would not finish in time since the auto commit would keep retrying.\u003c/li\u003e\n     * \u003c/ul\u003e\n     *\n     * Also note that this will generate a commit request even if there is another one in-flight,\n     * generated by the auto-commit on the interval logic, to ensure that the latest offsets are\n     * committed before revoking partitions.\n     *\n     * @return Future that will complete when the offsets are successfully committed. It will\n     * complete exceptionally if the commit fails with a non-retriable error, or if the retry\n     * timeout expires.\n     */\n    public CompletableFuture\u003cVoid\u003e maybeAutoCommitSyncBeforeRevocation(final long deadlineMs) {\n        if (!autoCommitEnabled()) {\n            return CompletableFuture.completedFuture(null);\n        }\n\n        CompletableFuture\u003cVoid\u003e result \u003d new CompletableFuture\u003c\u003e();\n        OffsetCommitRequestState requestState \u003d\n            createOffsetCommitRequest(subscriptions.allConsumed(), deadlineMs);\n        autoCommitSyncBeforeRevocationWithRetries(requestState, result);\n        return result;\n    }\n\n    private void autoCommitSyncBeforeRevocationWithRetries(OffsetCommitRequestState requestAttempt,\n                                                           CompletableFuture\u003cVoid\u003e result) {\n        CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e commitAttempt \u003d requestAutoCommit(requestAttempt);\n        commitAttempt.whenComplete((committedOffsets, error) -\u003e {\n            if (error \u003d\u003d null) {\n                result.complete(null);\n            } else {\n                if (error instanceof RetriableException || isStaleEpochErrorAndValidEpochAvailable(error)) {\n                    if (requestAttempt.isExpired()) {\n                        log.debug(\"Auto-commit sync before revocation timed out and won\u0027t be retried anymore\");\n                        result.completeExceptionally(maybeWrapAsTimeoutException(error));\n                    } else if (error instanceof UnknownTopicOrPartitionException) {\n                        log.debug(\"Auto-commit sync before revocation failed because topic or partition were deleted\");\n                        result.completeExceptionally(error);\n                    } else {\n                        // Make sure the auto-commit is retried with the latest offsets\n                        log.debug(\"Member {} will retry auto-commit of latest offsets after receiving retriable error {}\",\n                            memberInfo.memberId.orElse(\"undefined\"),\n                            error.getMessage());\n                        requestAttempt.offsets \u003d subscriptions.allConsumed();\n                        requestAttempt.resetFuture();\n                        autoCommitSyncBeforeRevocationWithRetries(requestAttempt, result);\n                    }\n                } else {\n                    log.debug(\"Auto-commit sync before revocation failed with non-retriable error\", error);\n                    result.completeExceptionally(error);\n                }\n            }\n        });\n    }\n\n    /**\n     * Clear the inflight auto-commit flag and log auto-commit completion status.\n     */\n    private BiConsumer\u003c? super Map\u003cTopicPartition, OffsetAndMetadata\u003e, ? super Throwable\u003e autoCommitCallback(final Map\u003cTopicPartition, OffsetAndMetadata\u003e allConsumedOffsets) {\n        return (response, throwable) -\u003e {\n            autoCommitState.ifPresent(autoCommitState -\u003e autoCommitState.setInflightCommitStatus(false));\n            if (throwable \u003d\u003d null) {\n                offsetCommitCallbackInvoker.enqueueInterceptorInvocation(allConsumedOffsets);\n                log.debug(\"Completed auto-commit of offsets {}\", allConsumedOffsets);\n            } else if (throwable instanceof RetriableCommitFailedException) {\n                log.debug(\"Auto-commit of offsets {} failed due to retriable error: {}\",\n                        allConsumedOffsets, throwable.getMessage());\n            } else {\n                log.warn(\"Auto-commit of offsets {} failed\", allConsumedOffsets, throwable);\n            }\n        };\n    }\n\n    /**\n     * Generate a request to commit offsets without retrying, even if it fails with a retriable\n     * error. The generated request will be added to the queue to be sent on the next call to\n     * {@link #poll(long)}.\n     *\n     * @param offsets Offsets to commit per partition.\n     * @return Future that will complete when a response is received, successfully or\n     * exceptionally depending on the response. If the request fails with a retriable error, the\n     * future will be completed with a {@link RetriableCommitFailedException}.\n     */\n    public CompletableFuture\u003cVoid\u003e commitAsync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets) {\n        if (offsets.isEmpty()) {\n            log.debug(\"Skipping commit of empty offsets\");\n            return CompletableFuture.completedFuture(null);\n        }\n        OffsetCommitRequestState commitRequest \u003d createOffsetCommitRequest(offsets, Long.MAX_VALUE);\n        pendingRequests.addOffsetCommitRequest(commitRequest);\n\n        CompletableFuture\u003cVoid\u003e asyncCommitResult \u003d new CompletableFuture\u003c\u003e();\n        commitRequest.future.whenComplete((committedOffsets, error) -\u003e {\n            if (error !\u003d null) {\n                asyncCommitResult.completeExceptionally(commitAsyncExceptionForError(error));\n            } else {\n                asyncCommitResult.complete(null);\n            }\n        });\n        return asyncCommitResult;\n    }\n\n    /**\n     * Commit offsets, retrying on expected retriable errors while the retry timeout hasn\u0027t expired.\n     *\n     * @param offsets               Offsets to commit\n     * @param deadlineMs            Time until which the request will be retried if it fails with\n     *                              an expected retriable error.\n     * @return Future that will complete when a successful response\n     */\n    public CompletableFuture\u003cVoid\u003e commitSync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                              final long deadlineMs) {\n        CompletableFuture\u003cVoid\u003e result \u003d new CompletableFuture\u003c\u003e();\n        OffsetCommitRequestState requestState \u003d createOffsetCommitRequest(offsets, deadlineMs);\n        commitSyncWithRetries(requestState, result);\n        return result;\n    }\n\n    private OffsetCommitRequestState createOffsetCommitRequest(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                                               final long deadlineMs) {\n        return jitter.isPresent() ?\n            new OffsetCommitRequestState(\n                offsets,\n                groupId,\n                groupInstanceId,\n                deadlineMs,\n                retryBackoffMs,\n                retryBackoffMaxMs,\n                jitter.getAsDouble(),\n                memberInfo) :\n            new OffsetCommitRequestState(\n                offsets,\n                groupId,\n                groupInstanceId,\n                deadlineMs,\n                retryBackoffMs,\n                retryBackoffMaxMs,\n                memberInfo);\n    }\n\n    private void commitSyncWithRetries(OffsetCommitRequestState requestAttempt,\n                                       CompletableFuture\u003cVoid\u003e result) {\n        pendingRequests.addOffsetCommitRequest(requestAttempt);\n\n        // Retry the same commit request while it fails with RetriableException and the retry\n        // timeout hasn\u0027t expired.\n        requestAttempt.future.whenComplete((res, error) -\u003e {\n            if (error \u003d\u003d null) {\n                result.complete(null);\n            } else {\n                if (error instanceof RetriableException) {\n                    if (requestAttempt.isExpired()) {\n                        log.info(\"OffsetCommit timeout expired so it won\u0027t be retried anymore\");\n                        result.completeExceptionally(maybeWrapAsTimeoutException(error));\n                    } else {\n                        requestAttempt.resetFuture();\n                        commitSyncWithRetries(requestAttempt, result);\n                    }\n                } else {\n                    result.completeExceptionally(commitSyncExceptionForError(error));\n                }\n            }\n        });\n    }\n\n    private Throwable commitSyncExceptionForError(Throwable error) {\n        if (error instanceof StaleMemberEpochException) {\n            return new CommitFailedException(\"OffsetCommit failed with stale member epoch.\"\n                + Errors.STALE_MEMBER_EPOCH.message());\n        }\n        return error;\n    }\n\n    private Throwable commitAsyncExceptionForError(Throwable error) {\n        if (error instanceof RetriableException) {\n            return new RetriableCommitFailedException(error);\n        }\n        return error;\n    }\n\n    /**\n     * Enqueue a request to fetch committed offsets, that will be sent on the next call to {@link #poll(long)}.\n     *\n     * @param partitions       Partitions to fetch offsets for.\n     * @param deadlineMs       Time until which the request should be retried if it fails\n     *                         with expected retriable errors.\n     * @return Future that will complete when a successful response is received, or the request\n     * fails and cannot be retried. Note that the request is retried whenever it fails with\n     * retriable expected error and the retry time hasn\u0027t expired.\n     */\n    public CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e fetchOffsets(\n        final Set\u003cTopicPartition\u003e partitions,\n        final long deadlineMs) {\n        if (partitions.isEmpty()) {\n            return CompletableFuture.completedFuture(Collections.emptyMap());\n        }\n        CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result \u003d new CompletableFuture\u003c\u003e();\n        OffsetFetchRequestState request \u003d createOffsetFetchRequest(partitions, deadlineMs);\n        fetchOffsetsWithRetries(request, result);\n        return result;\n    }\n\n    // Visible for testing\n    OffsetFetchRequestState createOffsetFetchRequest(final Set\u003cTopicPartition\u003e partitions,\n                                                             final long deadlineMs) {\n        return jitter.isPresent() ?\n            new OffsetFetchRequestState(\n                partitions,\n                retryBackoffMs,\n                retryBackoffMaxMs,\n                deadlineMs,\n                jitter.getAsDouble(),\n                memberInfo) :\n            new OffsetFetchRequestState(\n                partitions,\n                retryBackoffMs,\n                retryBackoffMaxMs,\n                deadlineMs,\n                memberInfo);\n    }\n\n    private void fetchOffsetsWithRetries(final OffsetFetchRequestState fetchRequest,\n                                         final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result) {\n        CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e currentResult \u003d pendingRequests.addOffsetFetchRequest(fetchRequest);\n\n        // Retry the same fetch request while it fails with RetriableException and the retry timeout hasn\u0027t expired.\n        currentResult.whenComplete((res, error) -\u003e {\n            boolean inflightRemoved \u003d pendingRequests.inflightOffsetFetches.remove(fetchRequest);\n            if (!inflightRemoved) {\n                log.warn(\"A duplicated, inflight, request was identified, but unable to find it in the \" +\n                    \"outbound buffer:\" + fetchRequest);\n            }\n            if (error \u003d\u003d null) {\n                result.complete(res);\n            } else {\n                if (error instanceof RetriableException || isStaleEpochErrorAndValidEpochAvailable(error)) {\n                    if (fetchRequest.isExpired()) {\n                        log.debug(\"OffsetFetch request for {} timed out and won\u0027t be retried anymore\", fetchRequest.requestedPartitions);\n                        result.completeExceptionally(maybeWrapAsTimeoutException(error));\n                    } else {\n                        fetchRequest.resetFuture();\n                        fetchOffsetsWithRetries(fetchRequest, result);\n                    }\n                } else\n                    result.completeExceptionally(error);\n            }\n        });\n    }\n\n    private boolean isStaleEpochErrorAndValidEpochAvailable(Throwable error) {\n        return error instanceof StaleMemberEpochException \u0026\u0026 memberInfo.memberEpoch.isPresent();\n    }\n\n    public void updateAutoCommitTimer(final long currentTimeMs) {\n        this.autoCommitState.ifPresent(t -\u003e t.updateTimer(currentTimeMs));\n    }\n\n    // Visible for testing\n    Queue\u003cOffsetCommitRequestState\u003e unsentOffsetCommitRequests() {\n        return pendingRequests.unsentOffsetCommits;\n    }\n\n    private List\u003cOffsetFetchRequestState\u003e unsentOffsetFetchRequests() {\n        return pendingRequests.unsentOffsetFetches;\n    }\n\n    private void handleCoordinatorDisconnect(Throwable exception, long currentTimeMs) {\n        if (exception instanceof DisconnectException) {\n            coordinatorRequestManager.markCoordinatorUnknown(exception.getMessage(), currentTimeMs);\n        }\n    }\n\n    /**\n     * Update latest member ID and epoch used by the member.\n     *\n     * @param memberEpoch New member epoch received. To be included in the new request.\n     * @param memberId Current member ID. To be included in the new request.\n     */\n    @Override\n    public void onMemberEpochUpdated(Optional\u003cInteger\u003e memberEpoch, Optional\u003cString\u003e memberId) {\n        if (!memberEpoch.isPresent() \u0026\u0026 memberInfo.memberEpoch.isPresent()) {\n            log.info(\"Member {} won\u0027t include member id and epoch in following offset \" +\n                \"commit/fetch requests because it has left the group.\", memberInfo.memberId.orElse(\"unknown\"));\n        }\n        memberInfo.memberId \u003d memberId;\n        memberInfo.memberEpoch \u003d memberEpoch;\n    }\n\n    /**\n     * @return True if auto-commit is enabled as defined in the config {@link ConsumerConfig#ENABLE_AUTO_COMMIT_CONFIG}\n     */\n    public boolean autoCommitEnabled() {\n        return autoCommitState.isPresent();\n    }\n\n    /**\n     * Reset the auto-commit timer to the auto-commit interval, so that the next auto-commit is\n     * sent out on the interval starting from now. If auto-commit is not enabled this will\n     * perform no action.\n     */\n    public void resetAutoCommitTimer() {\n        autoCommitState.ifPresent(AutoCommitState::resetTimer);\n    }\n\n    /**\n     * Reset the auto-commit timer to the provided time (backoff), so that the next auto-commit is\n     * sent out then. If auto-commit is not enabled this will perform no action.\n     */\n    public void resetAutoCommitTimer(long retryBackoffMs) {\n        autoCommitState.ifPresent(s -\u003e s.resetTimer(retryBackoffMs));\n    }\n\n    /**\n     * Drains the inflight offsetCommits during shutdown because we want to make sure all pending commits are sent\n     * before closing.\n     */\n    public NetworkClientDelegate.PollResult drainPendingOffsetCommitRequests() {\n        if (pendingRequests.unsentOffsetCommits.isEmpty())\n            return EMPTY;\n        List\u003cNetworkClientDelegate.UnsentRequest\u003e requests \u003d pendingRequests.drainPendingCommits();\n        return new NetworkClientDelegate.PollResult(Long.MAX_VALUE, requests);\n    }\n\n    private class OffsetCommitRequestState extends RetriableRequestState {\n        private Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets;\n        private final String groupId;\n        private final Optional\u003cString\u003e groupInstanceId;\n\n        /**\n         * Future containing the offsets that were committed. It completes when a response is\n         * received for the commit request.\n         */\n        private CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e future;\n\n        OffsetCommitRequestState(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                 final String groupId,\n                                 final Optional\u003cString\u003e groupInstanceId,\n                                 final long deadlineMs,\n                                 final long retryBackoffMs,\n                                 final long retryBackoffMaxMs,\n                                 final MemberInfo memberInfo) {\n            super(logContext, CommitRequestManager.class.getSimpleName(), retryBackoffMs,\n                retryBackoffMaxMs, memberInfo, deadlineTimer(time, deadlineMs));\n            this.offsets \u003d offsets;\n            this.groupId \u003d groupId;\n            this.groupInstanceId \u003d groupInstanceId;\n            this.future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        // Visible for testing\n        OffsetCommitRequestState(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                 final String groupId,\n                                 final Optional\u003cString\u003e groupInstanceId,\n                                 final long deadlineMs,\n                                 final long retryBackoffMs,\n                                 final long retryBackoffMaxMs,\n                                 final double jitter,\n                                 final MemberInfo memberInfo) {\n            super(logContext, CommitRequestManager.class.getSimpleName(), retryBackoffMs, 2,\n                retryBackoffMaxMs, jitter, memberInfo, deadlineTimer(time, deadlineMs));\n            this.offsets \u003d offsets;\n            this.groupId \u003d groupId;\n            this.groupInstanceId \u003d groupInstanceId;\n            this.future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        public NetworkClientDelegate.UnsentRequest toUnsentRequest() {\n            Map\u003cString, OffsetCommitRequestData.OffsetCommitRequestTopic\u003e requestTopicDataMap \u003d new HashMap\u003c\u003e();\n            for (Map.Entry\u003cTopicPartition, OffsetAndMetadata\u003e entry : offsets.entrySet()) {\n                TopicPartition topicPartition \u003d entry.getKey();\n                OffsetAndMetadata offsetAndMetadata \u003d entry.getValue();\n\n                OffsetCommitRequestData.OffsetCommitRequestTopic topic \u003d requestTopicDataMap\n                    .getOrDefault(topicPartition.topic(),\n                        new OffsetCommitRequestData.OffsetCommitRequestTopic()\n                            .setName(topicPartition.topic())\n                    );\n\n                topic.partitions().add(new OffsetCommitRequestData.OffsetCommitRequestPartition()\n                    .setPartitionIndex(topicPartition.partition())\n                    .setCommittedOffset(offsetAndMetadata.offset())\n                    .setCommittedLeaderEpoch(offsetAndMetadata.leaderEpoch().orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n                    .setCommittedMetadata(offsetAndMetadata.metadata())\n                );\n                requestTopicDataMap.put(topicPartition.topic(), topic);\n            }\n\n            OffsetCommitRequestData data \u003d new OffsetCommitRequestData()\n                    .setGroupId(this.groupId)\n                    .setGroupInstanceId(groupInstanceId.orElse(null))\n                    .setTopics(new ArrayList\u003c\u003e(requestTopicDataMap.values()));\n            if (memberInfo.memberId.isPresent()) {\n                data \u003d data.setMemberId(memberInfo.memberId.get());\n            }\n            if (memberInfo.memberEpoch.isPresent()) {\n                data \u003d data.setGenerationIdOrMemberEpoch(memberInfo.memberEpoch.get());\n                lastEpochSentOnCommit \u003d memberInfo.memberEpoch;\n            } else {\n                lastEpochSentOnCommit \u003d Optional.empty();\n            }\n\n            OffsetCommitRequest.Builder builder \u003d new OffsetCommitRequest.Builder(data);\n\n            return buildRequestWithResponseHandling(builder);\n        }\n\n        /**\n         * Handle OffsetCommitResponse. This will complete the request future successfully if no\n         * errors are found in the response. If the response contains errors, this will:\n         *   - handle expected errors and fail the future with specific exceptions depending on the error\n         *   - fail the future with a non-recoverable KafkaException for all unexpected errors (even if retriable)\n         */\n        @Override\n        public void onResponse(final ClientResponse response) {\n            metricsManager.recordRequestLatency(response.requestLatencyMs());\n            long currentTimeMs \u003d response.receivedTimeMs();\n            OffsetCommitResponse commitResponse \u003d (OffsetCommitResponse) response.responseBody();\n            Set\u003cString\u003e unauthorizedTopics \u003d new HashSet\u003c\u003e();\n            for (OffsetCommitResponseData.OffsetCommitResponseTopic topic : commitResponse.data().topics()) {\n                for (OffsetCommitResponseData.OffsetCommitResponsePartition partition : topic.partitions()) {\n                    TopicPartition tp \u003d new TopicPartition(topic.name(), partition.partitionIndex());\n\n                    Errors error \u003d Errors.forCode(partition.errorCode());\n                    if (error \u003d\u003d Errors.NONE) {\n                        OffsetAndMetadata offsetAndMetadata \u003d offsets.get(tp);\n                        long offset \u003d offsetAndMetadata.offset();\n                        log.debug(\"OffsetCommit completed successfully for offset {} partition {}\", offset, tp);\n                        continue;\n                    }\n\n                    onFailedAttempt(currentTimeMs);\n                    if (error \u003d\u003d Errors.GROUP_AUTHORIZATION_FAILED) {\n                        future.completeExceptionally(GroupAuthorizationException.forGroupId(groupId));\n                        return;\n                    } else if (error \u003d\u003d Errors.COORDINATOR_NOT_AVAILABLE ||\n                        error \u003d\u003d Errors.NOT_COORDINATOR ||\n                        error \u003d\u003d Errors.REQUEST_TIMED_OUT) {\n                        coordinatorRequestManager.markCoordinatorUnknown(error.message(), currentTimeMs);\n                        future.completeExceptionally(error.exception());\n                        return;\n                    } else if (error \u003d\u003d Errors.FENCED_INSTANCE_ID) {\n                        String fencedError \u003d \"OffsetCommit failed due to group instance id fenced: \" + groupInstanceId;\n                        log.error(fencedError);\n                        future.completeExceptionally(new CommitFailedException(fencedError));\n                        return;\n                    } else if (error \u003d\u003d Errors.OFFSET_METADATA_TOO_LARGE ||\n                        error \u003d\u003d Errors.INVALID_COMMIT_OFFSET_SIZE) {\n                        future.completeExceptionally(error.exception());\n                        return;\n                    } else if (error \u003d\u003d Errors.COORDINATOR_LOAD_IN_PROGRESS ||\n                        error \u003d\u003d Errors.UNKNOWN_TOPIC_OR_PARTITION) {\n                        // just retry\n                        future.completeExceptionally(error.exception());\n                        return;\n                    } else if (error \u003d\u003d Errors.UNKNOWN_MEMBER_ID) {\n                        log.error(\"OffsetCommit failed with {}\", error);\n                        future.completeExceptionally(new CommitFailedException(\"OffsetCommit \" +\n                            \"failed with unknown member ID. \" + error.message()));\n                        return;\n                    } else if (error \u003d\u003d Errors.STALE_MEMBER_EPOCH) {\n                        log.error(\"OffsetCommit failed for member {} with stale member epoch error. Last epoch sent: {}\",\n                            memberInfo.memberId.orElse(\"undefined\"),\n                            lastEpochSentOnCommit.isPresent() ? lastEpochSentOnCommit.get() : \"undefined\");\n                        future.completeExceptionally(error.exception());\n                        return;\n                    } else if (error \u003d\u003d Errors.TOPIC_AUTHORIZATION_FAILED) {\n                        // Collect all unauthorized topics before failing\n                        unauthorizedTopics.add(tp.topic());\n                    } else {\n                        // Fail with a non-retriable KafkaException for all unexpected errors\n                        // (even if they are retriable)\n                        future.completeExceptionally(new KafkaException(\"Unexpected error in commit: \" + error.message()));\n                        return;\n                    }\n                }\n            }\n\n            if (!unauthorizedTopics.isEmpty()) {\n                log.error(\"OffsetCommit failed due to not authorized to commit to topics {}\", unauthorizedTopics);\n                future.completeExceptionally(new TopicAuthorizationException(unauthorizedTopics));\n            } else {\n                future.complete(null);\n            }\n        }\n\n        @Override\n        String requestDescription() {\n            return \"OffsetCommit request for offsets \" + offsets;\n        }\n\n        @Override\n        CompletableFuture\u003c?\u003e future() {\n            return future;\n        }\n\n        void resetFuture() {\n            future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        @Override\n        void removeRequest() {\n            if (!unsentOffsetCommitRequests().remove(this)) {\n                log.warn(\"OffsetCommit request to remove not found in the outbound buffer: {}\", this);\n            }\n        }\n    }\n\n    // Visible for testing\n    Optional\u003cInteger\u003e lastEpochSentOnCommit() {\n        return lastEpochSentOnCommit;\n    }\n\n    /**\n     * Represents a request that can be retried or aborted, based on member ID and epoch\n     * information.\n     */\n    abstract class RetriableRequestState extends TimedRequestState {\n\n        /**\n         * Member info (ID and epoch) to be included in the request if present.\n         */\n        final MemberInfo memberInfo;\n\n        RetriableRequestState(LogContext logContext, String owner, long retryBackoffMs,\n                              long retryBackoffMaxMs, MemberInfo memberInfo, Timer timer) {\n            super(logContext, owner, retryBackoffMs, retryBackoffMaxMs, timer);\n            this.memberInfo \u003d memberInfo;\n        }\n\n        // Visible for testing\n        RetriableRequestState(LogContext logContext, String owner, long retryBackoffMs, int retryBackoffExpBase,\n                              long retryBackoffMaxMs, double jitter, MemberInfo memberInfo, Timer timer) {\n            super(logContext, owner, retryBackoffMs, retryBackoffExpBase, retryBackoffMaxMs, jitter, timer);\n            this.memberInfo \u003d memberInfo;\n        }\n\n        /**\n         * @return String containing the request name and arguments, to be used for logging\n         * purposes.\n         */\n        abstract String requestDescription();\n\n        /**\n         * @return Future that will complete with the request response or failure.\n         */\n        abstract CompletableFuture\u003c?\u003e future();\n\n        /**\n         * Complete the request future with a TimeoutException if the request has been sent out\n         * at least once and the timeout has been reached.\n         */\n        void maybeExpire() {\n            if (numAttempts \u003e 0 \u0026\u0026 isExpired()) {\n                removeRequest();\n                future().completeExceptionally(new TimeoutException(requestDescription() +\n                    \" could not complete before timeout expired.\"));\n            }\n        }\n\n        /**\n         * Build request with the given builder, including response handling logic.\n         */\n        NetworkClientDelegate.UnsentRequest buildRequestWithResponseHandling(final AbstractRequest.Builder\u003c?\u003e builder) {\n            NetworkClientDelegate.UnsentRequest request \u003d new NetworkClientDelegate.UnsentRequest(\n                builder,\n                coordinatorRequestManager.coordinator()\n            );\n            request.whenComplete(\n                (response, throwable) -\u003e {\n                    long completionTimeMs \u003d request.handler().completionTimeMs();\n                    handleClientResponse(response, throwable, completionTimeMs);\n                });\n            return request;\n        }\n\n        private void handleClientResponse(final ClientResponse response,\n                                          final Throwable error,\n                                          final long requestCompletionTimeMs) {\n            try {\n                if (error \u003d\u003d null) {\n                    onResponse(response);\n                } else {\n                    log.debug(\"{} completed with error\", requestDescription(), error);\n                    onFailedAttempt(requestCompletionTimeMs);\n                    handleCoordinatorDisconnect(error, requestCompletionTimeMs);\n                    future().completeExceptionally(error);\n                }\n            } catch (Throwable t) {\n                log.error(\"Unexpected error handling response for {}\", requestDescription(), t);\n                future().completeExceptionally(t);\n            }\n        }\n\n        @Override\n        public String toStringBase() {\n            return super.toStringBase() + \", \" + memberInfo;\n        }\n\n        abstract void onResponse(final ClientResponse response);\n\n        abstract void removeRequest();\n    }\n\n    class OffsetFetchRequestState extends RetriableRequestState {\n\n        /**\n         * Partitions to get committed offsets for.\n         */\n        public final Set\u003cTopicPartition\u003e requestedPartitions;\n\n        /**\n         * Future with the result of the request. This can be reset using {@link #resetFuture()}\n         * to get a new result when the request is retried.\n         */\n        private CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e future;\n\n        public OffsetFetchRequestState(final Set\u003cTopicPartition\u003e partitions,\n                                       final long retryBackoffMs,\n                                       final long retryBackoffMaxMs,\n                                       final long deadlineMs,\n                                       final MemberInfo memberInfo) {\n            super(logContext, CommitRequestManager.class.getSimpleName(), retryBackoffMs,\n                retryBackoffMaxMs, memberInfo, deadlineTimer(time, deadlineMs));\n            this.requestedPartitions \u003d partitions;\n            this.future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        public OffsetFetchRequestState(final Set\u003cTopicPartition\u003e partitions,\n                                       final long retryBackoffMs,\n                                       final long retryBackoffMaxMs,\n                                       final long deadlineMs,\n                                       final double jitter,\n                                       final MemberInfo memberInfo) {\n            super(logContext, CommitRequestManager.class.getSimpleName(), retryBackoffMs, 2,\n                retryBackoffMaxMs, jitter, memberInfo, deadlineTimer(time, deadlineMs));\n            this.requestedPartitions \u003d partitions;\n            this.future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        public boolean sameRequest(final OffsetFetchRequestState request) {\n            return requestedPartitions.equals(request.requestedPartitions);\n        }\n\n        public NetworkClientDelegate.UnsentRequest toUnsentRequest() {\n\n            OffsetFetchRequest.Builder builder;\n            if (memberInfo.memberId.isPresent() \u0026\u0026 memberInfo.memberEpoch.isPresent()) {\n                builder \u003d new OffsetFetchRequest.Builder(\n                        groupId,\n                        memberInfo.memberId.get(),\n                        memberInfo.memberEpoch.get(),\n                        true,\n                        new ArrayList\u003c\u003e(this.requestedPartitions),\n                        throwOnFetchStableOffsetUnsupported);\n            } else {\n                // Building request without passing member ID/epoch to leave the logic to choose\n                // default values when not present on the request builder.\n                builder \u003d new OffsetFetchRequest.Builder(\n                        groupId,\n                        true,\n                        new ArrayList\u003c\u003e(this.requestedPartitions),\n                        throwOnFetchStableOffsetUnsupported);\n            }\n            return buildRequestWithResponseHandling(builder);\n        }\n\n        /**\n         * Handle OffsetFetch response, including successful and failed.\n         */\n        @Override\n        void onResponse(final ClientResponse response) {\n            long currentTimeMs \u003d response.receivedTimeMs();\n            OffsetFetchResponse fetchResponse \u003d (OffsetFetchResponse) response.responseBody();\n            Errors responseError \u003d fetchResponse.groupLevelError(groupId);\n            if (responseError !\u003d Errors.NONE) {\n                onFailure(currentTimeMs, responseError);\n                return;\n            }\n            onSuccess(currentTimeMs, fetchResponse);\n        }\n\n        /**\n         * Handle failed responses. This will retry if the error is retriable, or complete the\n         * result future exceptionally in the case of non-recoverable or unexpected errors.\n         */\n        private void onFailure(final long currentTimeMs,\n                               final Errors responseError) {\n            log.debug(\"Offset fetch failed: {}\", responseError.message());\n            onFailedAttempt(currentTimeMs);\n            if (responseError \u003d\u003d COORDINATOR_LOAD_IN_PROGRESS) {\n                future.completeExceptionally(responseError.exception());\n            } else if (responseError \u003d\u003d Errors.UNKNOWN_MEMBER_ID) {\n                log.error(\"OffsetFetch failed with {} because the member is not part of the group\" +\n                    \" anymore.\", responseError);\n                future.completeExceptionally(responseError.exception());\n            } else if (responseError \u003d\u003d Errors.STALE_MEMBER_EPOCH) {\n                log.error(\"OffsetFetch failed with {} and the consumer is not part \" +\n                    \"of the group anymore (it probably left the group, got fenced\" +\n                    \" or failed). The request cannot be retried and will fail.\", responseError);\n                future.completeExceptionally(responseError.exception());\n            } else if (responseError \u003d\u003d Errors.NOT_COORDINATOR || responseError \u003d\u003d Errors.COORDINATOR_NOT_AVAILABLE) {\n                // Re-discover the coordinator and retry\n                coordinatorRequestManager.markCoordinatorUnknown(\"error response \" + responseError.name(), currentTimeMs);\n                future.completeExceptionally(responseError.exception());\n            } else if (responseError \u003d\u003d Errors.GROUP_AUTHORIZATION_FAILED) {\n                future.completeExceptionally(GroupAuthorizationException.forGroupId(groupId));\n            } else {\n                // Fail with a non-retriable KafkaException for all unexpected errors (even if\n                // they are retriable)\n                future.completeExceptionally(new KafkaException(\"Unexpected error in fetch offset response: \" + responseError.message()));\n            }\n        }\n\n        @Override\n        String requestDescription() {\n            return \"OffsetFetch request for partitions \" + requestedPartitions;\n        }\n\n        @Override\n        CompletableFuture\u003c?\u003e future() {\n            return future;\n        }\n\n        void resetFuture() {\n            future \u003d new CompletableFuture\u003c\u003e();\n        }\n\n        @Override\n        void removeRequest() {\n            if (!unsentOffsetFetchRequests().remove(this)) {\n                log.warn(\"OffsetFetch request to remove not found in the outbound buffer: {}\", this);\n            }\n        }\n\n        /**\n         * Handle OffsetFetch response that has no group level errors. This will look for\n         * partition level errors and fail the future accordingly, also recording a failed request\n         * attempt. If no partition level errors are found, this will complete the future with the\n         * offsets contained in the response, and record a successful request attempt.\n         */\n        private void onSuccess(final long currentTimeMs,\n                               final OffsetFetchResponse response) {\n            Set\u003cString\u003e unauthorizedTopics \u003d null;\n            Map\u003cTopicPartition, OffsetFetchResponse.PartitionData\u003e responseData \u003d\n                    response.partitionDataMap(groupId);\n            Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets \u003d new HashMap\u003c\u003e(responseData.size());\n            Set\u003cTopicPartition\u003e unstableTxnOffsetTopicPartitions \u003d new HashSet\u003c\u003e();\n            for (Map.Entry\u003cTopicPartition, OffsetFetchResponse.PartitionData\u003e entry : responseData.entrySet()) {\n                TopicPartition tp \u003d entry.getKey();\n                OffsetFetchResponse.PartitionData partitionData \u003d entry.getValue();\n                if (partitionData.hasError()) {\n                    onFailedAttempt(currentTimeMs);\n                    Errors error \u003d partitionData.error;\n                    log.debug(\"Failed to fetch offset for partition {}: {}\", tp, error.message());\n\n                    if (error \u003d\u003d Errors.UNKNOWN_TOPIC_OR_PARTITION) {\n                        future.completeExceptionally(new KafkaException(\"Topic or Partition \" + tp + \" does not exist\"));\n                        return;\n                    } else if (error \u003d\u003d Errors.TOPIC_AUTHORIZATION_FAILED) {\n                        if (unauthorizedTopics \u003d\u003d null) {\n                            unauthorizedTopics \u003d new HashSet\u003c\u003e();\n                        }\n                        unauthorizedTopics.add(tp.topic());\n                    } else if (error \u003d\u003d Errors.UNSTABLE_OFFSET_COMMIT) {\n                        unstableTxnOffsetTopicPartitions.add(tp);\n                    } else {\n                        // Fail with a non-retriable KafkaException for all unexpected partition\n                        // errors (even if they are retriable)\n                        future.completeExceptionally(new KafkaException(\"Unexpected error in fetch offset \" +\n                                \"response for partition \" + tp + \": \" + error.message()));\n                        return;\n                    }\n                } else if (partitionData.offset \u003e\u003d 0) {\n                    // record the position with the offset (-1 indicates no committed offset to fetch);\n                    // if there\u0027s no committed offset, record as null\n                    offsets.put(tp, new OffsetAndMetadata(partitionData.offset, partitionData.leaderEpoch, partitionData.metadata));\n                } else {\n                    log.info(\"Found no committed offset for partition {}\", tp);\n                    offsets.put(tp, null);\n                }\n            }\n\n            if (unauthorizedTopics !\u003d null) {\n                future.completeExceptionally(new TopicAuthorizationException(unauthorizedTopics));\n            } else if (!unstableTxnOffsetTopicPartitions.isEmpty()) {\n                // TODO: Optimization question: Do we need to retry all partitions upon a single partition error?\n                log.info(\"The following partitions still have unstable offsets \" +\n                        \"which are not cleared on the broker side: {}\" +\n                        \", this could be either \" +\n                        \"transactional offsets waiting for completion, or \" +\n                        \"normal offsets waiting for replication after appending to local log\", unstableTxnOffsetTopicPartitions);\n                future.completeExceptionally(new UnstableOffsetCommitException(\"There are \" +\n                    \"unstable offsets for the requested topic partitions\"));\n            } else {\n                onSuccessfulAttempt(currentTimeMs);\n                future.complete(offsets);\n            }\n        }\n\n        private void chainFuture(\n            final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e otherFuture) {\n            this.future.whenComplete((r, t) -\u003e {\n                if (t !\u003d null) {\n                    otherFuture.completeExceptionally(t);\n                } else {\n                    otherFuture.complete(r);\n                }\n            });\n        }\n\n        @Override\n        public String toStringBase() {\n            return super.toStringBase() +\n                    \", requestedPartitions\u003d\" + requestedPartitions;\n        }\n    }\n\n    /**\n     * \u003cp\u003eThis is used to stage the unsent {@link OffsetCommitRequestState} and {@link OffsetFetchRequestState}.\n     * \u003cli\u003eunsentOffsetCommits holds the offset commit requests that have not been sent out\u003c/\u003e\n     * \u003cli\u003eunsentOffsetFetches holds the offset fetch requests that have not been sent out\u003c/li\u003e\n     * \u003cli\u003einflightOffsetFetches holds the offset fetch requests that have been sent out but not completed\u003c/\u003e.\n     * \u003cp\u003e\n     * {@code addOffsetFetchRequest} dedupes the requests to avoid sending the same requests.\n     */\n\n    class PendingRequests {\n        // Queue is used to ensure the sequence of commit\n        Queue\u003cOffsetCommitRequestState\u003e unsentOffsetCommits \u003d new LinkedList\u003c\u003e();\n        List\u003cOffsetFetchRequestState\u003e unsentOffsetFetches \u003d new ArrayList\u003c\u003e();\n        List\u003cOffsetFetchRequestState\u003e inflightOffsetFetches \u003d new ArrayList\u003c\u003e();\n\n        // Visible for testing\n        boolean hasUnsentRequests() {\n            return !unsentOffsetCommits.isEmpty() || !unsentOffsetFetches.isEmpty();\n        }\n\n        /**\n         * Add a commit request to the queue, so that it\u0027s sent out on the next call to\n         * {@link #poll(long)}. This is used from all commits (sync, async, auto-commit).\n         */\n        OffsetCommitRequestState addOffsetCommitRequest(OffsetCommitRequestState request) {\n            log.debug(\"Enqueuing OffsetCommit request for offsets: {}\", request.offsets);\n            unsentOffsetCommits.add(request);\n            return request;\n        }\n\n        /**\n         * \u003cp\u003eAdding an offset fetch request to the outgoing buffer.  If the same request was made, we chain the future\n         * to the existing one.\n         *\n         * \u003cp\u003eIf the request is new, it invokes a callback to remove itself from the {@code inflightOffsetFetches}\n         * upon completion.\n         */\n        private CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e addOffsetFetchRequest(final OffsetFetchRequestState request) {\n            Optional\u003cOffsetFetchRequestState\u003e dupe \u003d\n                    unsentOffsetFetches.stream().filter(r -\u003e r.sameRequest(request)).findAny();\n            Optional\u003cOffsetFetchRequestState\u003e inflight \u003d\n                    inflightOffsetFetches.stream().filter(r -\u003e r.sameRequest(request)).findAny();\n\n            if (dupe.isPresent() || inflight.isPresent()) {\n                log.debug(\"Duplicated unsent offset fetch request found for partitions: {}\", request.requestedPartitions);\n                dupe.orElseGet(inflight::get).chainFuture(request.future);\n            } else {\n                log.debug(\"Enqueuing offset fetch request for partitions: {}\", request.requestedPartitions);\n                this.unsentOffsetFetches.add(request);\n            }\n            return request.future;\n        }\n\n        /**\n         * Clear {@code unsentOffsetCommits} and moves all the sendable request in {@code\n         * unsentOffsetFetches} to the {@code inflightOffsetFetches} to bookkeep all the inflight\n         * requests. Note: Sendable requests are determined by their timer as we are expecting\n         * backoff on failed attempt. See {@link RequestState}.\n         */\n        List\u003cNetworkClientDelegate.UnsentRequest\u003e drain(final long currentTimeMs) {\n            // not ready to sent request\n            List\u003cOffsetCommitRequestState\u003e unreadyCommitRequests \u003d unsentOffsetCommits.stream()\n                .filter(request -\u003e !request.canSendRequest(currentTimeMs))\n                .collect(Collectors.toList());\n\n            failAndRemoveExpiredCommitRequests();\n\n            // Add all unsent offset commit requests to the unsentRequests list\n            List\u003cNetworkClientDelegate.UnsentRequest\u003e unsentRequests \u003d unsentOffsetCommits.stream()\n                .filter(request -\u003e request.canSendRequest(currentTimeMs))\n                .peek(request -\u003e request.onSendAttempt(currentTimeMs))\n                .map(OffsetCommitRequestState::toUnsentRequest)\n                .collect(Collectors.toCollection(ArrayList::new));\n\n            // Partition the unsent offset fetch requests into sendable and non-sendable lists\n            Map\u003cBoolean, List\u003cOffsetFetchRequestState\u003e\u003e partitionedBySendability \u003d\n                    unsentOffsetFetches.stream()\n                            .collect(Collectors.partitioningBy(request -\u003e request.canSendRequest(currentTimeMs)));\n\n            failAndRemoveExpiredFetchRequests();\n\n            // Add all sendable offset fetch requests to the unsentRequests list and to the inflightOffsetFetches list\n            for (OffsetFetchRequestState request : partitionedBySendability.get(true)) {\n                request.onSendAttempt(currentTimeMs);\n                unsentRequests.add(request.toUnsentRequest());\n                inflightOffsetFetches.add(request);\n            }\n\n            // Clear the unsent offset commit and fetch lists and add all non-sendable offset fetch requests to the unsentOffsetFetches list\n            clearAll();\n            unsentOffsetFetches.addAll(partitionedBySendability.get(false));\n            unsentOffsetCommits.addAll(unreadyCommitRequests);\n\n            return Collections.unmodifiableList(unsentRequests);\n        }\n\n        /**\n         * Find the unsent commit requests that have expired, remove them and complete their\n         * futures with a TimeoutException.\n         */\n        private void failAndRemoveExpiredCommitRequests() {\n            Queue\u003cOffsetCommitRequestState\u003e requestsToPurge \u003d new LinkedList\u003c\u003e(unsentOffsetCommits);\n            requestsToPurge.forEach(RetriableRequestState::maybeExpire);\n        }\n\n        /**\n         * Find the unsent fetch requests that have expired, remove them and complete their\n         * futures with a TimeoutException.\n         */\n        private void failAndRemoveExpiredFetchRequests() {\n            Queue\u003cOffsetFetchRequestState\u003e requestsToPurge \u003d new LinkedList\u003c\u003e(unsentOffsetFetches);\n            requestsToPurge.forEach(RetriableRequestState::maybeExpire);\n        }\n\n        private void clearAll() {\n            unsentOffsetCommits.clear();\n            unsentOffsetFetches.clear();\n        }\n\n        private List\u003cNetworkClientDelegate.UnsentRequest\u003e drainPendingCommits() {\n            List\u003cNetworkClientDelegate.UnsentRequest\u003e res \u003d unsentOffsetCommits.stream()\n                .map(OffsetCommitRequestState::toUnsentRequest)\n                .collect(Collectors.toCollection(ArrayList::new));\n            clearAll();\n            return res;\n        }\n    }\n\n    /**\n     * Encapsulates the state of auto-committing and manages the auto-commit timer.\n     */\n    private static class AutoCommitState {\n        private final Timer timer;\n        private final long autoCommitInterval;\n        private boolean hasInflightCommit;\n\n        private final Logger log;\n\n        public AutoCommitState(\n                final Time time,\n                final long autoCommitInterval,\n                final LogContext logContext) {\n            this.autoCommitInterval \u003d autoCommitInterval;\n            this.timer \u003d time.timer(autoCommitInterval);\n            this.hasInflightCommit \u003d false;\n            this.log \u003d logContext.logger(getClass());\n        }\n\n        public boolean shouldAutoCommit() {\n            if (!this.timer.isExpired()) {\n                return false;\n            }\n            if (this.hasInflightCommit) {\n                log.trace(\"Skipping auto-commit on the interval because a previous one is still in-flight.\");\n                return false;\n            }\n            return true;\n        }\n\n        public void resetTimer() {\n            this.timer.reset(autoCommitInterval);\n        }\n\n        public void resetTimer(long retryBackoffMs) {\n            this.timer.reset(retryBackoffMs);\n        }\n\n        public long remainingMs(final long currentTimeMs) {\n            this.timer.update(currentTimeMs);\n            return this.timer.remainingMs();\n        }\n\n        public void updateTimer(final long currentTimeMs) {\n            this.timer.update(currentTimeMs);\n        }\n\n        public void setInflightCommitStatus(final boolean inflightCommitStatus) {\n            this.hasInflightCommit \u003d inflightCommitStatus;\n        }\n    }\n\n    static class MemberInfo {\n        Optional\u003cString\u003e memberId;\n        Optional\u003cInteger\u003e memberEpoch;\n\n        MemberInfo() {\n            this.memberId \u003d Optional.empty();\n            this.memberEpoch \u003d Optional.empty();\n        }\n\n        @Override\n        public String toString() {\n            return \"memberId\u003d\" + memberId.orElse(\"undefined\") +\n                    \", memberEpoch\u003d\" + (memberEpoch.isPresent() ? memberEpoch.get() : \"undefined\");\n        }\n    }\n}","methodCount":81},"candidatesTelemetryData":{"numberOfSuggestions":9,"candidates":[{"lineStart":419,"lineEnd":439,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetCommitRequest to class PendingRequests","description":"Move method createOffsetCommitRequest to org.apache.kafka.clients.consumer.internals.CommitRequestManager.PendingRequests\nRationale: The createOffsetCommitRequest() method is closely related to managing offset commit requests, which directly connects to the PendingRequests class\u0027s responsibilities. This move would enhance cohesion, as the method directly involves creating instances of OffsetCommitRequestState, which is stored in the unsentOffsetCommits field. By relocating the method here, we adhere to the Single Responsibility Principle, ensuring that the PendingRequests class handles all aspects of pending requests. However, this may require adjustments to existing call sites that currently invoke the method from its original class.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":419,"lineEnd":439,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetCommitRequest to class MemberInfo","description":"Move method createOffsetCommitRequest to org.apache.kafka.clients.consumer.internals.CommitRequestManager.MemberInfo\nRationale: The createOffsetCommitRequest() method relies on the memberInfo variable, which is a field of the MemberInfo class. Moving this method to MemberInfo would better encapsulate the logic related to members and their interactions with offset commits. This aligns with the Open/Closed Principle, as it allows the MemberInfo class to be extended with additional functionalities related to member state and commit requests without modifying existing code. However, this may introduce a tighter coupling between MemberInfo and offset commit logic, which could complicate future modifications.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":419,"lineEnd":439,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetCommitRequest to class Time","description":"Move method createOffsetCommitRequest to org.apache.kafka.common.utils.Time\nRationale: Although the createOffsetCommitRequest() method does not directly relate to the Time class, it does utilize a deadline parameter that could be managed in conjunction with time-related functionalities. Moving the method here could centralize time-related logic, enhancing the overall design by ensuring that time management and request creation are handled together. This approach could promote the Interface Segregation Principle by allowing other classes to depend only on the specific time functionalities they need. However, the relevance of the method to the Time class is weak, which may lead to confusion regarding its purpose and responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":503,"lineEnd":520,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetFetchRequest to class PendingRequests","description":"Move method createOffsetFetchRequest to org.apache.kafka.clients.consumer.internals.CommitRequestManager.PendingRequests\nRationale: The createOffsetFetchRequest() method is closely related to managing offset fetch requests, which aligns with the responsibilities of the PendingRequests class. Moving this method here adheres to the Single Responsibility Principle, as PendingRequests already handles offset fetch requests, thereby increasing cohesion within the class. This change would also promote better encapsulation, as the method would be situated with related functionalities. However, care must be taken to ensure that any dependencies on the current class\u0027s state are properly managed during the move.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":503,"lineEnd":520,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetFetchRequest to class MemberInfo","description":"Move method createOffsetFetchRequest to org.apache.kafka.clients.consumer.internals.CommitRequestManager.MemberInfo\nRationale: The createOffsetFetchRequest() method utilizes memberInfo as a parameter, indicating a strong association with member-related data. Relocating this method to MemberInfo would enhance the logical grouping of functionalities related to members, thus improving cohesion. This aligns with the Open/Closed Principle, as MemberInfo could be extended with new functionalities related to offset requests without modifying existing code. However, this move could lead to a bloated MemberInfo class if not managed properly, so careful consideration of its responsibilities is necessary.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":503,"lineEnd":520,"refactoringType":"MyMoveInstanceMethodRefactoring","refactoringInfo":"Move method createOffsetFetchRequest to class Time","description":"Move method createOffsetFetchRequest to org.apache.kafka.common.utils.Time\nRationale: The createOffsetFetchRequest() method includes a deadlineMs parameter, which is time-related. Moving this method to the Time class could enhance its relevance to time-related operations, improving the clarity of where time-dependent logic resides. This aligns with the Interface Segregation Principle, as it keeps time-related functionalities consolidated. However, this move may dilute the Time class\u0027s focus, as it would introduce request creation logic that doesn\u0027t directly pertain to time management, potentially leading to confusion about the class\u0027s responsibilities.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":210,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method findMinTime to class TimedRequestState","description":"move method findMinTime to PsiClass:TimedRequestState\nRationale: The findMinTime() method operates directly on a collection of RequestState objects, specifically utilizing the remainingBackoffMs() method. Moving it to TimedRequestState adheres to the Single Responsibility Principle by placing the logic closer to the data it operates on. This enhances cohesion, as TimedRequestState is responsible for timing-related logic. However, care should be taken to ensure that the method does not require a static context that might not be available in TimedRequestState.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":210,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method findMinTime to class NetworkClientDelegate","description":"move method findMinTime to PsiClass:NetworkClientDelegate\nRationale: Given that NetworkClientDelegate manages requests and their states, it is logical to move findMinTime() here. This aligns with the Open/Closed Principle, allowing the class to be extended with timing logic without modifying existing functionality. This move enhances the clarity of request handling. However, the method\u0027s static nature may need to be adjusted, as NetworkClientDelegate seems more instance-oriented.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false},{"lineStart":210,"lineEnd":215,"refactoringType":"MyMoveStaticMethodRefactoring","refactoringInfo":"Move Static method findMinTime to class FetchMetricsManager","description":"move method findMinTime to PsiClass:FetchMetricsManager\nRationale: Since FetchMetricsManager is involved in tracking metrics related to fetching, it can benefit from understanding the timing of requests. Moving findMinTime() here supports the Interface Segregation Principle by ensuring that classes only handle relevant data. This could improve the overall design by centralizing timing metrics. The main drawback is that it may introduce a dependency on request states that FetchMetricsManager may not need.","couldCreateRefObject":true,"applied":false,"startedRefactoringFlow":false,"undone":false}]},"iterationData":[{"iteration_num":-1,"suggested_move_methods":[{"method_name":"findMinTime","method_signature":"private static findMinTime(final Collection\u003c? extends RequestState\u003e requests, final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"maybeWrapAsTimeoutException","method_signature":"private maybeWrapAsTimeoutException(Throwable t)","target_class":"","rationale":""},{"method_name":"requestAutoCommit","method_signature":"private requestAutoCommit(final OffsetCommitRequestState requestState)","target_class":"","rationale":""},{"method_name":"maybeAutoCommitAsync","method_signature":"public maybeAutoCommitAsync()","target_class":"","rationale":""},{"method_name":"maybeResetTimerWithBackoff","method_signature":"private maybeResetTimerWithBackoff(final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result)","target_class":"","rationale":""},{"method_name":"maybeAutoCommitSyncBeforeRevocation","method_signature":"public maybeAutoCommitSyncBeforeRevocation(final long deadlineMs)","target_class":"","rationale":""},{"method_name":"autoCommitSyncBeforeRevocationWithRetries","method_signature":"private autoCommitSyncBeforeRevocationWithRetries(OffsetCommitRequestState requestAttempt,\n                                                           CompletableFuture\u003cVoid\u003e result)","target_class":"","rationale":""},{"method_name":"autoCommitCallback","method_signature":"private autoCommitCallback(final Map\u003cTopicPartition, OffsetAndMetadata\u003e allConsumedOffsets)","target_class":"","rationale":""},{"method_name":"commitAsync","method_signature":"public commitAsync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets)","target_class":"","rationale":""},{"method_name":"commitSync","method_signature":"public commitSync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                              final long deadlineMs)","target_class":"","rationale":""},{"method_name":"createOffsetCommitRequest","method_signature":"private createOffsetCommitRequest(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                                               final long deadlineMs)","target_class":"","rationale":""},{"method_name":"commitSyncWithRetries","method_signature":"private commitSyncWithRetries(OffsetCommitRequestState requestAttempt,\n                                       CompletableFuture\u003cVoid\u003e result)","target_class":"","rationale":""},{"method_name":"commitSyncExceptionForError","method_signature":"private commitSyncExceptionForError(Throwable error)","target_class":"","rationale":""},{"method_name":"commitAsyncExceptionForError","method_signature":"private commitAsyncExceptionForError(Throwable error)","target_class":"","rationale":""},{"method_name":"fetchOffsets","method_signature":"public fetchOffsets(\n        final Set\u003cTopicPartition\u003e partitions,\n        final long deadlineMs)","target_class":"","rationale":""},{"method_name":"createOffsetFetchRequest","method_signature":" createOffsetFetchRequest(final Set\u003cTopicPartition\u003e partitions,\n                                                             final long deadlineMs)","target_class":"","rationale":""},{"method_name":"fetchOffsetsWithRetries","method_signature":"private fetchOffsetsWithRetries(final OffsetFetchRequestState fetchRequest,\n                                         final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e result)","target_class":"","rationale":""},{"method_name":"isStaleEpochErrorAndValidEpochAvailable","method_signature":"private isStaleEpochErrorAndValidEpochAvailable(Throwable error)","target_class":"","rationale":""},{"method_name":"updateAutoCommitTimer","method_signature":"public updateAutoCommitTimer(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"handleCoordinatorDisconnect","method_signature":"private handleCoordinatorDisconnect(Throwable exception, long currentTimeMs)","target_class":"","rationale":""},{"method_name":"autoCommitEnabled","method_signature":"public autoCommitEnabled()","target_class":"","rationale":""},{"method_name":"resetAutoCommitTimer","method_signature":"public resetAutoCommitTimer()","target_class":"","rationale":""},{"method_name":"resetAutoCommitTimer","method_signature":"public resetAutoCommitTimer(long retryBackoffMs)","target_class":"","rationale":""},{"method_name":"drainPendingOffsetCommitRequests","method_signature":"public drainPendingOffsetCommitRequests()","target_class":"","rationale":""},{"method_name":"toUnsentRequest","method_signature":"public toUnsentRequest()","target_class":"","rationale":""},{"method_name":"maybeExpire","method_signature":" maybeExpire()","target_class":"","rationale":""},{"method_name":"buildRequestWithResponseHandling","method_signature":" buildRequestWithResponseHandling(final AbstractRequest.Builder\u003c?\u003e builder)","target_class":"","rationale":""},{"method_name":"handleClientResponse","method_signature":"private handleClientResponse(final ClientResponse response,\n                                          final Throwable error,\n                                          final long requestCompletionTimeMs)","target_class":"","rationale":""},{"method_name":"sameRequest","method_signature":"public sameRequest(final OffsetFetchRequestState request)","target_class":"","rationale":""},{"method_name":"toUnsentRequest","method_signature":"public toUnsentRequest()","target_class":"","rationale":""},{"method_name":"onFailure","method_signature":"private onFailure(final long currentTimeMs,\n                               final Errors responseError)","target_class":"","rationale":""},{"method_name":"onSuccess","method_signature":"private onSuccess(final long currentTimeMs,\n                               final OffsetFetchResponse response)","target_class":"","rationale":""},{"method_name":"chainFuture","method_signature":"private chainFuture(\n            final CompletableFuture\u003cMap\u003cTopicPartition, OffsetAndMetadata\u003e\u003e otherFuture)","target_class":"","rationale":""},{"method_name":"hasUnsentRequests","method_signature":" hasUnsentRequests()","target_class":"","rationale":""},{"method_name":"addOffsetCommitRequest","method_signature":" addOffsetCommitRequest(OffsetCommitRequestState request)","target_class":"","rationale":""},{"method_name":"addOffsetFetchRequest","method_signature":"private addOffsetFetchRequest(final OffsetFetchRequestState request)","target_class":"","rationale":""},{"method_name":"drain","method_signature":" drain(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"failAndRemoveExpiredCommitRequests","method_signature":"private failAndRemoveExpiredCommitRequests()","target_class":"","rationale":""},{"method_name":"failAndRemoveExpiredFetchRequests","method_signature":"private failAndRemoveExpiredFetchRequests()","target_class":"","rationale":""},{"method_name":"clearAll","method_signature":"private clearAll()","target_class":"","rationale":""},{"method_name":"drainPendingCommits","method_signature":"private drainPendingCommits()","target_class":"","rationale":""},{"method_name":"shouldAutoCommit","method_signature":"public shouldAutoCommit()","target_class":"","rationale":""},{"method_name":"resetTimer","method_signature":"public resetTimer()","target_class":"","rationale":""},{"method_name":"resetTimer","method_signature":"public resetTimer(long retryBackoffMs)","target_class":"","rationale":""},{"method_name":"remainingMs","method_signature":"public remainingMs(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"updateTimer","method_signature":"public updateTimer(final long currentTimeMs)","target_class":"","rationale":""}],"llm_response_time":0},{"iteration_num":-2,"suggested_move_methods":[{"method_name":"createOffsetCommitRequest","method_signature":"private createOffsetCommitRequest(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                                               final long deadlineMs)","target_class":"","rationale":""},{"method_name":"createOffsetFetchRequest","method_signature":" createOffsetFetchRequest(final Set\u003cTopicPartition\u003e partitions,\n                                                             final long deadlineMs)","target_class":"","rationale":""},{"method_name":"findMinTime","method_signature":"private static findMinTime(final Collection\u003c? extends RequestState\u003e requests, final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"addOffsetCommitRequest","method_signature":" addOffsetCommitRequest(OffsetCommitRequestState request)","target_class":"","rationale":""},{"method_name":"isStaleEpochErrorAndValidEpochAvailable","method_signature":"private isStaleEpochErrorAndValidEpochAvailable(Throwable error)","target_class":"","rationale":""},{"method_name":"drainPendingCommits","method_signature":"private drainPendingCommits()","target_class":"","rationale":""},{"method_name":"updateAutoCommitTimer","method_signature":"public updateAutoCommitTimer(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"maybeWrapAsTimeoutException","method_signature":"private maybeWrapAsTimeoutException(Throwable t)","target_class":"","rationale":""},{"method_name":"resetAutoCommitTimer","method_signature":"public resetAutoCommitTimer(long retryBackoffMs)","target_class":"","rationale":""},{"method_name":"hasUnsentRequests","method_signature":" hasUnsentRequests()","target_class":"","rationale":""},{"method_name":"commitSync","method_signature":"public commitSync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                              final long deadlineMs)","target_class":"","rationale":""},{"method_name":"clearAll","method_signature":"private clearAll()","target_class":"","rationale":""},{"method_name":"drain","method_signature":" drain(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"remainingMs","method_signature":"public remainingMs(final long currentTimeMs)","target_class":"","rationale":""},{"method_name":"failAndRemoveExpiredFetchRequests","method_signature":"private failAndRemoveExpiredFetchRequests()","target_class":"","rationale":""}],"llm_response_time":0}],"methodCompatibilityScores":{"private createOffsetCommitRequest(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                                               final long deadlineMs)":{"first":{"method_name":"createOffsetCommitRequest","method_signature":"private createOffsetCommitRequest(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                                               final long deadlineMs)","target_class":"","rationale":""},"second":0.2246192182825037}," createOffsetFetchRequest(final Set\u003cTopicPartition\u003e partitions,\n                                                             final long deadlineMs)":{"first":{"method_name":"createOffsetFetchRequest","method_signature":" createOffsetFetchRequest(final Set\u003cTopicPartition\u003e partitions,\n                                                             final long deadlineMs)","target_class":"","rationale":""},"second":0.23615133858171902},"private static findMinTime(final Collection\u003c? extends RequestState\u003e requests, final long currentTimeMs)":{"first":{"method_name":"findMinTime","method_signature":"private static findMinTime(final Collection\u003c? extends RequestState\u003e requests, final long currentTimeMs)","target_class":"","rationale":""},"second":0.32355425513482244}," addOffsetCommitRequest(OffsetCommitRequestState request)":{"first":{"method_name":"addOffsetCommitRequest","method_signature":" addOffsetCommitRequest(OffsetCommitRequestState request)","target_class":"","rationale":""},"second":0.34790656640306544},"private isStaleEpochErrorAndValidEpochAvailable(Throwable error)":{"first":{"method_name":"isStaleEpochErrorAndValidEpochAvailable","method_signature":"private isStaleEpochErrorAndValidEpochAvailable(Throwable error)","target_class":"","rationale":""},"second":0.35249197200478705},"private drainPendingCommits()":{"first":{"method_name":"drainPendingCommits","method_signature":"private drainPendingCommits()","target_class":"","rationale":""},"second":0.3614186747616722},"public updateAutoCommitTimer(final long currentTimeMs)":{"first":{"method_name":"updateAutoCommitTimer","method_signature":"public updateAutoCommitTimer(final long currentTimeMs)","target_class":"","rationale":""},"second":0.384169741343111},"private maybeWrapAsTimeoutException(Throwable t)":{"first":{"method_name":"maybeWrapAsTimeoutException","method_signature":"private maybeWrapAsTimeoutException(Throwable t)","target_class":"","rationale":""},"second":0.38567913206827525},"public resetAutoCommitTimer(long retryBackoffMs)":{"first":{"method_name":"resetAutoCommitTimer","method_signature":"public resetAutoCommitTimer(long retryBackoffMs)","target_class":"","rationale":""},"second":0.3866445503740876}," hasUnsentRequests()":{"first":{"method_name":"hasUnsentRequests","method_signature":" hasUnsentRequests()","target_class":"","rationale":""},"second":0.3867394278092403},"public commitSync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                              final long deadlineMs)":{"first":{"method_name":"commitSync","method_signature":"public commitSync(final Map\u003cTopicPartition, OffsetAndMetadata\u003e offsets,\n                                              final long deadlineMs)","target_class":"","rationale":""},"second":0.388886852432242},"private clearAll()":{"first":{"method_name":"clearAll","method_signature":"private clearAll()","target_class":"","rationale":""},"second":0.40905756685101724}," drain(final long currentTimeMs)":{"first":{"method_name":"drain","method_signature":" drain(final long currentTimeMs)","target_class":"","rationale":""},"second":0.4116219286087722},"public remainingMs(final long currentTimeMs)":{"first":{"method_name":"remainingMs","method_signature":"public remainingMs(final long currentTimeMs)","target_class":"","rationale":""},"second":0.4166188257552946},"private failAndRemoveExpiredFetchRequests()":{"first":{"method_name":"failAndRemoveExpiredFetchRequests","method_signature":"private failAndRemoveExpiredFetchRequests()","target_class":"","rationale":""},"second":0.41735536705144427}},"llmMethodPriority":{"priority_method_names":["findMinTime","isStaleEpochErrorAndValidEpochAvailable","drainPendingCommits","updateAutoCommitTimer","maybeWrapAsTimeoutException","resetAutoCommitTimer","clearAll","remainingMs","failAndRemoveExpiredFetchRequests","createOffsetCommitRequest","createOffsetFetchRequest","addOffsetCommitRequest","hasUnsentRequests","commitSync","drain"],"llm_response_time":3315},"targetClassMap":{"createOffsetCommitRequest":{"target_classes":[{"class_name":"Time","similarity_score":0.08467939854412665},{"class_name":"PendingRequests","similarity_score":0.1122777309953996},{"class_name":"MemberInfo","similarity_score":0.15944820103582016}],"target_classes_sorted_by_llm":["PendingRequests","MemberInfo","Time"],"llm_response_time":4488,"similarity_computation_time":14,"similarity_metric":"voyage"},"createOffsetFetchRequest":{"target_classes":[{"class_name":"Time","similarity_score":0.09979562822891704},{"class_name":"PendingRequests","similarity_score":0.14189270163615386},{"class_name":"MemberInfo","similarity_score":0.16912035630063652}],"target_classes_sorted_by_llm":["PendingRequests","MemberInfo","Time"],"llm_response_time":3530,"similarity_computation_time":6,"similarity_metric":"voyage"},"findMinTime":{"target_classes":[{"class_name":"OffsetFetcherUtils","similarity_score":0.319230468326712},{"class_name":"OffsetsForLeaderEpochUtils","similarity_score":0.27211919930493034},{"class_name":"FetchUtils","similarity_score":0.05378254348272378},{"class_name":"ConsumerUtils","similarity_score":0.316069770620507},{"class_name":"ProducerTestUtils","similarity_score":0.2509297168567094},{"class_name":"AdminUtils","similarity_score":0.2994390771035698},{"class_name":"OffsetForLeaderEpochClientTest","similarity_score":0.12680937463654585},{"class_name":"OffsetsRequestManagerTest","similarity_score":0.19123889872704306},{"class_name":"NetworkClientDelegate","similarity_score":0.40535607595572803},{"class_name":"NetworkClientUtils","similarity_score":0.1855821180064095},{"class_name":"RequestFuture","similarity_score":0.19697680231807616},{"class_name":"RequestFutureTest","similarity_score":0.18434706304362294},{"class_name":"TaskAssignmentUtilsTest","similarity_score":0.2212462454940722},{"class_name":"RequestManagers","similarity_score":0.23589325606530856},{"class_name":"AbstractPartitionAssignorTest","similarity_score":0.1899075409062081},{"class_name":"RackUtils","similarity_score":0.33150712147574624},{"class_name":"ProcessorContextUtils","similarity_score":0.32222690758580663},{"class_name":"Acknowledgements","similarity_score":0.17272213396336666},{"class_name":"MetricsUtils","similarity_score":0.13920485060019283},{"class_name":"AdminClientTestUtils","similarity_score":0.19716289023509295},{"class_name":"TimedRequestState","similarity_score":0.43649694645864895},{"class_name":"ExceptionUtils","similarity_score":0.3350953548974935},{"class_name":"TopicMetadataRequestManagerTest","similarity_score":0.24104358180603094},{"class_name":"ApplicationEventProcessor","similarity_score":0.2387121718647865},{"class_name":"ApplicationEventProcessorTest","similarity_score":0.2671624574914145},{"class_name":"CommitRequestManagerTest","similarity_score":0.20009317026354143},{"class_name":"CsvUtils","similarity_score":0.3503245248726853},{"class_name":"CompletedFetch","similarity_score":0.26207007105752833},{"class_name":"CompletedFetchTest","similarity_score":0.19511729704066325},{"class_name":"AssignmentTestUtils","similarity_score":0.31034228378952317},{"class_name":"AsyncKafkaConsumer","similarity_score":0.2782046592811887},{"class_name":"ConsumerGroupCommandTestUtils","similarity_score":0.2317516952028532},{"class_name":"AsyncKafkaConsumerTest","similarity_score":0.23839221458214},{"class_name":"ClientTelemetryUtils","similarity_score":0.32144312811284653},{"class_name":"ClientUtils","similarity_score":0.4189389998536276},{"class_name":"Fetch","similarity_score":0.21506388896609793},{"class_name":"ConsumerHeartbeatRequestManagerTest","similarity_score":0.19153915392660506},{"class_name":"FetchBufferTest","similarity_score":0.21308695873985192},{"class_name":"FetchCollectorTest","similarity_score":0.2272791682503336},{"class_name":"FetcherTest","similarity_score":0.19724043930642834},{"class_name":"FetchMetricsManager","similarity_score":0.3336512709168037},{"class_name":"ConsumerMembershipManagerTest","similarity_score":0.15932327863833784},{"class_name":"ConsumerMetrics","similarity_score":0.2367945640438493},{"class_name":"ConsumerNetworkThread","similarity_score":0.2091737607560986},{"class_name":"FetchRequestManagerTest","similarity_score":0.20042542506261785},{"class_name":"ShareCompletedFetch","similarity_score":0.3110136257837926},{"class_name":"ShareCompletedFetchTest","similarity_score":0.13910227104305253},{"class_name":"ConsumerProtocol","similarity_score":0.3038822515577858},{"class_name":"ConsumerProtocolUtils","similarity_score":0.30094204403568725}],"target_classes_sorted_by_llm":["TimedRequestState","NetworkClientDelegate","FetchMetricsManager","ClientUtils","OffsetFetcherUtils","ProcessorContextUtils","ClientTelemetryUtils","CsvUtils","ExceptionUtils","RackUtils"],"llm_response_time":11663,"similarity_computation_time":735,"similarity_metric":"voyage"}}}
