[
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "6f0d07633a5c8e6511f3d16e04561cb277b65407",
        "url": "https://github.com/apache/flink/commit/6f0d07633a5c8e6511f3d16e04561cb277b65407",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getWindowSize() : Optional<Duration> extracted from private createEndingState() : State<T> in class org.apache.flink.cep.nfa.compiler.NFACompiler.NFAFactoryCompiler & moved to class org.apache.flink.cep.pattern.Quantifier.Times",
            "leftSideLocations": [
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/nfa/compiler/NFACompiler.java",
                    "startLine": 314,
                    "endLine": 324,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private createEndingState() : State<T>"
                },
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/nfa/compiler/NFACompiler.java",
                    "startLine": 321,
                    "endLine": 322,
                    "startColumn": 13,
                    "endColumn": 99,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/pattern/Quantifier.java",
                    "startLine": 222,
                    "endLine": 224,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getWindowSize() : Optional<Duration>"
                },
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/pattern/Quantifier.java",
                    "startLine": 223,
                    "endLine": 223,
                    "startColumn": 13,
                    "endColumn": 52,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/nfa/compiler/NFACompiler.java",
                    "startLine": 314,
                    "endLine": 323,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "private createEndingState() : State<T>"
                },
                {
                    "filePath": "flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/nfa/compiler/NFACompiler.java",
                    "startLine": 321,
                    "endLine": 321,
                    "startColumn": 26,
                    "endColumn": 56,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "currentPattern.getWindowSize()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 21,
        "extraction_results": {
            "success": true,
            "newCommitHash": "eeaa68241593014a50ebbbf8bed822562d96ea3b",
            "newBranchName": "extract-getWindowSize-createEndingState-639deec"
        },
        "telemetry": {
            "id": "1f2a542a-8565-49ed-8841-985b1eaeeae9",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 1032,
                "lineStart": 54,
                "lineEnd": 1085,
                "bodyLineStart": 54,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/nfa/compiler/NFACompiler.java",
                "sourceCode": "/**\n * Compiler class containing methods to compile a {@link Pattern} into a {@link NFA} or a {@link\n * NFAFactory}.\n */\npublic class NFACompiler {\n\n    protected static final String ENDING_STATE_NAME = \"$endState$\";\n\n    /**\n     * Compiles the given pattern into a {@link NFAFactory}. The NFA factory can be used to create\n     * multiple NFAs.\n     *\n     * @param pattern Definition of sequence pattern\n     * @param timeoutHandling True if the NFA shall return timed out event patterns\n     * @param <T> Type of the input events\n     * @return Factory for NFAs corresponding to the given pattern\n     */\n    @SuppressWarnings(\"unchecked\")\n    public static <T> NFAFactory<T> compileFactory(\n            final Pattern<T, ?> pattern, boolean timeoutHandling) {\n        if (pattern == null) {\n            // return a factory for empty NFAs\n            return new NFAFactoryImpl<>(\n                    0,\n                    Collections.<String, Long>emptyMap(),\n                    Collections.<State<T>>emptyList(),\n                    timeoutHandling);\n        } else {\n            final NFAFactoryCompiler<T> nfaFactoryCompiler = new NFAFactoryCompiler<>(pattern);\n            nfaFactoryCompiler.compileFactory();\n            return new NFAFactoryImpl<>(\n                    nfaFactoryCompiler.getWindowTime(),\n                    nfaFactoryCompiler.getWindowTimes(),\n                    nfaFactoryCompiler.getStates(),\n                    timeoutHandling);\n        }\n    }\n\n    /**\n     * Verifies if the provided pattern can possibly generate empty match. Example of patterns that\n     * can possibly generate empty matches are: A*, A?, A* B? etc.\n     *\n     * @param pattern pattern to check\n     * @return true if empty match could potentially match the pattern, false otherwise\n     */\n    public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern) {\n        NFAFactoryCompiler<?> compiler = new NFAFactoryCompiler<>(checkNotNull(pattern));\n        compiler.compileFactory();\n        State<?> startState =\n                compiler.getStates().stream()\n                        .filter(State::isStart)\n                        .findFirst()\n                        .orElseThrow(\n                                () ->\n                                        new IllegalStateException(\n                                                \"Compiler produced no start state. It is a bug. File a jira.\"));\n\n        Set<State<?>> visitedStates = new HashSet<>();\n        final Stack<State<?>> statesToCheck = new Stack<>();\n        statesToCheck.push(startState);\n        while (!statesToCheck.isEmpty()) {\n            final State<?> currentState = statesToCheck.pop();\n            if (visitedStates.contains(currentState)) {\n                continue;\n            } else {\n                visitedStates.add(currentState);\n            }\n\n            for (StateTransition<?> transition : currentState.getStateTransitions()) {\n                if (transition.getAction() == StateTransitionAction.PROCEED) {\n                    if (transition.getTargetState().isFinal()) {\n                        return true;\n                    } else {\n                        statesToCheck.push(transition.getTargetState());\n                    }\n                }\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Converts a {@link Pattern} into graph of {@link State}. It enables sharing of compilation\n     * state across methods.\n     *\n     * @param <T>\n     */\n    static class NFAFactoryCompiler<T> {\n\n        private final NFAStateNameHandler stateNameHandler = new NFAStateNameHandler();\n        private final Map<String, State<T>> stopStates = new HashMap<>();\n        private final List<State<T>> states = new ArrayList<>();\n        private final Map<String, Long> windowTimes = new HashMap<>();\n\n        private Optional<Long> windowTime;\n        private GroupPattern<T, ?> currentGroupPattern;\n        private Map<GroupPattern<T, ?>, Boolean> firstOfLoopMap = new HashMap<>();\n        private Pattern<T, ?> currentPattern;\n        private Pattern<T, ?> followingPattern;\n        private final AfterMatchSkipStrategy afterMatchSkipStrategy;\n        private Map<String, State<T>> originalStateMap = new HashMap<>();\n\n        NFAFactoryCompiler(final Pattern<T, ?> pattern) {\n            this.currentPattern = pattern;\n            afterMatchSkipStrategy = pattern.getAfterMatchSkipStrategy();\n            windowTime = Optional.empty();\n        }\n\n        /**\n         * Compiles the given pattern into a {@link NFAFactory}. The NFA factory can be used to\n         * create multiple NFAs.\n         */\n        void compileFactory() {\n\n            Pattern<T, ?> lastPattern = currentPattern;\n\n            checkPatternNameUniqueness();\n\n            checkPatternSkipStrategy();\n\n            // we're traversing the pattern from the end to the beginning --> the first state is the\n            // final state\n            State<T> sinkState = createEndingState();\n            // add all the normal states\n            sinkState = createMiddleStates(sinkState);\n            // add the beginning state\n            createStartState(sinkState);\n\n            // check the window times between events for pattern\n            checkPatternWindowTimes();\n\n            if (lastPattern.getQuantifier().getConsumingStrategy()\n                            == Quantifier.ConsumingStrategy.NOT_FOLLOW\n                    && (!windowTimes.containsKey(lastPattern.getName())\n                            || windowTimes.get(lastPattern.getName()) <= 0)\n                    && getWindowTime() == 0) {\n                throw new MalformedPatternException(\n                        \"NotFollowedBy is not supported without windowTime as a last part of a Pattern!\");\n            }\n        }\n\n        AfterMatchSkipStrategy getAfterMatchSkipStrategy() {\n            return afterMatchSkipStrategy;\n        }\n\n        List<State<T>> getStates() {\n            return states;\n        }\n\n        long getWindowTime() {\n            return windowTime.orElse(0L);\n        }\n\n        Map<String, Long> getWindowTimes() {\n            return windowTimes;\n        }\n\n        /** Check pattern window times between events. */\n        private void checkPatternWindowTimes() {\n            windowTime.ifPresent(\n                    windowTime -> {\n                        if (windowTimes.values().stream().anyMatch(time -> time > windowTime)) {\n                            throw new MalformedPatternException(\n                                    \"The window length between the previous and current event cannot be larger than the window length between the first and last event for a Pattern.\");\n                        }\n                    });\n        }\n\n        /** Check pattern after match skip strategy. */\n        private void checkPatternSkipStrategy() {\n            if (afterMatchSkipStrategy.getPatternName().isPresent()) {\n                String patternName = afterMatchSkipStrategy.getPatternName().get();\n                Pattern<T, ?> pattern = currentPattern;\n                while (pattern.getPrevious() != null && !pattern.getName().equals(patternName)) {\n                    pattern = pattern.getPrevious();\n                }\n\n                // pattern name match check.\n                if (!pattern.getName().equals(patternName)) {\n                    throw new MalformedPatternException(\n                            \"The pattern name specified in AfterMatchSkipStrategy \"\n                                    + \"can not be found in the given Pattern\");\n                }\n            }\n        }\n\n        /**\n         * Check if there are duplicate pattern names. If yes, it throws a {@link\n         * MalformedPatternException}.\n         */\n        private void checkPatternNameUniqueness() {\n            // make sure there is no pattern with name \"$endState$\"\n            stateNameHandler.checkNameUniqueness(ENDING_STATE_NAME);\n            Pattern patternToCheck = currentPattern;\n            while (patternToCheck != null) {\n                checkPatternNameUniqueness(patternToCheck);\n                patternToCheck = patternToCheck.getPrevious();\n            }\n            stateNameHandler.clear();\n        }\n\n        /**\n         * Check if the given pattern's name is already used or not. If yes, it throws a {@link\n         * MalformedPatternException}.\n         *\n         * @param pattern The pattern to be checked\n         */\n        private void checkPatternNameUniqueness(final Pattern pattern) {\n            if (pattern instanceof GroupPattern) {\n                Pattern patternToCheck = ((GroupPattern) pattern).getRawPattern();\n                while (patternToCheck != null) {\n                    checkPatternNameUniqueness(patternToCheck);\n                    patternToCheck = patternToCheck.getPrevious();\n                }\n            } else {\n                stateNameHandler.checkNameUniqueness(pattern.getName());\n            }\n        }\n\n        /**\n         * Retrieves list of conditions resulting in Stop state and names of the corresponding NOT\n         * patterns.\n         *\n         * <p>A current not condition can be produced in two cases:\n         *\n         * <ol>\n         *   <li>the previous pattern is a {@link Quantifier.ConsumingStrategy#NOT_FOLLOW}\n         *   <li>exists a backward path of {@link Quantifier.QuantifierProperty#OPTIONAL} patterns\n         *       to {@link Quantifier.ConsumingStrategy#NOT_FOLLOW}\n         * </ol>\n         *\n         * <p><b>WARNING:</b> for more info on the second case see: {@link\n         * NFAFactoryCompiler#copyWithoutTransitiveNots(State)}\n         *\n         * @return list of not conditions with corresponding names\n         */\n        private List<Tuple2<IterativeCondition<T>, String>> getCurrentNotCondition() {\n            List<Tuple2<IterativeCondition<T>, String>> notConditions = new ArrayList<>();\n\n            Pattern<T, ? extends T> previousPattern = currentPattern;\n            while (previousPattern.getPrevious() != null\n                    && (previousPattern\n                                    .getPrevious()\n                                    .getQuantifier()\n                                    .hasProperty(Quantifier.QuantifierProperty.OPTIONAL)\n                            || previousPattern.getPrevious().getQuantifier().getConsumingStrategy()\n                                    == Quantifier.ConsumingStrategy.NOT_FOLLOW)) {\n\n                previousPattern = previousPattern.getPrevious();\n\n                if (previousPattern.getQuantifier().getConsumingStrategy()\n                        == Quantifier.ConsumingStrategy.NOT_FOLLOW) {\n                    final IterativeCondition<T> notCondition = getTakeCondition(previousPattern);\n                    notConditions.add(Tuple2.of(notCondition, previousPattern.getName()));\n                }\n            }\n            return notConditions;\n        }\n\n        /**\n         * Creates the dummy Final {@link State} of the NFA graph.\n         *\n         * @return dummy Final state\n         */\n        private State<T> createEndingState() {\n            State<T> endState = createState(ENDING_STATE_NAME, State.StateType.Final);\n            getWindowSize();\n            return endState;\n        }\n\n        private void getWindowSize() {\n            windowTime =\n                    Optional.ofNullable(currentPattern.getWindowTime()).map(Time::toMilliseconds);\n        }\n\n        /**\n         * Creates all the states between Start and Final state.\n         *\n         * @param sinkState the state that last state should point to (always the Final state)\n         * @return the next state after Start in the resulting graph\n         */\n        private State<T> createMiddleStates(final State<T> sinkState) {\n            State<T> lastSink = sinkState;\n            while (currentPattern.getPrevious() != null) {\n\n                if (currentPattern.getQuantifier().getConsumingStrategy()\n                        == Quantifier.ConsumingStrategy.NOT_FOLLOW) {\n                    // skip notFollow patterns, they are converted into edge conditions\n                    if ((currentPattern.getWindowTime(WithinType.PREVIOUS_AND_CURRENT) != null\n                                    || getWindowTime() > 0)\n                            && lastSink.isFinal()) {\n                        final State<T> notFollow = createState(State.StateType.Pending, true);\n                        final IterativeCondition<T> notCondition = getTakeCondition(currentPattern);\n                        final State<T> stopState =\n                                createStopState(notCondition, currentPattern.getName());\n                        notFollow.addProceed(stopState, notCondition);\n                        notFollow.addIgnore(new RichNotCondition<>(notCondition));\n                        lastSink = notFollow;\n                    }\n                } else if (currentPattern.getQuantifier().getConsumingStrategy()\n                        == Quantifier.ConsumingStrategy.NOT_NEXT) {\n                    final State<T> notNext = createState(State.StateType.Normal, true);\n                    final IterativeCondition<T> notCondition = getTakeCondition(currentPattern);\n                    final State<T> stopState =\n                            createStopState(notCondition, currentPattern.getName());\n\n                    if (lastSink.isFinal()) {\n                        // so that the proceed to final is not fired\n                        notNext.addIgnore(lastSink, new RichNotCondition<>(notCondition));\n                    } else {\n                        notNext.addProceed(lastSink, new RichNotCondition<>(notCondition));\n                    }\n                    notNext.addProceed(stopState, notCondition);\n                    lastSink = notNext;\n                } else {\n                    lastSink = convertPattern(lastSink);\n                }\n\n                // we traverse the pattern graph backwards\n                followingPattern = currentPattern;\n                currentPattern = currentPattern.getPrevious();\n\n                final Time currentWindowTime = currentPattern.getWindowTime();\n                if (currentWindowTime != null\n                        && currentWindowTime.toMilliseconds() < windowTime.orElse(Long.MAX_VALUE)) {\n                    // the window time is the global minimum of all window times of each state\n                    windowTime = Optional.of(currentWindowTime.toMilliseconds());\n                }\n            }\n            return lastSink;\n        }\n\n        /**\n         * Creates the Start {@link State} of the resulting NFA graph.\n         *\n         * @param sinkState the state that Start state should point to (always first state of middle\n         *     states)\n         * @return created state\n         */\n        @SuppressWarnings(\"unchecked\")\n        private State<T> createStartState(State<T> sinkState) {\n            final State<T> beginningState = convertPattern(sinkState);\n            beginningState.makeStart();\n            return beginningState;\n        }\n\n        private State<T> convertPattern(final State<T> sinkState) {\n            final State<T> lastSink;\n\n            final Quantifier quantifier = currentPattern.getQuantifier();\n            if (quantifier.hasProperty(Quantifier.QuantifierProperty.LOOPING)) {\n\n                // if loop has started then all notPatterns previous to the optional states are no\n                // longer valid\n                setCurrentGroupPatternFirstOfLoop(false);\n                final State<T> sink = copyWithoutTransitiveNots(sinkState);\n                final State<T> looping = createLooping(sink);\n\n                setCurrentGroupPatternFirstOfLoop(true);\n                lastSink = createTimesState(looping, sinkState, currentPattern.getTimes());\n            } else if (quantifier.hasProperty(Quantifier.QuantifierProperty.TIMES)) {\n                lastSink = createTimesState(sinkState, sinkState, currentPattern.getTimes());\n            } else {\n                lastSink = createSingletonState(sinkState);\n            }\n            addStopStates(lastSink);\n\n            return lastSink;\n        }\n\n        private State<T> createState(State.StateType stateType, boolean isTake) {\n            State<T> state = createState(currentPattern.getName(), stateType);\n            if (isTake) {\n                Times times = currentPattern.getTimes();\n                Time windowTime = currentPattern.getWindowTime(WithinType.PREVIOUS_AND_CURRENT);\n                if (times == null && windowTime != null) {\n                    windowTimes.put(state.getName(), windowTime.toMilliseconds());\n                } else if (times != null\n                        && times.getWindowTime() != null\n                        && state.getName().contains(STATE_NAME_DELIM)) {\n                    windowTimes.put(state.getName(), times.getWindowTime().toMilliseconds());\n                }\n            }\n            return state;\n        }\n\n        /**\n         * Creates a state with {@link State.StateType#Normal} and adds it to the collection of\n         * created states. Should be used instead of instantiating with new operator.\n         *\n         * @param name the name of the state\n         * @param stateType the type of the state\n         * @return the created state\n         */\n        private State<T> createState(String name, State.StateType stateType) {\n            String stateName = stateNameHandler.getUniqueInternalName(name);\n            State<T> state = new State<>(stateName, stateType);\n            states.add(state);\n            return state;\n        }\n\n        private State<T> createStopState(\n                final IterativeCondition<T> notCondition, final String name) {\n            // We should not duplicate the notStates. All states from which we can stop should point\n            // to the same one.\n            State<T> stopState = stopStates.get(name);\n            if (stopState == null) {\n                stopState = createState(name, State.StateType.Stop);\n                stopState.addTake(notCondition);\n                stopStates.put(name, stopState);\n            }\n            return stopState;\n        }\n\n        /**\n         * This method creates an alternative state that is target for TAKE transition from an\n         * optional State. Accepting an event in optional State discards all not Patterns that were\n         * present before it.\n         *\n         * <p>E.g for a Pattern\n         * begin(\"a\").notFollowedBy(\"b\").followedByAny(\"c\").optional().followedByAny(\"d\") a sequence\n         * like : {a c b d} is a valid match, but {a b d} is not.\n         *\n         * <p><b>NOTICE:</b> This method creates copy only if it necessary.\n         *\n         * @param sinkState a state to create copy without transitive nots\n         * @return the copy of the state itself if no modifications were needed\n         */\n        private State<T> copyWithoutTransitiveNots(final State<T> sinkState) {\n            final List<Tuple2<IterativeCondition<T>, String>> currentNotCondition =\n                    getCurrentNotCondition();\n\n            if (currentNotCondition.isEmpty()\n                    || !currentPattern\n                            .getQuantifier()\n                            .hasProperty(Quantifier.QuantifierProperty.OPTIONAL)) {\n                // we do not create an alternative path if we are NOT in an OPTIONAL state or there\n                // is no NOTs prior to\n                // the optional state\n                return sinkState;\n            }\n\n            final State<T> copyOfSink = createState(sinkState.getName(), sinkState.getStateType());\n\n            for (StateTransition<T> tStateTransition : sinkState.getStateTransitions()) {\n\n                if (tStateTransition.getAction() == StateTransitionAction.PROCEED) {\n                    State<T> targetState = tStateTransition.getTargetState();\n                    boolean remove = false;\n                    if (targetState.isStop()) {\n                        for (Tuple2<IterativeCondition<T>, String> notCondition :\n                                currentNotCondition) {\n                            if (targetState.getName().equals(notCondition.f1)) {\n                                remove = true;\n                            }\n                        }\n                    } else {\n                        targetState = copyWithoutTransitiveNots(tStateTransition.getTargetState());\n                    }\n\n                    if (!remove) {\n                        copyOfSink.addStateTransition(\n                                tStateTransition.getAction(),\n                                targetState,\n                                tStateTransition.getCondition());\n                    }\n                } else {\n                    copyOfSink.addStateTransition(\n                            tStateTransition.getAction(),\n                            tStateTransition\n                                            .getTargetState()\n                                            .equals(tStateTransition.getSourceState())\n                                    ? copyOfSink\n                                    : tStateTransition.getTargetState(),\n                            tStateTransition.getCondition());\n                }\n            }\n            return copyOfSink;\n        }\n\n        private State<T> copy(final State<T> state) {\n            final State<T> copyOfState =\n                    createState(\n                            NFAStateNameHandler.getOriginalNameFromInternal(state.getName()),\n                            state.getStateType());\n            for (StateTransition<T> tStateTransition : state.getStateTransitions()) {\n                copyOfState.addStateTransition(\n                        tStateTransition.getAction(),\n                        tStateTransition.getTargetState().equals(tStateTransition.getSourceState())\n                                ? copyOfState\n                                : tStateTransition.getTargetState(),\n                        tStateTransition.getCondition());\n            }\n            return copyOfState;\n        }\n\n        private void addStopStates(final State<T> state) {\n            for (Tuple2<IterativeCondition<T>, String> notCondition : getCurrentNotCondition()) {\n                final State<T> stopState = createStopState(notCondition.f0, notCondition.f1);\n                state.addProceed(stopState, notCondition.f0);\n            }\n        }\n\n        private void addStopStateToLooping(final State<T> loopingState) {\n            if (followingPattern != null\n                    && followingPattern.getQuantifier().getConsumingStrategy()\n                            == Quantifier.ConsumingStrategy.NOT_FOLLOW) {\n                final IterativeCondition<T> notCondition = getTakeCondition(followingPattern);\n                final State<T> stopState =\n                        createStopState(notCondition, followingPattern.getName());\n                loopingState.addProceed(stopState, notCondition);\n            }\n        }\n\n        /**\n         * Creates a \"complex\" state consisting of given number of states with same {@link\n         * IterativeCondition}.\n         *\n         * @param sinkState the state that the created state should point to\n         * @param proceedState state that the state being converted should proceed to\n         * @param times number of times the state should be copied\n         * @return the first state of the \"complex\" state, next state should point to it\n         */\n        @SuppressWarnings(\"unchecked\")\n        private State<T> createTimesState(\n                final State<T> sinkState, final State<T> proceedState, Times times) {\n            State<T> lastSink = sinkState;\n            setCurrentGroupPatternFirstOfLoop(false);\n            final IterativeCondition<T> untilCondition =\n                    (IterativeCondition<T>) currentPattern.getUntilCondition();\n            final IterativeCondition<T> innerIgnoreCondition =\n                    extendWithUntilCondition(\n                            getInnerIgnoreCondition(currentPattern), untilCondition, false);\n            final IterativeCondition<T> takeCondition =\n                    extendWithUntilCondition(\n                            getTakeCondition(currentPattern), untilCondition, true);\n\n            if (currentPattern.getQuantifier().hasProperty(Quantifier.QuantifierProperty.GREEDY)\n                    && times.getFrom() != times.getTo()) {\n                if (untilCondition != null) {\n                    State<T> sinkStateCopy = copy(sinkState);\n                    originalStateMap.put(sinkState.getName(), sinkStateCopy);\n                }\n                updateWithGreedyCondition(sinkState, takeCondition);\n            }\n\n            for (int i = times.getFrom(); i < times.getTo(); i++) {\n                lastSink =\n                        createSingletonState(\n                                lastSink, proceedState, takeCondition, innerIgnoreCondition, true);\n                addStopStateToLooping(lastSink);\n            }\n            for (int i = 0; i < times.getFrom() - 1; i++) {\n                lastSink =\n                        createSingletonState(\n                                lastSink, null, takeCondition, innerIgnoreCondition, false);\n                addStopStateToLooping(lastSink);\n            }\n            // we created the intermediate states in the loop, now we create the start of the loop.\n            setCurrentGroupPatternFirstOfLoop(true);\n            return createSingletonState(\n                    lastSink,\n                    proceedState,\n                    takeCondition,\n                    getIgnoreCondition(currentPattern),\n                    isPatternOptional(currentPattern));\n        }\n\n        /**\n         * Marks the current group pattern as the head of the TIMES quantifier or not.\n         *\n         * @param isFirstOfLoop whether the current group pattern is the head of the TIMES\n         *     quantifier\n         */\n        @SuppressWarnings(\"unchecked\")\n        private void setCurrentGroupPatternFirstOfLoop(boolean isFirstOfLoop) {\n            if (currentPattern instanceof GroupPattern) {\n                firstOfLoopMap.put((GroupPattern<T, ?>) currentPattern, isFirstOfLoop);\n            }\n        }\n\n        /**\n         * Checks if the current group pattern is the head of the TIMES/LOOPING quantifier or not a\n         * TIMES/LOOPING quantifier pattern.\n         */\n        private boolean isCurrentGroupPatternFirstOfLoop() {\n            if (firstOfLoopMap.containsKey(currentGroupPattern)) {\n                return firstOfLoopMap.get(currentGroupPattern);\n            } else {\n                return true;\n            }\n        }\n\n        /**\n         * Checks if the given pattern is the head pattern of the current group pattern.\n         *\n         * @param pattern the pattern to be checked\n         * @return {@code true} iff the given pattern is in a group pattern and it is the head\n         *     pattern of the group pattern, {@code false} otherwise\n         */\n        private boolean headOfGroup(Pattern<T, ?> pattern) {\n            return currentGroupPattern != null && pattern.getPrevious() == null;\n        }\n\n        /**\n         * Checks if the given pattern is optional. If the given pattern is the head of a group\n         * pattern, the optional status depends on the group pattern.\n         */\n        private boolean isPatternOptional(Pattern<T, ?> pattern) {\n            return pattern.getQuantifier().hasProperty(Quantifier.QuantifierProperty.OPTIONAL);\n        }\n\n        private boolean isHeadOfOptionalGroupPattern(Pattern<T, ?> pattern) {\n            if (!headOfGroup(pattern)) {\n                return false;\n            }\n            return isCurrentGroupPatternFirstOfLoop()\n                    && currentGroupPattern\n                            .getQuantifier()\n                            .hasProperty(Quantifier.QuantifierProperty.OPTIONAL);\n        }\n\n        /**\n         * Creates a simple single state. For an OPTIONAL state it also consists of a similar state\n         * without the PROCEED edge, so that for each PROCEED transition branches in computation\n         * state graph can be created only once.\n         *\n         * @param sinkState state that the state being converted should point to\n         * @return the created state\n         */\n        @SuppressWarnings(\"unchecked\")\n        private State<T> createSingletonState(final State<T> sinkState) {\n            return createSingletonState(\n                    sinkState,\n                    sinkState,\n                    getTakeCondition(currentPattern),\n                    getIgnoreCondition(currentPattern),\n                    isPatternOptional(currentPattern));\n        }\n\n        /**\n         * Creates a simple single state. For an OPTIONAL state it also consists of a similar state\n         * without the PROCEED edge, so that for each PROCEED transition branches in computation\n         * state graph can be created only once.\n         *\n         * @param ignoreCondition condition that should be applied to IGNORE transition\n         * @param sinkState state that the state being converted should point to\n         * @param proceedState state that the state being converted should proceed to\n         * @param isOptional whether the state being converted is optional\n         * @return the created state\n         */\n        @SuppressWarnings(\"unchecked\")\n        private State<T> createSingletonState(\n                final State<T> sinkState,\n                final State<T> proceedState,\n                final IterativeCondition<T> takeCondition,\n                final IterativeCondition<T> ignoreCondition,\n                final boolean isOptional) {\n            if (currentPattern instanceof GroupPattern) {\n                return createGroupPatternState(\n                        (GroupPattern) currentPattern, sinkState, proceedState, isOptional);\n            }\n\n            final State<T> singletonState = createState(State.StateType.Normal, true);\n            // if event is accepted then all notPatterns previous to the optional states are no\n            // longer valid\n            final State<T> sink = copyWithoutTransitiveNots(sinkState);\n            singletonState.addTake(sink, takeCondition);\n\n            // if no element accepted the previous nots are still valid.\n            final IterativeCondition<T> proceedCondition = getTrueFunction();\n\n            if (isOptional) {\n                if (currentPattern\n                        .getQuantifier()\n                        .hasProperty(Quantifier.QuantifierProperty.GREEDY)) {\n                    final IterativeCondition<T> untilCondition =\n                            (IterativeCondition<T>) currentPattern.getUntilCondition();\n                    if (untilCondition != null) {\n                        singletonState.addProceed(\n                                originalStateMap.get(proceedState.getName()),\n                                new RichAndCondition<>(proceedCondition, untilCondition));\n                    }\n                    singletonState.addProceed(\n                            proceedState,\n                            untilCondition != null\n                                    ? new RichAndCondition<>(\n                                            proceedCondition,\n                                            new RichNotCondition<>(untilCondition))\n                                    : proceedCondition);\n                } else {\n                    singletonState.addProceed(proceedState, proceedCondition);\n                }\n            }\n\n            if (ignoreCondition != null) {\n                final State<T> ignoreState;\n                if (isOptional || isHeadOfOptionalGroupPattern(currentPattern)) {\n                    ignoreState = createState(State.StateType.Normal, false);\n                    ignoreState.addTake(sink, takeCondition);\n                    ignoreState.addIgnore(ignoreCondition);\n                    addStopStates(ignoreState);\n                } else {\n                    ignoreState = singletonState;\n                }\n                singletonState.addIgnore(ignoreState, ignoreCondition);\n            }\n            return singletonState;\n        }\n\n        /**\n         * Create all the states for the group pattern.\n         *\n         * @param groupPattern the group pattern to create the states for\n         * @param sinkState the state that the group pattern being converted should point to\n         * @param proceedState the state that the group pattern being converted should proceed to\n         * @param isOptional whether the group pattern being converted is optional\n         * @return the first state of the states of the group pattern\n         */\n        private State<T> createGroupPatternState(\n                final GroupPattern<T, ?> groupPattern,\n                final State<T> sinkState,\n                final State<T> proceedState,\n                final boolean isOptional) {\n            final IterativeCondition<T> proceedCondition = getTrueFunction();\n\n            Pattern<T, ?> oldCurrentPattern = currentPattern;\n            Pattern<T, ?> oldFollowingPattern = followingPattern;\n            GroupPattern<T, ?> oldGroupPattern = currentGroupPattern;\n\n            State<T> lastSink = sinkState;\n            currentGroupPattern = groupPattern;\n            currentPattern = groupPattern.getRawPattern();\n            lastSink = createMiddleStates(lastSink);\n            lastSink = convertPattern(lastSink);\n            if (isOptional) {\n                // for the first state of a group pattern, its PROCEED edge should point to\n                // the following state of that group pattern\n                lastSink.addProceed(proceedState, proceedCondition);\n            }\n            currentPattern = oldCurrentPattern;\n            followingPattern = oldFollowingPattern;\n            currentGroupPattern = oldGroupPattern;\n            return lastSink;\n        }\n\n        /**\n         * Create the states for the group pattern as a looping one.\n         *\n         * @param groupPattern the group pattern to create the states for\n         * @param sinkState the state that the group pattern being converted should point to\n         * @return the first state of the states of the group pattern\n         */\n        private State<T> createLoopingGroupPatternState(\n                final GroupPattern<T, ?> groupPattern, final State<T> sinkState) {\n            final IterativeCondition<T> proceedCondition = getTrueFunction();\n\n            Pattern<T, ?> oldCurrentPattern = currentPattern;\n            Pattern<T, ?> oldFollowingPattern = followingPattern;\n            GroupPattern<T, ?> oldGroupPattern = currentGroupPattern;\n\n            final State<T> dummyState = createState(State.StateType.Normal, true);\n            State<T> lastSink = dummyState;\n            currentGroupPattern = groupPattern;\n            currentPattern = groupPattern.getRawPattern();\n            lastSink = createMiddleStates(lastSink);\n            lastSink = convertPattern(lastSink);\n            lastSink.addProceed(sinkState, proceedCondition);\n            dummyState.addProceed(lastSink, proceedCondition);\n            currentPattern = oldCurrentPattern;\n            followingPattern = oldFollowingPattern;\n            currentGroupPattern = oldGroupPattern;\n            return lastSink;\n        }\n\n        /**\n         * Creates the given state as a looping one. Looping state is one with TAKE edge to itself\n         * and PROCEED edge to the sinkState. It also consists of a similar state without the\n         * PROCEED edge, so that for each PROCEED transition branches in computation state graph can\n         * be created only once.\n         *\n         * @param sinkState the state that the converted state should point to\n         * @return the first state of the created complex state\n         */\n        @SuppressWarnings(\"unchecked\")\n        private State<T> createLooping(final State<T> sinkState) {\n            if (currentPattern instanceof GroupPattern) {\n                return createLoopingGroupPatternState((GroupPattern) currentPattern, sinkState);\n            }\n            final IterativeCondition<T> untilCondition =\n                    (IterativeCondition<T>) currentPattern.getUntilCondition();\n\n            final IterativeCondition<T> ignoreCondition =\n                    extendWithUntilCondition(\n                            getInnerIgnoreCondition(currentPattern), untilCondition, false);\n            final IterativeCondition<T> takeCondition =\n                    extendWithUntilCondition(\n                            getTakeCondition(currentPattern), untilCondition, true);\n\n            IterativeCondition<T> proceedCondition = getTrueFunction();\n            final State<T> loopingState = createState(State.StateType.Normal, true);\n\n            if (currentPattern.getQuantifier().hasProperty(Quantifier.QuantifierProperty.GREEDY)) {\n                if (untilCondition != null) {\n                    State<T> sinkStateCopy = copy(sinkState);\n                    loopingState.addProceed(\n                            sinkStateCopy,\n                            new RichAndCondition<>(proceedCondition, untilCondition));\n                    originalStateMap.put(sinkState.getName(), sinkStateCopy);\n                }\n                loopingState.addProceed(\n                        sinkState,\n                        untilCondition != null\n                                ? new RichAndCondition<>(\n                                        proceedCondition, new RichNotCondition<>(untilCondition))\n                                : proceedCondition);\n                updateWithGreedyCondition(sinkState, getTakeCondition(currentPattern));\n            } else {\n                loopingState.addProceed(sinkState, proceedCondition);\n            }\n            loopingState.addTake(takeCondition);\n\n            addStopStateToLooping(loopingState);\n\n            if (ignoreCondition != null) {\n                final State<T> ignoreState = createState(State.StateType.Normal, false);\n                ignoreState.addTake(loopingState, takeCondition);\n                ignoreState.addIgnore(ignoreCondition);\n                loopingState.addIgnore(ignoreState, ignoreCondition);\n\n                addStopStateToLooping(ignoreState);\n            }\n            return loopingState;\n        }\n\n        /**\n         * This method extends the given condition with stop(until) condition if necessary. The\n         * until condition needs to be applied only if both of the given conditions are not null.\n         *\n         * @param condition the condition to extend\n         * @param untilCondition the until condition to join with the given condition\n         * @param isTakeCondition whether the {@code condition} is for {@code TAKE} edge\n         * @return condition with AND applied or the original condition\n         */\n        private IterativeCondition<T> extendWithUntilCondition(\n                IterativeCondition<T> condition,\n                IterativeCondition<T> untilCondition,\n                boolean isTakeCondition) {\n            if (untilCondition != null && condition != null) {\n                return new RichAndCondition<>(new RichNotCondition<>(untilCondition), condition);\n            } else if (untilCondition != null && isTakeCondition) {\n                return new RichNotCondition<>(untilCondition);\n            }\n\n            return condition;\n        }\n\n        /**\n         * @return The {@link IterativeCondition condition} for the {@code IGNORE} edge that\n         *     corresponds to the specified {@link Pattern} and extended with stop(until) condition\n         *     if necessary. It is applicable only for inner states of a complex state like looping\n         *     or times.\n         */\n        @SuppressWarnings(\"unchecked\")\n        private IterativeCondition<T> getInnerIgnoreCondition(Pattern<T, ?> pattern) {\n            Quantifier.ConsumingStrategy consumingStrategy =\n                    pattern.getQuantifier().getInnerConsumingStrategy();\n            if (headOfGroup(pattern)) {\n                // for the head pattern of a group pattern, we should consider the\n                // inner consume strategy of the group pattern\n                consumingStrategy = currentGroupPattern.getQuantifier().getInnerConsumingStrategy();\n            }\n\n            IterativeCondition<T> innerIgnoreCondition = null;\n            switch (consumingStrategy) {\n                case STRICT:\n                    innerIgnoreCondition = null;\n                    break;\n                case SKIP_TILL_NEXT:\n                    innerIgnoreCondition =\n                            new RichNotCondition<>((IterativeCondition<T>) pattern.getCondition());\n                    break;\n                case SKIP_TILL_ANY:\n                    innerIgnoreCondition = BooleanConditions.trueFunction();\n                    break;\n            }\n\n            if (currentGroupPattern != null && currentGroupPattern.getUntilCondition() != null) {\n                innerIgnoreCondition =\n                        extendWithUntilCondition(\n                                innerIgnoreCondition,\n                                (IterativeCondition<T>) currentGroupPattern.getUntilCondition(),\n                                false);\n            }\n            return innerIgnoreCondition;\n        }\n\n        /**\n         * @return The {@link IterativeCondition condition} for the {@code IGNORE} edge that\n         *     corresponds to the specified {@link Pattern} and extended with stop(until) condition\n         *     if necessary. For more on strategy see {@link Quantifier}\n         */\n        @SuppressWarnings(\"unchecked\")\n        private IterativeCondition<T> getIgnoreCondition(Pattern<T, ?> pattern) {\n            Quantifier.ConsumingStrategy consumingStrategy =\n                    pattern.getQuantifier().getConsumingStrategy();\n            if (headOfGroup(pattern)) {\n                // for the head pattern of a group pattern, we should consider the inner consume\n                // strategy\n                // of the group pattern if the group pattern is not the head of the TIMES/LOOPING\n                // quantifier;\n                // otherwise, we should consider the consume strategy of the group pattern\n                if (isCurrentGroupPatternFirstOfLoop()) {\n                    consumingStrategy = currentGroupPattern.getQuantifier().getConsumingStrategy();\n                } else {\n                    consumingStrategy =\n                            currentGroupPattern.getQuantifier().getInnerConsumingStrategy();\n                }\n            }\n\n            IterativeCondition<T> ignoreCondition = null;\n            switch (consumingStrategy) {\n                case STRICT:\n                    ignoreCondition = null;\n                    break;\n                case SKIP_TILL_NEXT:\n                    ignoreCondition =\n                            new RichNotCondition<>((IterativeCondition<T>) pattern.getCondition());\n                    break;\n                case SKIP_TILL_ANY:\n                    ignoreCondition = BooleanConditions.trueFunction();\n                    break;\n            }\n\n            if (currentGroupPattern != null && currentGroupPattern.getUntilCondition() != null) {\n                ignoreCondition =\n                        extendWithUntilCondition(\n                                ignoreCondition,\n                                (IterativeCondition<T>) currentGroupPattern.getUntilCondition(),\n                                false);\n            }\n            return ignoreCondition;\n        }\n\n        /**\n         * @return the {@link IterativeCondition condition} for the {@code TAKE} edge that\n         *     corresponds to the specified {@link Pattern} and extended with stop(until) condition\n         *     if necessary.\n         */\n        @SuppressWarnings(\"unchecked\")\n        private IterativeCondition<T> getTakeCondition(Pattern<T, ?> pattern) {\n            IterativeCondition<T> takeCondition = (IterativeCondition<T>) pattern.getCondition();\n            if (currentGroupPattern != null && currentGroupPattern.getUntilCondition() != null) {\n                takeCondition =\n                        extendWithUntilCondition(\n                                takeCondition,\n                                (IterativeCondition<T>) currentGroupPattern.getUntilCondition(),\n                                true);\n            }\n            return takeCondition;\n        }\n\n        /** @return An true function extended with stop(until) condition if necessary. */\n        @SuppressWarnings(\"unchecked\")\n        private IterativeCondition<T> getTrueFunction() {\n            IterativeCondition<T> trueCondition = BooleanConditions.trueFunction();\n            if (currentGroupPattern != null && currentGroupPattern.getUntilCondition() != null) {\n                trueCondition =\n                        extendWithUntilCondition(\n                                trueCondition,\n                                (IterativeCondition<T>) currentGroupPattern.getUntilCondition(),\n                                true);\n            }\n            return trueCondition;\n        }\n\n        private void updateWithGreedyCondition(\n                State<T> state, IterativeCondition<T> takeCondition) {\n            for (StateTransition<T> stateTransition : state.getStateTransitions()) {\n                stateTransition.setCondition(\n                        new RichAndCondition<>(\n                                stateTransition.getCondition(),\n                                new RichNotCondition<>(takeCondition)));\n            }\n        }\n    }\n\n    /**\n     * Factory interface for {@link NFA}.\n     *\n     * @param <T> Type of the input events which are processed by the NFA\n     */\n    public interface NFAFactory<T> extends Serializable {\n        NFA<T> createNFA();\n    }\n\n    /**\n     * Implementation of the {@link NFAFactory} interface.\n     *\n     * <p>The implementation takes the input type serializer, the window time and the set of states\n     * and their transitions to be able to create an NFA from them.\n     *\n     * @param <T> Type of the input events which are processed by the NFA\n     */\n    private static class NFAFactoryImpl<T> implements NFAFactory<T> {\n\n        private static final long serialVersionUID = 8939783698296714379L;\n\n        private final long windowTime;\n        private final Map<String, Long> windowTimes;\n        private final Collection<State<T>> states;\n        private final boolean timeoutHandling;\n\n        private NFAFactoryImpl(\n                long windowTime,\n                Map<String, Long> windowTimes,\n                Collection<State<T>> states,\n                boolean timeoutHandling) {\n\n            this.windowTime = windowTime;\n            this.windowTimes = windowTimes;\n            this.states = states;\n            this.timeoutHandling = timeoutHandling;\n        }\n\n        @Override\n        public NFA<T> createNFA() {\n            return new NFA<>(states, windowTimes, windowTime, timeoutHandling);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 1,
                "candidates": [
                    {
                        "lineStart": 255,
                        "lineEnd": 271,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method checkPatternNameUniqueness to class NFAStateNameHandler",
                        "description": "Move method checkPatternNameUniqueness to org.apache.flink.cep.nfa.compiler.NFAStateNameHandler\nRationale: The method checkPatternNameUniqueness directly interacts with the stateNameHandler to check the uniqueness of pattern names, making it more appropriate for it to reside within the NFAStateNameHandler class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    }
                ]
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "compileFactory",
                            "method_signature": "public static <T> NFAFactory<T> compileFactory(final Pattern<T, ?> pattern, boolean timeoutHandling)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The compileFactory method is responsible for compiling a pattern into an NFAFactory, which is a core functionality of the NFAFactoryCompiler class. Moving it to NFAFactoryCompiler would enhance cohesion and encapsulation."
                        },
                        {
                            "method_name": "canProduceEmptyMatches",
                            "method_signature": "public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The canProduceEmptyMatches method checks if a pattern can generate empty matches, which is a specific functionality related to the NFA compilation process. It should be moved to NFAFactoryCompiler to maintain a clear separation of responsibilities."
                        },
                        {
                            "method_name": "getCurrentNotCondition",
                            "method_signature": "private List<Tuple2<IterativeCondition<T>, String>> getCurrentNotCondition()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The getCurrentNotCondition method is used to retrieve conditions related to the current state of the NFA compilation process. It is closely tied to the logic of the NFAFactoryCompiler and should be moved there for better organization."
                        },
                        {
                            "method_name": "checkPatternWindowTimes",
                            "method_signature": "private void checkPatternWindowTimes()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternWindowTimes method is responsible for validating window times in patterns, which is a specific concern of the NFA compilation process. Moving it to NFAFactoryCompiler would improve the class's focus."
                        },
                        {
                            "method_name": "checkPatternSkipStrategy",
                            "method_signature": "private void checkPatternSkipStrategy()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternSkipStrategy method checks the skip strategy of patterns, which is relevant to the NFA compilation logic. It should be moved to NFAFactoryCompiler to enhance the class's clarity and purpose."
                        },
                        {
                            "method_name": "checkPatternNameUniqueness",
                            "method_signature": "private void checkPatternNameUniqueness()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternNameUniqueness method ensures that pattern names are unique, which is a validation step in the NFA compilation process. It should be moved to NFAFactoryCompiler for better encapsulation."
                        },
                        {
                            "method_name": "createEndingState",
                            "method_signature": "private State<T> createEndingState()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createEndingState method is responsible for creating the final state of the NFA, which is a core part of the NFA compilation process. It should be moved to NFAFactoryCompiler to align with its responsibilities."
                        },
                        {
                            "method_name": "createMiddleStates",
                            "method_signature": "private State<T> createMiddleStates(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createMiddleStates method creates the states between the start and final states of the NFA, which is a fundamental part of the NFA compilation process. It should be moved to NFAFactoryCompiler for better organization."
                        },
                        {
                            "method_name": "createStartState",
                            "method_signature": "private State<T> createStartState(State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createStartState method creates the starting state of the NFA, which is essential to the NFA compilation process. It should be moved to NFAFactoryCompiler to maintain a clear focus on NFA creation."
                        },
                        {
                            "method_name": "convertPattern",
                            "method_signature": "private State<T> convertPattern(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The convertPattern method is responsible for converting patterns into states, which is a key part of the NFA compilation process. It should be moved to NFAFactoryCompiler to enhance the class's clarity."
                        },
                        {
                            "method_name": "createSingletonState",
                            "method_signature": "private State<T> createSingletonState(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createSingletonState method creates a single state for the NFA, which is a fundamental operation in the NFA compilation process. It should be moved to NFAFactoryCompiler for better organization."
                        }
                    ],
                    "llm_response_time": 15497
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "compileFactory",
                            "method_signature": "public static <T> NFAFactory<T> compileFactory(final Pattern<T, ?> pattern, boolean timeoutHandling)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The compileFactory method is responsible for compiling a pattern into an NFAFactory, which is a core functionality of the NFAFactoryCompiler class. Moving it to NFAFactoryCompiler would enhance cohesion and encapsulation."
                        },
                        {
                            "method_name": "canProduceEmptyMatches",
                            "method_signature": "public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The canProduceEmptyMatches method checks if a pattern can generate empty matches, which is a specific functionality related to the NFAFactoryCompiler's role in compiling patterns. Moving it to NFAFactoryCompiler would improve the organization of related functionalities."
                        },
                        {
                            "method_name": "getCurrentNotCondition",
                            "method_signature": "private List<Tuple2<IterativeCondition<T>, String>> getCurrentNotCondition()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The getCurrentNotCondition method is closely tied to the state transitions and conditions that the NFAFactoryCompiler manages. Moving it to NFAFactoryCompiler would enhance the clarity of the code structure."
                        },
                        {
                            "method_name": "checkPatternWindowTimes",
                            "method_signature": "private void checkPatternWindowTimes()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternWindowTimes method is responsible for validating window times, which is a specific concern of the NFAFactoryCompiler. Moving it would align the method with the class's responsibilities."
                        },
                        {
                            "method_name": "checkPatternSkipStrategy",
                            "method_signature": "private void checkPatternSkipStrategy()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternSkipStrategy method checks the skip strategy of patterns, which is relevant to the compilation process handled by NFAFactoryCompiler. Moving it would improve the organization of related logic."
                        },
                        {
                            "method_name": "checkPatternNameUniqueness",
                            "method_signature": "private void checkPatternNameUniqueness()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternNameUniqueness method ensures that pattern names are unique, which is a validation step in the compilation process. Moving it to NFAFactoryCompiler would enhance the class's focus on pattern compilation."
                        },
                        {
                            "method_name": "createEndingState",
                            "method_signature": "private State<T> createEndingState()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createEndingState method is responsible for creating the final state of the NFA, which is a core part of the NFAFactoryCompiler's functionality. Moving it would improve the cohesion of the class."
                        },
                        {
                            "method_name": "createMiddleStates",
                            "method_signature": "private State<T> createMiddleStates(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createMiddleStates method constructs the states between the start and final states of the NFA, which is a direct responsibility of the NFAFactoryCompiler. Moving it would enhance the clarity of the code structure."
                        },
                        {
                            "method_name": "createStartState",
                            "method_signature": "private State<T> createStartState(State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createStartState method creates the starting state of the NFA, which is a specific task related to the NFAFactoryCompiler's role. Moving it would improve the organization of related functionalities."
                        },
                        {
                            "method_name": "convertPattern",
                            "method_signature": "private State<T> convertPattern(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The convertPattern method is responsible for converting patterns into states, which is a core functionality of the NFAFactoryCompiler. Moving it would enhance the cohesion of the class."
                        },
                        {
                            "method_name": "createSingletonState",
                            "method_signature": "private State<T> createSingletonState(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createSingletonState method creates a single state for the NFA, which is a specific task related to the NFAFactoryCompiler's responsibilities. Moving it would improve the organization of related logic."
                        }
                    ],
                    "llm_response_time": 13168
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "compileFactory",
                            "method_signature": "public static <T> NFAFactory<T> compileFactory(final Pattern<T, ?> pattern, boolean timeoutHandling)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The compileFactory method is responsible for compiling a pattern into an NFAFactory, which is the primary responsibility of the NFAFactoryCompiler class. Moving it there would enhance cohesion."
                        },
                        {
                            "method_name": "canProduceEmptyMatches",
                            "method_signature": "public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The canProduceEmptyMatches method checks if a pattern can generate empty matches, which is a specific functionality related to the NFAFactoryCompiler's role in handling patterns. It should be moved to maintain a clear separation of concerns."
                        }
                    ],
                    "llm_response_time": 3936
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "compileFactory",
                            "method_signature": "public static <T> NFAFactory<T> compileFactory(final Pattern<T, ?> pattern, boolean timeoutHandling)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The compileFactory method is responsible for compiling a pattern into an NFAFactory, which is a core functionality of the NFAFactoryCompiler class. Moving it to NFAFactoryCompiler would enhance cohesion and encapsulation."
                        },
                        {
                            "method_name": "canProduceEmptyMatches",
                            "method_signature": "public static boolean canProduceEmptyMatches(final Pattern<?, ?> pattern)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The canProduceEmptyMatches method checks if a pattern can generate empty matches, which is a specific functionality related to the NFA compilation process. It should be moved to NFAFactoryCompiler to maintain a clear separation of responsibilities."
                        },
                        {
                            "method_name": "getCurrentNotCondition",
                            "method_signature": "private List<Tuple2<IterativeCondition<T>, String>> getCurrentNotCondition()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The getCurrentNotCondition method is used to retrieve conditions related to the current state of the NFA compilation process. It is closely tied to the logic of the NFAFactoryCompiler and should be moved there for better organization."
                        },
                        {
                            "method_name": "checkPatternWindowTimes",
                            "method_signature": "private void checkPatternWindowTimes()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternWindowTimes method is responsible for validating window times in patterns, which is a specific concern of the NFA compilation process. Moving it to NFAFactoryCompiler would improve the class's focus."
                        },
                        {
                            "method_name": "checkPatternSkipStrategy",
                            "method_signature": "private void checkPatternSkipStrategy()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternSkipStrategy method checks the skip strategy of patterns, which is relevant to the NFA compilation logic. It should be moved to NFAFactoryCompiler to enhance the class's clarity and purpose."
                        },
                        {
                            "method_name": "checkPatternNameUniqueness",
                            "method_signature": "private void checkPatternNameUniqueness()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The checkPatternNameUniqueness method ensures that pattern names are unique, which is a validation step in the NFA compilation process. It should be moved to NFAFactoryCompiler for better encapsulation."
                        },
                        {
                            "method_name": "createEndingState",
                            "method_signature": "private State<T> createEndingState()",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createEndingState method is responsible for creating the final state of the NFA, which is a core part of the NFA compilation process. It should be moved to NFAFactoryCompiler to align with its responsibilities."
                        },
                        {
                            "method_name": "createMiddleStates",
                            "method_signature": "private State<T> createMiddleStates(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createMiddleStates method creates the states between the start and final states of the NFA, which is a fundamental part of the NFA compilation process. It should be moved to NFAFactoryCompiler for better organization."
                        },
                        {
                            "method_name": "createStartState",
                            "method_signature": "private State<T> createStartState(State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createStartState method creates the starting state of the NFA, which is essential to the NFA compilation process. It should be moved to NFAFactoryCompiler to maintain a clear focus on NFA creation."
                        },
                        {
                            "method_name": "convertPattern",
                            "method_signature": "private State<T> convertPattern(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The convertPattern method is responsible for converting patterns into states, which is a key part of the NFA compilation process. It should be moved to NFAFactoryCompiler to enhance the class's clarity."
                        },
                        {
                            "method_name": "createSingletonState",
                            "method_signature": "private State<T> createSingletonState(final State<T> sinkState)",
                            "target_class": "NFAFactoryCompiler",
                            "rationale": "The createSingletonState method creates a single state for the NFA, which is a fundamental operation in the NFA compilation process. It should be moved to NFAFactoryCompiler for better organization."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "compileFactory",
                    "canProduceEmptyMatches",
                    "checkPatternWindowTimes",
                    "checkPatternSkipStrategy",
                    "checkPatternNameUniqueness",
                    "createEndingState",
                    "createMiddleStates",
                    "createStartState",
                    "convertPattern",
                    "createSingletonState",
                    "getCurrentNotCondition"
                ],
                "llm_response_time": 1536
            },
            "targetClassMap": {
                "compileFactory": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1591,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "checkPatternWindowTimes": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1617,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "checkPatternSkipStrategy": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1437,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "checkPatternNameUniqueness": {
                    "target_classes": [
                        {
                            "class_name": "NFAStateNameHandler",
                            "similarity_score": 0.6136364839432282
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "NFAStateNameHandler"
                    ],
                    "llm_response_time": 1110,
                    "similarity_computation_time": 6,
                    "similarity_metric": "cosine"
                },
                "createEndingState": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2005,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "createMiddleStates": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1776,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "createStartState": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1708,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "convertPattern": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 3193,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "createSingletonState": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1804,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getCurrentNotCondition": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2344,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "21403e31f4761bdddf5e4e802e0e5eb9b4533202",
        "url": "https://github.com/apache/flink/commit/21403e31f4761bdddf5e4e802e0e5eb9b4533202",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public isQueryHint(hintName String) : boolean extracted from public visit(other RelNode) : RelNode in class org.apache.flink.table.planner.hint.ClearJoinHintsOnUnmatchedNodesShuttle & moved to class org.apache.flink.table.planner.hint.FlinkHints",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/ClearJoinHintsOnUnmatchedNodesShuttle.java",
                    "startLine": 51,
                    "endLine": 81,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public visit(other RelNode) : RelNode"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/ClearJoinHintsOnUnmatchedNodesShuttle.java",
                    "startLine": 62,
                    "endLine": 62,
                    "startColumn": 42,
                    "endColumn": 81,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/FlinkHints.java",
                    "startLine": 265,
                    "endLine": 268,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public isQueryHint(hintName String) : boolean"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/FlinkHints.java",
                    "startLine": 267,
                    "endLine": 267,
                    "startColumn": 9,
                    "endColumn": 95,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/ClearQueryHintsOnUnmatchedNodesShuttle.java",
                    "startLine": 51,
                    "endLine": 81,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public visit(other RelNode) : RelNode"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/hint/ClearQueryHintsOnUnmatchedNodesShuttle.java",
                    "startLine": 62,
                    "endLine": 62,
                    "startColumn": 42,
                    "endColumn": 76,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "FlinkHints.isQueryHint(h.hintName)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 22,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "6afe98daf6190a77a67a1fa8ac8f12337a75f8e7",
        "url": "https://github.com/apache/flink/commit/6afe98daf6190a77a67a1fa8ac8f12337a75f8e7",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public createWriter(context WriterInitContext) : SinkWriter<InputT> extracted from public createWriter(initContext InitContext, context StateInitializationContext) : SinkWriter<InputT> in class org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler & moved to class org.apache.flink.api.connector.sink2.Sink",
            "leftSideLocations": [
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 89,
                    "endLine": 120,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public createWriter(initContext InitContext, context StateInitializationContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 117,
                    "endLine": 117,
                    "startColumn": 13,
                    "endColumn": 57,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java",
                    "startLine": 67,
                    "endLine": 76,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public createWriter(context WriterInitContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java",
                    "startLine": 75,
                    "endLine": 75,
                    "startColumn": 9,
                    "endColumn": 62,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 92,
                    "endLine": 128,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public createWriter(initContext WriterInitContext, context StateInitializationContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 125,
                    "endLine": 125,
                    "startColumn": 31,
                    "endColumn": 61,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "sink.createWriter(initContext)"
                }
            ],
            "isStatic": false
        },
        "ref_id": 23,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "40cbf231e3dc15129b69136941adc15beebe8ef6",
        "url": "https://github.com/apache/flink/commit/40cbf231e3dc15129b69136941adc15beebe8ef6",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public createWriter(context WriterInitContext) : SinkWriter<InputT> extracted from public createWriter(initContext InitContext, context StateInitializationContext) : SinkWriter<InputT> in class org.apache.flink.streaming.runtime.operators.sink.StatefulSinkWriterStateHandler & moved to class org.apache.flink.api.connector.sink2.Sink",
            "leftSideLocations": [
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 89,
                    "endLine": 120,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public createWriter(initContext InitContext, context StateInitializationContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 117,
                    "endLine": 117,
                    "startColumn": 13,
                    "endColumn": 57,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java",
                    "startLine": 69,
                    "endLine": 78,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public createWriter(context WriterInitContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java",
                    "startLine": 77,
                    "endLine": 77,
                    "startColumn": 9,
                    "endColumn": 62,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 92,
                    "endLine": 128,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public createWriter(initContext WriterInitContext, context StateInitializationContext) : SinkWriter<InputT>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/sink/StatefulSinkWriterStateHandler.java",
                    "startLine": 125,
                    "endLine": 125,
                    "startColumn": 31,
                    "endColumn": 61,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "sink.createWriter(initContext)"
                }
            ],
            "isStatic": false
        },
        "ref_id": 23,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "1f7622d4d23bfcb76f466469ec36585054864f04",
        "url": "https://github.com/apache/flink/commit/1f7622d4d23bfcb76f466469ec36585054864f04",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public convertConfigToWritableLines(configuration Configuration, flattenYaml boolean) : List<String> extracted from public appendConfiguration(config Configuration) : void in class org.apache.flink.tests.util.flink.FlinkDistribution & moved to class org.apache.flink.configuration.ConfigurationUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java",
                    "startLine": 415,
                    "endLine": 429,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public appendConfiguration(config Configuration) : void"
                },
                {
                    "filePath": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java",
                    "startLine": 422,
                    "endLine": 422,
                    "startColumn": 39,
                    "endColumn": 79,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java",
                    "startLine": 420,
                    "endLine": 423,
                    "startColumn": 9,
                    "endColumn": 55,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 204,
                    "endLine": 258,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public convertConfigToWritableLines(configuration Configuration, flattenYaml boolean) : List<String>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 255,
                    "endLine": 255,
                    "startColumn": 35,
                    "endColumn": 75,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 254,
                    "endLine": 256,
                    "startColumn": 13,
                    "endColumn": 51,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java",
                    "startLine": 416,
                    "endLine": 426,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public appendConfiguration(config Configuration) : void"
                },
                {
                    "filePath": "flink-end-to-end-tests/flink-end-to-end-tests-common/src/main/java/org/apache/flink/tests/util/flink/FlinkDistribution.java",
                    "startLine": 425,
                    "endLine": 425,
                    "startColumn": 17,
                    "endColumn": 84,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "ConfigurationUtils.convertConfigToWritableLines(mergedConfig,true)"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 250,
                    "endLine": 251,
                    "startColumn": 13,
                    "endColumn": 74,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 253,
                    "endLine": 253,
                    "startColumn": 13,
                    "endColumn": 85,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 249,
                    "endLine": 252,
                    "startColumn": 57,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 252,
                    "endLine": 257,
                    "startColumn": 16,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 249,
                    "endLine": 257,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 24,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "1f7622d4d23bfcb76f466469ec36585054864f04",
        "url": "https://github.com/apache/flink/commit/1f7622d4d23bfcb76f466469ec36585054864f04",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public convertConfigToWritableLines(configuration Configuration, flattenYaml boolean) : List<String> extracted from private createTemporaryFlinkConfFile(finalConfiguration Configuration, tempDirectory Path) : Path in class org.apache.flink.connector.testframe.container.FlinkImageBuilder & moved to class org.apache.flink.configuration.ConfigurationUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testframe/container/FlinkImageBuilder.java",
                    "startLine": 293,
                    "endLine": 306,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private createTemporaryFlinkConfFile(finalConfiguration Configuration, tempDirectory Path) : Path"
                },
                {
                    "filePath": "flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testframe/container/FlinkImageBuilder.java",
                    "startLine": 302,
                    "endLine": 302,
                    "startColumn": 39,
                    "endColumn": 79,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testframe/container/FlinkImageBuilder.java",
                    "startLine": 299,
                    "endLine": 303,
                    "startColumn": 9,
                    "endColumn": 56,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 204,
                    "endLine": 258,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public convertConfigToWritableLines(configuration Configuration, flattenYaml boolean) : List<String>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 255,
                    "endLine": 255,
                    "startColumn": 35,
                    "endColumn": 75,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 254,
                    "endLine": 256,
                    "startColumn": 13,
                    "endColumn": 51,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testframe/container/FlinkImageBuilder.java",
                    "startLine": 293,
                    "endLine": 304,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "private createTemporaryFlinkConfFile(finalConfiguration Configuration, tempDirectory Path) : Path"
                },
                {
                    "filePath": "flink-test-utils-parent/flink-connector-test-utils/src/main/java/org/apache/flink/connector/testframe/container/FlinkImageBuilder.java",
                    "startLine": 301,
                    "endLine": 301,
                    "startColumn": 17,
                    "endColumn": 90,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "ConfigurationUtils.convertConfigToWritableLines(finalConfiguration,true)"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 250,
                    "endLine": 251,
                    "startColumn": 13,
                    "endColumn": 74,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 253,
                    "endLine": 253,
                    "startColumn": 13,
                    "endColumn": 85,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 249,
                    "endLine": 252,
                    "startColumn": 57,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 252,
                    "endLine": 257,
                    "startColumn": 16,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/configuration/ConfigurationUtils.java",
                    "startLine": 249,
                    "endLine": 257,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 25,
        "extraction_results": {
            "success": true,
            "newCommitHash": "6e5b6b17fcd83bdb84e929e7e16b80da3554df2b",
            "newBranchName": "extract-convertConfigToWritableLines-createTemporaryFlinkConfFile-bcd448b"
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "9a22ff7e961cb5d8b52401e567e59954bff35d50",
        "url": "https://github.com/apache/flink/commit/9a22ff7e961cb5d8b52401e567e59954bff35d50",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public accept(stateWindowResult W, stateWindowsToBeMerged Collection<W>) : void extracted from public merge(mergeResult W, mergedWindows Collection<W>, stateWindowResult W, stateWindowsToBeMerged Collection<W>) : void in class org.apache.flink.table.runtime.operators.window.groupwindow.internal.MergingWindowProcessFunction.MergingFunctionImpl & moved to class org.apache.flink.table.runtime.operators.window.groupwindow.internal.MergingWindowProcessFunction.DefaultAccMergingConsumer",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 129,
                    "endLine": 186,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public merge(mergeResult W, mergedWindows Collection<W>, stateWindowResult W, stateWindowsToBeMerged Collection<W>) : void"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 169,
                    "endLine": 169,
                    "startColumn": 17,
                    "endColumn": 82,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 171,
                    "endLine": 171,
                    "startColumn": 21,
                    "endColumn": 71,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 173,
                    "endLine": 173,
                    "startColumn": 17,
                    "endColumn": 80,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 175,
                    "endLine": 175,
                    "startColumn": 21,
                    "endColumn": 64,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 177,
                    "endLine": 177,
                    "startColumn": 25,
                    "endColumn": 56,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 180,
                    "endLine": 180,
                    "startColumn": 21,
                    "endColumn": 45,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 181,
                    "endLine": 181,
                    "startColumn": 21,
                    "endColumn": 47,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 183,
                    "endLine": 183,
                    "startColumn": 17,
                    "endColumn": 64,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 184,
                    "endLine": 184,
                    "startColumn": 17,
                    "endColumn": 73,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 170,
                    "endLine": 172,
                    "startColumn": 17,
                    "endColumn": 18,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 176,
                    "endLine": 178,
                    "startColumn": 21,
                    "endColumn": 22,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 174,
                    "endLine": 182,
                    "startColumn": 17,
                    "endColumn": 18,
                    "codeElementType": "ENHANCED_FOR_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 170,
                    "endLine": 172,
                    "startColumn": 40,
                    "endColumn": 18,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 176,
                    "endLine": 178,
                    "startColumn": 38,
                    "endColumn": 22,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 174,
                    "endLine": 182,
                    "startColumn": 52,
                    "endColumn": 18,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 214,
                    "endLine": 233,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public accept(stateWindowResult W, stateWindowsToBeMerged Collection<W>) : void"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 217,
                    "endLine": 217,
                    "startColumn": 13,
                    "endColumn": 78,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 219,
                    "endLine": 219,
                    "startColumn": 17,
                    "endColumn": 67,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 221,
                    "endLine": 221,
                    "startColumn": 13,
                    "endColumn": 76,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 223,
                    "endLine": 223,
                    "startColumn": 17,
                    "endColumn": 60,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 225,
                    "endLine": 225,
                    "startColumn": 21,
                    "endColumn": 52,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 228,
                    "endLine": 228,
                    "startColumn": 17,
                    "endColumn": 41,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 229,
                    "endLine": 229,
                    "startColumn": 17,
                    "endColumn": 43,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 231,
                    "endLine": 231,
                    "startColumn": 13,
                    "endColumn": 60,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 232,
                    "endLine": 232,
                    "startColumn": 13,
                    "endColumn": 69,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 218,
                    "endLine": 220,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 224,
                    "endLine": 226,
                    "startColumn": 17,
                    "endColumn": 18,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 222,
                    "endLine": 230,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "ENHANCED_FOR_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 218,
                    "endLine": 220,
                    "startColumn": 36,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 224,
                    "endLine": 226,
                    "startColumn": 34,
                    "endColumn": 18,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 222,
                    "endLine": 230,
                    "startColumn": 48,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 145,
                    "endLine": 191,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public merge(mergeResult W, mergedWindows Collection<W>, stateWindowResult W, stateWindowsToBeMerged Collection<W>) : void"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/operators/window/groupwindow/internal/MergingWindowProcessFunction.java",
                    "startLine": 186,
                    "endLine": 186,
                    "startColumn": 21,
                    "endColumn": 89,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "accMergingConsumer.accept(stateWindowResult,stateWindowsToBeMerged)"
                }
            ],
            "isStatic": false
        },
        "ref_id": 26,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "84444d5071984a8543a81574dc69c0c9849a8a4a",
        "url": "https://github.com/apache/flink/commit/84444d5071984a8543a81574dc69c0c9849a8a4a",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public createSerializer(config SerializerConfig) : TypeSerializer<T> extracted from public initializeSerializerUnlessSet(executionConfig ExecutionConfig) : void in class org.apache.flink.api.common.state.StateDescriptor & moved to class org.apache.flink.api.common.typeinfo.TypeInformation",
            "leftSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java",
                    "startLine": 312,
                    "endLine": 326,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public initializeSerializerUnlessSet(executionConfig ExecutionConfig) : void"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java",
                    "startLine": 323,
                    "endLine": 323,
                    "startColumn": 25,
                    "endColumn": 82,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java",
                    "startLine": 322,
                    "endLine": 324,
                    "startColumn": 65,
                    "endColumn": 22,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 171,
                    "endLine": 186,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public createSerializer(config SerializerConfig) : TypeSerializer<T>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 182,
                    "endLine": 182,
                    "startColumn": 13,
                    "endColumn": 54,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 180,
                    "endLine": 183,
                    "startColumn": 29,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java",
                    "startLine": 312,
                    "endLine": 329,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public initializeSerializerUnlessSet(executionConfig ExecutionConfig) : void"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java",
                    "startLine": 323,
                    "endLine": 326,
                    "startColumn": 32,
                    "endColumn": 81,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "typeInformation.createSerializer(executionConfig == null ? null : executionConfig.getSerializerConfig())"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 181,
                    "endLine": 181,
                    "startColumn": 13,
                    "endColumn": 100,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 184,
                    "endLine": 184,
                    "startColumn": 13,
                    "endColumn": 61,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 183,
                    "endLine": 185,
                    "startColumn": 16,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java",
                    "startLine": 180,
                    "endLine": 185,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 27,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "f32b2a9e347d7539819a88252e4e32deba247515",
        "url": "https://github.com/apache/flink/commit/f32b2a9e347d7539819a88252e4e32deba247515",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata> extracted from public StreamExecGlobalGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], localAggInputRowType RowType, generateUpdateBefore boolean, needRetraction boolean, indexOfCountStar Integer, inputProperty InputProperty, outputType RowType, description String) in class org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGlobalGroupAggregate & moved to class org.apache.flink.table.planner.plan.nodes.exec.StateMetadata",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGlobalGroupAggregate.java",
                    "startLine": 127,
                    "endLine": 155,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public StreamExecGlobalGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], localAggInputRowType RowType, generateUpdateBefore boolean, needRetraction boolean, indexOfCountStar Integer, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGlobalGroupAggregate.java",
                    "startLine": 139,
                    "endLine": 154,
                    "startColumn": 9,
                    "endColumn": 30,
                    "codeElementType": "CONSTRUCTOR_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 112,
                    "endLine": 121,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata>"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 114,
                    "endLine": 120,
                    "startColumn": 9,
                    "endColumn": 37,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGlobalGroupAggregate.java",
                    "startLine": 127,
                    "endLine": 157,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public StreamExecGlobalGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], localAggInputRowType RowType, generateUpdateBefore boolean, needRetraction boolean, indexOfCountStar Integer, stateTtlFromHint Long, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGlobalGroupAggregate.java",
                    "startLine": 152,
                    "endLine": 153,
                    "startColumn": 17,
                    "endColumn": 67,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "StateMetadata.getOneInputOperatorDefaultMeta(stateTtlFromHint,tableConfig,STATE_NAME)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 28,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "f32b2a9e347d7539819a88252e4e32deba247515",
        "url": "https://github.com/apache/flink/commit/f32b2a9e347d7539819a88252e4e32deba247515",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata> extracted from public StreamExecGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], generateUpdateBefore boolean, needRetraction boolean, inputProperty InputProperty, outputType RowType, description String) in class org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecGroupAggregate & moved to class org.apache.flink.table.planner.plan.nodes.exec.StateMetadata",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGroupAggregate.java",
                    "startLine": 116,
                    "endLine": 139,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public StreamExecGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], generateUpdateBefore boolean, needRetraction boolean, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGroupAggregate.java",
                    "startLine": 126,
                    "endLine": 138,
                    "startColumn": 9,
                    "endColumn": 30,
                    "codeElementType": "CONSTRUCTOR_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 112,
                    "endLine": 121,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata>"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 114,
                    "endLine": 120,
                    "startColumn": 9,
                    "endColumn": 37,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGroupAggregate.java",
                    "startLine": 116,
                    "endLine": 141,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public StreamExecGroupAggregate(tableConfig ReadableConfig, grouping int[], aggCalls AggregateCall[], aggCallNeedRetractions boolean[], generateUpdateBefore boolean, needRetraction boolean, stateTtlFromHint Long, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecGroupAggregate.java",
                    "startLine": 136,
                    "endLine": 137,
                    "startColumn": 17,
                    "endColumn": 67,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "StateMetadata.getOneInputOperatorDefaultMeta(stateTtlFromHint,tableConfig,STATE_NAME)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 29,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "f32b2a9e347d7539819a88252e4e32deba247515",
        "url": "https://github.com/apache/flink/commit/f32b2a9e347d7539819a88252e4e32deba247515",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata> extracted from public StreamExecIncrementalGroupAggregate(tableConfig ReadableConfig, partialAggGrouping int[], finalAggGrouping int[], partialOriginalAggCalls AggregateCall[], partialAggCallNeedRetractions boolean[], partialLocalAggInputType RowType, partialAggNeedRetraction boolean, inputProperty InputProperty, outputType RowType, description String) in class org.apache.flink.table.planner.plan.nodes.exec.stream.StreamExecIncrementalGroupAggregate & moved to class org.apache.flink.table.planner.plan.nodes.exec.StateMetadata",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecIncrementalGroupAggregate.java",
                    "startLine": 121,
                    "endLine": 147,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public StreamExecIncrementalGroupAggregate(tableConfig ReadableConfig, partialAggGrouping int[], finalAggGrouping int[], partialOriginalAggCalls AggregateCall[], partialAggCallNeedRetractions boolean[], partialLocalAggInputType RowType, partialAggNeedRetraction boolean, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecIncrementalGroupAggregate.java",
                    "startLine": 132,
                    "endLine": 146,
                    "startColumn": 9,
                    "endColumn": 30,
                    "codeElementType": "CONSTRUCTOR_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 112,
                    "endLine": 121,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getOneInputOperatorDefaultMeta(stateTtlFromHint Long, tableConfig ReadableConfig, stateName String) : List<StateMetadata>"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/StateMetadata.java",
                    "startLine": 114,
                    "endLine": 120,
                    "startColumn": 9,
                    "endColumn": 37,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecIncrementalGroupAggregate.java",
                    "startLine": 121,
                    "endLine": 149,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public StreamExecIncrementalGroupAggregate(tableConfig ReadableConfig, partialAggGrouping int[], finalAggGrouping int[], partialOriginalAggCalls AggregateCall[], partialAggCallNeedRetractions boolean[], partialLocalAggInputType RowType, partialAggNeedRetraction boolean, stateTtlFromHint Long, inputProperty InputProperty, outputType RowType, description String)"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/plan/nodes/exec/stream/StreamExecIncrementalGroupAggregate.java",
                    "startLine": 144,
                    "endLine": 145,
                    "startColumn": 17,
                    "endColumn": 67,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "StateMetadata.getOneInputOperatorDefaultMeta(stateTtlFromHint,tableConfig,STATE_NAME)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 30,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "cd9a9f76cbc3a288abd49ba12c0edba3ce208ec7",
        "url": "https://github.com/apache/flink/commit/cd9a9f76cbc3a288abd49ba12c0edba3ce208ec7",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public of(environment Environment) : SubtaskKey extracted from public FsMergingCheckpointStorageAccess(fs FileSystem, checkpointBaseDirectory Path, defaultSavepointDirectory Path, jobId JobID, fileSizeThreshold int, writeBufferSize int, fileMergingSnapshotManager FileMergingSnapshotManager, environment Environment) in class org.apache.flink.runtime.state.filesystem.FsMergingCheckpointStorageAccess & moved to class org.apache.flink.runtime.checkpoint.filemerging.FileMergingSnapshotManager.SubtaskKey",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsMergingCheckpointStorageAccess.java",
                    "startLine": 44,
                    "endLine": 67,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public FsMergingCheckpointStorageAccess(fs FileSystem, checkpointBaseDirectory Path, defaultSavepointDirectory Path, jobId JobID, fileSizeThreshold int, writeBufferSize int, fileMergingSnapshotManager FileMergingSnapshotManager, environment Environment)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsMergingCheckpointStorageAccess.java",
                    "startLine": 63,
                    "endLine": 66,
                    "startColumn": 9,
                    "endColumn": 52,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/filemerging/FileMergingSnapshotManager.java",
                    "startLine": 181,
                    "endLine": 185,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public of(environment Environment) : SubtaskKey"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/filemerging/FileMergingSnapshotManager.java",
                    "startLine": 182,
                    "endLine": 184,
                    "startColumn": 13,
                    "endColumn": 48,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsMergingCheckpointStorageAccess.java",
                    "startLine": 43,
                    "endLine": 63,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public FsMergingCheckpointStorageAccess(fs FileSystem, checkpointBaseDirectory Path, defaultSavepointDirectory Path, jobId JobID, fileSizeThreshold int, writeBufferSize int, fileMergingSnapshotManager FileMergingSnapshotManager, environment Environment)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/filesystem/FsMergingCheckpointStorageAccess.java",
                    "startLine": 62,
                    "endLine": 62,
                    "startColumn": 27,
                    "endColumn": 53,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "SubtaskKey.of(environment)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 31,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "21306f4f5dbcc72a2cde2f15e6c072951aa03f49",
        "url": "https://github.com/apache/flink/commit/21306f4f5dbcc72a2cde2f15e6c072951aa03f49",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method private deleteBaseDirectory(baseDirectory String) : void extracted from public close() : void in class org.apache.flink.python.env.AbstractPythonEnvironmentManager.PythonLeasedResource & moved to class org.apache.flink.python.env.AbstractPythonEnvironmentManager",
            "leftSideLocations": [
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 476,
                    "endLine": 501,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public close() : void"
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 478,
                    "endLine": 478,
                    "startColumn": 13,
                    "endColumn": 29,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 481,
                    "endLine": 481,
                    "startColumn": 21,
                    "endColumn": 72,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 482,
                    "endLine": 482,
                    "startColumn": 21,
                    "endColumn": 27,
                    "codeElementType": "BREAK_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 484,
                    "endLine": 484,
                    "startColumn": 21,
                    "endColumn": 31,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 486,
                    "endLine": 490,
                    "startColumn": 25,
                    "endColumn": 36,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 492,
                    "endLine": 496,
                    "startColumn": 25,
                    "endColumn": 36,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 497,
                    "endLine": 497,
                    "startColumn": 25,
                    "endColumn": 31,
                    "codeElementType": "BREAK_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 480,
                    "endLine": 499,
                    "startColumn": 17,
                    "endColumn": 18,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 485,
                    "endLine": 498,
                    "startColumn": 21,
                    "endColumn": 22,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 483,
                    "endLine": 499,
                    "startColumn": 19,
                    "endColumn": 18,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 479,
                    "endLine": 500,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "WHILE_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 485,
                    "endLine": 491,
                    "startColumn": 68,
                    "endColumn": 22,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 491,
                    "endLine": 498,
                    "startColumn": 28,
                    "endColumn": 22,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 479,
                    "endLine": 500,
                    "startColumn": 26,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 223,
                    "endLine": 247,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "private deleteBaseDirectory(baseDirectory String) : void"
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 224,
                    "endLine": 224,
                    "startColumn": 9,
                    "endColumn": 25,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 227,
                    "endLine": 227,
                    "startColumn": 17,
                    "endColumn": 68,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 228,
                    "endLine": 228,
                    "startColumn": 17,
                    "endColumn": 23,
                    "codeElementType": "BREAK_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 230,
                    "endLine": 230,
                    "startColumn": 17,
                    "endColumn": 27,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 232,
                    "endLine": 236,
                    "startColumn": 21,
                    "endColumn": 32,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 238,
                    "endLine": 242,
                    "startColumn": 21,
                    "endColumn": 32,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 243,
                    "endLine": 243,
                    "startColumn": 21,
                    "endColumn": 27,
                    "codeElementType": "BREAK_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 226,
                    "endLine": 245,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 231,
                    "endLine": 244,
                    "startColumn": 17,
                    "endColumn": 18,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 229,
                    "endLine": 245,
                    "startColumn": 15,
                    "endColumn": 14,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 225,
                    "endLine": 246,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "WHILE_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 231,
                    "endLine": 237,
                    "startColumn": 64,
                    "endColumn": 18,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 237,
                    "endLine": 244,
                    "startColumn": 24,
                    "endColumn": 18,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 225,
                    "endLine": 246,
                    "startColumn": 22,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 509,
                    "endLine": 512,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public close() : void"
                },
                {
                    "filePath": "flink-python/src/main/java/org/apache/flink/python/env/AbstractPythonEnvironmentManager.java",
                    "startLine": 511,
                    "endLine": 511,
                    "startColumn": 13,
                    "endColumn": 47,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "deleteBaseDirectory(baseDirectory)"
                }
            ],
            "isStatic": true
        },
        "ref_id": 32,
        "extraction_results": {
            "success": true,
            "newCommitHash": "c847763a76ba9a0dccddb2c165b43bb87b81d5ff",
            "newBranchName": "extract-deleteBaseDirectory-close-3959289"
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "2e257896661ad5e0dca521fa274cad3a0bae7a61",
        "url": "https://github.com/apache/flink/commit/2e257896661ad5e0dca521fa274cad3a0bae7a61",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getMinBuffersPerGate() : int extracted from public createGateBuffersSpec(configuredMaxRequiredBuffersPerGate Optional<Integer>, configuredNetworkBuffersPerChannel int, configuredFloatingNetworkBuffersPerGate int, partitionType ResultPartitionType, numInputChannels int, enableTieredStorage boolean) : GateBuffersSpec in class org.apache.flink.runtime.io.network.partition.consumer.InputGateSpecUtils & moved to class org.apache.flink.runtime.io.network.partition.hybrid.tiered.common.TieredStorageConfiguration",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGateSpecUtils.java",
                    "startLine": 39,
                    "endLine": 75,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public createGateBuffersSpec(configuredMaxRequiredBuffersPerGate Optional<Integer>, configuredNetworkBuffersPerChannel int, configuredFloatingNetworkBuffersPerGate int, partitionType ResultPartitionType, numInputChannels int, enableTieredStorage boolean) : GateBuffersSpec"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGateSpecUtils.java",
                    "startLine": 64,
                    "endLine": 67,
                    "startColumn": 9,
                    "endColumn": 50,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGateSpecUtils.java",
                    "startLine": 64,
                    "endLine": 64,
                    "startColumn": 13,
                    "endColumn": 30,
                    "codeElementType": "SIMPLE_NAME",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java",
                    "startLine": 166,
                    "endLine": 173,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getMinBuffersPerGate() : int"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java",
                    "startLine": 172,
                    "endLine": 172,
                    "startColumn": 9,
                    "endColumn": 34,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/common/TieredStorageConfiguration.java",
                    "startLine": 172,
                    "endLine": 172,
                    "startColumn": 16,
                    "endColumn": 33,
                    "codeElementType": "SIMPLE_NAME",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGateSpecUtils.java",
                    "startLine": 38,
                    "endLine": 75,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public createGateBuffersSpec(configuredMaxRequiredBuffersPerGate Optional<Integer>, configuredNetworkBuffersPerChannel int, configuredFloatingNetworkBuffersPerGate int, partitionType ResultPartitionType, numInputChannels int, tieredStorageConfiguration TieredStorageConfiguration) : GateBuffersSpec"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/consumer/InputGateSpecUtils.java",
                    "startLine": 66,
                    "endLine": 66,
                    "startColumn": 27,
                    "endColumn": 76,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "tieredStorageConfiguration.getMinBuffersPerGate()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 33,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88138d08e731d3084d59bf14cc2fb51bdf4afbd8",
        "url": "https://github.com/apache/flink/commit/88138d08e731d3084d59bf14cc2fb51bdf4afbd8",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public builder() : TestingBufferPool.Builder extracted from package testOnUpstreamBlockedAndResumed() : void in class org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannelTest & moved to class org.apache.flink.runtime.io.network.buffer.TestingBufferPool",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1376,
                    "endLine": 1423,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "package testOnUpstreamBlockedAndResumed() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1378,
                    "endLine": 1378,
                    "startColumn": 9,
                    "endColumn": 57,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/TestingBufferPool.java",
                    "startLine": 130,
                    "endLine": 132,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public builder() : TestingBufferPool.Builder"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/TestingBufferPool.java",
                    "startLine": 131,
                    "endLine": 131,
                    "startColumn": 9,
                    "endColumn": 48,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1379,
                    "endLine": 1433,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "package testOnUpstreamBlockedAndResumed() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1382,
                    "endLine": 1382,
                    "startColumn": 17,
                    "endColumn": 44,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "TestingBufferPool.builder()"
                }
            ],
            "isStatic": true
        },
        "ref_id": 34,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88138d08e731d3084d59bf14cc2fb51bdf4afbd8",
        "url": "https://github.com/apache/flink/commit/88138d08e731d3084d59bf14cc2fb51bdf4afbd8",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public builder() : TestingBufferPool.Builder extracted from package testRequestBuffer() : void in class org.apache.flink.runtime.io.network.partition.consumer.RemoteInputChannelTest & moved to class org.apache.flink.runtime.io.network.buffer.TestingBufferPool",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1425,
                    "endLine": 1448,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "package testRequestBuffer() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1427,
                    "endLine": 1427,
                    "startColumn": 9,
                    "endColumn": 57,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/TestingBufferPool.java",
                    "startLine": 130,
                    "endLine": 132,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public builder() : TestingBufferPool.Builder"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/buffer/TestingBufferPool.java",
                    "startLine": 131,
                    "endLine": 131,
                    "startColumn": 9,
                    "endColumn": 48,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1435,
                    "endLine": 1465,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "package testRequestBuffer() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/consumer/RemoteInputChannelTest.java",
                    "startLine": 1438,
                    "endLine": 1438,
                    "startColumn": 17,
                    "endColumn": 44,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "TestingBufferPool.builder()"
                }
            ],
            "isStatic": true
        },
        "ref_id": 35,
        "extraction_results": {
            "success": true,
            "newCommitHash": "d03c97b06fe3bff25c9612705ec59b6894725bc9",
            "newBranchName": "extract-builder-testRequestBuffer-2e25789"
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "ed75795e97800177cb67141ab838632d5ec55bb5",
        "url": "https://github.com/apache/flink/commit/ed75795e97800177cb67141ab838632d5ec55bb5",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public isLocalRecoveryOrLocalBackupEnabled() : boolean extracted from public localStateStoreForSubtask(jobId JobID, allocationID AllocationID, jobVertexID JobVertexID, subtaskIndex int, clusterConfiguration Configuration, jobConfiguration Configuration) : TaskLocalStateStore in class org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager & moved to class org.apache.flink.runtime.state.LocalRecoveryConfig",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 123,
                    "endLine": 225,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public localStateStoreForSubtask(jobId JobID, allocationID AllocationID, jobVertexID JobVertexID, subtaskIndex int, clusterConfiguration Configuration, jobConfiguration Configuration) : TaskLocalStateStore"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 161,
                    "endLine": 161,
                    "startColumn": 21,
                    "endColumn": 41,
                    "codeElementType": "IF_STATEMENT_CONDITION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 161,
                    "endLine": 161,
                    "startColumn": 21,
                    "endColumn": 41,
                    "codeElementType": "SIMPLE_NAME",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/LocalRecoveryConfig.java",
                    "startLine": 65,
                    "endLine": 67,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public isLocalRecoveryOrLocalBackupEnabled() : boolean"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/LocalRecoveryConfig.java",
                    "startLine": 66,
                    "endLine": 66,
                    "startColumn": 9,
                    "endColumn": 59,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/LocalRecoveryConfig.java",
                    "startLine": 66,
                    "endLine": 66,
                    "startColumn": 16,
                    "endColumn": 36,
                    "codeElementType": "SIMPLE_NAME",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 128,
                    "endLine": 230,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public localStateStoreForSubtask(jobId JobID, allocationID AllocationID, jobVertexID JobVertexID, subtaskIndex int, clusterConfiguration Configuration, jobConfiguration Configuration) : TaskLocalStateStore"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 184,
                    "endLine": 184,
                    "startColumn": 21,
                    "endColumn": 78,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "localRecoveryConfig.isLocalRecoveryOrLocalBackupEnabled()"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/state/TaskExecutorLocalStateStoresManager.java",
                    "startLine": 193,
                    "endLine": 193,
                    "startColumn": 28,
                    "endColumn": 85,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "localRecoveryConfig.isLocalRecoveryOrLocalBackupEnabled()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 36,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "294084872604d599c1e2c52302ce0f08bb0e6492",
        "url": "https://github.com/apache/flink/commit/294084872604d599c1e2c52302ce0f08bb0e6492",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public handleRequest(state State, type StateRequestType, payload IN) : InternalStateFuture<OUT> extracted from public asyncClear() : StateFuture<Void> in class org.apache.flink.runtime.taskprocessing.AsyncExecutionControllerTest.TestValueState & moved to class org.apache.flink.runtime.asyncprocessing.AsyncExecutionController",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 204,
                    "endLine": 213,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public asyncClear() : StateFuture<Void>"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 212,
                    "endLine": 212,
                    "startColumn": 13,
                    "endColumn": 32,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 128,
                    "endLine": 152,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public handleRequest(state State, type StateRequestType, payload IN) : InternalStateFuture<OUT>"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 151,
                    "endLine": 151,
                    "startColumn": 9,
                    "endColumn": 28,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 248,
                    "endLine": 251,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public asyncClear() : StateFuture<Void>"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 250,
                    "endLine": 250,
                    "startColumn": 20,
                    "endColumn": 94,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "asyncExecutionController.handleRequest(this,StateRequestType.CLEAR,null)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 140,
                    "endLine": 140,
                    "startColumn": 9,
                    "endColumn": 90,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 141,
                    "endLine": 142,
                    "startColumn": 9,
                    "endColumn": 87,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 145,
                    "endLine": 145,
                    "startColumn": 13,
                    "endColumn": 41,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 147,
                    "endLine": 147,
                    "startColumn": 13,
                    "endColumn": 43,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 150,
                    "endLine": 150,
                    "startColumn": 9,
                    "endColumn": 32,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 144,
                    "endLine": 146,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 146,
                    "endLine": 148,
                    "startColumn": 16,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 144,
                    "endLine": 148,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 37,
        "extraction_results": {
            "success": false
        },
        "telemetry": {
            "id": "1d6bfd18-9e23-424f-943e-2318544b0b63",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 242,
                "lineStart": 39,
                "lineEnd": 280,
                "bodyLineStart": 39,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                "sourceCode": "/** Test for {@link AsyncExecutionController}. */\nclass AsyncExecutionControllerTest {\n\n    // todo(20240330): this test is not completed, cause the order preservation is not implemented\n    // yet, just for illustrating the interaction between AEC and Async state API.\n    @Test\n    void testStateOrder() {\n        AsyncExecutionController aec =\n                new AsyncExecutionController<>(\n                        new SyncMailboxExecutor(), new TestStateExecutor(), 3);\n        TestUnderlyingState underlyingState = new TestUnderlyingState();\n        TestValueState valueState = new TestValueState(aec, underlyingState);\n        AtomicInteger output = new AtomicInteger();\n        Consumer<Void> userCode =\n                empty ->\n                        valueState\n                                .asyncValue()\n                                .thenAccept(\n                                        val -> {\n                                            if (val == null) {\n                                                valueState\n                                                        .asyncUpdate(1)\n                                                        .thenAccept(o -> output.set(1));\n                                            } else {\n                                                valueState\n                                                        .asyncUpdate(val + 1)\n                                                        .thenAccept(o -> output.set(val + 1));\n                                            }\n                                        });\n\n        // ============================ element1 ============================\n        String record1 = \"key1-r1\";\n        String key1 = \"key1\";\n        // Simulate the wrapping in {@link RecordProcessorUtils#getRecordProcessor()}, wrapping the\n        // record and key with RecordContext.\n        RecordContext<String, String> recordContext1 = new RecordContext<>(record1, key1);\n        valueState.setCurrentRecordCtx(recordContext1);\n        // execute user code\n        userCode.accept(null);\n        recordContext1.release();\n        assertThat(output.get()).isEqualTo(1);\n\n        // ============================ element2 ============================\n        String record2 = \"key1-r2\";\n        String key2 = \"key1\";\n        RecordContext<String, String> recordContext2 = new RecordContext<>(record2, key2);\n        valueState.setCurrentRecordCtx(recordContext2);\n        // execute user code\n        userCode.accept(null);\n        recordContext2.release();\n        assertThat(output.get()).isEqualTo(2);\n\n        // ============================ element3 ============================\n        String record3 = \"key3-r3\";\n        String key3 = \"key3\";\n        RecordContext<String, String> recordContext3 = new RecordContext<>(record3, key3);\n        valueState.setCurrentRecordCtx(recordContext3);\n        // execute user code\n        userCode.accept(null);\n        recordContext3.release();\n        assertThat(output.get()).isEqualTo(1);\n    }\n\n    class TestRequestParameter implements ProcessingRequest.Parameter<String> {\n        private String key;\n        private Integer value;\n\n        public TestRequestParameter(String key) {\n            this(key, null);\n        }\n\n        public TestRequestParameter(String key, Integer value) {\n            this.key = key;\n            this.value = value;\n        }\n\n        @Override\n        public Optional<String> getKey() {\n            return key == null ? Optional.empty() : Optional.of(key);\n        }\n\n        @Override\n        public Optional<?> getValue() {\n            return value == null ? Optional.empty() : Optional.of(value);\n        }\n    }\n\n    /** Simulate the underlying state that is actually used to execute the request. */\n    class TestUnderlyingState {\n\n        private HashMap<String, Integer> hashMap;\n\n        public TestUnderlyingState() {\n            this.hashMap = new HashMap<>();\n        }\n\n        public Integer get(String key) {\n            return hashMap.get(key);\n        }\n\n        public void update(String key, Integer val) {\n            hashMap.put(key, val);\n        }\n    }\n\n    class TestProcessingRequest<OUT> implements ProcessingRequest<OUT> {\n\n        private TestUnderlyingState underlyingState;\n\n        private TestRequestParameter requestParameter;\n\n        private RequestType requestType;\n\n        private InternalStateFuture<OUT> stateFuture;\n\n        public TestProcessingRequest(\n                TestUnderlyingState underlyingState,\n                TestRequestParameter parameter,\n                RequestType requestType,\n                InternalStateFuture<OUT> stateFuture) {\n            this.underlyingState = underlyingState;\n            this.requestParameter = parameter;\n            this.requestType = requestType;\n            this.stateFuture = stateFuture;\n        }\n\n        @Override\n        public Optional<TestUnderlyingState> getUnderlyingState() {\n            if (requestType == RequestType.SYNC) {\n                return Optional.empty();\n            }\n            return Optional.of(underlyingState);\n        }\n\n        @Override\n        public Parameter getParameter() {\n            return requestParameter;\n        }\n\n        @Override\n        public StateFuture<OUT> getFuture() {\n            return stateFuture;\n        }\n\n        @Override\n        public RequestType getRequestType() {\n            return requestType;\n        }\n    }\n\n    class TestValueState implements ValueState<Integer> {\n\n        private AsyncExecutionController asyncExecutionController;\n\n        private TestUnderlyingState underlyingState;\n\n        private StateFutureImpl.CallbackRunner runner = Runnable::run;\n\n        private RecordContext<String, String> currentRecordCtx;\n\n        public TestValueState(AsyncExecutionController aec, TestUnderlyingState underlyingState) {\n            this.asyncExecutionController = aec;\n            this.underlyingState = underlyingState;\n        }\n\n        @Override\n        public StateFuture<Void> asyncClear() {\n            StateFutureImpl<Void> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter = new TestRequestParameter(currentRecordCtx.getKey());\n            ProcessingRequest<Void> request =\n                    new TestProcessingRequest<Void>(\n                            underlyingState, parameter, RequestType.DELETE, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        @Override\n        public StateFuture<Integer> asyncValue() {\n            StateFutureImpl<Integer> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter = new TestRequestParameter(currentRecordCtx.getKey());\n            ProcessingRequest<Integer> request =\n                    new TestProcessingRequest<>(\n                            underlyingState, parameter, RequestType.GET, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        @Override\n        public StateFuture<Void> asyncUpdate(Integer value) {\n            StateFutureImpl<Void> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter =\n                    new TestRequestParameter(currentRecordCtx.getKey(), value);\n            ProcessingRequest<Void> request =\n                    new TestProcessingRequest<Void>(\n                            underlyingState, parameter, RequestType.PUT, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        public void setCurrentRecordCtx(RecordContext<String, String> recordCtx) {\n            this.currentRecordCtx = recordCtx;\n        }\n    }\n\n    /**\n     * A brief implementation of {@link StateExecutor}, to illustrate the interaction between AEC\n     * and StateExecutor.\n     */\n    class TestStateExecutor implements StateExecutor {\n\n        public TestStateExecutor() {}\n\n        @Override\n        public CompletableFuture<Boolean> executeBatchRequests(\n                Iterable<ProcessingRequest<?>> processingRequests) {\n            CompletableFuture<Boolean> future = new CompletableFuture<>();\n            for (ProcessingRequest request : processingRequests) {\n                if (request.getRequestType() == RequestType.GET) {\n                    Preconditions.checkState(request.getUnderlyingState().isPresent());\n                    TestUnderlyingState underlyingState =\n                            (TestUnderlyingState) request.getUnderlyingState().get();\n                    Integer val =\n                            underlyingState.get(\n                                    ((TestRequestParameter) request.getParameter()).getKey().get());\n                    ((StateFutureImpl<Integer>) request.getFuture()).complete(val);\n                } else if (request.getRequestType() == RequestType.PUT) {\n                    Preconditions.checkState(request.getUnderlyingState().isPresent());\n                    TestUnderlyingState underlyingState =\n                            (TestUnderlyingState) request.getUnderlyingState().get();\n                    TestRequestParameter parameter = (TestRequestParameter) request.getParameter();\n                    underlyingState.update(\n                            parameter.getKey().get(), (Integer) parameter.getValue().get());\n                    ((StateFutureImpl<Void>) request.getFuture()).complete(null);\n                } else {\n                    throw new UnsupportedOperationException(\"Unsupported request type\");\n                }\n            }\n            future.complete(true);\n            return future;\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 1,
                "candidates": [
                    {
                        "lineStart": 237,
                        "lineEnd": 239,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method setCurrentRecordCtx to class CallbackRunner",
                        "description": "Move method setCurrentRecordCtx to org.apache.flink.core.state.StateFutureImpl.CallbackRunner\nRationale: The method setCurrentRecordCtx likely deals with managing the context of a record during a callback operation, making it more relevant to the CallbackRunner class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    }
                ]
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        }
                    ],
                    "llm_response_time": 6331
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        }
                    ],
                    "llm_response_time": 6833
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is directly related to the operations of the TestValueState and should be encapsulated within that class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is responsible for retrieving the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is related to updating the value state and should be encapsulated within the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the execution of batch requests and should be part of the TestStateExecutor class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getUnderlyingState() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getParameter",
                            "method_signature": "public Parameter getParameter()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getParameter() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getFuture",
                            "method_signature": "public StateFuture<OUT> getFuture()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getFuture() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getRequestType",
                            "method_signature": "public RequestType getRequestType()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getRequestType() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        }
                    ],
                    "llm_response_time": 7720
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        },
                        {
                            "method_name": "getParameter",
                            "method_signature": "public Parameter getParameter()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getParameter() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getFuture",
                            "method_signature": "public StateFuture<OUT> getFuture()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getFuture() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getRequestType",
                            "method_signature": "public RequestType getRequestType()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getRequestType() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "setCurrentRecordCtx",
                    "getUnderlyingState",
                    "update",
                    "asyncClear",
                    "asyncValue",
                    "asyncUpdate",
                    "executeBatchRequests",
                    "getParameter",
                    "getFuture",
                    "getRequestType"
                ],
                "llm_response_time": 932
            },
            "targetClassMap": {
                "setCurrentRecordCtx": {
                    "target_classes": [
                        {
                            "class_name": "TestUnderlyingState",
                            "similarity_score": 0.4539796922502258
                        },
                        {
                            "class_name": "CallbackRunner",
                            "similarity_score": 0.2637521893583148
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "CallbackRunner",
                        "TestUnderlyingState"
                    ],
                    "llm_response_time": 2083,
                    "similarity_computation_time": 15,
                    "similarity_metric": "cosine"
                },
                "getUnderlyingState": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1904,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "update": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1372,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncClear": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1951,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncValue": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 3278,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncUpdate": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 3311,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "executeBatchRequests": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1512,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getParameter": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1438,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getFuture": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1831,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getRequestType": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2029,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "294084872604d599c1e2c52302ce0f08bb0e6492",
        "url": "https://github.com/apache/flink/commit/294084872604d599c1e2c52302ce0f08bb0e6492",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public handleRequest(state State, type StateRequestType, payload IN) : InternalStateFuture<OUT> extracted from public asyncValue() : StateFuture<Integer> in class org.apache.flink.runtime.taskprocessing.AsyncExecutionControllerTest.TestValueState & moved to class org.apache.flink.runtime.asyncprocessing.AsyncExecutionController",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 215,
                    "endLine": 224,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public asyncValue() : StateFuture<Integer>"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 223,
                    "endLine": 223,
                    "startColumn": 13,
                    "endColumn": 32,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 128,
                    "endLine": 152,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public handleRequest(state State, type StateRequestType, payload IN) : InternalStateFuture<OUT>"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 151,
                    "endLine": 151,
                    "startColumn": 9,
                    "endColumn": 28,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 253,
                    "endLine": 256,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public asyncValue() : StateFuture<Integer>"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionControllerTest.java",
                    "startLine": 255,
                    "endLine": 255,
                    "startColumn": 20,
                    "endColumn": 98,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "asyncExecutionController.handleRequest(this,StateRequestType.VALUE_GET,null)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 140,
                    "endLine": 140,
                    "startColumn": 9,
                    "endColumn": 90,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 141,
                    "endLine": 142,
                    "startColumn": 9,
                    "endColumn": 87,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 145,
                    "endLine": 145,
                    "startColumn": 13,
                    "endColumn": 41,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 147,
                    "endLine": 147,
                    "startColumn": 13,
                    "endColumn": 43,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 150,
                    "endLine": 150,
                    "startColumn": 9,
                    "endColumn": 32,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 144,
                    "endLine": 146,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 146,
                    "endLine": 148,
                    "startColumn": 16,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/asyncprocessing/AsyncExecutionController.java",
                    "startLine": 144,
                    "endLine": 148,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 38,
        "extraction_results": {
            "success": true,
            "newCommitHash": "d4246de9d95ed9c9e2679acd3b55f9fd7357c73e",
            "newBranchName": "extract-handleRequest-asyncValue-60c771b"
        },
        "telemetry": {
            "id": "1d6bfd18-9e23-424f-943e-2318544b0b63",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 242,
                "lineStart": 39,
                "lineEnd": 280,
                "bodyLineStart": 39,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-runtime/src/test/java/org/apache/flink/runtime/taskprocessing/AsyncExecutionControllerTest.java",
                "sourceCode": "/** Test for {@link AsyncExecutionController}. */\nclass AsyncExecutionControllerTest {\n\n    // todo(20240330): this test is not completed, cause the order preservation is not implemented\n    // yet, just for illustrating the interaction between AEC and Async state API.\n    @Test\n    void testStateOrder() {\n        AsyncExecutionController aec =\n                new AsyncExecutionController<>(\n                        new SyncMailboxExecutor(), new TestStateExecutor(), 3);\n        TestUnderlyingState underlyingState = new TestUnderlyingState();\n        TestValueState valueState = new TestValueState(aec, underlyingState);\n        AtomicInteger output = new AtomicInteger();\n        Consumer<Void> userCode =\n                empty ->\n                        valueState\n                                .asyncValue()\n                                .thenAccept(\n                                        val -> {\n                                            if (val == null) {\n                                                valueState\n                                                        .asyncUpdate(1)\n                                                        .thenAccept(o -> output.set(1));\n                                            } else {\n                                                valueState\n                                                        .asyncUpdate(val + 1)\n                                                        .thenAccept(o -> output.set(val + 1));\n                                            }\n                                        });\n\n        // ============================ element1 ============================\n        String record1 = \"key1-r1\";\n        String key1 = \"key1\";\n        // Simulate the wrapping in {@link RecordProcessorUtils#getRecordProcessor()}, wrapping the\n        // record and key with RecordContext.\n        RecordContext<String, String> recordContext1 = new RecordContext<>(record1, key1);\n        valueState.setCurrentRecordCtx(recordContext1);\n        // execute user code\n        userCode.accept(null);\n        recordContext1.release();\n        assertThat(output.get()).isEqualTo(1);\n\n        // ============================ element2 ============================\n        String record2 = \"key1-r2\";\n        String key2 = \"key1\";\n        RecordContext<String, String> recordContext2 = new RecordContext<>(record2, key2);\n        valueState.setCurrentRecordCtx(recordContext2);\n        // execute user code\n        userCode.accept(null);\n        recordContext2.release();\n        assertThat(output.get()).isEqualTo(2);\n\n        // ============================ element3 ============================\n        String record3 = \"key3-r3\";\n        String key3 = \"key3\";\n        RecordContext<String, String> recordContext3 = new RecordContext<>(record3, key3);\n        valueState.setCurrentRecordCtx(recordContext3);\n        // execute user code\n        userCode.accept(null);\n        recordContext3.release();\n        assertThat(output.get()).isEqualTo(1);\n    }\n\n    class TestRequestParameter implements ProcessingRequest.Parameter<String> {\n        private String key;\n        private Integer value;\n\n        public TestRequestParameter(String key) {\n            this(key, null);\n        }\n\n        public TestRequestParameter(String key, Integer value) {\n            this.key = key;\n            this.value = value;\n        }\n\n        @Override\n        public Optional<String> getKey() {\n            return key == null ? Optional.empty() : Optional.of(key);\n        }\n\n        @Override\n        public Optional<?> getValue() {\n            return value == null ? Optional.empty() : Optional.of(value);\n        }\n    }\n\n    /** Simulate the underlying state that is actually used to execute the request. */\n    class TestUnderlyingState {\n\n        private HashMap<String, Integer> hashMap;\n\n        public TestUnderlyingState() {\n            this.hashMap = new HashMap<>();\n        }\n\n        public Integer get(String key) {\n            return hashMap.get(key);\n        }\n\n        public void update(String key, Integer val) {\n            hashMap.put(key, val);\n        }\n    }\n\n    class TestProcessingRequest<OUT> implements ProcessingRequest<OUT> {\n\n        private TestUnderlyingState underlyingState;\n\n        private TestRequestParameter requestParameter;\n\n        private RequestType requestType;\n\n        private InternalStateFuture<OUT> stateFuture;\n\n        public TestProcessingRequest(\n                TestUnderlyingState underlyingState,\n                TestRequestParameter parameter,\n                RequestType requestType,\n                InternalStateFuture<OUT> stateFuture) {\n            this.underlyingState = underlyingState;\n            this.requestParameter = parameter;\n            this.requestType = requestType;\n            this.stateFuture = stateFuture;\n        }\n\n        @Override\n        public Optional<TestUnderlyingState> getUnderlyingState() {\n            if (requestType == RequestType.SYNC) {\n                return Optional.empty();\n            }\n            return Optional.of(underlyingState);\n        }\n\n        @Override\n        public Parameter getParameter() {\n            return requestParameter;\n        }\n\n        @Override\n        public StateFuture<OUT> getFuture() {\n            return stateFuture;\n        }\n\n        @Override\n        public RequestType getRequestType() {\n            return requestType;\n        }\n    }\n\n    class TestValueState implements ValueState<Integer> {\n\n        private AsyncExecutionController asyncExecutionController;\n\n        private TestUnderlyingState underlyingState;\n\n        private StateFutureImpl.CallbackRunner runner = Runnable::run;\n\n        private RecordContext<String, String> currentRecordCtx;\n\n        public TestValueState(AsyncExecutionController aec, TestUnderlyingState underlyingState) {\n            this.asyncExecutionController = aec;\n            this.underlyingState = underlyingState;\n        }\n\n        @Override\n        public StateFuture<Void> asyncClear() {\n            StateFutureImpl<Void> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter = new TestRequestParameter(currentRecordCtx.getKey());\n            ProcessingRequest<Void> request =\n                    new TestProcessingRequest<Void>(\n                            underlyingState, parameter, RequestType.DELETE, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        @Override\n        public StateFuture<Integer> asyncValue() {\n            StateFutureImpl<Integer> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter = new TestRequestParameter(currentRecordCtx.getKey());\n            ProcessingRequest<Integer> request =\n                    new TestProcessingRequest<>(\n                            underlyingState, parameter, RequestType.GET, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        @Override\n        public StateFuture<Void> asyncUpdate(Integer value) {\n            StateFutureImpl<Void> stateFuture = new StateFutureImpl<>(runner);\n            TestRequestParameter parameter =\n                    new TestRequestParameter(currentRecordCtx.getKey(), value);\n            ProcessingRequest<Void> request =\n                    new TestProcessingRequest<Void>(\n                            underlyingState, parameter, RequestType.PUT, stateFuture);\n            asyncExecutionController.handleProcessingRequest(request, currentRecordCtx);\n            return stateFuture;\n        }\n\n        public void setCurrentRecordCtx(RecordContext<String, String> recordCtx) {\n            this.currentRecordCtx = recordCtx;\n        }\n    }\n\n    /**\n     * A brief implementation of {@link StateExecutor}, to illustrate the interaction between AEC\n     * and StateExecutor.\n     */\n    class TestStateExecutor implements StateExecutor {\n\n        public TestStateExecutor() {}\n\n        @Override\n        public CompletableFuture<Boolean> executeBatchRequests(\n                Iterable<ProcessingRequest<?>> processingRequests) {\n            CompletableFuture<Boolean> future = new CompletableFuture<>();\n            for (ProcessingRequest request : processingRequests) {\n                if (request.getRequestType() == RequestType.GET) {\n                    Preconditions.checkState(request.getUnderlyingState().isPresent());\n                    TestUnderlyingState underlyingState =\n                            (TestUnderlyingState) request.getUnderlyingState().get();\n                    Integer val =\n                            underlyingState.get(\n                                    ((TestRequestParameter) request.getParameter()).getKey().get());\n                    ((StateFutureImpl<Integer>) request.getFuture()).complete(val);\n                } else if (request.getRequestType() == RequestType.PUT) {\n                    Preconditions.checkState(request.getUnderlyingState().isPresent());\n                    TestUnderlyingState underlyingState =\n                            (TestUnderlyingState) request.getUnderlyingState().get();\n                    TestRequestParameter parameter = (TestRequestParameter) request.getParameter();\n                    underlyingState.update(\n                            parameter.getKey().get(), (Integer) parameter.getValue().get());\n                    ((StateFutureImpl<Void>) request.getFuture()).complete(null);\n                } else {\n                    throw new UnsupportedOperationException(\"Unsupported request type\");\n                }\n            }\n            future.complete(true);\n            return future;\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 1,
                "candidates": [
                    {
                        "lineStart": 237,
                        "lineEnd": 239,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method setCurrentRecordCtx to class CallbackRunner",
                        "description": "Move method setCurrentRecordCtx to org.apache.flink.core.state.StateFutureImpl.CallbackRunner\nRationale: The method setCurrentRecordCtx likely deals with managing the context of a record during a callback operation, making it more relevant to the CallbackRunner class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    }
                ]
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        }
                    ],
                    "llm_response_time": 6331
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        }
                    ],
                    "llm_response_time": 6833
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is directly related to the operations of the TestValueState and should be encapsulated within that class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is responsible for retrieving the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is related to updating the value state and should be encapsulated within the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the execution of batch requests and should be part of the TestStateExecutor class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getUnderlyingState() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getParameter",
                            "method_signature": "public Parameter getParameter()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getParameter() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getFuture",
                            "method_signature": "public StateFuture<OUT> getFuture()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getFuture() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getRequestType",
                            "method_signature": "public RequestType getRequestType()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getRequestType() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        }
                    ],
                    "llm_response_time": 7720
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "setCurrentRecordCtx",
                            "method_signature": "public void setCurrentRecordCtx(RecordContext<String, String> recordCtx)",
                            "target_class": "TestValueState",
                            "rationale": "The method setCurrentRecordCtx() is specific to managing the current record context for the value state and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "getUnderlyingState",
                            "method_signature": "public Optional<TestUnderlyingState> getUnderlyingState()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The method getUnderlyingState() is directly related to the processing request and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "update",
                            "method_signature": "public void update(String key, Integer val)",
                            "target_class": "TestUnderlyingState",
                            "rationale": "The update() method is responsible for modifying the underlying state and should be part of the TestUnderlyingState class."
                        },
                        {
                            "method_name": "asyncClear",
                            "method_signature": "public StateFuture<Void> asyncClear()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncClear() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncValue",
                            "method_signature": "public StateFuture<Integer> asyncValue()",
                            "target_class": "TestValueState",
                            "rationale": "The asyncValue() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "asyncUpdate",
                            "method_signature": "public StateFuture<Void> asyncUpdate(Integer value)",
                            "target_class": "TestValueState",
                            "rationale": "The asyncUpdate() method is specific to the value state operations and should be part of the TestValueState class."
                        },
                        {
                            "method_name": "executeBatchRequests",
                            "method_signature": "public CompletableFuture<Boolean> executeBatchRequests(Iterable<ProcessingRequest<?>> processingRequests)",
                            "target_class": "TestStateExecutor",
                            "rationale": "The executeBatchRequests() method is specific to the state execution logic and should be part of the TestStateExecutor class."
                        },
                        {
                            "method_name": "getParameter",
                            "method_signature": "public Parameter getParameter()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getParameter() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getFuture",
                            "method_signature": "public StateFuture<OUT> getFuture()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getFuture() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        },
                        {
                            "method_name": "getRequestType",
                            "method_signature": "public RequestType getRequestType()",
                            "target_class": "TestProcessingRequest",
                            "rationale": "The getRequestType() method is specific to processing requests and should be part of the TestProcessingRequest class."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "setCurrentRecordCtx",
                    "getUnderlyingState",
                    "update",
                    "asyncClear",
                    "asyncValue",
                    "asyncUpdate",
                    "executeBatchRequests",
                    "getParameter",
                    "getFuture",
                    "getRequestType"
                ],
                "llm_response_time": 932
            },
            "targetClassMap": {
                "setCurrentRecordCtx": {
                    "target_classes": [
                        {
                            "class_name": "TestUnderlyingState",
                            "similarity_score": 0.4539796922502258
                        },
                        {
                            "class_name": "CallbackRunner",
                            "similarity_score": 0.2637521893583148
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "CallbackRunner",
                        "TestUnderlyingState"
                    ],
                    "llm_response_time": 2083,
                    "similarity_computation_time": 15,
                    "similarity_metric": "cosine"
                },
                "getUnderlyingState": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1904,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "update": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1372,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncClear": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1951,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncValue": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 3278,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "asyncUpdate": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 3311,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "executeBatchRequests": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1512,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getParameter": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1438,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getFuture": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1831,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getRequestType": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2029,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "b3fdb07c04114c515cfc5893e89528bbfb4384ed",
        "url": "https://github.com/apache/flink/commit/b3fdb07c04114c515cfc5893e89528bbfb4384ed",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getFileFromTargetDir(cls Class<?>, fileFilter Predicate<Path>) : File extracted from private getFlinkClientsJar() : File in class org.apache.flink.client.program.artifact.ArtifactFetchManagerTest & moved to class org.apache.flink.testutils.TestingUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 231,
                    "endLine": 251,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private getFlinkClientsJar() : File"
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 248,
                    "endLine": 248,
                    "startColumn": 9,
                    "endColumn": 43,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 250,
                    "endLine": 250,
                    "startColumn": 9,
                    "endColumn": 52,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 232,
                    "endLine": 237,
                    "startColumn": 9,
                    "endColumn": 36,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 238,
                    "endLine": 238,
                    "startColumn": 9,
                    "endColumn": 60,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 240,
                    "endLine": 246,
                    "startColumn": 9,
                    "endColumn": 90,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 77,
                    "endLine": 87,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getFileFromTargetDir(cls Class<?>, fileFilter Predicate<Path>) : File"
                },
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 84,
                    "endLine": 84,
                    "startColumn": 9,
                    "endColumn": 43,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 86,
                    "endLine": 86,
                    "startColumn": 9,
                    "endColumn": 52,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 79,
                    "endLine": 79,
                    "startColumn": 9,
                    "endColumn": 98,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 80,
                    "endLine": 80,
                    "startColumn": 9,
                    "endColumn": 66,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/test/java/org/apache/flink/testutils/TestingUtils.java",
                    "startLine": 82,
                    "endLine": 83,
                    "startColumn": 9,
                    "endColumn": 96,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 221,
                    "endLine": 228,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "private getFlinkClientsJar() : File"
                },
                {
                    "filePath": "flink-clients/src/test/java/org/apache/flink/client/program/artifact/ArtifactFetchManagerTest.java",
                    "startLine": 222,
                    "endLine": 227,
                    "startColumn": 16,
                    "endColumn": 81,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "TestingUtils.getFileFromTargetDir(ArtifactFetchManager.class,p -> org.apache.flink.util.FileUtils.isJarFile(p) && p.toFile().getName().startsWith(\"flink-clients\") && !p.toFile().getName().contains(\"test-utils\"))"
                }
            ],
            "isStatic": true
        },
        "ref_id": 39,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public valueIsNull() : boolean extracted from public process() : CompletableFuture<Void> in class org.apache.flink.state.forst.ForStWriteBatchOperation & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 61,
                    "endLine": 87,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 69,
                    "endLine": 69,
                    "startColumn": 33,
                    "endColumn": 54,
                    "codeElementType": "IF_STATEMENT_CONDITION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 50,
                    "endLine": 52,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public valueIsNull() : boolean"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 51,
                    "endLine": 51,
                    "startColumn": 9,
                    "endColumn": 30,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 54,
                    "endLine": 82,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 61,
                    "endLine": 61,
                    "startColumn": 33,
                    "endColumn": 54,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.valueIsNull()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 40,
        "extraction_results": {
            "success": true,
            "newCommitHash": "88fa5edf85dcede4c745c035fb53ec6e11ea1512",
            "newBranchName": "extract-valueIsNull-process-ffa3869"
        },
        "telemetry": {
            "id": "ce22ca78-8389-46bc-a109-e64a67136706",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 82,
                "lineStart": 32,
                "lineEnd": 113,
                "bodyLineStart": 32,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                "sourceCode": "/**\n * The writeBatch operation implementation for ForStDB.\n *\n * @param <K> The type of key in put access request.\n * @param <V> The type of value in put access request.\n */\npublic class ForStWriteBatchOperation<K, V> implements ForStDBOperation<Void> {\n\n    private static final int PER_RECORD_ESTIMATE_BYTES = 100;\n\n    private final RocksDB db;\n\n    private final List<PutRequest<K, V>> batchRequest;\n\n    private final WriteOptions writeOptions;\n\n    private final Executor executor;\n\n    ForStWriteBatchOperation(\n            RocksDB db,\n            List<PutRequest<K, V>> batchRequest,\n            WriteOptions writeOptions,\n            Executor executor) {\n        this.db = db;\n        this.batchRequest = batchRequest;\n        this.writeOptions = writeOptions;\n        this.executor = executor;\n    }\n\n    @Override\n    public CompletableFuture<Void> process() {\n        return CompletableFuture.runAsync(\n                () -> {\n                    try (WriteBatch writeBatch =\n                            new WriteBatch(batchRequest.size() * PER_RECORD_ESTIMATE_BYTES)) {\n                        for (PutRequest<K, V> request : batchRequest) {\n                            ForStInnerTable<K, V> table = request.table;\n                            if (valueIsNull(request)) {\n                                // put(key, null) == delete(key)\n                                writeBatch.delete(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key));\n                            } else {\n                                writeBatch.put(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key),\n                                        table.serializeValue(request.value));\n                            }\n                        }\n                        db.write(writeOptions, writeBatch);\n                    } catch (Exception e) {\n                        throw new CompletionException(\"Error while adding data to ForStDB\", e);\n                    }\n                },\n                executor);\n    }\n\n    private boolean valueIsNull(PutRequest<K, V> request) {\n        return request.value == null;\n    }\n\n    /** The Put access request for ForStDB. */\n    static class PutRequest<K, V> {\n        final K key;\n        @Nullable final V value;\n        final ForStInnerTable<K, V> table;\n\n        private PutRequest(K key, V value, ForStInnerTable<K, V> table) {\n            this.key = key;\n            this.value = value;\n            this.table = table;\n        }\n\n        /**\n         * If the value of the PutRequest is null, then the request will signify the deletion of the\n         * data associated with that key.\n         */\n        static <K, V> PutRequest<K, V> of(K key, @Nullable V value, ForStInnerTable<K, V> table) {\n            return new PutRequest<>(key, value, table);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 7590
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1604
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1786
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1890
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "valueIsNull"
                ],
                "llm_response_time": 556
            },
            "targetClassMap": {
                "valueIsNull": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1638,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getColumnFamilyHandle() : ColumnFamilyHandle extracted from public process() : CompletableFuture<Void> in class org.apache.flink.state.forst.ForStWriteBatchOperation & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 61,
                    "endLine": 87,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 71,
                    "endLine": 73,
                    "startColumn": 33,
                    "endColumn": 74,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 72,
                    "endLine": 72,
                    "startColumn": 41,
                    "endColumn": 70,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 54,
                    "endLine": 56,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getColumnFamilyHandle() : ColumnFamilyHandle"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 9,
                    "endColumn": 46,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 16,
                    "endColumn": 45,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 54,
                    "endLine": 82,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 64,
                    "endLine": 64,
                    "startColumn": 41,
                    "endColumn": 72,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.getColumnFamilyHandle()"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 68,
                    "endLine": 68,
                    "startColumn": 41,
                    "endColumn": 72,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.getColumnFamilyHandle()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 41,
        "extraction_results": {
            "success": false
        },
        "telemetry": {
            "id": "ce22ca78-8389-46bc-a109-e64a67136706",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 82,
                "lineStart": 32,
                "lineEnd": 113,
                "bodyLineStart": 32,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                "sourceCode": "/**\n * The writeBatch operation implementation for ForStDB.\n *\n * @param <K> The type of key in put access request.\n * @param <V> The type of value in put access request.\n */\npublic class ForStWriteBatchOperation<K, V> implements ForStDBOperation<Void> {\n\n    private static final int PER_RECORD_ESTIMATE_BYTES = 100;\n\n    private final RocksDB db;\n\n    private final List<PutRequest<K, V>> batchRequest;\n\n    private final WriteOptions writeOptions;\n\n    private final Executor executor;\n\n    ForStWriteBatchOperation(\n            RocksDB db,\n            List<PutRequest<K, V>> batchRequest,\n            WriteOptions writeOptions,\n            Executor executor) {\n        this.db = db;\n        this.batchRequest = batchRequest;\n        this.writeOptions = writeOptions;\n        this.executor = executor;\n    }\n\n    @Override\n    public CompletableFuture<Void> process() {\n        return CompletableFuture.runAsync(\n                () -> {\n                    try (WriteBatch writeBatch =\n                            new WriteBatch(batchRequest.size() * PER_RECORD_ESTIMATE_BYTES)) {\n                        for (PutRequest<K, V> request : batchRequest) {\n                            ForStInnerTable<K, V> table = request.table;\n                            if (valueIsNull(request)) {\n                                // put(key, null) == delete(key)\n                                writeBatch.delete(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key));\n                            } else {\n                                writeBatch.put(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key),\n                                        table.serializeValue(request.value));\n                            }\n                        }\n                        db.write(writeOptions, writeBatch);\n                    } catch (Exception e) {\n                        throw new CompletionException(\"Error while adding data to ForStDB\", e);\n                    }\n                },\n                executor);\n    }\n\n    private boolean valueIsNull(PutRequest<K, V> request) {\n        return request.value == null;\n    }\n\n    /** The Put access request for ForStDB. */\n    static class PutRequest<K, V> {\n        final K key;\n        @Nullable final V value;\n        final ForStInnerTable<K, V> table;\n\n        private PutRequest(K key, V value, ForStInnerTable<K, V> table) {\n            this.key = key;\n            this.value = value;\n            this.table = table;\n        }\n\n        /**\n         * If the value of the PutRequest is null, then the request will signify the deletion of the\n         * data associated with that key.\n         */\n        static <K, V> PutRequest<K, V> of(K key, @Nullable V value, ForStInnerTable<K, V> table) {\n            return new PutRequest<>(key, value, table);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 7590
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1604
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1786
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1890
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "valueIsNull"
                ],
                "llm_response_time": 556
            },
            "targetClassMap": {
                "valueIsNull": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1638,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getColumnFamilyHandle() : ColumnFamilyHandle extracted from public testValueStateWriteBatch() : void in class org.apache.flink.state.forst.ForStWriteBatchOperationTest & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 35,
                    "endLine": 61,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public testValueStateWriteBatch() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 58,
                    "endLine": 58,
                    "startColumn": 13,
                    "endColumn": 81,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 58,
                    "endLine": 58,
                    "startColumn": 40,
                    "endColumn": 69,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 54,
                    "endLine": 56,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getColumnFamilyHandle() : ColumnFamilyHandle"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 9,
                    "endColumn": 46,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 16,
                    "endColumn": 45,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 35,
                    "endLine": 61,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public testValueStateWriteBatch() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 58,
                    "endLine": 58,
                    "startColumn": 40,
                    "endColumn": 71,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.getColumnFamilyHandle()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 42,
        "extraction_results": {
            "success": true,
            "newCommitHash": "8a2a51d6ebbd77751725f0e5aac85c3a964fdfb7",
            "newBranchName": "extract-getColumnFamilyHandle-testValueStateWriteBatch-ffa3869"
        },
        "telemetry": {
            "id": "5ca6fd7f-7c7e-4561-8579-d13161378a02",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 76,
                "lineStart": 33,
                "lineEnd": 108,
                "bodyLineStart": 33,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                "sourceCode": "/** Unit test for {@link ForStWriteBatchOperation}. */\npublic class ForStWriteBatchOperationTest extends ForStDBOperationTestBase {\n\n    @Test\n    public void testValueStateWriteBatch() throws Exception {\n        ForStValueState<Integer, String> valueState1 = buildForStValueState(\"test-write-batch-1\");\n        ForStValueState<Integer, String> valueState2 = buildForStValueState(\"test-write-batch-2\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(\n                    PutRequest.of(\n                            buildContextKey(i),\n                            String.valueOf(i),\n                            ((i % 2 == 0) ? valueState1 : valueState2)));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            assertThat(table.deserializeValue(valueBytes)).isEqualTo(request.value);\n        }\n    }\n\n    private byte[] getColumnFamilyHandle(\n            ForStInnerTable<ContextKey<Integer>, String> table,\n            byte[] keyBytes) throws RocksDBException {\n        byte[] valueBytes = db.get(table.getColumnFamilyHandle(), keyBytes);\n        return valueBytes;\n    }\n\n    @Test\n    public void testWriteBatchWithNullValue() throws Exception {\n        ForStValueState<Integer, String> valueState = buildForStValueState(\"test-write-batch\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        // 1. write some data without null value\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(PutRequest.of(buildContextKey(i), String.valueOf(i), valueState));\n        }\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // 2. update data with null value\n        batchPutRequest.clear();\n        for (int i = 0; i < keyNum; i++) {\n            if (i % 8 == 0) {\n                batchPutRequest.add(PutRequest.of(buildContextKey(i), null, valueState));\n            } else {\n                batchPutRequest.add(\n                        PutRequest.of(buildContextKey(i), String.valueOf(i * 2), valueState));\n            }\n        }\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation2 =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation2.process().get();\n\n        // 3.  check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            String value = (valueBytes == null) ? null : table.deserializeValue(valueBytes);\n            assertThat(value).isEqualTo(request.value);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 9074
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 2320
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStInnerTable",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the ForStInnerTable, making it more appropriate for it to reside within the ForStInnerTable class."
                        }
                    ],
                    "llm_response_time": 2073
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 1861
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "getColumnFamilyHandle"
                ],
                "llm_response_time": 664
            },
            "targetClassMap": {
                "getColumnFamilyHandle": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1945,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getColumnFamilyHandle() : ColumnFamilyHandle extracted from public testWriteBatchWithNullValue() : void in class org.apache.flink.state.forst.ForStWriteBatchOperationTest & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 63,
                    "endLine": 99,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public testWriteBatchWithNullValue() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 95,
                    "endLine": 95,
                    "startColumn": 13,
                    "endColumn": 81,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 95,
                    "endLine": 95,
                    "startColumn": 40,
                    "endColumn": 69,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 54,
                    "endLine": 56,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getColumnFamilyHandle() : ColumnFamilyHandle"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 9,
                    "endColumn": 46,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 16,
                    "endColumn": 45,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 63,
                    "endLine": 112,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public testWriteBatchWithNullValue() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 105,
                    "endLine": 105,
                    "startColumn": 40,
                    "endColumn": 71,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.getColumnFamilyHandle()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 43,
        "extraction_results": {
            "success": false
        },
        "telemetry": {
            "id": "5ca6fd7f-7c7e-4561-8579-d13161378a02",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 76,
                "lineStart": 33,
                "lineEnd": 108,
                "bodyLineStart": 33,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                "sourceCode": "/** Unit test for {@link ForStWriteBatchOperation}. */\npublic class ForStWriteBatchOperationTest extends ForStDBOperationTestBase {\n\n    @Test\n    public void testValueStateWriteBatch() throws Exception {\n        ForStValueState<Integer, String> valueState1 = buildForStValueState(\"test-write-batch-1\");\n        ForStValueState<Integer, String> valueState2 = buildForStValueState(\"test-write-batch-2\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(\n                    PutRequest.of(\n                            buildContextKey(i),\n                            String.valueOf(i),\n                            ((i % 2 == 0) ? valueState1 : valueState2)));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            assertThat(table.deserializeValue(valueBytes)).isEqualTo(request.value);\n        }\n    }\n\n    private byte[] getColumnFamilyHandle(\n            ForStInnerTable<ContextKey<Integer>, String> table,\n            byte[] keyBytes) throws RocksDBException {\n        byte[] valueBytes = db.get(table.getColumnFamilyHandle(), keyBytes);\n        return valueBytes;\n    }\n\n    @Test\n    public void testWriteBatchWithNullValue() throws Exception {\n        ForStValueState<Integer, String> valueState = buildForStValueState(\"test-write-batch\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        // 1. write some data without null value\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(PutRequest.of(buildContextKey(i), String.valueOf(i), valueState));\n        }\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // 2. update data with null value\n        batchPutRequest.clear();\n        for (int i = 0; i < keyNum; i++) {\n            if (i % 8 == 0) {\n                batchPutRequest.add(PutRequest.of(buildContextKey(i), null, valueState));\n            } else {\n                batchPutRequest.add(\n                        PutRequest.of(buildContextKey(i), String.valueOf(i * 2), valueState));\n            }\n        }\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation2 =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation2.process().get();\n\n        // 3.  check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            String value = (valueBytes == null) ? null : table.deserializeValue(valueBytes);\n            assertThat(value).isEqualTo(request.value);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 9074
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 2320
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStInnerTable",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the ForStInnerTable, making it more appropriate for it to reside within the ForStInnerTable class."
                        }
                    ],
                    "llm_response_time": 2073
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 1861
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "getColumnFamilyHandle"
                ],
                "llm_response_time": 664
            },
            "targetClassMap": {
                "getColumnFamilyHandle": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1945,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public buildSerializedKey() : byte[] extracted from public process() : CompletableFuture<Void> in class org.apache.flink.state.forst.ForStWriteBatchOperation & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 61,
                    "endLine": 87,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 71,
                    "endLine": 73,
                    "startColumn": 33,
                    "endColumn": 74,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 58,
                    "endLine": 60,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public buildSerializedKey() : byte[]"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 59,
                    "endLine": 59,
                    "startColumn": 9,
                    "endColumn": 40,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 54,
                    "endLine": 82,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public process() : CompletableFuture<Void>"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 65,
                    "endLine": 65,
                    "startColumn": 41,
                    "endColumn": 69,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.buildSerializedKey()"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                    "startLine": 69,
                    "endLine": 69,
                    "startColumn": 41,
                    "endColumn": 69,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.buildSerializedKey()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 44,
        "extraction_results": {
            "success": true,
            "newCommitHash": "1ac7ac57ced57a8d22a850e76985db7e754af2b2",
            "newBranchName": "extract-buildSerializedKey-process-ffa3869"
        },
        "telemetry": {
            "id": "ce22ca78-8389-46bc-a109-e64a67136706",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 82,
                "lineStart": 32,
                "lineEnd": 113,
                "bodyLineStart": 32,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStWriteBatchOperation.java",
                "sourceCode": "/**\n * The writeBatch operation implementation for ForStDB.\n *\n * @param <K> The type of key in put access request.\n * @param <V> The type of value in put access request.\n */\npublic class ForStWriteBatchOperation<K, V> implements ForStDBOperation<Void> {\n\n    private static final int PER_RECORD_ESTIMATE_BYTES = 100;\n\n    private final RocksDB db;\n\n    private final List<PutRequest<K, V>> batchRequest;\n\n    private final WriteOptions writeOptions;\n\n    private final Executor executor;\n\n    ForStWriteBatchOperation(\n            RocksDB db,\n            List<PutRequest<K, V>> batchRequest,\n            WriteOptions writeOptions,\n            Executor executor) {\n        this.db = db;\n        this.batchRequest = batchRequest;\n        this.writeOptions = writeOptions;\n        this.executor = executor;\n    }\n\n    @Override\n    public CompletableFuture<Void> process() {\n        return CompletableFuture.runAsync(\n                () -> {\n                    try (WriteBatch writeBatch =\n                            new WriteBatch(batchRequest.size() * PER_RECORD_ESTIMATE_BYTES)) {\n                        for (PutRequest<K, V> request : batchRequest) {\n                            ForStInnerTable<K, V> table = request.table;\n                            if (valueIsNull(request)) {\n                                // put(key, null) == delete(key)\n                                writeBatch.delete(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key));\n                            } else {\n                                writeBatch.put(\n                                        table.getColumnFamilyHandle(),\n                                        table.serializeKey(request.key),\n                                        table.serializeValue(request.value));\n                            }\n                        }\n                        db.write(writeOptions, writeBatch);\n                    } catch (Exception e) {\n                        throw new CompletionException(\"Error while adding data to ForStDB\", e);\n                    }\n                },\n                executor);\n    }\n\n    private boolean valueIsNull(PutRequest<K, V> request) {\n        return request.value == null;\n    }\n\n    /** The Put access request for ForStDB. */\n    static class PutRequest<K, V> {\n        final K key;\n        @Nullable final V value;\n        final ForStInnerTable<K, V> table;\n\n        private PutRequest(K key, V value, ForStInnerTable<K, V> table) {\n            this.key = key;\n            this.value = value;\n            this.table = table;\n        }\n\n        /**\n         * If the value of the PutRequest is null, then the request will signify the deletion of the\n         * data associated with that key.\n         */\n        static <K, V> PutRequest<K, V> of(K key, @Nullable V value, ForStInnerTable<K, V> table) {\n            return new PutRequest<>(key, value, table);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 7590
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1604
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1786
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks the value of a PutRequest instance. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 1890
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "valueIsNull",
                            "method_signature": "private boolean valueIsNull(PutRequest<K, V> request)",
                            "target_class": "PutRequest",
                            "rationale": "The valueIsNull method is directly related to the PutRequest class, as it checks if the value of a PutRequest is null. Moving it to the PutRequest class would encapsulate the logic related to the request itself."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "valueIsNull"
                ],
                "llm_response_time": 556
            },
            "targetClassMap": {
                "valueIsNull": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1638,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public buildSerializedKey() : byte[] extracted from public testValueStateWriteBatch() : void in class org.apache.flink.state.forst.ForStWriteBatchOperationTest & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 35,
                    "endLine": 61,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public testValueStateWriteBatch() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 57,
                    "endLine": 57,
                    "startColumn": 13,
                    "endColumn": 63,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 58,
                    "endLine": 60,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public buildSerializedKey() : byte[]"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 59,
                    "endLine": 59,
                    "startColumn": 9,
                    "endColumn": 40,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 35,
                    "endLine": 61,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public testValueStateWriteBatch() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 57,
                    "endLine": 57,
                    "startColumn": 31,
                    "endColumn": 59,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.buildSerializedKey()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 45,
        "extraction_results": {
            "success": false
        },
        "telemetry": {
            "id": "5ca6fd7f-7c7e-4561-8579-d13161378a02",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 76,
                "lineStart": 33,
                "lineEnd": 108,
                "bodyLineStart": 33,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                "sourceCode": "/** Unit test for {@link ForStWriteBatchOperation}. */\npublic class ForStWriteBatchOperationTest extends ForStDBOperationTestBase {\n\n    @Test\n    public void testValueStateWriteBatch() throws Exception {\n        ForStValueState<Integer, String> valueState1 = buildForStValueState(\"test-write-batch-1\");\n        ForStValueState<Integer, String> valueState2 = buildForStValueState(\"test-write-batch-2\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(\n                    PutRequest.of(\n                            buildContextKey(i),\n                            String.valueOf(i),\n                            ((i % 2 == 0) ? valueState1 : valueState2)));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            assertThat(table.deserializeValue(valueBytes)).isEqualTo(request.value);\n        }\n    }\n\n    private byte[] getColumnFamilyHandle(\n            ForStInnerTable<ContextKey<Integer>, String> table,\n            byte[] keyBytes) throws RocksDBException {\n        byte[] valueBytes = db.get(table.getColumnFamilyHandle(), keyBytes);\n        return valueBytes;\n    }\n\n    @Test\n    public void testWriteBatchWithNullValue() throws Exception {\n        ForStValueState<Integer, String> valueState = buildForStValueState(\"test-write-batch\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        // 1. write some data without null value\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(PutRequest.of(buildContextKey(i), String.valueOf(i), valueState));\n        }\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // 2. update data with null value\n        batchPutRequest.clear();\n        for (int i = 0; i < keyNum; i++) {\n            if (i % 8 == 0) {\n                batchPutRequest.add(PutRequest.of(buildContextKey(i), null, valueState));\n            } else {\n                batchPutRequest.add(\n                        PutRequest.of(buildContextKey(i), String.valueOf(i * 2), valueState));\n            }\n        }\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation2 =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation2.process().get();\n\n        // 3.  check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            String value = (valueBytes == null) ? null : table.deserializeValue(valueBytes);\n            assertThat(value).isEqualTo(request.value);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 9074
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 2320
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStInnerTable",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the ForStInnerTable, making it more appropriate for it to reside within the ForStInnerTable class."
                        }
                    ],
                    "llm_response_time": 2073
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 1861
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "getColumnFamilyHandle"
                ],
                "llm_response_time": 664
            },
            "targetClassMap": {
                "getColumnFamilyHandle": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1945,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "88f6d069784355a516ba3b94ef780597dca1adf4",
        "url": "https://github.com/apache/flink/commit/88f6d069784355a516ba3b94ef780597dca1adf4",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public buildSerializedKey() : byte[] extracted from public testWriteBatchWithNullValue() : void in class org.apache.flink.state.forst.ForStWriteBatchOperationTest & moved to class org.apache.flink.state.forst.ForStDBPutRequest",
            "leftSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 63,
                    "endLine": 99,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public testWriteBatchWithNullValue() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 94,
                    "endLine": 94,
                    "startColumn": 13,
                    "endColumn": 63,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 58,
                    "endLine": 60,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public buildSerializedKey() : byte[]"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/main/java/org/apache/flink/state/forst/ForStDBPutRequest.java",
                    "startLine": 59,
                    "endLine": 59,
                    "startColumn": 9,
                    "endColumn": 40,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 63,
                    "endLine": 112,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public testWriteBatchWithNullValue() : void"
                },
                {
                    "filePath": "flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                    "startLine": 104,
                    "endLine": 104,
                    "startColumn": 31,
                    "endColumn": 59,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "request.buildSerializedKey()"
                }
            ],
            "isStatic": false
        },
        "ref_id": 46,
        "extraction_results": {
            "success": true,
            "newCommitHash": "eedeb1bf0c68465b453e5b976e7fff7a83bfd9a9",
            "newBranchName": "extract-buildSerializedKey-testWriteBatchWithNullValue-ffa3869"
        },
        "telemetry": {
            "id": "5ca6fd7f-7c7e-4561-8579-d13161378a02",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 76,
                "lineStart": 33,
                "lineEnd": 108,
                "bodyLineStart": 33,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-state-backends/flink-statebackend-forst/src/test/java/org/apache/flink/state/forst/ForStWriteBatchOperationTest.java",
                "sourceCode": "/** Unit test for {@link ForStWriteBatchOperation}. */\npublic class ForStWriteBatchOperationTest extends ForStDBOperationTestBase {\n\n    @Test\n    public void testValueStateWriteBatch() throws Exception {\n        ForStValueState<Integer, String> valueState1 = buildForStValueState(\"test-write-batch-1\");\n        ForStValueState<Integer, String> valueState2 = buildForStValueState(\"test-write-batch-2\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(\n                    PutRequest.of(\n                            buildContextKey(i),\n                            String.valueOf(i),\n                            ((i % 2 == 0) ? valueState1 : valueState2)));\n        }\n\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            assertThat(table.deserializeValue(valueBytes)).isEqualTo(request.value);\n        }\n    }\n\n    private byte[] getColumnFamilyHandle(\n            ForStInnerTable<ContextKey<Integer>, String> table,\n            byte[] keyBytes) throws RocksDBException {\n        byte[] valueBytes = db.get(table.getColumnFamilyHandle(), keyBytes);\n        return valueBytes;\n    }\n\n    @Test\n    public void testWriteBatchWithNullValue() throws Exception {\n        ForStValueState<Integer, String> valueState = buildForStValueState(\"test-write-batch\");\n        List<PutRequest<ContextKey<Integer>, String>> batchPutRequest = new ArrayList<>();\n        // 1. write some data without null value\n        int keyNum = 100;\n        for (int i = 0; i < keyNum; i++) {\n            batchPutRequest.add(PutRequest.of(buildContextKey(i), String.valueOf(i), valueState));\n        }\n        ExecutorService executor = Executors.newFixedThreadPool(2);\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation.process().get();\n\n        // 2. update data with null value\n        batchPutRequest.clear();\n        for (int i = 0; i < keyNum; i++) {\n            if (i % 8 == 0) {\n                batchPutRequest.add(PutRequest.of(buildContextKey(i), null, valueState));\n            } else {\n                batchPutRequest.add(\n                        PutRequest.of(buildContextKey(i), String.valueOf(i * 2), valueState));\n            }\n        }\n        ForStWriteBatchOperation<ContextKey<Integer>, String> writeBatchOperation2 =\n                new ForStWriteBatchOperation<>(db, batchPutRequest, new WriteOptions(), executor);\n        writeBatchOperation2.process().get();\n\n        // 3.  check data correctness\n        for (PutRequest<ContextKey<Integer>, String> request : batchPutRequest) {\n            ForStInnerTable<ContextKey<Integer>, String> table = request.table;\n            byte[] keyBytes = table.serializeKey(request.key);\n            byte[] valueBytes = getColumnFamilyHandle(table, keyBytes);\n            String value = (valueBytes == null) ? null : table.deserializeValue(valueBytes);\n            assertThat(value).isEqualTo(request.value);\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 9074
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 2320
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStInnerTable",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the ForStInnerTable, making it more appropriate for it to reside within the ForStInnerTable class."
                        }
                    ],
                    "llm_response_time": 2073
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 1861
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getColumnFamilyHandle",
                            "method_signature": "private byte[] getColumnFamilyHandle(ForStInnerTable<ContextKey<Integer>, String> table, byte[] keyBytes) throws RocksDBException",
                            "target_class": "ForStWriteBatchOperation",
                            "rationale": "The method getColumnFamilyHandle is primarily concerned with retrieving data from the database, which aligns more closely with the responsibilities of the ForStWriteBatchOperation class. Moving it there would enhance cohesion."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "getColumnFamilyHandle"
                ],
                "llm_response_time": 664
            },
            "targetClassMap": {
                "getColumnFamilyHandle": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1945,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "bb0f4429598db703e69d951986291862cbd5416b",
        "url": "https://github.com/apache/flink/commit/bb0f4429598db703e69d951986291862cbd5416b",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public unchecked(functionWithException FunctionWithException<A,B,?>) : Function<A,B> extracted from public thenApply(fn Function<? super T,? extends U>) : StateFuture<U> in class org.apache.flink.core.state.StateFutureImpl & moved to class org.apache.flink.util.function.FunctionWithException",
            "leftSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 54,
                    "endLine": 77,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public thenApply(fn Function<? super T,? extends U>) : StateFuture<U>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 59,
                    "endLine": 59,
                    "startColumn": 17,
                    "endColumn": 57,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 57,
                    "endLine": 76,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 74,
                    "endLine": 76,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 45,
                    "endLine": 63,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public unchecked(functionWithException FunctionWithException<A,B,?>) : Function<A,B>"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 56,
                    "endLine": 56,
                    "startColumn": 17,
                    "endColumn": 55,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 55,
                    "endLine": 61,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 57,
                    "endLine": 61,
                    "startColumn": 15,
                    "endColumn": 14,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 59,
                    "endLine": 96,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public thenApply(fn FunctionWithException<? super T,? extends U,? extends Exception>) : StateFuture<U>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 73,
                    "endLine": 73,
                    "startColumn": 19,
                    "endColumn": 54,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "FunctionWithException.unchecked(fn)"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 54,
                    "endLine": 62,
                    "startColumn": 9,
                    "endColumn": 11,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 47,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "bb0f4429598db703e69d951986291862cbd5416b",
        "url": "https://github.com/apache/flink/commit/bb0f4429598db703e69d951986291862cbd5416b",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public unchecked(functionWithException FunctionWithException<A,B,?>) : Function<A,B> extracted from public thenCompose(action Function<? super T,? extends StateFuture<U>>) : StateFuture<U> in class org.apache.flink.core.state.StateFutureImpl & moved to class org.apache.flink.util.function.FunctionWithException",
            "leftSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 105,
                    "endLine": 128,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public thenCompose(action Function<? super T,? extends StateFuture<U>>) : StateFuture<U>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 108,
                    "endLine": 127,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 125,
                    "endLine": 127,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 45,
                    "endLine": 63,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public unchecked(functionWithException FunctionWithException<A,B,?>) : Function<A,B>"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 55,
                    "endLine": 61,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 57,
                    "endLine": 61,
                    "startColumn": 15,
                    "endColumn": 14,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 137,
                    "endLine": 175,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public thenCompose(action FunctionWithException<? super T,? extends StateFuture<U>,? extends Exception>) : StateFuture<U>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 153,
                    "endLine": 153,
                    "startColumn": 20,
                    "endColumn": 59,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "FunctionWithException.unchecked(action)"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 54,
                    "endLine": 62,
                    "startColumn": 9,
                    "endColumn": 11,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/FunctionWithException.java",
                    "startLine": 56,
                    "endLine": 56,
                    "startColumn": 17,
                    "endColumn": 55,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 48,
        "extraction_results": {
            "success": true,
            "newCommitHash": "25b6ac2477514bf6815231f13b77d786d73ae85a",
            "newBranchName": "extract-unchecked-thenCompose-1c34ca0"
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "bb0f4429598db703e69d951986291862cbd5416b",
        "url": "https://github.com/apache/flink/commit/bb0f4429598db703e69d951986291862cbd5416b",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public unchecked(throwingConsumer ThrowingConsumer<A,?>) : Consumer<A> extracted from public thenAccept(action Consumer<? super T>) : StateFuture<Void> in class org.apache.flink.core.state.StateFutureImpl & moved to class org.apache.flink.util.function.ThrowingConsumer",
            "leftSideLocations": [
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 79,
                    "endLine": 103,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public thenAccept(action Consumer<? super T>) : StateFuture<Void>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 82,
                    "endLine": 102,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 100,
                    "endLine": 102,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/ThrowingConsumer.java",
                    "startLine": 44,
                    "endLine": 59,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public unchecked(throwingConsumer ThrowingConsumer<A,?>) : Consumer<A>"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/ThrowingConsumer.java",
                    "startLine": 53,
                    "endLine": 57,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/ThrowingConsumer.java",
                    "startLine": 55,
                    "endLine": 57,
                    "startColumn": 15,
                    "endColumn": 14,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 98,
                    "endLine": 135,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public thenAccept(action ThrowingConsumer<? super T,? extends Exception>) : StateFuture<Void>"
                },
                {
                    "filePath": "flink-core/src/main/java/org/apache/flink/core/state/StateFutureImpl.java",
                    "startLine": 111,
                    "endLine": 111,
                    "startColumn": 13,
                    "endColumn": 47,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "ThrowingConsumer.unchecked(action)"
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/ThrowingConsumer.java",
                    "startLine": 52,
                    "endLine": 58,
                    "startColumn": 9,
                    "endColumn": 11,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-core-api/src/main/java/org/apache/flink/util/function/ThrowingConsumer.java",
                    "startLine": 54,
                    "endLine": 54,
                    "startColumn": 17,
                    "endColumn": 44,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 49,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "3d40bd7dd197b12b7b156bd758b4129148e885d1",
        "url": "https://github.com/apache/flink/commit/3d40bd7dd197b12b7b156bd758b4129148e885d1",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method private rewrite(rewriter TokenStreamRewriter) : Map<String,List<String>> extracted from public rewrite(context String) : RewriteGroupedCode in class org.apache.flink.table.codesplit.BlockStatementGrouper & moved to class org.apache.flink.table.codesplit.BlockStatementGrouper.BlockStatementGrouperVisitor",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 129,
                    "endLine": 164,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public rewrite(context String) : RewriteGroupedCode"
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 151,
                    "endLine": 152,
                    "startColumn": 9,
                    "endColumn": 74,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 160,
                    "endLine": 160,
                    "startColumn": 13,
                    "endColumn": 69,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 157,
                    "endLine": 157,
                    "startColumn": 34,
                    "endColumn": 60,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 155,
                    "endLine": 158,
                    "startColumn": 13,
                    "endColumn": 59,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 153,
                    "endLine": 161,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "ENHANCED_FOR_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 154,
                    "endLine": 161,
                    "startColumn": 36,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 283,
                    "endLine": 302,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "private rewrite(rewriter TokenStreamRewriter) : Map<String,List<String>>"
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 284,
                    "endLine": 285,
                    "startColumn": 13,
                    "endColumn": 78,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 298,
                    "endLine": 298,
                    "startColumn": 17,
                    "endColumn": 73,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 291,
                    "endLine": 291,
                    "startColumn": 44,
                    "endColumn": 64,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 289,
                    "endLine": 292,
                    "startColumn": 17,
                    "endColumn": 63,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 287,
                    "endLine": 299,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "ENHANCED_FOR_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 287,
                    "endLine": 299,
                    "startColumn": 84,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 135,
                    "endLine": 151,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public rewrite(context String) : RewriteGroupedCode"
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 148,
                    "endLine": 148,
                    "startColumn": 56,
                    "endColumn": 81,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "visitor.rewrite(rewriter)"
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 288,
                    "endLine": 288,
                    "startColumn": 17,
                    "endColumn": 74,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 293,
                    "endLine": 296,
                    "startColumn": 17,
                    "endColumn": 72,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                    "startLine": 301,
                    "endLine": 301,
                    "startColumn": 13,
                    "endColumn": 33,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 50,
        "extraction_results": {
            "success": true,
            "newCommitHash": "35a3a0727c94ebdeeb407153c9e6d3fdc94cb64f",
            "newBranchName": "extract-rewrite-rewrite-54f037f"
        },
        "telemetry": {
            "id": "3cafdd8d-eaed-4950-8a71-78b569947a59",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 446,
                "lineStart": 40,
                "lineEnd": 485,
                "bodyLineStart": 40,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-table/flink-table-code-splitter/src/main/java/org/apache/flink/table/codesplit/BlockStatementGrouper.java",
                "sourceCode": "/**\n * Groups end extract single line statements such as operations on fields/local variables, IF and\n * WHILE statements and extract new method for each group making them smaller.\n *\n * <p>BlockStatementGrouper does not recognize if statement operates on local of class member\n * variable. Because of that, code must be preprocessed by {@link DeclarationRewriter} which\n * converts all local variables extracted as to member variables.\n *\n * <p><i>Before</i>\n *\n * <pre><code>\n * {\n *     a[0] += b[1];\n *     b[1] += a[1];\n *     while (counter > 0) {\n *         myFun_whileBody0_0(a, b);\n *         if (a[0] > 0) {\n *             myFun_whileBody0_0_ifBody0(a, b);\n *         } else {\n *             myFun_whileBody0_0_ifBody1(a, b);\n *         }\n *         counter--;\n *     }\n *\n *     a[2] += b[2];\n *     b[3] += a[3];\n * }\n *\n * </code></pre>\n *\n * <p><i>After</i>\n *\n * <pre><code>\n * {\n *     myFun_rewriteGroup4(a, b);\n *     myFun_rewriteGroup5(a, b);\n * }\n * </code></pre>\n *\n * <p>Where bodies of extracted \"methods\" are:\n *\n * <pre><code>\n *     myFun_rewriteGroup4 ->\n *         a[0] += b[1];\n *         b[1] += a[1];\n *         while (counter > 0) {\n *             myFun_rewriteGroup0_1_rewriteGroup3(a, b);\n *             counter--;\n *         }\n * </code></pre>\n *\n * <pre><code>\n *     myFun_rewriteGroup5 ->\n *         a[2] += b[2];\n *         b[3] += a[3];\n * </code></pre>\n *\n * <pre><code>\n *     myFun_rewriteGroup0_1_rewriteGroup3 ->\n *         myFun_whileBody0_0(a, b);\n *         if (a[0] > 0) {\n *             myFun_whileBody0_0_ifBody0(a, b);\n *         } else {\n *             myFun_whileBody0_0_ifBody1(a, b);\n *         }\n * </code></pre>\n */\n@Internal\npublic class BlockStatementGrouper {\n\n    private final String code;\n\n    private final long maxMethodLength;\n\n    private final String parameters;\n\n    /**\n     * Initialize new BlockStatementGrouper.\n     *\n     * @param code code block that should be rewritten for statement grouping.\n     * @param maxMethodLength maximal length of the extracted code block.\n     * @param parameters parameters definition that should be used for extracted methods.\n     */\n    public BlockStatementGrouper(String code, long maxMethodLength, String parameters) {\n        this.code = code;\n        this.maxMethodLength = maxMethodLength;\n        this.parameters = parameters;\n    }\n\n    /**\n     * Rewrite code block used for initialization of this object. The code block is grouped into new\n     * methods.\n     *\n     * @param context prefix used for extracted group names.\n     * @return {@link RewriteGroupedCode} representing rewritten code block and containing extracted\n     *     groups with their names and content.\n     */\n    public RewriteGroupedCode rewrite(String context) {\n\n        BlockStatementGrouperVisitor visitor =\n                new BlockStatementGrouperVisitor(maxMethodLength, parameters);\n        CommonTokenStream tokenStream =\n                new CommonTokenStream(new JavaLexer(CharStreams.fromString(code)));\n        JavaParser javaParser = new JavaParser(tokenStream);\n        javaParser.getInterpreter().setPredictionMode(PredictionMode.SLL);\n        TokenStreamRewriter rewriter = new TokenStreamRewriter(tokenStream);\n        visitor.visitStatement(javaParser.statement(), context, rewriter);\n\n        visitor.rewrite();\n        Map<String, Pair<TokenStreamRewriter, List<LocalGroupElement>>> groups = visitor.groups;\n\n        Map<String, List<String>> groupStrings =\n                CollectionUtil.newHashMapWithExpectedSize(groups.size());\n        rewrite(groups, groupStrings);\n\n        return new RewriteGroupedCode(rewriter.getText(), groupStrings);\n    }\n\n    private void rewrite(\n            Map<String, Pair<TokenStreamRewriter, List<LocalGroupElement>>> groups,\n            Map<String, List<String>> groupStrings) {\n        for (Entry<String, Pair<TokenStreamRewriter, List<LocalGroupElement>>> group :\n                groups.entrySet()) {\n            List<String> collectedStringGroups =\n                    group.getValue().getValue().stream()\n                            .map(LocalGroupElement::getBody)\n                            .collect(Collectors.toList());\n\n            groupStrings.put(group.getKey(), collectedStringGroups);\n        }\n    }\n\n    private static class BlockStatementGrouperVisitor {\n\n        private final Map<String, Pair<TokenStreamRewriter, List<LocalGroupElement>>> groups =\n                new HashMap<>();\n\n        private final long maxMethodLength;\n\n        private final String parameters;\n\n        private int counter = 0;\n\n        private BlockStatementGrouperVisitor(long maxMethodLength, String parameters) {\n            this.maxMethodLength = maxMethodLength;\n            this.parameters = parameters;\n        }\n\n        public void visitStatement(\n                StatementContext ctx, String context, TokenStreamRewriter rewriter) {\n\n            if (ctx.getChildCount() == 0) {\n                return;\n            }\n\n            // For these statements here we want to process all \"branches\" separately, for example\n            // TRUE and FALSE branch of IF/ELSE block.\n            // each statement can be rewritten and extracted.\n            if (ctx.WHILE() != null || ctx.IF() != null || ctx.ELSE() != null) {\n                for (StatementContext statement : ctx.statement()) {\n                    if (shouldExtract(statement)) {\n                        String localContext = String.format(\"%s_%d\", context, counter++);\n                        groupBlock(statement, localContext, rewriter);\n                    }\n                }\n            } else {\n                // The block did not start from IF/ELSE/WHILE statement\n                if (shouldExtract(ctx)) {\n                    groupBlock(ctx, context, rewriter);\n                }\n            }\n        }\n\n        // Group continuous block of statements together. If Statement is an IF/ELSE/WHILE,\n        // its body can be further grouped by recursive call to visitStatement method.\n        private void groupBlock(\n                StatementContext ctx, String context, TokenStreamRewriter rewriter) {\n            int localGroupCodeLength = 0;\n            List<LocalGroupElement> localGroup = new ArrayList<>();\n            for (BlockStatementContext bsc : ctx.block().blockStatement()) {\n\n                StatementContext statement = bsc.statement();\n                if (statement.IF() != null\n                        || statement.ELSE() != null\n                        || statement.WHILE() != null) {\n                    String localContext = context + \"_rewriteGroup\" + this.counter++;\n\n                    CommonTokenStream tokenStream =\n                            new CommonTokenStream(\n                                    new JavaLexer(\n                                            CharStreams.fromString(\n                                                    CodeSplitUtil.getContextString(statement))));\n                    TokenStreamRewriter localRewriter = new TokenStreamRewriter(tokenStream);\n                    JavaParser javaParser = new JavaParser(tokenStream);\n                    javaParser.getInterpreter().setPredictionMode(PredictionMode.SLL);\n                    visitStatement(javaParser.statement(), localContext, localRewriter);\n\n                    localGroup.add(new RewriteContextGroupElement(statement, localRewriter));\n\n                    // new method call length to the localGroupCodeLength. The \"3\" contains two\n                    // brackets for parameters and semicolon at the end of method call\n                    localGroupCodeLength += 3 + localContext.length() + parameters.length();\n                } else {\n\n                    if (localGroupCodeLength + 1 + bsc.getText().length() <= maxMethodLength) {\n                        localGroup.add(new ContextGroupElement(bsc));\n                        localGroupCodeLength += bsc.getText().length();\n                    } else {\n                        if (addLocalGroup(localGroup, context, rewriter)) {\n                            localGroup = new ArrayList<>();\n                            localGroupCodeLength = 0;\n                        }\n                        localGroupCodeLength += bsc.getText().length();\n                        localGroup.add(new ContextGroupElement(bsc));\n                    }\n                }\n            }\n\n            // Groups that have only one statement that is \"single line statement\" such as\n            // \"a[2] += b[2];\" will not be extracted.\n            addLocalGroup(localGroup, context, rewriter);\n        }\n\n        private boolean addLocalGroup(\n                List<LocalGroupElement> localGroup, String context, TokenStreamRewriter rewriter) {\n            if (localGroup.size() > 1\n                    || (localGroup.size() == 1\n                            && canGroupAsSingleStatement(localGroup.get(0).getContext()))) {\n                String localContext = context + \"_rewriteGroup\" + this.counter++;\n                groups.put(localContext, Pair.of(rewriter, localGroup));\n                return true;\n            }\n\n            return false;\n        }\n\n        private boolean canGroupAsSingleStatement(ParserRuleContext context) {\n\n            StatementContext statement;\n\n            if (context instanceof StatementContext) {\n                statement = (StatementContext) context;\n            } else if (context instanceof BlockStatementContext) {\n                statement = ((BlockStatementContext) context).statement();\n            } else {\n                return false;\n            }\n\n            return statement != null\n                    && (statement.IF() != null\n                            || statement.ELSE() != null\n                            || statement.WHILE() != null);\n        }\n\n        private boolean shouldExtract(StatementContext ctx) {\n            return ctx != null\n                    && ctx.block() != null\n                    && ctx.block().blockStatement() != null\n                    // if there is only one statement in the block it's useless to extract\n                    // it into a separate function\n                    && ctx.block().blockStatement().size() > 1\n                    // should not extract blocks with return statements\n                    && getNumOfReturnOrJumpStatements(ctx.block()) == 0;\n        }\n\n        private int getNumOfReturnOrJumpStatements(ParserRuleContext ctx) {\n            ReturnAndJumpCounter counter = new ReturnAndJumpCounter();\n            counter.visit(ctx);\n            return counter.getCounter();\n        }\n\n        private void rewrite() {\n            for (Entry<String, Pair<TokenStreamRewriter, List<LocalGroupElement>>> group :\n                    groups.entrySet()) {\n                Pair<TokenStreamRewriter, List<LocalGroupElement>> pair = group.getValue();\n                TokenStreamRewriter rewriter = pair.getKey();\n                List<LocalGroupElement> value = pair.getValue();\n                rewriter.replace(\n                        value.get(0).getStart(),\n                        value.get(value.size() - 1).getStop(),\n                        group.getKey() + \"(\" + this.parameters + \");\");\n            }\n        }\n    }\n\n    /**\n     * Represents an extracted statement, it boundaries (start and stop token) and its String\n     * representation. For example single line statement like: int a = 3; or block statement like\n     * IF/ELSE/WHILE bodies.\n     */\n    private interface LocalGroupElement {\n\n        /** @return start {@link Token} for this group element. */\n        Token getStart();\n\n        /** @return stop {@link Token} for this group element. */\n        Token getStop();\n\n        /** @return String representation of this group element. */\n        String getBody();\n\n        ParserRuleContext getContext();\n    }\n\n    /**\n     * Extracted element that is represented solely by {@link ParserRuleContext}. It's used for\n     * extracted statements that represent single line statement such as variable operation that\n     * will not be further rewritten.\n     */\n    private static class ContextGroupElement implements LocalGroupElement {\n\n        private final ParserRuleContext parserRuleContext;\n\n        private ContextGroupElement(ParserRuleContext parserRuleContext) {\n            this.parserRuleContext = parserRuleContext;\n        }\n\n        @Override\n        public Token getStart() {\n            return this.parserRuleContext.start;\n        }\n\n        @Override\n        public Token getStop() {\n            return this.parserRuleContext.stop;\n        }\n\n        @Override\n        public String getBody() {\n            return CodeSplitUtil.getContextString(this.parserRuleContext);\n        }\n\n        @Override\n        public ParserRuleContext getContext() {\n            return this.parserRuleContext;\n        }\n    }\n\n    /**\n     * Extracted element that is represented by {@link ParserRuleContext} and {@link\n     * TokenStreamRewriter} It's used for extracted block statements that represent TRUE/FALSE\n     * branches of IF/ELSE statements or WHILE's statement body. The string representation is\n     * extracted from {@link TokenStreamRewriter} which could be further rewritten.\n     *\n     * <p>This element can be used for IF/ELSE/WHILE statements that will be rewritten in further\n     * processing. Then this statement in the original code cen be rewritten using Start and Stop\n     * tokens, whereas the getBody() method backed by TokenStreamRewriter will return the rewritten\n     * value of the original statement.\n     *\n     * <p>The example would parserRuleContext and rewriter representing below statement:\n     *\n     * <pre><code>\n     *   while (counter > 0) {\n     *     myFun_whileBody0_0(a, b);\n     *     if (a[0] > 0) {\n     *       myFun_whileBody0_0_ifBody0(a, b);\n     *     } else {\n     *       myFun_whileBody0_0_ifBody1(a, b);\n     *     }\n     *\n     *     a[2] += b[2];\n     *     b[3] += a[3];\n     *     if (a[0] > 0) {\n     *       System.out.println(\"Hello\");\n     *     } else {\n     *       System.out.println(\"World\");\n     *     }\n     *\n     *         counter--;\n     *     }\n     * </code></pre>\n     *\n     * <p>This statement, being a part of a different statement will be further rewritten, new\n     * methods will be extracted from its body. At the end in order to rewrite the original\n     * statement we need to know what is the current form of this expression. For that we can call\n     * getBody() method, which in this case will return:\n     *\n     * <pre><code>\n     * while (counter > 0) {\n     *   myFun_rewriteGroup0_1_rewriteGroup3(a, b);\n     *\n     *   myFun_rewriteGroup0_1_rewriteGroup5(a, b);\n     *\n     *   counter--;\n     * }\n     * </code></pre>\n     */\n    private static class RewriteContextGroupElement implements LocalGroupElement {\n\n        private final ParserRuleContext parserRuleContext;\n\n        private final TokenStreamRewriter rewriter;\n\n        private RewriteContextGroupElement(\n                ParserRuleContext parserRuleContext, TokenStreamRewriter rewriter) {\n            this.parserRuleContext = parserRuleContext;\n            this.rewriter = rewriter;\n        }\n\n        @Override\n        public Token getStart() {\n            return this.parserRuleContext.start;\n        }\n\n        @Override\n        public Token getStop() {\n            return this.parserRuleContext.stop;\n        }\n\n        @Override\n        public String getBody() {\n            return this.rewriter.getText();\n        }\n\n        @Override\n        public ParserRuleContext getContext() {\n            return this.parserRuleContext;\n        }\n    }\n\n    /**\n     * This object represents a rewritten code block. It contains its new form along with all\n     * extracted groups and their names.\n     */\n    public static class RewriteGroupedCode {\n\n        /** Rewritten code block containing calls to extracted methods. */\n        private final String rewriteCode;\n\n        /** All extracted groups with their names. */\n        private final Map<String, List<String>> groups;\n\n        public RewriteGroupedCode(String rewriteCode, Map<String, List<String>> groups) {\n            this.rewriteCode = rewriteCode;\n            this.groups = groups;\n        }\n\n        public String getRewriteCode() {\n            return rewriteCode;\n        }\n\n        public Map<String, List<String>> getGroups() {\n            return this.groups;\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 0,
                "candidates": []
            },
            "processingTime": {
                "llmResponseTime": -1,
                "pluginProcessingTime": -1,
                "totalTime": 29162
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getNumOfReturnOrJumpStatements",
                            "method_signature": "private int getNumOfReturnOrJumpStatements(ParserRuleContext ctx)",
                            "target_class": "ReturnAndJumpCounter",
                            "rationale": "This method is responsible for counting return or jump statements in a given context, which aligns with the responsibilities of the ReturnAndJumpCounter class. Moving it there would enhance cohesion."
                        },
                        {
                            "method_name": "shouldExtract",
                            "method_signature": "private boolean shouldExtract(StatementContext ctx)",
                            "target_class": "StatementExtractor",
                            "rationale": "The logic for determining whether a statement should be extracted is a distinct responsibility that could be encapsulated in a separate class, such as StatementExtractor, improving the Single Responsibility Principle."
                        },
                        {
                            "method_name": "addLocalGroup",
                            "method_signature": "private boolean addLocalGroup(List<LocalGroupElement> localGroup, String context, TokenStreamRewriter rewriter)",
                            "target_class": "LocalGroupManager",
                            "rationale": "The method manages the addition of local groups, which could be better handled by a dedicated class like LocalGroupManager, promoting separation of concerns."
                        },
                        {
                            "method_name": "canGroupAsSingleStatement",
                            "method_signature": "private boolean canGroupAsSingleStatement(ParserRuleContext context)",
                            "target_class": "StatementGroupingUtil",
                            "rationale": "This method checks if a statement can be grouped as a single statement, which is a utility function that could be moved to a utility class like StatementGroupingUtil for better organization."
                        }
                    ],
                    "llm_response_time": 5442
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "getNumOfReturnOrJumpStatements",
                            "method_signature": "private int getNumOfReturnOrJumpStatements(ParserRuleContext ctx)",
                            "target_class": "ReturnAndJumpCounter",
                            "rationale": "This method is responsible for counting return or jump statements in a given context, which aligns with the responsibilities of the ReturnAndJumpCounter class. Moving it there would enhance cohesion."
                        },
                        {
                            "method_name": "shouldExtract",
                            "method_signature": "private boolean shouldExtract(StatementContext ctx)",
                            "target_class": "ExtractionCriteriaEvaluator",
                            "rationale": "The logic for determining whether a statement should be extracted could be better encapsulated in a dedicated class focused on evaluating extraction criteria, improving separation of concerns."
                        },
                        {
                            "method_name": "rewrite",
                            "method_signature": "private void rewrite()",
                            "target_class": "CodeRewriter",
                            "rationale": "The rewrite method is responsible for modifying the code structure, which is a core responsibility of a rewriter. Moving it to a CodeRewriter class would clarify the purpose and responsibilities of each class."
                        }
                    ],
                    "llm_response_time": 3265
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "getNumOfReturnOrJumpStatements",
                            "method_signature": "private int getNumOfReturnOrJumpStatements(ParserRuleContext ctx)",
                            "target_class": "ReturnAndJumpCounter",
                            "rationale": "This method is responsible for counting return or jump statements in a given context, which aligns with the responsibilities of the ReturnAndJumpCounter class. Moving it there would enhance cohesion."
                        },
                        {
                            "method_name": "shouldExtract",
                            "method_signature": "private boolean shouldExtract(StatementContext ctx)",
                            "target_class": "StatementExtractor",
                            "rationale": "The logic for determining whether a statement should be extracted belongs to a dedicated class that handles statement extraction logic, improving separation of concerns."
                        },
                        {
                            "method_name": "addLocalGroup",
                            "method_signature": "private boolean addLocalGroup(List<LocalGroupElement> localGroup, String context, TokenStreamRewriter rewriter)",
                            "target_class": "LocalGroupManager",
                            "rationale": "This method manages the addition of local groups, which is a specific responsibility that could be encapsulated in a LocalGroupManager class, enhancing clarity and maintainability."
                        },
                        {
                            "method_name": "canGroupAsSingleStatement",
                            "method_signature": "private boolean canGroupAsSingleStatement(ParserRuleContext context)",
                            "target_class": "StatementGroupingUtil",
                            "rationale": "This method checks if a statement can be grouped as a single statement, which is a utility function that would fit well in a utility class dedicated to statement grouping."
                        }
                    ],
                    "llm_response_time": 9259
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "getNumOfReturnOrJumpStatements",
                            "method_signature": "private int getNumOfReturnOrJumpStatements(ParserRuleContext ctx)",
                            "target_class": "ReturnAndJumpCounter",
                            "rationale": "This method is responsible for counting return or jump statements in a given context, which aligns with the responsibilities of the ReturnAndJumpCounter class. Moving it there would enhance cohesion."
                        },
                        {
                            "method_name": "shouldExtract",
                            "method_signature": "private boolean shouldExtract(StatementContext ctx)",
                            "target_class": "StatementExtractor",
                            "rationale": "The logic for determining whether a statement should be extracted is a distinct responsibility that could be encapsulated in a separate class, such as StatementExtractor, improving the Single Responsibility Principle."
                        },
                        {
                            "method_name": "addLocalGroup",
                            "method_signature": "private boolean addLocalGroup(List<LocalGroupElement> localGroup, String context, TokenStreamRewriter rewriter)",
                            "target_class": "LocalGroupManager",
                            "rationale": "The method manages the addition of local groups, which could be better handled by a dedicated class like LocalGroupManager, promoting separation of concerns."
                        },
                        {
                            "method_name": "canGroupAsSingleStatement",
                            "method_signature": "private boolean canGroupAsSingleStatement(ParserRuleContext context)",
                            "target_class": "StatementGroupingUtil",
                            "rationale": "This method checks if a statement can be grouped as a single statement, which is a utility function that could be moved to a utility class like StatementGroupingUtil for better organization."
                        },
                        {
                            "method_name": "rewrite",
                            "method_signature": "private void rewrite()",
                            "target_class": "CodeRewriter",
                            "rationale": "The rewrite method is responsible for modifying the code structure, which is a core responsibility of a rewriter. Moving it to a CodeRewriter class would clarify the purpose and responsibilities of each class."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "shouldExtract",
                    "addLocalGroup",
                    "getNumOfReturnOrJumpStatements",
                    "canGroupAsSingleStatement",
                    "rewrite"
                ],
                "llm_response_time": 901
            },
            "targetClassMap": {
                "shouldExtract": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1936,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "addLocalGroup": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2830,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "getNumOfReturnOrJumpStatements": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 2266,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "canGroupAsSingleStatement": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1536,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "rewrite": {
                    "target_classes": [],
                    "target_classes_sorted_by_llm": [],
                    "llm_response_time": 1443,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "b8173eb662ee5823de40de356869d0064de2c22a",
        "url": "https://github.com/apache/flink/commit/b8173eb662ee5823de40de356869d0064de2c22a",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public setDynamicParallelism(parallelism int) : void extracted from private changeJobVertexParallelism(jobVertex ExecutionJobVertex, parallelism int) : void in class org.apache.flink.runtime.scheduler.adaptivebatch.AdaptiveBatchScheduler & moved to class org.apache.flink.runtime.jobgraph.JobVertex",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/AdaptiveBatchScheduler.java",
                    "startLine": 627,
                    "endLine": 643,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private changeJobVertexParallelism(jobVertex ExecutionJobVertex, parallelism int) : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/AdaptiveBatchScheduler.java",
                    "startLine": 633,
                    "endLine": 633,
                    "startColumn": 9,
                    "endColumn": 62,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobVertex.java",
                    "startLine": 281,
                    "endLine": 284,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public setDynamicParallelism(parallelism int) : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobVertex.java",
                    "startLine": 282,
                    "endLine": 282,
                    "startColumn": 9,
                    "endColumn": 37,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/AdaptiveBatchScheduler.java",
                    "startLine": 627,
                    "endLine": 643,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "private changeJobVertexParallelism(jobVertex ExecutionJobVertex, parallelism int) : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/AdaptiveBatchScheduler.java",
                    "startLine": 633,
                    "endLine": 633,
                    "startColumn": 9,
                    "endColumn": 68,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "jobVertex.getJobVertex().setDynamicParallelism(parallelism)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobVertex.java",
                    "startLine": 283,
                    "endLine": 283,
                    "startColumn": 9,
                    "endColumn": 40,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 51,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "32b563dd29c5b08e4574773815c014c1c0cca12e",
        "url": "https://github.com/apache/flink/commit/32b563dd29c5b08e4574773815c014c1c0cca12e",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public addPartitionAndGetShuffleDescriptor(jobID JobID, resultPartitionID ResultPartitionID) : TierShuffleDescriptor extracted from package testAddAndReleasePartition() : void in class org.apache.flink.runtime.io.network.partition.hybrid.tiered.tier.remote.RemoteTierMasterAgentTest & moved to class org.apache.flink.runtime.io.network.partition.hybrid.tiered.tier.remote.RemoteTierMasterAgent",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgentTest.java",
                    "startLine": 40,
                    "endLine": 56,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "package testAddAndReleasePartition() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgentTest.java",
                    "startLine": 53,
                    "endLine": 53,
                    "startColumn": 9,
                    "endColumn": 51,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgent.java",
                    "startLine": 57,
                    "endLine": 65,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public addPartitionAndGetShuffleDescriptor(jobID JobID, resultPartitionID ResultPartitionID) : TierShuffleDescriptor"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgent.java",
                    "startLine": 64,
                    "endLine": 64,
                    "startColumn": 9,
                    "endColumn": 61,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgentTest.java",
                    "startLine": 42,
                    "endLine": 60,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "package testAddAndReleasePartition() : void"
                },
                {
                    "filePath": "flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgentTest.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 17,
                    "endColumn": 96,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "masterAgent.addPartitionAndGetShuffleDescriptor(new JobID(),resultPartitionID)"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgent.java",
                    "startLine": 61,
                    "endLine": 63,
                    "startColumn": 9,
                    "endColumn": 96,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgent.java",
                    "startLine": 60,
                    "endLine": 60,
                    "startColumn": 9,
                    "endColumn": 77,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": false
        },
        "ref_id": 52,
        "extraction_results": {
            "success": true,
            "newCommitHash": "526c65d3db5b19bfc2101cd68c9e08f502309b79",
            "newBranchName": "extract-addPartitionAndGetShuffleDescriptor-testAddAndReleasePartition-fe74f74"
        },
        "telemetry": {
            "id": "45c7e9f0-b710-45c2-a553-b4e63a365acd",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 29,
                "lineStart": 35,
                "lineEnd": 63,
                "bodyLineStart": 35,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-runtime/src/test/java/org/apache/flink/runtime/io/network/partition/hybrid/tiered/tier/remote/RemoteTierMasterAgentTest.java",
                "sourceCode": "/** Tests for {@link RemoteTierMasterAgent}. */\nclass RemoteTierMasterAgentTest {\n\n    @TempDir private File tempFolder;\n\n    @Test\n    void testAddAndReleasePartition() throws IOException {\n        TieredStoragePartitionId partitionId =\n                TieredStorageIdMappingUtils.convertId(new ResultPartitionID());\n        File partitionFile = new File(getPartitionPath(partitionId, tempFolder.getAbsolutePath()));\n        assertThat(partitionFile.createNewFile()).isTrue();\n        assertThat(partitionFile.exists()).isTrue();\n\n        TieredStorageResourceRegistry resourceRegistry = new TieredStorageResourceRegistry();\n        RemoteTierMasterAgent masterAgent =\n                new RemoteTierMasterAgent(tempFolder.getAbsolutePath(), resourceRegistry);\n        masterAgent.addPartition(partitionId);\n        assertThat(partitionFile.exists()).isTrue();\n        addPartitionAndGetShuffleDescriptor(partitionId, masterAgent);\n\n        assertThat(partitionFile.exists()).isFalse();\n    }\n\n    private void addPartitionAndGetShuffleDescriptor(\n            TieredStoragePartitionId partitionId,\n            RemoteTierMasterAgent masterAgent) {\n        masterAgent.releasePartition(partitionId);\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 1,
                "candidates": [
                    {
                        "lineStart": 57,
                        "lineEnd": 61,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method addPartitionAndGetShuffleDescriptor to class RemoteTierMasterAgent",
                        "description": "Move method addPartitionAndGetShuffleDescriptor to org.apache.flink.runtime.io.network.partition.hybrid.tiered.tier.remote.RemoteTierMasterAgent\nRationale: The method directly interacts with the RemoteTierMasterAgent instance by calling its releasePartition method, indicating that it is more relevant to the functionality of the RemoteTierMasterAgent class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    }
                ]
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "addPartitionAndGetShuffleDescriptor",
                            "method_signature": "private void addPartitionAndGetShuffleDescriptor(TieredStoragePartitionId partitionId, RemoteTierMasterAgent masterAgent)",
                            "target_class": "RemoteTierMasterAgent",
                            "rationale": "The method addPartitionAndGetShuffleDescriptor is primarily operating on the RemoteTierMasterAgent instance and is essentially a helper method for its functionality. Moving it to the RemoteTierMasterAgent class would encapsulate related behavior and improve cohesion."
                        }
                    ],
                    "llm_response_time": 2140
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "addPartitionAndGetShuffleDescriptor",
                            "method_signature": "private void addPartitionAndGetShuffleDescriptor(TieredStoragePartitionId partitionId, RemoteTierMasterAgent masterAgent)",
                            "target_class": "RemoteTierMasterAgent",
                            "rationale": "The method addPartitionAndGetShuffleDescriptor is primarily operating on the RemoteTierMasterAgent instance, and it directly calls its method releasePartition. Moving this method to the RemoteTierMasterAgent class would encapsulate the functionality related to partition management within the class itself."
                        }
                    ],
                    "llm_response_time": 2414
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "addPartitionAndGetShuffleDescriptor",
                            "method_signature": "private void addPartitionAndGetShuffleDescriptor(TieredStoragePartitionId partitionId, RemoteTierMasterAgent masterAgent)",
                            "target_class": "RemoteTierMasterAgent",
                            "rationale": "The method addPartitionAndGetShuffleDescriptor is primarily operating on the RemoteTierMasterAgent instance and is essentially a utility function that could be part of the RemoteTierMasterAgent class itself."
                        }
                    ],
                    "llm_response_time": 2961
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "addPartitionAndGetShuffleDescriptor",
                            "method_signature": "private void addPartitionAndGetShuffleDescriptor(TieredStoragePartitionId partitionId, RemoteTierMasterAgent masterAgent)",
                            "target_class": "RemoteTierMasterAgent",
                            "rationale": "The method addPartitionAndGetShuffleDescriptor is primarily operating on the RemoteTierMasterAgent instance and is essentially a helper method for its functionality. Moving it to the RemoteTierMasterAgent class would encapsulate related behavior and improve cohesion."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "addPartitionAndGetShuffleDescriptor"
                ],
                "llm_response_time": 513
            },
            "targetClassMap": {
                "addPartitionAndGetShuffleDescriptor": {
                    "target_classes": [
                        {
                            "class_name": "TieredStoragePartitionId",
                            "similarity_score": 0.3481553119113957
                        },
                        {
                            "class_name": "RemoteTierMasterAgent",
                            "similarity_score": 0.4183300132670378
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "RemoteTierMasterAgent",
                        "TieredStoragePartitionId"
                    ],
                    "llm_response_time": 1977,
                    "similarity_computation_time": 3,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "d0f9bb40a614c3c52c7abc9e608391e4bca9a3ca",
        "url": "https://github.com/apache/flink/commit/d0f9bb40a614c3c52c7abc9e608391e4bca9a3ca",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getDistributionFromSqlDistribution(distribution SqlDistribution) : TableDistribution extracted from private mergeDistribution(sourceTableDistribution Optional<TableDistribution>, sqlCreateTable SqlCreateTable, mergingStrategies Map<SqlTableLike.FeatureOption,SqlTableLike.MergingStrategy>) : Optional<TableDistribution> in class org.apache.flink.table.planner.operations.SqlCreateTableConverter & moved to class org.apache.flink.table.planner.utils.OperationConverterUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 244,
                    "endLine": 280,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private mergeDistribution(sourceTableDistribution Optional<TableDistribution>, sqlCreateTable SqlCreateTable, mergingStrategies Map<SqlTableLike.FeatureOption,SqlTableLike.MergingStrategy>) : Optional<TableDistribution>"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 251,
                    "endLine": 256,
                    "startColumn": 13,
                    "endColumn": 89,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 257,
                    "endLine": 257,
                    "startColumn": 13,
                    "endColumn": 40,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 258,
                    "endLine": 258,
                    "startColumn": 13,
                    "endColumn": 89,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 260,
                    "endLine": 260,
                    "startColumn": 17,
                    "endColumn": 76,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 263,
                    "endLine": 263,
                    "startColumn": 13,
                    "endColumn": 66,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 265,
                    "endLine": 265,
                    "startColumn": 13,
                    "endColumn": 87,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 267,
                    "endLine": 270,
                    "startColumn": 17,
                    "endColumn": 63,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 269,
                    "endLine": 269,
                    "startColumn": 43,
                    "endColumn": 74,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 259,
                    "endLine": 261,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 266,
                    "endLine": 271,
                    "startColumn": 13,
                    "endColumn": 14,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 259,
                    "endLine": 261,
                    "startColumn": 53,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 266,
                    "endLine": 271,
                    "startColumn": 34,
                    "endColumn": 14,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 112,
                    "endLine": 135,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getDistributionFromSqlDistribution(distribution SqlDistribution) : TableDistribution"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 114,
                    "endLine": 118,
                    "startColumn": 9,
                    "endColumn": 85,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 119,
                    "endLine": 119,
                    "startColumn": 9,
                    "endColumn": 36,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 120,
                    "endLine": 120,
                    "startColumn": 9,
                    "endColumn": 65,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 122,
                    "endLine": 122,
                    "startColumn": 13,
                    "endColumn": 72,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 125,
                    "endLine": 125,
                    "startColumn": 9,
                    "endColumn": 62,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 127,
                    "endLine": 127,
                    "startColumn": 9,
                    "endColumn": 63,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 129,
                    "endLine": 132,
                    "startColumn": 13,
                    "endColumn": 59,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 131,
                    "endLine": 131,
                    "startColumn": 39,
                    "endColumn": 70,
                    "codeElementType": "LAMBDA_EXPRESSION_BODY",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 121,
                    "endLine": 123,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 128,
                    "endLine": 133,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 121,
                    "endLine": 123,
                    "startColumn": 49,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 128,
                    "endLine": 133,
                    "startColumn": 30,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 242,
                    "endLine": 259,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "private mergeDistribution(sourceTableDistribution Optional<TableDistribution>, sqlCreateTable SqlCreateTable, mergingStrategies Map<SqlTableLike.FeatureOption,SqlTableLike.MergingStrategy>) : Optional<TableDistribution>"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/operations/SqlCreateTableConverter.java",
                    "startLine": 250,
                    "endLine": 251,
                    "startColumn": 21,
                    "endColumn": 62,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "OperationConverterUtils.getDistributionFromSqlDistribution(sqlCreateTable.getDistribution())"
                },
                {
                    "filePath": "flink-table/flink-table-planner/src/main/java/org/apache/flink/table/planner/utils/OperationConverterUtils.java",
                    "startLine": 134,
                    "endLine": 134,
                    "startColumn": 9,
                    "endColumn": 71,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 53,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "7f1399561b3ff303ea48ec0b93eef79eaaf3e4c8",
        "url": "https://github.com/apache/flink/commit/7f1399561b3ff303ea48ec0b93eef79eaaf3e4c8",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public scheduleOperation(callback Runnable, delay Duration) : void extracted from private rescaleWhenCooldownPeriodIsOver() : void in class org.apache.flink.runtime.scheduler.adaptive.Executing & moved to class org.apache.flink.runtime.scheduler.adaptive.Executing",
            "leftSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/Executing.java",
                    "startLine": 207,
                    "endLine": 215,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "private rescaleWhenCooldownPeriodIsOver() : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/Executing.java",
                    "startLine": 213,
                    "endLine": 213,
                    "startColumn": 13,
                    "endColumn": 78,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/Executing.java",
                    "startLine": 131,
                    "endLine": 134,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public scheduleOperation(callback Runnable, delay Duration) : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/Executing.java",
                    "startLine": 133,
                    "endLine": 133,
                    "startColumn": 9,
                    "endColumn": 51,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/DefaultRescaleManager.java",
                    "startLine": 96,
                    "endLine": 104,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public onChange() : void"
                },
                {
                    "filePath": "flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/DefaultRescaleManager.java",
                    "startLine": 102,
                    "endLine": 102,
                    "startColumn": 13,
                    "endColumn": 85,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "rescaleContext.scheduleOperation(this::maybeRescale,scalingIntervalMin)"
                }
            ],
            "isStatic": false
        },
        "ref_id": 54,
        "extraction_results": {
            "success": true,
            "newCommitHash": "aa7d4fc3b28b00dc0c56eb2053710ad2f4aee99b",
            "newBranchName": "extract-scheduleOperation-rescaleWhenCooldownPeriodIsOver-7fc3aac"
        },
        "telemetry": {
            "id": "09af8ca3-047f-4663-abcf-cda95d732e5e",
            "hostFunctionTelemetryData": {
                "hostFunctionSize": 292,
                "lineStart": 51,
                "lineEnd": 342,
                "bodyLineStart": 51,
                "language": "java",
                "filePath": "/Users/abhiram/Documents/TBE/evaluation_projects/flink/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptive/Executing.java",
                "sourceCode": "/** State which represents a running job with an {@link ExecutionGraph} and assigned slots. */\nclass Executing extends StateWithExecutionGraph implements ResourceListener {\n\n    private final Context context;\n    private final Instant lastRescale;\n    // only one schedule at the time\n    private boolean rescaleScheduled = false;\n    @VisibleForTesting final Duration scalingIntervalMin;\n    @VisibleForTesting @Nullable final Duration scalingIntervalMax;\n\n    Executing(\n            ExecutionGraph executionGraph,\n            ExecutionGraphHandler executionGraphHandler,\n            OperatorCoordinatorHandler operatorCoordinatorHandler,\n            Logger logger,\n            Context context,\n            ClassLoader userCodeClassLoader,\n            List<ExceptionHistoryEntry> failureCollection,\n            Duration scalingIntervalMin,\n            @Nullable Duration scalingIntervalMax,\n            Instant lastRescale) {\n        super(\n                context,\n                executionGraph,\n                executionGraphHandler,\n                operatorCoordinatorHandler,\n                logger,\n                userCodeClassLoader,\n                failureCollection);\n        this.context = context;\n        Preconditions.checkState(\n                executionGraph.getState() == JobStatus.RUNNING, \"Assuming running execution graph\");\n        this.scalingIntervalMin = scalingIntervalMin;\n        this.scalingIntervalMax = scalingIntervalMax;\n        // Executing is recreated with each restart (when we rescale)\n        // we consider the first execution of the pipeline as a rescale event\n        this.lastRescale = lastRescale;\n\n        deploy();\n\n        // check if new resources have come available in the meantime\n        context.runIfState(this, this::rescaleWhenCooldownPeriodIsOver, Duration.ZERO);\n    }\n\n    @Override\n    public JobStatus getJobStatus() {\n        return JobStatus.RUNNING;\n    }\n\n    @Override\n    public void cancel() {\n        context.goToCanceling(\n                getExecutionGraph(),\n                getExecutionGraphHandler(),\n                getOperatorCoordinatorHandler(),\n                getFailures());\n    }\n\n    @Override\n    void onFailure(Throwable cause, CompletableFuture<Map<String, String>> failureLabels) {\n        FailureResultUtil.restartOrFail(\n                context.howToHandleFailure(cause, failureLabels), context, this);\n    }\n\n    @Override\n    void onGloballyTerminalState(JobStatus globallyTerminalState) {\n        context.goToFinished(ArchivedExecutionGraph.createFrom(getExecutionGraph()));\n    }\n\n    private void deploy() {\n        for (ExecutionJobVertex executionJobVertex :\n                getExecutionGraph().getVerticesTopologically()) {\n            for (ExecutionVertex executionVertex : executionJobVertex.getTaskVertices()) {\n                if (executionVertex.getExecutionState() == ExecutionState.CREATED\n                        || executionVertex.getExecutionState() == ExecutionState.SCHEDULED) {\n                    deploySafely(executionVertex);\n                }\n            }\n        }\n    }\n\n    private void deploySafely(ExecutionVertex executionVertex) {\n        try {\n            executionVertex.deploy();\n        } catch (JobException e) {\n            handleDeploymentFailure(executionVertex, e);\n        }\n    }\n\n    private void handleDeploymentFailure(ExecutionVertex executionVertex, JobException e) {\n        executionVertex.markFailed(e);\n    }\n\n    @Override\n    public void onNewResourcesAvailable() {\n        rescaleWhenCooldownPeriodIsOver();\n    }\n\n    @Override\n    public void onNewResourceRequirements() {\n        rescaleWhenCooldownPeriodIsOver();\n    }\n\n    /** Force rescaling as long as the target parallelism is different from the current one. */\n    private void forceRescale() {\n        if (context.shouldRescale(getExecutionGraph(), true)) {\n            getLogger()\n                    .info(\n                            \"Added resources are still there after {} time({}), force a rescale.\",\n                            JobManagerOptions.SCHEDULER_SCALING_INTERVAL_MAX.key(),\n                            scalingIntervalMax);\n            context.goToRestarting(\n                    getExecutionGraph(),\n                    getExecutionGraphHandler(),\n                    getOperatorCoordinatorHandler(),\n                    Duration.ofMillis(0L),\n                    getFailures());\n        }\n    }\n\n    /**\n     * Rescale the job if {@link Context#shouldRescale} is true. Otherwise, force a rescale using\n     * {@link Executing#forceRescale()} after {@link\n     * JobManagerOptions#SCHEDULER_SCALING_INTERVAL_MAX}.\n     */\n    private void maybeRescale() {\n        rescaleScheduled = false;\n        if (context.shouldRescale(getExecutionGraph(), false)) {\n            getLogger().info(\"Can change the parallelism of the job. Restarting the job.\");\n            context.goToRestarting(\n                    getExecutionGraph(),\n                    getExecutionGraphHandler(),\n                    getOperatorCoordinatorHandler(),\n                    Duration.ofMillis(0L),\n                    getFailures());\n        } else if (scalingIntervalMax != null) {\n            getLogger()\n                    .info(\n                            \"The longer the pipeline runs, the more the (small) resource gain is worth the restarting time. \"\n                                    + \"Last resource added does not meet {}, force a rescale after {} time({}) if the resource is still there.\",\n                            JobManagerOptions.MIN_PARALLELISM_INCREASE,\n                            JobManagerOptions.SCHEDULER_SCALING_INTERVAL_MAX.key(),\n                            scalingIntervalMax);\n            if (timeSinceLastRescale().compareTo(scalingIntervalMax) > 0) {\n                forceRescale();\n            } else {\n                // schedule a force rescale in JobManagerOptions.SCHEDULER_SCALING_INTERVAL_MAX time\n                context.runIfState(this, this::forceRescale, scalingIntervalMax);\n            }\n        }\n    }\n\n    private Duration timeSinceLastRescale() {\n        return Duration.between(lastRescale, Instant.now());\n    }\n\n    private void rescaleWhenCooldownPeriodIsOver() {\n        if (timeSinceLastRescale().compareTo(scalingIntervalMin) > 0) {\n            maybeRescale();\n        } else if (!rescaleScheduled) {\n            rescaleScheduled = true;\n            // schedule maybeRescale resetting the cooldown period\n            scheduleOperation();\n        }\n    }\n\n    private void scheduleOperation() {\n        context.runIfState(this, this::maybeRescale, scalingIntervalMin);\n    }\n\n    CompletableFuture<String> stopWithSavepoint(\n            @Nullable final String targetDirectory,\n            boolean terminate,\n            SavepointFormatType formatType) {\n        final ExecutionGraph executionGraph = getExecutionGraph();\n\n        StopWithSavepointTerminationManager.checkSavepointActionPreconditions(\n                executionGraph.getCheckpointCoordinator(),\n                targetDirectory,\n                executionGraph.getJobID(),\n                getLogger());\n\n        getLogger().info(\"Triggering stop-with-savepoint for job {}.\", executionGraph.getJobID());\n\n        CheckpointScheduling schedulingProvider = new CheckpointSchedulingProvider(executionGraph);\n\n        schedulingProvider.stopCheckpointScheduler();\n\n        final CompletableFuture<String> savepointFuture =\n                Objects.requireNonNull(executionGraph.getCheckpointCoordinator())\n                        .triggerSynchronousSavepoint(terminate, targetDirectory, formatType)\n                        .thenApply(CompletedCheckpoint::getExternalPointer);\n        return context.goToStopWithSavepoint(\n                executionGraph,\n                getExecutionGraphHandler(),\n                getOperatorCoordinatorHandler(),\n                schedulingProvider,\n                savepointFuture,\n                getFailures());\n    }\n\n    /** Context of the {@link Executing} state. */\n    interface Context\n            extends StateWithExecutionGraph.Context,\n                    StateTransitions.ToCancelling,\n                    StateTransitions.ToFailing,\n                    StateTransitions.ToRestarting,\n                    StateTransitions.ToStopWithSavepoint {\n\n        /**\n         * Asks how to handle the failure.\n         *\n         * @param failure failure describing the failure cause\n         * @param failureLabels future of labels from error classification.\n         * @return {@link FailureResult} which describes how to handle the failure\n         */\n        FailureResult howToHandleFailure(\n                Throwable failure, CompletableFuture<Map<String, String>> failureLabels);\n\n        /**\n         * Asks if we should rescale the currently executing job.\n         *\n         * @param executionGraph executionGraph for making the scaling decision.\n         * @param forceRescale should we force rescaling\n         * @return true, if we should rescale\n         */\n        boolean shouldRescale(ExecutionGraph executionGraph, boolean forceRescale);\n\n        /**\n         * Runs the given action after a delay if the state at this time equals the expected state.\n         *\n         * @param expectedState expectedState describes the required state at the time of running\n         *     the action\n         * @param action action to run if the expected state equals the actual state\n         * @param delay delay after which to run the action\n         * @return a ScheduledFuture representing pending completion of the task\n         */\n        ScheduledFuture<?> runIfState(State expectedState, Runnable action, Duration delay);\n    }\n\n    static class Factory implements StateFactory<Executing> {\n\n        private final Context context;\n        private final Logger log;\n        private final ExecutionGraph executionGraph;\n        private final ExecutionGraphHandler executionGraphHandler;\n        private final OperatorCoordinatorHandler operatorCoordinatorHandler;\n        private final ClassLoader userCodeClassLoader;\n        private final List<ExceptionHistoryEntry> failureCollection;\n        private final Duration scalingIntervalMin;\n        private final Duration scalingIntervalMax;\n\n        Factory(\n                ExecutionGraph executionGraph,\n                ExecutionGraphHandler executionGraphHandler,\n                OperatorCoordinatorHandler operatorCoordinatorHandler,\n                Logger log,\n                Context context,\n                ClassLoader userCodeClassLoader,\n                List<ExceptionHistoryEntry> failureCollection,\n                Duration scalingIntervalMin,\n                Duration scalingIntervalMax) {\n            this.context = context;\n            this.log = log;\n            this.executionGraph = executionGraph;\n            this.executionGraphHandler = executionGraphHandler;\n            this.operatorCoordinatorHandler = operatorCoordinatorHandler;\n            this.userCodeClassLoader = userCodeClassLoader;\n            this.failureCollection = failureCollection;\n            this.scalingIntervalMin = scalingIntervalMin;\n            this.scalingIntervalMax = scalingIntervalMax;\n        }\n\n        public Class<Executing> getStateClass() {\n            return Executing.class;\n        }\n\n        public Executing getState() {\n            return new Executing(\n                    executionGraph,\n                    executionGraphHandler,\n                    operatorCoordinatorHandler,\n                    log,\n                    context,\n                    userCodeClassLoader,\n                    failureCollection,\n                    scalingIntervalMin,\n                    scalingIntervalMax,\n                    Instant.now());\n        }\n    }\n}"
            },
            "candidatesTelemetryData": {
                "numberOfSuggestions": 7,
                "candidates": [
                    {
                        "lineStart": 220,
                        "lineEnd": 249,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method stopWithSavepoint to class Context",
                        "description": "Move method stopWithSavepoint to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The method stopWithSavepoint() interacts with the execution context and manages the transition to a stop-with-savepoint state, making it more appropriate for the Context class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 139,
                        "lineEnd": 141,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method handleDeploymentFailure to class ExecutionVertex",
                        "description": "Move method handleDeploymentFailure to org.apache.flink.runtime.executiongraph.ExecutionVertex\nRationale: The method handleDeploymentFailure directly interacts with the ExecutionVertex instance by calling markFailed, indicating that it is closely related to the state and behavior of ExecutionVertex.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 153,
                        "lineEnd": 168,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method forceRescale to class Context",
                        "description": "Move method forceRescale to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The method forceRescale() interacts directly with the context to determine if rescaling is necessary and initiates a restart process, making it more appropriate for the Context class.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 170,
                        "lineEnd": 200,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method maybeRescale to class Context",
                        "description": "Move method maybeRescale to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The method 'maybeRescale()' heavily relies on the 'context' object to determine whether rescaling should occur, making it more appropriate for the 'Context' class, which likely encapsulates the logic related to job execution and scaling decisions.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 206,
                        "lineEnd": 214,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method rescaleWhenCooldownPeriodIsOver to class Context",
                        "description": "Move method rescaleWhenCooldownPeriodIsOver to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The method rescaleWhenCooldownPeriodIsOver() deals with timing and scheduling operations related to scaling, which is likely a responsibility of the Context class that manages the state and behavior of the system.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 202,
                        "lineEnd": 204,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method timeSinceLastRescale to class Context",
                        "description": "Move method timeSinceLastRescale to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The method timeSinceLastRescale() likely relates to the state or timing of a process within the Context class, making it more appropriate to handle timing-related calculations there.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    },
                    {
                        "lineStart": 216,
                        "lineEnd": 218,
                        "refactoringType": "MyMoveMethodRefactoring",
                        "refactoringInfo": "Move method scheduleOperation to class Context",
                        "description": "Move method scheduleOperation to org.apache.flink.runtime.scheduler.adaptive.Executing.Context\nRationale: The scheduleOperation() method interacts directly with the context to run operations based on its state, making it more appropriate for the Context class, which likely manages the state and operations.",
                        "couldCreateRefObject": true,
                        "applied": false,
                        "undone": false
                    }
                ]
            },
            "iterationData": [
                {
                    "iteration_num": 1,
                    "suggested_move_methods": [
                        {
                            "method_name": "stopWithSavepoint",
                            "method_signature": "CompletableFuture<String> stopWithSavepoint(@Nullable final String targetDirectory, boolean terminate, SavepointFormatType formatType)",
                            "target_class": "CheckpointCoordinator",
                            "rationale": "The stopWithSavepoint method is primarily concerned with checkpointing logic, which is more relevant to the CheckpointCoordinator class. Moving it there would enhance cohesion and maintainability."
                        },
                        {
                            "method_name": "handleDeploymentFailure",
                            "method_signature": "private void handleDeploymentFailure(ExecutionVertex executionVertex, JobException e)",
                            "target_class": "ExecutionVertex",
                            "rationale": "The handleDeploymentFailure method deals specifically with the failure of an execution vertex, which is a responsibility that should belong to the ExecutionVertex class."
                        },
                        {
                            "method_name": "forceRescale",
                            "method_signature": "private void forceRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The forceRescale method is related to resource management and scaling decisions, which would be more appropriately handled by a ResourceManager class."
                        },
                        {
                            "method_name": "maybeRescale",
                            "method_signature": "private void maybeRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The maybeRescale method is also related to resource scaling decisions and should be moved to a ResourceManager class to separate concerns."
                        },
                        {
                            "method_name": "timeSinceLastRescale",
                            "method_signature": "private Duration timeSinceLastRescale()",
                            "target_class": "RescaleTracker",
                            "rationale": "The timeSinceLastRescale method is focused on tracking rescale timing, which could be better encapsulated in a dedicated RescaleTracker class."
                        }
                    ],
                    "llm_response_time": 6461
                },
                {
                    "iteration_num": 2,
                    "suggested_move_methods": [
                        {
                            "method_name": "stopWithSavepoint",
                            "method_signature": "CompletableFuture<String> stopWithSavepoint(@Nullable final String targetDirectory, boolean terminate, SavepointFormatType formatType)",
                            "target_class": "CheckpointCoordinator",
                            "rationale": "The stopWithSavepoint method is primarily concerned with checkpointing logic, which is more aligned with the responsibilities of a CheckpointCoordinator class. Moving it there would adhere to the Single Responsibility Principle."
                        },
                        {
                            "method_name": "handleDeploymentFailure",
                            "method_signature": "private void handleDeploymentFailure(ExecutionVertex executionVertex, JobException e)",
                            "target_class": "ExecutionVertex",
                            "rationale": "The handleDeploymentFailure method deals specifically with the failure of an ExecutionVertex. It would be more appropriate for this logic to reside within the ExecutionVertex class, which can encapsulate its own failure handling."
                        },
                        {
                            "method_name": "forceRescale",
                            "method_signature": "private void forceRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The forceRescale method is related to resource management and scaling decisions, which should be handled by a dedicated ResourceManager class. This would help separate concerns and improve maintainability."
                        },
                        {
                            "method_name": "maybeRescale",
                            "method_signature": "private void maybeRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The maybeRescale method is also related to resource scaling logic. Moving it to a ResourceManager class would centralize scaling logic and improve the clarity of the Executing class."
                        },
                        {
                            "method_name": "rescaleWhenCooldownPeriodIsOver",
                            "method_signature": "private void rescaleWhenCooldownPeriodIsOver()",
                            "target_class": "ResourceManager",
                            "rationale": "Similar to the previous methods, rescaleWhenCooldownPeriodIsOver is focused on resource scaling. It should be moved to a ResourceManager class to better encapsulate resource-related operations."
                        }
                    ],
                    "llm_response_time": 5783
                },
                {
                    "iteration_num": 3,
                    "suggested_move_methods": [
                        {
                            "method_name": "stopWithSavepoint",
                            "method_signature": "CompletableFuture<String> stopWithSavepoint(@Nullable final String targetDirectory, boolean terminate, SavepointFormatType formatType)",
                            "target_class": "CheckpointCoordinator",
                            "rationale": "The stopWithSavepoint method is primarily concerned with checkpointing logic, which is more aligned with the responsibilities of a CheckpointCoordinator class. Moving it there would adhere to the Single Responsibility Principle."
                        },
                        {
                            "method_name": "handleDeploymentFailure",
                            "method_signature": "private void handleDeploymentFailure(ExecutionVertex executionVertex, JobException e)",
                            "target_class": "ExecutionVertex",
                            "rationale": "The handleDeploymentFailure method deals specifically with the failure of an execution vertex, which is a responsibility that should belong to the ExecutionVertex class."
                        },
                        {
                            "method_name": "forceRescale",
                            "method_signature": "private void forceRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The forceRescale method is related to resource management and scaling decisions, which would be more appropriately handled by a ResourceManager class."
                        },
                        {
                            "method_name": "maybeRescale",
                            "method_signature": "private void maybeRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The maybeRescale method is also related to resource scaling logic, and moving it to a ResourceManager class would help separate concerns related to resource management."
                        },
                        {
                            "method_name": "scheduleOperation",
                            "method_signature": "private void scheduleOperation()",
                            "target_class": "Scheduler",
                            "rationale": "The scheduleOperation method is responsible for scheduling tasks, which is a core responsibility of a Scheduler class. Moving it there would improve code organization."
                        }
                    ],
                    "llm_response_time": 7035
                },
                {
                    "iteration_num": -1,
                    "suggested_move_methods": [
                        {
                            "method_name": "stopWithSavepoint",
                            "method_signature": "CompletableFuture<String> stopWithSavepoint(@Nullable final String targetDirectory, boolean terminate, SavepointFormatType formatType)",
                            "target_class": "CheckpointCoordinator",
                            "rationale": "The stopWithSavepoint method is primarily concerned with checkpointing logic, which is more relevant to the CheckpointCoordinator class. Moving it there would enhance cohesion and maintainability."
                        },
                        {
                            "method_name": "handleDeploymentFailure",
                            "method_signature": "private void handleDeploymentFailure(ExecutionVertex executionVertex, JobException e)",
                            "target_class": "ExecutionVertex",
                            "rationale": "The handleDeploymentFailure method deals specifically with the failure of an execution vertex, which is a responsibility that should belong to the ExecutionVertex class."
                        },
                        {
                            "method_name": "forceRescale",
                            "method_signature": "private void forceRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The forceRescale method is related to resource management and scaling decisions, which would be more appropriately handled by a ResourceManager class."
                        },
                        {
                            "method_name": "maybeRescale",
                            "method_signature": "private void maybeRescale()",
                            "target_class": "ResourceManager",
                            "rationale": "The maybeRescale method is also related to resource scaling decisions and should be moved to a ResourceManager class to separate concerns."
                        },
                        {
                            "method_name": "timeSinceLastRescale",
                            "method_signature": "private Duration timeSinceLastRescale()",
                            "target_class": "RescaleTracker",
                            "rationale": "The timeSinceLastRescale method is focused on tracking rescale timing, which could be better encapsulated in a dedicated RescaleTracker class."
                        },
                        {
                            "method_name": "rescaleWhenCooldownPeriodIsOver",
                            "method_signature": "private void rescaleWhenCooldownPeriodIsOver()",
                            "target_class": "ResourceManager",
                            "rationale": "Similar to the previous methods, rescaleWhenCooldownPeriodIsOver is focused on resource scaling. It should be moved to a ResourceManager class to better encapsulate resource-related operations."
                        },
                        {
                            "method_name": "scheduleOperation",
                            "method_signature": "private void scheduleOperation()",
                            "target_class": "Scheduler",
                            "rationale": "The scheduleOperation method is responsible for scheduling tasks, which is a core responsibility of a Scheduler class. Moving it there would improve code organization."
                        }
                    ],
                    "llm_response_time": 0
                }
            ],
            "llmMethodPriority": {
                "priority_method_names": [
                    "stopWithSavepoint",
                    "handleDeploymentFailure",
                    "forceRescale",
                    "maybeRescale",
                    "rescaleWhenCooldownPeriodIsOver",
                    "timeSinceLastRescale",
                    "scheduleOperation"
                ],
                "llm_response_time": 1143
            },
            "targetClassMap": {
                "stopWithSavepoint": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.03844732240543962
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 1149,
                    "similarity_computation_time": 1,
                    "similarity_metric": "cosine"
                },
                "handleDeploymentFailure": {
                    "target_classes": [
                        {
                            "class_name": "ExecutionVertex",
                            "similarity_score": 0.3712641411931103
                        },
                        {
                            "class_name": "JobException",
                            "similarity_score": 0.35320862855067836
                        },
                        {
                            "class_name": "Context",
                            "similarity_score": 0.022197571940400895
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "ExecutionVertex",
                        "JobException",
                        "Context"
                    ],
                    "llm_response_time": 1832,
                    "similarity_computation_time": 4,
                    "similarity_metric": "cosine"
                },
                "forceRescale": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.24697177918005664
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 828,
                    "similarity_computation_time": 1,
                    "similarity_metric": "cosine"
                },
                "maybeRescale": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.5049253156878059
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 1868,
                    "similarity_computation_time": 1,
                    "similarity_metric": "cosine"
                },
                "rescaleWhenCooldownPeriodIsOver": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.15413218701427758
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 992,
                    "similarity_computation_time": 0,
                    "similarity_metric": "cosine"
                },
                "timeSinceLastRescale": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.03531612070110083
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 1210,
                    "similarity_computation_time": 1,
                    "similarity_metric": "cosine"
                },
                "scheduleOperation": {
                    "target_classes": [
                        {
                            "class_name": "Context",
                            "similarity_score": 0.02354408046740055
                        }
                    ],
                    "target_classes_sorted_by_llm": [
                        "Context"
                    ],
                    "llm_response_time": 923,
                    "similarity_computation_time": 1,
                    "similarity_metric": "cosine"
                }
            }
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "02d89caede088d334daf13fb26103aaec6d3ac19",
        "url": "https://github.com/apache/flink/commit/02d89caede088d334daf13fb26103aaec6d3ac19",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public create(inputActivityClock RelativeClock) : TimestampsAndWatermarksContext extracted from public createProgressiveEventTimeLogic(watermarkStrategy WatermarkStrategy<E>, metrics MetricGroup, timeService ProcessingTimeService, periodicWatermarkIntervalMillis long) : TimestampsAndWatermarks<E> in class org.apache.flink.streaming.api.operators.source.TimestampsAndWatermarks & moved to class org.apache.flink.streaming.api.operators.source.TimestampsAndWatermarks.TimestampsAndWatermarksContextProvider",
            "leftSideLocations": [
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 90,
                    "endLine": 106,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public createProgressiveEventTimeLogic(watermarkStrategy WatermarkStrategy<E>, metrics MetricGroup, timeService ProcessingTimeService, periodicWatermarkIntervalMillis long) : TimestampsAndWatermarks<E>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 96,
                    "endLine": 96,
                    "startColumn": 9,
                    "endColumn": 100,
                    "codeElementType": "VARIABLE_DECLARATION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 143,
                    "endLine": 145,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public create(inputActivityClock RelativeClock) : TimestampsAndWatermarksContext"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 144,
                    "endLine": 144,
                    "startColumn": 13,
                    "endColumn": 84,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 96,
                    "endLine": 120,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public createProgressiveEventTimeLogic(watermarkStrategy WatermarkStrategy<E>, metrics MetricGroup, timeService ProcessingTimeService, periodicWatermarkIntervalMillis long, mainInputActivityClock RelativeClock, clock Clock, taskIOMetricGroup TaskIOMetricGroup) : TimestampsAndWatermarks<E>"
                },
                {
                    "filePath": "flink-streaming-java/src/main/java/org/apache/flink/streaming/api/operators/source/TimestampsAndWatermarks.java",
                    "startLine": 109,
                    "endLine": 109,
                    "startColumn": 25,
                    "endColumn": 71,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "contextProvider.create(mainInputActivityClock)"
                }
            ],
            "isStatic": false
        },
        "ref_id": 55,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "url": "https://github.com/apache/flink/commit/e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getRegexpMatcher(str StringData, regex StringData) : Matcher extracted from public eval(str StringData, regex StringData) : Integer in class org.apache.flink.table.runtime.functions.scalar.RegexpCountFunction & moved to class org.apache.flink.table.runtime.functions.SqlFunctionUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 41,
                    "endLine": 59,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public eval(str StringData, regex StringData) : Integer"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 50,
                    "endLine": 50,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 48,
                    "endLine": 48,
                    "startColumn": 13,
                    "endColumn": 90,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 47,
                    "endLine": 51,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 49,
                    "endLine": 51,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 42,
                    "endLine": 44,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 42,
                    "endLine": 44,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 479,
                    "endLine": 492,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getRegexpMatcher(str StringData, regex StringData) : Matcher"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 490,
                    "endLine": 490,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 488,
                    "endLine": 488,
                    "startColumn": 13,
                    "endColumn": 87,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 487,
                    "endLine": 491,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 489,
                    "endLine": 491,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 40,
                    "endLine": 51,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public eval(str StringData, regex StringData) : Integer"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpCountFunction.java",
                    "startLine": 41,
                    "endLine": 41,
                    "startColumn": 27,
                    "endColumn": 55,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "getRegexpMatcher(str,regex)"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 485,
                    "endLine": 485,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 56,
        "extraction_results": {
            "success": true,
            "newCommitHash": "c035f77a48381e9ba9eb419509e4bacb67f3fb40",
            "newBranchName": "extract-getRegexpMatcher-eval-cbbb1cd"
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "url": "https://github.com/apache/flink/commit/e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getRegexpMatcher(str StringData, regex StringData) : Matcher extracted from public eval(str StringData, regex StringData, extractIndex Number) : ArrayData in class org.apache.flink.table.runtime.functions.scalar.RegexpExtractAllFunction & moved to class org.apache.flink.table.runtime.functions.SqlFunctionUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 50,
                    "endLine": 74,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public eval(str StringData, regex StringData, extractIndex Number) : ArrayData"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 60,
                    "endLine": 60,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 58,
                    "endLine": 58,
                    "startColumn": 13,
                    "endColumn": 90,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 57,
                    "endLine": 61,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 59,
                    "endLine": 61,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 479,
                    "endLine": 492,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getRegexpMatcher(str StringData, regex StringData) : Matcher"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 490,
                    "endLine": 490,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 488,
                    "endLine": 488,
                    "startColumn": 13,
                    "endColumn": 87,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 487,
                    "endLine": 491,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 489,
                    "endLine": 491,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 49,
                    "endLine": 70,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public eval(str StringData, regex StringData, extractIndex Number) : ArrayData"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpExtractAllFunction.java",
                    "startLine": 55,
                    "endLine": 55,
                    "startColumn": 27,
                    "endColumn": 55,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "getRegexpMatcher(str,regex)"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 485,
                    "endLine": 485,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 57,
        "extraction_results": {
            "success": false
        }
    },
    {
        "repository": "https://github.com/apache/flink.git",
        "sha1": "e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "url": "https://github.com/apache/flink/commit/e8c1d1b9d411e17130a57851c0bbaecb2e816048",
        "move_method_refactoring": {
            "type": "Extract And Move Method",
            "description": "Extract And Move Method public getRegexpMatcher(str StringData, regex StringData) : Matcher extracted from public eval(str StringData, regex StringData) : Integer in class org.apache.flink.table.runtime.functions.scalar.RegexpInstrFunction & moved to class org.apache.flink.table.runtime.functions.SqlFunctionUtils",
            "leftSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 41,
                    "endLine": 54,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration before extraction",
                    "codeElement": "public eval(str StringData, regex StringData) : Integer"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 50,
                    "endLine": 50,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 48,
                    "endLine": 48,
                    "startColumn": 13,
                    "endColumn": 90,
                    "codeElementType": "EXPRESSION_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 47,
                    "endLine": 51,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 49,
                    "endLine": 51,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 42,
                    "endLine": 44,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 42,
                    "endLine": 44,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code from source method declaration",
                    "codeElement": null
                }
            ],
            "rightSideLocations": [
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 479,
                    "endLine": 492,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "extracted method declaration",
                    "codeElement": "public getRegexpMatcher(str StringData, regex StringData) : Matcher"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 490,
                    "endLine": 490,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 488,
                    "endLine": 488,
                    "startColumn": 13,
                    "endColumn": 87,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 487,
                    "endLine": 491,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "TRY_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 489,
                    "endLine": 491,
                    "startColumn": 11,
                    "endColumn": 10,
                    "codeElementType": "CATCH_CLAUSE",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 9,
                    "endColumn": 10,
                    "codeElementType": "IF_STATEMENT",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 484,
                    "endLine": 486,
                    "startColumn": 43,
                    "endColumn": 10,
                    "codeElementType": "BLOCK",
                    "description": "extracted code to extracted method declaration",
                    "codeElement": null
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 40,
                    "endLine": 46,
                    "startColumn": 5,
                    "endColumn": 6,
                    "codeElementType": "METHOD_DECLARATION",
                    "description": "source method declaration after extraction",
                    "codeElement": "public eval(str StringData, regex StringData) : Integer"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/scalar/RegexpInstrFunction.java",
                    "startLine": 41,
                    "endLine": 41,
                    "startColumn": 27,
                    "endColumn": 55,
                    "codeElementType": "METHOD_INVOCATION",
                    "description": "extracted method invocation",
                    "codeElement": "getRegexpMatcher(str,regex)"
                },
                {
                    "filePath": "flink-table/flink-table-runtime/src/main/java/org/apache/flink/table/runtime/functions/SqlFunctionUtils.java",
                    "startLine": 485,
                    "endLine": 485,
                    "startColumn": 13,
                    "endColumn": 25,
                    "codeElementType": "RETURN_STATEMENT",
                    "description": "added statement in extracted method declaration",
                    "codeElement": null
                }
            ],
            "isStatic": true
        },
        "ref_id": 58,
        "extraction_results": {
            "success": true,
            "newCommitHash": "404454f2a40f80ae1753aeff1e5e3da8fc45420a",
            "newBranchName": "extract-getRegexpMatcher-eval-cbbb1cd"
        }
    }
]