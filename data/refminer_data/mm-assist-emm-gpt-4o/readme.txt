setup: context limit of 128k tokens
model: gpt-4o
temp: 0